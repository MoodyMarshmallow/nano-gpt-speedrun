{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3 Full Run: Baseline vs Elementwise (full length, lr=0.00468, 3 seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /workspace/ese-3060-project/.venv/bin/activate\n",
    "python -m ipykernel install --user --name ese3060-venv --display-name \"ese3060 venv\"\n",
    "echo \"Kernel installed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, subprocess, json, glob, re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%cd /workspace/ese-3060-project\n",
    "\n",
    "# Detect project root: prefer PROJ_ROOT env, else repo root (parent if running from notebooks/)\n",
    "cwd = Path.cwd().expanduser().resolve()\n",
    "default_root = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "PROJ_ROOT = Path(os.environ.get('PROJ_ROOT', default_root)).expanduser().resolve()\n",
    "SCRIPT_PATH = PROJ_ROOT / 'train_gpt.py'\n",
    "RESULTS = PROJ_ROOT / 'experiments' / 'results_stage3.csv'\n",
    "RESULTS_ALL = PROJ_ROOT / 'experiments' / 'results.csv'\n",
    "CURVES_CSV = PROJ_ROOT / 'experiments' / 'log_curves_stage3.csv'\n",
    "LOG_DIR = PROJ_ROOT / 'logs'\n",
    "SPLITTER = PROJ_ROOT / 'scripts' / 'split_results.py'\n",
    "\n",
    "# If stage-specific results not found, fall back to aggregated\n",
    "if not RESULTS.exists() and RESULTS_ALL.exists():\n",
    "    RESULTS = RESULTS_ALL\n",
    "\n",
    "print('Project root:', PROJ_ROOT)\n",
    "print('Results:', RESULTS)\n",
    "print('Log dir:', LOG_DIR)\n",
    "print('Curves CSV:', CURVES_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime knobs\n",
    "NPROC = None                # auto-detect GPU count if None\n",
    "LR = 0.00468\n",
    "SEEDS = [1337, 2337, 3337]  # 3 seeds per config\n",
    "NUM_ITER = 5100             # full length\n",
    "WARMUP_ITERS = 0\n",
    "WARMDOWN_ITERS = 1450\n",
    "VAL_EVERY = 125\n",
    "CONFIGS = {\n",
    "    \"baseline\":    {\"ATTNGATE\": \"none\",        \"GATEPOS\": \"sdpa\", \"GATEACT\": \"sigmoid\"},\n",
    "    \"elementwise\": {\"ATTNGATE\": \"elementwise\", \"GATEPOS\": \"sdpa\", \"GATEACT\": \"sigmoid\"},\n",
    "}\n",
    "TORCHRUN = \"torchrun\"\n",
    "LAUNCH = False             # set True to actually run\n",
    "\n",
    "# torchrun helpers\n",
    "if NPROC is None:\n",
    "    try:\n",
    "        gpu_count = int(subprocess.check_output(\"nvidia-smi --list-gpus | wc -l\", shell=True).decode().strip())\n",
    "    except Exception:\n",
    "        gpu_count = 0\n",
    "    NPROC = max(gpu_count, 1)\n",
    "\n",
    "assert SCRIPT_PATH.exists(), f\"Missing train script: {SCRIPT_PATH}\"\n",
    "\n",
    "def run_job(name, cfg, seed):\n",
    "    env = os.environ.copy()\n",
    "    env.update({\n",
    "        \"ATTNGATE\": cfg[\"ATTNGATE\"],\n",
    "        \"GATEPOS\": cfg[\"GATEPOS\"],\n",
    "        \"GATEACT\": cfg[\"GATEACT\"],\n",
    "        \"LR\": str(LR),\n",
    "        \"SEED\": str(seed),\n",
    "        \"NUM_ITERATIONS\": str(NUM_ITER),\n",
    "        \"WARMUP_ITERS\": str(WARMUP_ITERS),\n",
    "        \"WARMDOWN_ITERS\": str(WARMDOWN_ITERS),\n",
    "        \"VAL_EVERY\": str(VAL_EVERY),\n",
    "    })\n",
    "    cmd = [TORCHRUN, \"--standalone\", f\"--nproc_per_node={NPROC}\", str(SCRIPT_PATH)]\n",
    "    print(f\"\\n>>> Launching {name} seed={seed} lr={LR:.5f} nproc={NPROC}\")\n",
    "    if not LAUNCH:\n",
    "        return 0\n",
    "    proc = subprocess.run(cmd, env=env)\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(f\"Run failed: {name} seed {seed} rc={proc.returncode}\")\n",
    "\n",
    "for cfg_name, cfg_env in CONFIGS.items():\n",
    "    for seed in SEEDS:\n",
    "        run_job(cfg_name, cfg_env, seed)\n",
    "\n",
    "if LAUNCH:\n",
    "    # Refresh splits (stage1=1500, stage2=800; stage3 remains in main results unless you add a stage3 filter later)\n",
    "    subprocess.run([\"python\", str(SPLITTER), \"--stage1-iters\", \"1500\", \"--stage2-iters\", \"800\"], check=False)\n",
    "\n",
    "print(\"Done (LAUNCH=\" + str(LAUNCH) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "if RESULTS.exists():\n",
    "    df = pd.read_csv(RESULTS)\n",
    "elif RESULTS_ALL.exists():\n",
    "    df = pd.read_csv(RESULTS_ALL)\n",
    "    # filter best-effort for stage3 params\n",
    "    df = df[(df.get('num_iterations',0)==NUM_ITER) & (df.get('learning_rate',0).round(5)==LR) & (df.get('warmdown_iters',0)==WARMDOWN_ITERS)]\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "df.head() if not df.empty else df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate comparison with deltas (elementwise vs baseline)\n",
    "if not df.empty:\n",
    "    agg = df.groupby('attn_gate').agg(\n",
    "        runs=('run_id','count'),\n",
    "        mean_best_val=('best_val_loss','mean'),\n",
    "        std_best_val=('best_val_loss','std'),\n",
    "        mean_final_val=('final_val_loss','mean'),\n",
    "        mean_ms_step=('ms_per_step','mean'),\n",
    "        std_ms_step=('ms_per_step','std'),\n",
    "    ).reset_index()\n",
    "    display(agg)\n",
    "    if 'none' in agg['attn_gate'].values and 'elementwise' in agg['attn_gate'].values:\n",
    "        base = agg.set_index('attn_gate').loc['none']\n",
    "        elem = agg.set_index('attn_gate').loc['elementwise']\n",
    "        delta_loss = elem['mean_best_val'] - base['mean_best_val']\n",
    "        std_loss = base['std_best_val'] if pd.notna(base['std_best_val']) and base['std_best_val']!=0 else float('nan')\n",
    "        z_loss = delta_loss / std_loss if std_loss==std_loss and std_loss!=0 else float('nan')\n",
    "        delta_ms = elem['mean_ms_step'] - base['mean_ms_step']\n",
    "        std_ms = base['std_ms_step'] if pd.notna(base['std_ms_step']) and base['std_ms_step']!=0 else float('nan')\n",
    "        z_ms = delta_ms / std_ms if std_ms==std_ms and std_ms!=0 else float('nan')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        ax.bar([0], [delta_loss])\n",
    "        ax.set_xticks([0]); ax.set_xticklabels(['elementwise - baseline'])\n",
    "        ax.set_ylabel('Δ best val loss (lower better)')\n",
    "        ax.bar_label(ax.containers[0], labels=[f'z={z_loss:.2f}' if z_loss==z_loss else 'z=NA'])\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        ax.bar([0], [delta_ms])\n",
    "        ax.set_xticks([0]); ax.set_xticklabels(['elementwise - baseline'])\n",
    "        ax.set_ylabel('Δ ms/step (lower better)')\n",
    "        ax.bar_label(ax.containers[0], labels=[f'z={z_ms:.2f}' if z_ms==z_ms else 'z=NA'])\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout(); plt.show()\n",
    "    else:\n",
    "        print('Baseline or elementwise missing; cannot compute deltas.')\n",
    "else:\n",
    "    print('No stage3 results found; ensure runs are logged.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse logs and plot mean curves per attn_gate\n",
    "VAL_RE = re.compile(r\"step:(\\d+)/(\\d+).*val_loss:([0-9.]+).*train_time:(\\d+)ms\")\n",
    "rows = []\n",
    "for path in LOG_DIR.glob('*.txt') if LOG_DIR.exists() else []:\n",
    "    rid = path.stem\n",
    "    cfg = df[df['run_id']==rid]\n",
    "    if cfg.empty:\n",
    "        continue\n",
    "    cfg = cfg.iloc[0]\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            m = VAL_RE.search(line)\n",
    "            if m:\n",
    "                step = int(m.group(1))\n",
    "                vloss = float(m.group(3))\n",
    "                t_ms = int(m.group(4))\n",
    "                rows.append({\n",
    "                    'run_id': rid,\n",
    "                    'step': step,\n",
    "                    'val_loss': vloss,\n",
    "                    'train_time_ms': t_ms,\n",
    "                    'attn_gate': cfg['attn_gate'],\n",
    "                    'learning_rate': cfg['learning_rate'],\n",
    "                })\n",
    "curves = pd.DataFrame(rows)\n",
    "\n",
    "if not curves.empty:\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    for gate, sub in curves.groupby('attn_gate'):\n",
    "        sub = sub.sort_values('train_time_ms')\n",
    "        mean_curve = sub.groupby('train_time_ms')['val_loss'].mean().reset_index()\n",
    "        ax.plot(mean_curve['train_time_ms']/1000.0, mean_curve['val_loss'], label=gate)\n",
    "    ax.set_xlabel('train_time (s)')\n",
    "    ax.set_ylabel('val_loss')\n",
    "    ax.set_title('Mean val_loss vs train time (full run)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No curves to plot.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export curves\n",
    "if not curves.empty:\n",
    "    CURVES_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    curves.to_csv(CURVES_CSV, index=False)\n",
    "    print(f\"Saved curves to {CURVES_CSV}\")\n",
    "else:\n",
    "    print('curves is empty; nothing to export.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ese3060 venv",
   "language": "python",
   "name": "ese3060-venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
