{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2.5: Baseline vs Elementwise (1500 iters, wd=1450, lr=0.00468)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source /workspace/ese-3060-project/.venv/bin/activate\n",
    "python -m ipykernel install --user --name ese3060-venv --display-name \"ese3060 venv\"\n",
    "echo \"Kernel installed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, json, glob, re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%cd /workspace/ese-3060-project\n",
    "\n",
    "PROJECT_ROOT = os.environ.get('PROJ_ROOT', '/workspace/ese-3060-project')\n",
    "SCRIPT_PATH = os.path.join(PROJECT_ROOT, 'train_gpt.py')\n",
    "RESULTS_ALL = os.path.join(PROJECT_ROOT, 'experiments', 'results.csv')\n",
    "RESULTS = os.path.join(PROJECT_ROOT, 'experiments', 'results_stage2_5.csv')\n",
    "LOG_DIR = os.path.join(PROJECT_ROOT, 'logs')\n",
    "SPLITTER = os.path.join(PROJECT_ROOT, 'scripts', 'split_results.py')\n",
    "PROJECT_ROOT, SCRIPT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime knobs\n",
    "NPROC = None                # auto-detect if None\n",
    "LR = 0.00468\n",
    "SEEDS = [1337, 2337]        # two runs per config\n",
    "NUM_ITER = 1500\n",
    "WARMUP_ITERS = 0\n",
    "WARMDOWN_ITERS = 1450\n",
    "VAL_EVERY = 125\n",
    "CONFIGS = {\n",
    "    \"baseline\":    {\"ATTNGATE\": \"none\",        \"GATEPOS\": \"sdpa\", \"GATEACT\": \"sigmoid\"},\n",
    "    \"elementwise\": {\"ATTNGATE\": \"elementwise\", \"GATEPOS\": \"sdpa\", \"GATEACT\": \"sigmoid\"},\n",
    "}\n",
    "TORCHRUN = \"torchrun\"\n",
    "LAUNCH = False             # set True to actually run\n",
    "\n",
    "# torchrun helpers\n",
    "if NPROC is None:\n",
    "    try:\n",
    "        gpu_count = int(subprocess.check_output(\"nvidia-smi --list-gpus | wc -l\", shell=True).decode().strip())\n",
    "    except Exception:\n",
    "        gpu_count = 0\n",
    "    NPROC = max(gpu_count, 1)\n",
    "\n",
    "assert os.path.exists(SCRIPT_PATH), f\"Missing train script: {SCRIPT_PATH}\"\n",
    "\n",
    "def run_job(name, cfg, seed):\n",
    "    env = os.environ.copy()\n",
    "    env.update({\n",
    "        \"ATTNGATE\": cfg[\"ATTNGATE\"],\n",
    "        \"GATEPOS\": cfg[\"GATEPOS\"],\n",
    "        \"GATEACT\": cfg[\"GATEACT\"],\n",
    "        \"LR\": str(LR),\n",
    "        \"SEED\": str(seed),\n",
    "        \"NUM_ITERATIONS\": str(NUM_ITER),\n",
    "        \"WARMUP_ITERS\": str(WARMUP_ITERS),\n",
    "        \"WARMDOWN_ITERS\": str(WARMDOWN_ITERS),\n",
    "        \"VAL_EVERY\": str(VAL_EVERY),\n",
    "    })\n",
    "    cmd = [TORCHRUN, \"--standalone\", f\"--nproc_per_node={NPROC}\", SCRIPT_PATH]\n",
    "    print(f\"\\n>>> Launching {name} seed={seed} lr={LR:.5f} nproc={NPROC}\")\n",
    "    if not LAUNCH:\n",
    "        return 0\n",
    "    proc = subprocess.run(cmd, env=env)\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError(f\"Run failed: {name} seed {seed} rc={proc.returncode}\")\n",
    "\n",
    "for cfg_name, cfg_env in CONFIGS.items():\n",
    "    for seed in SEEDS:\n",
    "        run_job(cfg_name, cfg_env, seed)\n",
    "\n",
    "if LAUNCH:\n",
    "    # after runs, refresh splits\n",
    "    subprocess.run([\"python\", SPLITTER, \"--stage1-iters\", \"1500\", \"--stage2-iters\", \"800\"], check=False)\n",
    "\n",
    "print(\"Done (LAUNCH=\" + str(LAUNCH) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results (prefer stage2_5 split if present)\n",
    "if os.path.exists(RESULTS):\n",
    "    df = pd.read_csv(RESULTS)\n",
    "elif os.path.exists(RESULTS_ALL):\n",
    "    df = pd.read_csv(RESULTS_ALL)\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "df.head() if not df.empty else df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grouping\n",
    "stage = df.copy()\n",
    "if not stage.empty:\n",
    "    agg = stage.groupby([\"attn_gate\", \"learning_rate\"]).agg(\n",
    "        runs=(\"run_id\", \"count\"),\n",
    "        mean_best_val=(\"best_val_loss\", \"mean\"),\n",
    "        std_best_val=(\"best_val_loss\", \"std\"),\n",
    "        mean_ms_step=(\"ms_per_step\", \"mean\"),\n",
    "    ).reset_index()\n",
    "    display(agg)\n",
    "    if not agg.empty:\n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        for gate, sub in agg.groupby('attn_gate'):\n",
    "            ax.errorbar(sub['learning_rate'], sub['mean_best_val'], yerr=sub['std_best_val'], marker='o', capsize=4, label=gate)\n",
    "        ax.set_xlabel('learning_rate')\n",
    "        ax.set_ylabel('best_val_loss')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No stage 2.5 data yet; run jobs first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse logs and plot curves\n",
    "VAL_RE = re.compile(r\"step:(\\d+)/(\\d+).*val_loss:([0-9.]+).*train_time:(\\d+)ms\")\n",
    "rows = []\n",
    "for path in Path(LOG_DIR).glob('*.txt') if os.path.exists(LOG_DIR) else []:\n",
    "    run_id = path.stem\n",
    "    cfg = stage[stage['run_id']==run_id]\n",
    "    if cfg.empty:\n",
    "        continue\n",
    "    cfg = cfg.iloc[0]\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            m = VAL_RE.search(line)\n",
    "            if m:\n",
    "                step = int(m.group(1))\n",
    "                loss = float(m.group(3))\n",
    "                t_ms = int(m.group(4))\n",
    "                rows.append({'run_id': run_id, 'step': step, 'val_loss': loss, 'train_time_ms': t_ms, 'attn_gate': cfg['attn_gate'], 'learning_rate': cfg['learning_rate']})\n",
    "curves = pd.DataFrame(rows)\n",
    "if not curves.empty:\n",
    "    fig, axes = plt.subplots(1, len(curves['attn_gate'].unique()), figsize=(12,4), sharey=True)\n",
    "    if len(curves['attn_gate'].unique())==1:\n",
    "        axes=[axes]\n",
    "    for ax, (gate, sub) in zip(axes, curves.groupby('attn_gate')):\n",
    "        for lr, sublr in sub.groupby('learning_rate'):\n",
    "            sublr = sublr.sort_values('train_time_ms')\n",
    "            ax.plot(sublr['train_time_ms']/1000.0, sublr['val_loss'], label=f\"lr={lr:.5f}\")\n",
    "        ax.set_title(f\"attn_gate={gate}\")\n",
    "        ax.set_xlabel('train_time (s)')\n",
    "        ax.set_ylabel('val_loss')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No matching logs parsed; run jobs first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export curves\n",
    "if 'curves' in locals() and not curves.empty:\n",
    "    export_path = Path(PROJ_ROOT) / 'experiments' / 'log_curves_stage2_5.csv'\n",
    "    export_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    curves.to_csv(export_path, index=False)\n",
    "    print(f'Saved curves to {export_path}')\n",
    "else:\n",
    "    print('curves is empty; nothing to export.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ese3060 venv",
   "language": "python",
   "name": "ese3060-venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
