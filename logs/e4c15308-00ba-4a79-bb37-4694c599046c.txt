====================================================================================================
# NOTE: record from https://github.com/KellerJordan/modded-nanogpt/blob/master/records/track_1_short/2024-10-14_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt
# ====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
import json
import dataclasses
import subprocess
import csv
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \\sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=3e-4, momentum=0.95, nesterov=True, backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]
            for p in group['params']:
                g = p.grad
                if g is None:
                    continue
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.mul_(momentum).add_(g)
                if group['nesterov']:
                    g = g.add(buf, alpha=momentum)
                if g.size(0) == 3 * g.size(1): # split grouped QKV parameters
                    g = torch.cat([zeropower_backend(g1, steps=group['backend_steps']) for g1 in g.split(g.size(1))])
                    scale = g.size(1)**0.5
                else:
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    scale = max(g.size(0), g.size(1))**0.5 # scale to have update.square().mean() == 1
                p.data.add_(g, alpha=-lr * scale)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

def _apply_gate_act(logits: torch.Tensor, kind: str) -> torch.Tensor:
    if kind == "sigmoid":
        return torch.sigmoid(logits)
    if kind == "ns_sigmoid":
        return 0.5 + 0.5 * torch.sigmoid(logits)
    raise ValueError(f"unknown gate_act={kind}")

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.attn_gate = getattr(config, "attn_gate", "none")
        self.gate_pos = getattr(config, "gate_pos", "sdpa")
        self.gate_act = getattr(config, "gate_act", "sigmoid")
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)
        if self.attn_gate == "headwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_head, bias=False)
            self.gate_param = None
        elif self.attn_gate == "elementwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_embd, bias=False)
            self.gate_param = None
        elif self.attn_gate == "const":
            self.c_gate = None
            self.gate_param = nn.Parameter(torch.zeros(self.n_head, self.head_dim))
        else:
            self.c_gate = None
            self.gate_param = None

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        if self.attn_gate != "none" and self.gate_pos == "value":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            v = v * gate
        cos, sin = self.rotary(q)
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2) # (B, T, n_head, head_dim)
        if self.attn_gate != "none" and self.gate_pos == "sdpa":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            y = y * gate
        y = y.contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768
    attn_gate : str = "none"
    gate_pos : str = "sdpa"
    gate_act : str = "sigmoid"

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying

    def forward(self, idx, targets=None, return_logits=True):

        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8*64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 5100 # number of iterations to run
    learning_rate : float = 0.0036
    warmup_iters : int = 0
    warmdown_iters : int = 1450 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    seed : int = 1337
    attn_gate : str = "none" # none|headwise|elementwise|const
    gate_pos : str = "sdpa" # sdpa|value
    gate_act : str = "sigmoid" # sigmoid|ns_sigmoid
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

def apply_env_overrides():
    # environment-variable overrides allow quick sweeps without editing code
    args.learning_rate = float(os.environ.get("LR", args.learning_rate))
    args.seed = int(os.environ.get("SEED", args.seed))
    args.attn_gate = os.environ.get("ATTNGATE", args.attn_gate)
    args.gate_pos = os.environ.get("GATEPOS", args.gate_pos)
    args.gate_act = os.environ.get("GATEACT", args.gate_act)
    args.num_iterations = int(os.environ.get("NUM_ITER", args.num_iterations))
    args.val_loss_every = int(os.environ.get("VAL_EVERY", args.val_loss_every))

def get_git_commit():
    try:
        return subprocess.check_output(["git", "rev-parse", "HEAD"], text=True).strip()
    except Exception:
        return "unknown"

apply_env_overrides()
torch.manual_seed(args.seed)
torch.cuda.manual_seed_all(args.seed)
np.random.seed(args.seed)

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.
git_commit = get_git_commit() if master_process else "unknown"

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(
    vocab_size=num_vocab,
    n_layer=12,
    n_head=6,
    n_embd=768,
    attn_gate=args.attn_gate,
    gate_pos=args.gate_pos,
    gate_act=args.gate_act,
))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
optimizer1 = torch.optim.AdamW(raw_model.lm_head.parameters(), lr=args.learning_rate, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer2 = Muon(raw_model.transformer.h.parameters(), lr=0.1*args.learning_rate, momentum=0.95)
optimizers = [optimizer1, optimizer2]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        f.write(f"git_commit: {git_commit}\n")
        f.write(f"seed: {args.seed}\n")
        f.write("hyperparameters:\n")
        f.write(json.dumps(dataclasses.asdict(args), indent=2))
        f.write("\n")
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')

training_time_ms = 0
best_val_loss = float("inf")
final_val_loss = None
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        val_loss_item = val_loss.item()
        final_val_loss = val_loss_item
        best_val_loss = min(best_val_loss, val_loss_item)
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms\n')
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            _, loss = model(x, y, return_logits=False)
            train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process:
        approx_time = training_time_ms + 1000 * (time.time() - t0)
        print(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")
        with open(logfile, "a") as f:
            f.write(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms\n")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")
    timed_steps_final = max(args.num_iterations - 9, 1)
    ms_per_step = training_time_ms / timed_steps_final
    os.makedirs("experiments", exist_ok=True)
    results_path = os.path.join("experiments", "results.csv")
    fieldnames = [
        "run_id",
        "date",
        "git_commit",
        "seed",
        "attn_gate",
        "gate_pos",
        "gate_act",
        "learning_rate",
        "batch_size",
        "device_batch_size",
        "sequence_length",
        "num_iterations",
        "warmdown_iters",
        "final_val_loss",
        "best_val_loss",
        "train_time_ms",
        "ms_per_step",
        "gpu_name",
        "n_gpus",
        "runpod_instance",
        "notes",
    ]
    final_loss_value = final_val_loss if final_val_loss is not None else float("nan")
    best_loss_value = best_val_loss if best_val_loss < float("inf") else float("nan")
    row = {
        "run_id": run_id,
        "date": time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime()),
        "git_commit": git_commit,
        "seed": args.seed,
        "attn_gate": args.attn_gate,
        "gate_pos": args.gate_pos,
        "gate_act": args.gate_act,
        "learning_rate": args.learning_rate,
        "batch_size": args.batch_size,
        "device_batch_size": args.device_batch_size,
        "sequence_length": args.sequence_length,
        "num_iterations": args.num_iterations,
        "warmdown_iters": args.warmdown_iters,
        "final_val_loss": final_loss_value,
        "best_val_loss": best_loss_value,
        "train_time_ms": training_time_ms,
        "ms_per_step": ms_per_step,
        "gpu_name": torch.cuda.get_device_name(ddp_local_rank),
        "n_gpus": ddp_world_size,
        "runpod_instance": os.environ.get("RUNPOD_INSTANCE_TYPE", "unknown"),
        "notes": "",
    }
    write_header = not os.path.exists(results_path)
    with open(results_path, "a", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if write_header:
            writer.writeheader()
        writer.writerow(row)
====================================================================================================
git_commit: 21aae13b20675947154a15b640706eb3a47e5fcd
seed: 1337
hyperparameters:
{
  "input_bin": "data/fineweb10B/fineweb_train_*.bin",
  "input_val_bin": "data/fineweb10B/fineweb_val_*.bin",
  "batch_size": 512,
  "device_batch_size": 64,
  "sequence_length": 1024,
  "num_iterations": 1500,
  "learning_rate": 0.0036,
  "warmup_iters": 0,
  "warmdown_iters": 1450,
  "weight_decay": 0,
  "seed": 1337,
  "attn_gate": "elementwise",
  "gate_pos": "sdpa",
  "gate_act": "sigmoid",
  "val_loss_every": 125,
  "val_tokens": 10485760,
  "save_every": 0
}
Running pytorch 2.8.0+cu128 compiled for CUDA 12.8
nvidia-smi:
Sun Dec  7 10:22:31 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:00:07.0 Off |                    0 |
| N/A   46C    P0            116W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          On  |   00000000:00:08.0 Off |                    0 |
| N/A   48C    P0            119W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100 80GB PCIe          On  |   00000000:00:09.0 Off |                    0 |
| N/A   43C    P0            141W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100 80GB PCIe          On  |   00000000:00:0A.0 Off |                    0 |
| N/A   44C    P0            111W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100 80GB PCIe          On  |   00000000:00:0B.0 Off |                    0 |
| N/A   48C    P0            116W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100 80GB PCIe          On  |   00000000:00:0C.0 Off |                    0 |
| N/A   45C    P0            109W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100 80GB PCIe          On  |   00000000:00:0D.0 Off |                    0 |
| N/A   48C    P0            117W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100 80GB PCIe          On  |   00000000:00:0E.0 Off |                    0 |
| N/A   47C    P0            114W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1500 val_loss:16.0015 train_time:243ms step_avg:nanms
step:1/1500 train_loss:16.0007 train_time:71752ms step_avg:nanms
step:2/1500 train_loss:9.5243 train_time:72634ms step_avg:nanms
step:3/1500 train_loss:8.6020 train_time:73050ms step_avg:nanms
step:4/1500 train_loss:7.8832 train_time:73463ms step_avg:nanms
step:5/1500 train_loss:7.5251 train_time:73878ms step_avg:nanms
step:6/1500 train_loss:7.4784 train_time:74293ms step_avg:nanms
step:7/1500 train_loss:6.9910 train_time:74708ms step_avg:nanms
step:8/1500 train_loss:7.2589 train_time:75122ms step_avg:nanms
step:9/1500 train_loss:7.0517 train_time:75537ms step_avg:nanms
step:10/1500 train_loss:6.8427 train_time:75952ms step_avg:nanms
step:11/1500 train_loss:6.7972 train_time:403ms step_avg:nanms
step:12/1500 train_loss:6.6968 train_time:818ms step_avg:nanms
step:13/1500 train_loss:6.5290 train_time:1233ms step_avg:410.92ms
step:14/1500 train_loss:6.5294 train_time:1649ms step_avg:412.22ms
step:15/1500 train_loss:6.5136 train_time:2064ms step_avg:412.70ms
step:16/1500 train_loss:6.4340 train_time:2479ms step_avg:413.18ms
step:17/1500 train_loss:6.4493 train_time:2895ms step_avg:413.61ms
step:18/1500 train_loss:6.4802 train_time:3313ms step_avg:414.11ms
step:19/1500 train_loss:6.3078 train_time:3728ms step_avg:414.24ms
step:20/1500 train_loss:6.3371 train_time:4145ms step_avg:414.48ms
step:21/1500 train_loss:6.0020 train_time:4561ms step_avg:414.59ms
step:22/1500 train_loss:6.3652 train_time:4977ms step_avg:414.78ms
step:23/1500 train_loss:6.5773 train_time:5395ms step_avg:414.99ms
step:24/1500 train_loss:6.2641 train_time:5811ms step_avg:415.05ms
step:25/1500 train_loss:6.4059 train_time:6227ms step_avg:415.11ms
step:26/1500 train_loss:6.1107 train_time:6642ms step_avg:415.12ms
step:27/1500 train_loss:6.0288 train_time:7061ms step_avg:415.36ms
step:28/1500 train_loss:6.1851 train_time:7479ms step_avg:415.50ms
step:29/1500 train_loss:5.8588 train_time:7895ms step_avg:415.51ms
step:30/1500 train_loss:6.1455 train_time:8312ms step_avg:415.58ms
step:31/1500 train_loss:5.9755 train_time:8728ms step_avg:415.61ms
step:32/1500 train_loss:5.9541 train_time:9144ms step_avg:415.66ms
step:33/1500 train_loss:5.7843 train_time:9561ms step_avg:415.68ms
step:34/1500 train_loss:6.0761 train_time:9977ms step_avg:415.70ms
step:35/1500 train_loss:5.9993 train_time:10394ms step_avg:415.77ms
step:36/1500 train_loss:6.1478 train_time:10809ms step_avg:415.74ms
step:37/1500 train_loss:6.0794 train_time:11228ms step_avg:415.84ms
step:38/1500 train_loss:5.9794 train_time:11645ms step_avg:415.89ms
step:39/1500 train_loss:5.8646 train_time:12060ms step_avg:415.88ms
step:40/1500 train_loss:5.8784 train_time:12477ms step_avg:415.91ms
step:41/1500 train_loss:5.7989 train_time:12893ms step_avg:415.90ms
step:42/1500 train_loss:5.8186 train_time:13309ms step_avg:415.90ms
step:43/1500 train_loss:5.7054 train_time:13725ms step_avg:415.92ms
step:44/1500 train_loss:5.8044 train_time:14141ms step_avg:415.90ms
step:45/1500 train_loss:5.7711 train_time:14559ms step_avg:415.98ms
step:46/1500 train_loss:5.9270 train_time:14975ms step_avg:415.97ms
step:47/1500 train_loss:5.7159 train_time:15390ms step_avg:415.95ms
step:48/1500 train_loss:5.5918 train_time:15805ms step_avg:415.93ms
step:49/1500 train_loss:5.8071 train_time:16222ms step_avg:415.95ms
step:50/1500 train_loss:5.6961 train_time:16639ms step_avg:415.98ms
step:51/1500 train_loss:5.8276 train_time:17057ms step_avg:416.03ms
step:52/1500 train_loss:5.6921 train_time:17474ms step_avg:416.05ms
step:53/1500 train_loss:5.5548 train_time:17890ms step_avg:416.04ms
step:54/1500 train_loss:5.6915 train_time:18307ms step_avg:416.08ms
step:55/1500 train_loss:5.5678 train_time:18725ms step_avg:416.12ms
step:56/1500 train_loss:5.9098 train_time:19142ms step_avg:416.14ms
step:57/1500 train_loss:5.5630 train_time:19559ms step_avg:416.15ms
step:58/1500 train_loss:5.4415 train_time:19974ms step_avg:416.12ms
step:59/1500 train_loss:5.5769 train_time:20391ms step_avg:416.14ms
step:60/1500 train_loss:5.5505 train_time:20807ms step_avg:416.14ms
step:61/1500 train_loss:5.6607 train_time:21223ms step_avg:416.14ms
step:62/1500 train_loss:5.4178 train_time:21641ms step_avg:416.18ms
step:63/1500 train_loss:5.5182 train_time:22060ms step_avg:416.22ms
step:64/1500 train_loss:5.5040 train_time:22476ms step_avg:416.22ms
step:65/1500 train_loss:5.1510 train_time:22892ms step_avg:416.23ms
step:66/1500 train_loss:5.3126 train_time:23310ms step_avg:416.24ms
step:67/1500 train_loss:5.4713 train_time:23726ms step_avg:416.25ms
step:68/1500 train_loss:5.3424 train_time:24143ms step_avg:416.25ms
step:69/1500 train_loss:5.5997 train_time:24558ms step_avg:416.24ms
step:70/1500 train_loss:5.2488 train_time:24977ms step_avg:416.29ms
step:71/1500 train_loss:5.2704 train_time:25393ms step_avg:416.28ms
step:72/1500 train_loss:5.4719 train_time:25811ms step_avg:416.30ms
step:73/1500 train_loss:5.4150 train_time:26228ms step_avg:416.32ms
step:74/1500 train_loss:5.2876 train_time:26645ms step_avg:416.33ms
step:75/1500 train_loss:5.4214 train_time:27062ms step_avg:416.34ms
step:76/1500 train_loss:5.3777 train_time:27478ms step_avg:416.33ms
step:77/1500 train_loss:5.3419 train_time:27895ms step_avg:416.34ms
step:78/1500 train_loss:5.4259 train_time:28313ms step_avg:416.36ms
step:79/1500 train_loss:5.5031 train_time:28729ms step_avg:416.36ms
step:80/1500 train_loss:5.2668 train_time:29146ms step_avg:416.37ms
step:81/1500 train_loss:5.3873 train_time:29562ms step_avg:416.37ms
step:82/1500 train_loss:5.1509 train_time:29979ms step_avg:416.38ms
step:83/1500 train_loss:5.3339 train_time:30395ms step_avg:416.38ms
step:84/1500 train_loss:5.2760 train_time:30812ms step_avg:416.38ms
step:85/1500 train_loss:5.2687 train_time:31229ms step_avg:416.39ms
step:86/1500 train_loss:5.1143 train_time:31645ms step_avg:416.38ms
step:87/1500 train_loss:5.3372 train_time:32061ms step_avg:416.38ms
step:88/1500 train_loss:5.2374 train_time:32478ms step_avg:416.39ms
step:89/1500 train_loss:5.2922 train_time:32894ms step_avg:416.39ms
step:90/1500 train_loss:5.2537 train_time:33312ms step_avg:416.39ms
step:91/1500 train_loss:5.1885 train_time:33728ms step_avg:416.40ms
step:92/1500 train_loss:5.1657 train_time:34145ms step_avg:416.40ms
step:93/1500 train_loss:5.3009 train_time:34562ms step_avg:416.41ms
step:94/1500 train_loss:5.1192 train_time:34979ms step_avg:416.41ms
step:95/1500 train_loss:5.1233 train_time:35394ms step_avg:416.40ms
step:96/1500 train_loss:5.1707 train_time:35811ms step_avg:416.41ms
step:97/1500 train_loss:5.0783 train_time:36226ms step_avg:416.39ms
step:98/1500 train_loss:5.1613 train_time:36643ms step_avg:416.40ms
step:99/1500 train_loss:5.0794 train_time:37059ms step_avg:416.39ms
step:100/1500 train_loss:5.2071 train_time:37476ms step_avg:416.40ms
step:101/1500 train_loss:5.1798 train_time:37894ms step_avg:416.42ms
step:102/1500 train_loss:5.0869 train_time:38312ms step_avg:416.43ms
step:103/1500 train_loss:5.1756 train_time:38728ms step_avg:416.43ms
step:104/1500 train_loss:5.1221 train_time:39144ms step_avg:416.43ms
step:105/1500 train_loss:4.9900 train_time:39560ms step_avg:416.42ms
step:106/1500 train_loss:5.0798 train_time:39978ms step_avg:416.44ms
step:107/1500 train_loss:5.2636 train_time:40394ms step_avg:416.43ms
step:108/1500 train_loss:5.0562 train_time:40811ms step_avg:416.44ms
step:109/1500 train_loss:4.8504 train_time:41229ms step_avg:416.45ms
step:110/1500 train_loss:5.0311 train_time:41645ms step_avg:416.45ms
step:111/1500 train_loss:5.0133 train_time:42063ms step_avg:416.46ms
step:112/1500 train_loss:4.9759 train_time:42481ms step_avg:416.48ms
step:113/1500 train_loss:5.0864 train_time:42899ms step_avg:416.49ms
step:114/1500 train_loss:5.0144 train_time:43317ms step_avg:416.51ms
step:115/1500 train_loss:4.8625 train_time:43734ms step_avg:416.51ms
step:116/1500 train_loss:5.0295 train_time:44150ms step_avg:416.51ms
step:117/1500 train_loss:4.9311 train_time:44567ms step_avg:416.51ms
step:118/1500 train_loss:4.8842 train_time:44984ms step_avg:416.52ms
step:119/1500 train_loss:5.0374 train_time:45401ms step_avg:416.53ms
step:120/1500 train_loss:4.9841 train_time:45819ms step_avg:416.54ms
step:121/1500 train_loss:4.9307 train_time:46238ms step_avg:416.55ms
step:122/1500 train_loss:4.8150 train_time:46658ms step_avg:416.59ms
step:123/1500 train_loss:4.9409 train_time:47074ms step_avg:416.58ms
step:124/1500 train_loss:4.7834 train_time:47492ms step_avg:416.60ms
step:125/1500 train_loss:5.1013 train_time:47908ms step_avg:416.59ms
step:125/1500 val_loss:4.9323 train_time:47922ms step_avg:416.71ms
step:126/1500 train_loss:4.9865 train_time:48330ms step_avg:416.64ms
step:127/1500 train_loss:4.9250 train_time:48748ms step_avg:416.65ms
step:128/1500 train_loss:4.9864 train_time:49165ms step_avg:416.65ms
step:129/1500 train_loss:4.8518 train_time:49583ms step_avg:416.67ms
step:130/1500 train_loss:5.1737 train_time:50001ms step_avg:416.68ms
step:131/1500 train_loss:4.9118 train_time:50418ms step_avg:416.68ms
step:132/1500 train_loss:4.9293 train_time:50835ms step_avg:416.68ms
step:133/1500 train_loss:4.8737 train_time:51253ms step_avg:416.69ms
step:134/1500 train_loss:4.9159 train_time:51669ms step_avg:416.69ms
step:135/1500 train_loss:4.8080 train_time:52086ms step_avg:416.69ms
step:136/1500 train_loss:4.9379 train_time:52503ms step_avg:416.69ms
step:137/1500 train_loss:4.7079 train_time:52921ms step_avg:416.70ms
step:138/1500 train_loss:4.8692 train_time:53338ms step_avg:416.70ms
step:139/1500 train_loss:4.8196 train_time:53756ms step_avg:416.71ms
step:140/1500 train_loss:4.8518 train_time:54172ms step_avg:416.70ms
step:141/1500 train_loss:4.9129 train_time:54589ms step_avg:416.71ms
step:142/1500 train_loss:4.7816 train_time:55011ms step_avg:416.75ms
step:143/1500 train_loss:4.8417 train_time:55428ms step_avg:416.75ms
step:144/1500 train_loss:4.7134 train_time:55845ms step_avg:416.75ms
step:145/1500 train_loss:4.8467 train_time:56264ms step_avg:416.77ms
step:146/1500 train_loss:4.7946 train_time:56680ms step_avg:416.77ms
step:147/1500 train_loss:4.6673 train_time:57098ms step_avg:416.77ms
step:148/1500 train_loss:4.8243 train_time:57516ms step_avg:416.78ms
step:149/1500 train_loss:4.8174 train_time:57933ms step_avg:416.78ms
step:150/1500 train_loss:4.8471 train_time:58357ms step_avg:416.84ms
step:151/1500 train_loss:4.8820 train_time:58776ms step_avg:416.85ms
step:152/1500 train_loss:4.7685 train_time:59193ms step_avg:416.85ms
step:153/1500 train_loss:4.7735 train_time:59612ms step_avg:416.87ms
step:154/1500 train_loss:4.8585 train_time:60030ms step_avg:416.87ms
step:155/1500 train_loss:4.8159 train_time:60448ms step_avg:416.88ms
step:156/1500 train_loss:4.7670 train_time:60864ms step_avg:416.88ms
step:157/1500 train_loss:4.7878 train_time:61282ms step_avg:416.89ms
step:158/1500 train_loss:4.9016 train_time:61700ms step_avg:416.89ms
step:159/1500 train_loss:4.6926 train_time:62115ms step_avg:416.88ms
step:160/1500 train_loss:4.7622 train_time:62533ms step_avg:416.89ms
step:161/1500 train_loss:4.6092 train_time:62950ms step_avg:416.89ms
step:162/1500 train_loss:4.7815 train_time:63369ms step_avg:416.90ms
step:163/1500 train_loss:4.8199 train_time:63787ms step_avg:416.91ms
step:164/1500 train_loss:4.8023 train_time:64204ms step_avg:416.91ms
step:165/1500 train_loss:4.6106 train_time:64621ms step_avg:416.91ms
step:166/1500 train_loss:4.7375 train_time:65040ms step_avg:416.92ms
step:167/1500 train_loss:4.8717 train_time:65457ms step_avg:416.93ms
step:168/1500 train_loss:4.6593 train_time:65875ms step_avg:416.93ms
step:169/1500 train_loss:4.7618 train_time:66302ms step_avg:416.99ms
step:170/1500 train_loss:4.6079 train_time:66720ms step_avg:417.00ms
step:171/1500 train_loss:4.5135 train_time:67137ms step_avg:417.00ms
step:172/1500 train_loss:4.6668 train_time:67554ms step_avg:417.00ms
step:173/1500 train_loss:4.6503 train_time:67972ms step_avg:417.01ms
step:174/1500 train_loss:4.7056 train_time:68390ms step_avg:417.01ms
step:175/1500 train_loss:4.8626 train_time:68808ms step_avg:417.02ms
step:176/1500 train_loss:4.7084 train_time:69225ms step_avg:417.02ms
step:177/1500 train_loss:4.5597 train_time:69643ms step_avg:417.02ms
step:178/1500 train_loss:4.5296 train_time:70060ms step_avg:417.02ms
step:179/1500 train_loss:4.6050 train_time:70477ms step_avg:417.02ms
step:180/1500 train_loss:4.6138 train_time:70895ms step_avg:417.03ms
step:181/1500 train_loss:4.6016 train_time:71314ms step_avg:417.04ms
step:182/1500 train_loss:4.7360 train_time:71732ms step_avg:417.04ms
step:183/1500 train_loss:4.5978 train_time:72152ms step_avg:417.06ms
step:184/1500 train_loss:4.5463 train_time:72566ms step_avg:417.05ms
step:185/1500 train_loss:4.5616 train_time:72983ms step_avg:417.05ms
step:186/1500 train_loss:4.6837 train_time:73400ms step_avg:417.05ms
step:187/1500 train_loss:4.5981 train_time:73817ms step_avg:417.04ms
step:188/1500 train_loss:4.7920 train_time:74233ms step_avg:417.04ms
step:189/1500 train_loss:4.6138 train_time:75638ms step_avg:422.56ms
step:190/1500 train_loss:4.5359 train_time:76198ms step_avg:423.32ms
step:191/1500 train_loss:4.6766 train_time:76613ms step_avg:423.28ms
step:192/1500 train_loss:4.5162 train_time:77029ms step_avg:423.24ms
step:193/1500 train_loss:4.4491 train_time:77447ms step_avg:423.21ms
step:194/1500 train_loss:4.6824 train_time:77864ms step_avg:423.17ms
step:195/1500 train_loss:4.6052 train_time:78281ms step_avg:423.14ms
step:196/1500 train_loss:4.7861 train_time:78699ms step_avg:423.12ms
step:197/1500 train_loss:4.6469 train_time:79116ms step_avg:423.08ms
step:198/1500 train_loss:4.4989 train_time:79531ms step_avg:423.04ms
step:199/1500 train_loss:4.5747 train_time:79948ms step_avg:423.01ms
step:200/1500 train_loss:4.4383 train_time:80365ms step_avg:422.97ms
step:201/1500 train_loss:4.5272 train_time:80783ms step_avg:422.95ms
step:202/1500 train_loss:4.4236 train_time:81201ms step_avg:422.92ms
step:203/1500 train_loss:4.6852 train_time:81616ms step_avg:422.88ms
step:204/1500 train_loss:4.5461 train_time:82034ms step_avg:422.85ms
step:205/1500 train_loss:4.5756 train_time:82450ms step_avg:422.82ms
step:206/1500 train_loss:4.6870 train_time:82866ms step_avg:422.78ms
step:207/1500 train_loss:4.3466 train_time:83283ms step_avg:422.76ms
step:208/1500 train_loss:4.5049 train_time:83700ms step_avg:422.73ms
step:209/1500 train_loss:4.4845 train_time:84118ms step_avg:422.70ms
step:210/1500 train_loss:4.6404 train_time:84535ms step_avg:422.68ms
step:211/1500 train_loss:4.5656 train_time:84952ms step_avg:422.65ms
step:212/1500 train_loss:4.4427 train_time:85368ms step_avg:422.62ms
step:213/1500 train_loss:4.5546 train_time:85783ms step_avg:422.58ms
step:214/1500 train_loss:4.4189 train_time:86200ms step_avg:422.55ms
step:215/1500 train_loss:4.4916 train_time:86618ms step_avg:422.53ms
step:216/1500 train_loss:4.3540 train_time:87034ms step_avg:422.49ms
step:217/1500 train_loss:4.4533 train_time:87449ms step_avg:422.46ms
step:218/1500 train_loss:4.4289 train_time:87868ms step_avg:422.44ms
step:219/1500 train_loss:4.4439 train_time:88284ms step_avg:422.41ms
step:220/1500 train_loss:4.4404 train_time:88704ms step_avg:422.40ms
step:221/1500 train_loss:4.4761 train_time:89121ms step_avg:422.37ms
step:222/1500 train_loss:4.4910 train_time:89535ms step_avg:422.34ms
step:223/1500 train_loss:4.4135 train_time:89953ms step_avg:422.31ms
step:224/1500 train_loss:4.4292 train_time:90369ms step_avg:422.29ms
step:225/1500 train_loss:4.6159 train_time:90785ms step_avg:422.26ms
step:226/1500 train_loss:4.2961 train_time:91201ms step_avg:422.23ms
step:227/1500 train_loss:4.3347 train_time:91619ms step_avg:422.21ms
step:228/1500 train_loss:4.3411 train_time:92035ms step_avg:422.18ms
step:229/1500 train_loss:4.5006 train_time:92452ms step_avg:422.15ms
step:230/1500 train_loss:4.2954 train_time:92868ms step_avg:422.13ms
step:231/1500 train_loss:4.4237 train_time:93285ms step_avg:422.10ms
step:232/1500 train_loss:4.2969 train_time:93702ms step_avg:422.08ms
step:233/1500 train_loss:4.3091 train_time:94118ms step_avg:422.06ms
step:234/1500 train_loss:4.4670 train_time:94534ms step_avg:422.03ms
step:235/1500 train_loss:4.3510 train_time:94950ms step_avg:422.00ms
step:236/1500 train_loss:4.2550 train_time:95367ms step_avg:421.98ms
step:237/1500 train_loss:4.4625 train_time:95782ms step_avg:421.95ms
step:238/1500 train_loss:4.4180 train_time:96200ms step_avg:421.93ms
step:239/1500 train_loss:4.2835 train_time:96616ms step_avg:421.90ms
step:240/1500 train_loss:4.4345 train_time:97032ms step_avg:421.88ms
step:241/1500 train_loss:4.4353 train_time:97450ms step_avg:421.86ms
step:242/1500 train_loss:4.3142 train_time:97865ms step_avg:421.83ms
step:243/1500 train_loss:4.4967 train_time:98282ms step_avg:421.81ms
step:244/1500 train_loss:4.3310 train_time:98699ms step_avg:421.79ms
step:245/1500 train_loss:4.3642 train_time:99113ms step_avg:421.76ms
step:246/1500 train_loss:4.4470 train_time:99531ms step_avg:421.74ms
step:247/1500 train_loss:4.3873 train_time:99948ms step_avg:421.72ms
step:248/1500 train_loss:4.3170 train_time:100365ms step_avg:421.70ms
step:249/1500 train_loss:4.4445 train_time:100783ms step_avg:421.69ms
step:250/1500 train_loss:4.2247 train_time:101200ms step_avg:421.67ms
step:250/1500 val_loss:4.3203 train_time:101213ms step_avg:421.72ms
step:251/1500 train_loss:4.2753 train_time:101621ms step_avg:421.67ms
step:252/1500 train_loss:4.3854 train_time:102039ms step_avg:421.65ms
step:253/1500 train_loss:4.4197 train_time:102457ms step_avg:421.63ms
step:254/1500 train_loss:4.2461 train_time:102875ms step_avg:421.62ms
step:255/1500 train_loss:4.1971 train_time:103291ms step_avg:421.60ms
step:256/1500 train_loss:4.3818 train_time:103707ms step_avg:421.57ms
step:257/1500 train_loss:4.2878 train_time:104125ms step_avg:421.56ms
step:258/1500 train_loss:4.3027 train_time:104542ms step_avg:421.54ms
step:259/1500 train_loss:4.2627 train_time:104960ms step_avg:421.53ms
step:260/1500 train_loss:4.3016 train_time:105377ms step_avg:421.51ms
step:261/1500 train_loss:4.3490 train_time:105792ms step_avg:421.48ms
step:262/1500 train_loss:4.3100 train_time:106207ms step_avg:421.46ms
step:263/1500 train_loss:4.2693 train_time:106624ms step_avg:421.44ms
step:264/1500 train_loss:4.1852 train_time:107040ms step_avg:421.42ms
step:265/1500 train_loss:4.2697 train_time:107456ms step_avg:421.40ms
step:266/1500 train_loss:4.1309 train_time:107874ms step_avg:421.38ms
step:267/1500 train_loss:4.1980 train_time:108289ms step_avg:421.36ms
step:268/1500 train_loss:4.2036 train_time:108706ms step_avg:421.34ms
step:269/1500 train_loss:4.2171 train_time:109123ms step_avg:421.33ms
step:270/1500 train_loss:4.1347 train_time:109540ms step_avg:421.31ms
step:271/1500 train_loss:4.3675 train_time:109958ms step_avg:421.29ms
step:272/1500 train_loss:4.2618 train_time:110375ms step_avg:421.28ms
step:273/1500 train_loss:4.1863 train_time:110792ms step_avg:421.26ms
step:274/1500 train_loss:4.2201 train_time:111209ms step_avg:421.25ms
step:275/1500 train_loss:4.2998 train_time:111627ms step_avg:421.23ms
step:276/1500 train_loss:4.3256 train_time:112043ms step_avg:421.21ms
step:277/1500 train_loss:4.5032 train_time:112460ms step_avg:421.20ms
step:278/1500 train_loss:4.2901 train_time:112876ms step_avg:421.18ms
step:279/1500 train_loss:4.3642 train_time:113295ms step_avg:421.17ms
step:280/1500 train_loss:4.2543 train_time:113711ms step_avg:421.15ms
step:281/1500 train_loss:4.3711 train_time:114128ms step_avg:421.14ms
step:282/1500 train_loss:4.2094 train_time:114545ms step_avg:421.12ms
step:283/1500 train_loss:4.2467 train_time:114969ms step_avg:421.13ms
step:284/1500 train_loss:4.1643 train_time:115384ms step_avg:421.11ms
step:285/1500 train_loss:4.3054 train_time:115801ms step_avg:421.10ms
step:286/1500 train_loss:4.3125 train_time:116218ms step_avg:421.08ms
step:287/1500 train_loss:4.3406 train_time:116637ms step_avg:421.07ms
step:288/1500 train_loss:4.1764 train_time:117053ms step_avg:421.06ms
step:289/1500 train_loss:4.2583 train_time:117469ms step_avg:421.04ms
step:290/1500 train_loss:4.1227 train_time:117886ms step_avg:421.02ms
step:291/1500 train_loss:4.1111 train_time:118302ms step_avg:421.00ms
step:292/1500 train_loss:4.2076 train_time:118719ms step_avg:420.99ms
step:293/1500 train_loss:4.1099 train_time:119136ms step_avg:420.97ms
step:294/1500 train_loss:4.1608 train_time:119551ms step_avg:420.95ms
step:295/1500 train_loss:4.1990 train_time:119968ms step_avg:420.94ms
step:296/1500 train_loss:4.0770 train_time:120386ms step_avg:420.93ms
step:297/1500 train_loss:4.0953 train_time:120805ms step_avg:420.92ms
step:298/1500 train_loss:4.1011 train_time:121222ms step_avg:420.91ms
step:299/1500 train_loss:4.2094 train_time:121640ms step_avg:420.90ms
step:300/1500 train_loss:4.0683 train_time:122057ms step_avg:420.89ms
step:301/1500 train_loss:4.2082 train_time:122474ms step_avg:420.87ms
step:302/1500 train_loss:4.2222 train_time:122890ms step_avg:420.85ms
step:303/1500 train_loss:4.1573 train_time:123305ms step_avg:420.84ms
step:304/1500 train_loss:4.2237 train_time:123723ms step_avg:420.83ms
step:305/1500 train_loss:4.1951 train_time:124140ms step_avg:420.81ms
step:306/1500 train_loss:4.6842 train_time:124557ms step_avg:420.80ms
step:307/1500 train_loss:4.1663 train_time:124973ms step_avg:420.79ms
step:308/1500 train_loss:4.0746 train_time:125390ms step_avg:420.77ms
step:309/1500 train_loss:4.2329 train_time:125807ms step_avg:420.76ms
step:310/1500 train_loss:4.0825 train_time:126224ms step_avg:420.75ms
step:311/1500 train_loss:4.3086 train_time:126641ms step_avg:420.74ms
step:312/1500 train_loss:4.1643 train_time:127059ms step_avg:420.73ms
step:313/1500 train_loss:4.0983 train_time:127475ms step_avg:420.71ms
step:314/1500 train_loss:4.1876 train_time:127892ms step_avg:420.70ms
step:315/1500 train_loss:4.3133 train_time:128309ms step_avg:420.69ms
step:316/1500 train_loss:4.1914 train_time:128726ms step_avg:420.67ms
step:317/1500 train_loss:4.0215 train_time:129142ms step_avg:420.66ms
step:318/1500 train_loss:4.0990 train_time:129558ms step_avg:420.64ms
step:319/1500 train_loss:4.1390 train_time:129975ms step_avg:420.63ms
step:320/1500 train_loss:4.1121 train_time:130392ms step_avg:420.62ms
step:321/1500 train_loss:4.2194 train_time:130809ms step_avg:420.61ms
step:322/1500 train_loss:4.1745 train_time:131225ms step_avg:420.59ms
step:323/1500 train_loss:4.1391 train_time:131642ms step_avg:420.58ms
step:324/1500 train_loss:4.2301 train_time:132059ms step_avg:420.57ms
step:325/1500 train_loss:4.1809 train_time:132474ms step_avg:420.55ms
step:326/1500 train_loss:4.2486 train_time:132891ms step_avg:420.54ms
step:327/1500 train_loss:4.1084 train_time:133308ms step_avg:420.53ms
step:328/1500 train_loss:4.6057 train_time:133724ms step_avg:420.52ms
step:329/1500 train_loss:4.2877 train_time:134140ms step_avg:420.50ms
step:330/1500 train_loss:4.0325 train_time:134557ms step_avg:420.49ms
step:331/1500 train_loss:3.9759 train_time:134974ms step_avg:420.48ms
step:332/1500 train_loss:4.1917 train_time:135392ms step_avg:420.47ms
step:333/1500 train_loss:4.1161 train_time:135807ms step_avg:420.46ms
step:334/1500 train_loss:4.0990 train_time:136223ms step_avg:420.44ms
step:335/1500 train_loss:4.0562 train_time:136640ms step_avg:420.43ms
step:336/1500 train_loss:4.2279 train_time:137057ms step_avg:420.42ms
step:337/1500 train_loss:4.1687 train_time:137473ms step_avg:420.41ms
step:338/1500 train_loss:4.6529 train_time:137891ms step_avg:420.40ms
step:339/1500 train_loss:4.1551 train_time:138307ms step_avg:420.39ms
step:340/1500 train_loss:4.0989 train_time:138724ms step_avg:420.37ms
step:341/1500 train_loss:4.1356 train_time:139140ms step_avg:420.36ms
step:342/1500 train_loss:4.0594 train_time:139557ms step_avg:420.35ms
step:343/1500 train_loss:4.0235 train_time:139974ms step_avg:420.34ms
step:344/1500 train_loss:4.0707 train_time:140390ms step_avg:420.33ms
step:345/1500 train_loss:4.2025 train_time:140807ms step_avg:420.32ms
step:346/1500 train_loss:4.0460 train_time:141223ms step_avg:420.31ms
step:347/1500 train_loss:3.9751 train_time:141639ms step_avg:420.30ms
step:348/1500 train_loss:4.0295 train_time:142057ms step_avg:420.29ms
step:349/1500 train_loss:4.0664 train_time:142475ms step_avg:420.28ms
step:350/1500 train_loss:4.0254 train_time:142892ms step_avg:420.27ms
step:351/1500 train_loss:3.7485 train_time:143307ms step_avg:420.25ms
step:352/1500 train_loss:4.0217 train_time:143723ms step_avg:420.24ms
step:353/1500 train_loss:4.3575 train_time:144141ms step_avg:420.24ms
step:354/1500 train_loss:3.8694 train_time:144556ms step_avg:420.22ms
step:355/1500 train_loss:4.1287 train_time:144972ms step_avg:420.21ms
step:356/1500 train_loss:3.9968 train_time:145389ms step_avg:420.20ms
step:357/1500 train_loss:4.0924 train_time:145806ms step_avg:420.19ms
step:358/1500 train_loss:4.0507 train_time:146223ms step_avg:420.18ms
step:359/1500 train_loss:4.0469 train_time:146639ms step_avg:420.17ms
step:360/1500 train_loss:4.1152 train_time:147056ms step_avg:420.16ms
step:361/1500 train_loss:3.6693 train_time:147471ms step_avg:420.14ms
step:362/1500 train_loss:4.2196 train_time:147888ms step_avg:420.14ms
step:363/1500 train_loss:4.1160 train_time:148305ms step_avg:420.13ms
step:364/1500 train_loss:4.0371 train_time:148721ms step_avg:420.12ms
step:365/1500 train_loss:3.9467 train_time:149138ms step_avg:420.11ms
step:366/1500 train_loss:4.1165 train_time:149553ms step_avg:420.09ms
step:367/1500 train_loss:4.0742 train_time:149969ms step_avg:420.08ms
step:368/1500 train_loss:4.0608 train_time:150387ms step_avg:420.07ms
step:369/1500 train_loss:4.0427 train_time:150803ms step_avg:420.06ms
step:370/1500 train_loss:3.9412 train_time:151219ms step_avg:420.05ms
step:371/1500 train_loss:4.0867 train_time:151637ms step_avg:420.05ms
step:372/1500 train_loss:3.9605 train_time:152054ms step_avg:420.04ms
step:373/1500 train_loss:3.8910 train_time:152472ms step_avg:420.03ms
step:374/1500 train_loss:4.1061 train_time:152889ms step_avg:420.02ms
step:375/1500 train_loss:4.0328 train_time:153304ms step_avg:420.01ms
step:375/1500 val_loss:4.0301 train_time:153319ms step_avg:420.05ms
step:376/1500 train_loss:4.0093 train_time:153725ms step_avg:420.01ms
step:377/1500 train_loss:4.0691 train_time:154141ms step_avg:420.00ms
step:378/1500 train_loss:3.9826 train_time:155152ms step_avg:421.61ms
step:379/1500 train_loss:4.0408 train_time:155572ms step_avg:421.60ms
step:380/1500 train_loss:4.0736 train_time:156106ms step_avg:421.91ms
step:381/1500 train_loss:4.1394 train_time:156522ms step_avg:421.89ms
step:382/1500 train_loss:4.0471 train_time:156937ms step_avg:421.87ms
step:383/1500 train_loss:4.0230 train_time:157355ms step_avg:421.86ms
step:384/1500 train_loss:3.9813 train_time:157770ms step_avg:421.85ms
step:385/1500 train_loss:4.0632 train_time:158187ms step_avg:421.83ms
step:386/1500 train_loss:3.9747 train_time:158604ms step_avg:421.82ms
step:387/1500 train_loss:4.0873 train_time:159021ms step_avg:421.81ms
step:388/1500 train_loss:4.2684 train_time:159437ms step_avg:421.79ms
step:389/1500 train_loss:3.9922 train_time:159854ms step_avg:421.78ms
step:390/1500 train_loss:3.9802 train_time:160270ms step_avg:421.76ms
step:391/1500 train_loss:4.0817 train_time:160687ms step_avg:421.75ms
step:392/1500 train_loss:4.0084 train_time:161104ms step_avg:421.74ms
step:393/1500 train_loss:4.1118 train_time:161522ms step_avg:421.73ms
step:394/1500 train_loss:3.9494 train_time:161938ms step_avg:421.71ms
step:395/1500 train_loss:4.0848 train_time:162357ms step_avg:421.71ms
step:396/1500 train_loss:3.8285 train_time:162774ms step_avg:421.70ms
step:397/1500 train_loss:4.0293 train_time:163191ms step_avg:421.68ms
step:398/1500 train_loss:4.0735 train_time:163608ms step_avg:421.67ms
step:399/1500 train_loss:4.0847 train_time:164024ms step_avg:421.66ms
step:400/1500 train_loss:3.9722 train_time:164439ms step_avg:421.64ms
step:401/1500 train_loss:4.0386 train_time:164855ms step_avg:421.63ms
step:402/1500 train_loss:4.1018 train_time:165273ms step_avg:421.61ms
step:403/1500 train_loss:4.0272 train_time:165689ms step_avg:421.60ms
step:404/1500 train_loss:4.1379 train_time:166107ms step_avg:421.59ms
step:405/1500 train_loss:3.8915 train_time:166523ms step_avg:421.58ms
step:406/1500 train_loss:3.9830 train_time:166939ms step_avg:421.56ms
step:407/1500 train_loss:4.2738 train_time:167357ms step_avg:421.55ms
step:408/1500 train_loss:3.9815 train_time:167774ms step_avg:421.54ms
step:409/1500 train_loss:4.0097 train_time:168191ms step_avg:421.53ms
step:410/1500 train_loss:4.0533 train_time:168607ms step_avg:421.52ms
step:411/1500 train_loss:3.9384 train_time:169023ms step_avg:421.50ms
step:412/1500 train_loss:3.9552 train_time:169439ms step_avg:421.49ms
step:413/1500 train_loss:4.3758 train_time:169856ms step_avg:421.48ms
step:414/1500 train_loss:3.8443 train_time:170271ms step_avg:421.46ms
step:415/1500 train_loss:4.2080 train_time:170689ms step_avg:421.45ms
step:416/1500 train_loss:3.9498 train_time:171105ms step_avg:421.44ms
step:417/1500 train_loss:3.9533 train_time:171522ms step_avg:421.43ms
step:418/1500 train_loss:4.1428 train_time:171939ms step_avg:421.42ms
step:419/1500 train_loss:3.8744 train_time:172356ms step_avg:421.41ms
step:420/1500 train_loss:3.9909 train_time:172773ms step_avg:421.40ms
step:421/1500 train_loss:3.9244 train_time:173188ms step_avg:421.38ms
step:422/1500 train_loss:3.8371 train_time:173604ms step_avg:421.37ms
step:423/1500 train_loss:3.9671 train_time:174019ms step_avg:421.35ms
step:424/1500 train_loss:4.0537 train_time:174436ms step_avg:421.34ms
step:425/1500 train_loss:3.8157 train_time:174857ms step_avg:421.34ms
step:426/1500 train_loss:3.9920 train_time:175273ms step_avg:421.33ms
step:427/1500 train_loss:3.8748 train_time:175690ms step_avg:421.32ms
step:428/1500 train_loss:4.0902 train_time:176107ms step_avg:421.31ms
step:429/1500 train_loss:4.0062 train_time:176523ms step_avg:421.30ms
step:430/1500 train_loss:3.9423 train_time:176939ms step_avg:421.28ms
step:431/1500 train_loss:3.9089 train_time:177356ms step_avg:421.27ms
step:432/1500 train_loss:3.8137 train_time:177773ms step_avg:421.26ms
step:433/1500 train_loss:3.9511 train_time:178189ms step_avg:421.25ms
step:434/1500 train_loss:4.0072 train_time:178606ms step_avg:421.24ms
step:435/1500 train_loss:3.9536 train_time:179022ms step_avg:421.23ms
step:436/1500 train_loss:4.0029 train_time:179438ms step_avg:421.22ms
step:437/1500 train_loss:4.0087 train_time:179854ms step_avg:421.20ms
step:438/1500 train_loss:3.8929 train_time:180271ms step_avg:421.19ms
step:439/1500 train_loss:3.9049 train_time:180687ms step_avg:421.18ms
step:440/1500 train_loss:3.8842 train_time:181105ms step_avg:421.18ms
step:441/1500 train_loss:4.0598 train_time:181994ms step_avg:422.26ms
step:442/1500 train_loss:3.9511 train_time:182409ms step_avg:422.24ms
step:443/1500 train_loss:3.9357 train_time:182825ms step_avg:422.23ms
step:444/1500 train_loss:3.8236 train_time:183242ms step_avg:422.22ms
step:445/1500 train_loss:4.0928 train_time:183658ms step_avg:422.20ms
step:446/1500 train_loss:4.0244 train_time:184073ms step_avg:422.19ms
step:447/1500 train_loss:4.0135 train_time:184489ms step_avg:422.17ms
step:448/1500 train_loss:3.9327 train_time:184904ms step_avg:422.16ms
step:449/1500 train_loss:4.0334 train_time:185321ms step_avg:422.14ms
step:450/1500 train_loss:3.8602 train_time:185738ms step_avg:422.13ms
step:451/1500 train_loss:3.8978 train_time:186155ms step_avg:422.12ms
step:452/1500 train_loss:3.7596 train_time:186573ms step_avg:422.11ms
step:453/1500 train_loss:3.8853 train_time:186998ms step_avg:422.12ms
step:454/1500 train_loss:3.8544 train_time:187413ms step_avg:422.10ms
step:455/1500 train_loss:3.8127 train_time:187829ms step_avg:422.09ms
step:456/1500 train_loss:4.0355 train_time:188245ms step_avg:422.07ms
step:457/1500 train_loss:3.8993 train_time:188661ms step_avg:422.06ms
step:458/1500 train_loss:3.9758 train_time:189077ms step_avg:422.05ms
step:459/1500 train_loss:4.0098 train_time:189492ms step_avg:422.03ms
step:460/1500 train_loss:3.8131 train_time:189908ms step_avg:422.02ms
step:461/1500 train_loss:3.9841 train_time:190324ms step_avg:422.01ms
step:462/1500 train_loss:3.8765 train_time:190742ms step_avg:422.00ms
step:463/1500 train_loss:3.9002 train_time:191159ms step_avg:421.98ms
step:464/1500 train_loss:3.9570 train_time:191575ms step_avg:421.97ms
step:465/1500 train_loss:3.8975 train_time:191991ms step_avg:421.96ms
step:466/1500 train_loss:3.9055 train_time:192407ms step_avg:421.94ms
step:467/1500 train_loss:3.9923 train_time:192823ms step_avg:421.93ms
step:468/1500 train_loss:4.0079 train_time:193239ms step_avg:421.92ms
step:469/1500 train_loss:3.9807 train_time:193655ms step_avg:421.91ms
step:470/1500 train_loss:3.8704 train_time:194073ms step_avg:421.90ms
step:471/1500 train_loss:3.9490 train_time:194487ms step_avg:421.88ms
step:472/1500 train_loss:4.0090 train_time:194905ms step_avg:421.87ms
step:473/1500 train_loss:3.9500 train_time:195322ms step_avg:421.86ms
step:474/1500 train_loss:3.9006 train_time:195737ms step_avg:421.85ms
step:475/1500 train_loss:3.7610 train_time:196156ms step_avg:421.84ms
step:476/1500 train_loss:4.1926 train_time:196571ms step_avg:421.83ms
step:477/1500 train_loss:3.9466 train_time:196987ms step_avg:421.81ms
step:478/1500 train_loss:3.7593 train_time:197401ms step_avg:421.80ms
step:479/1500 train_loss:3.9938 train_time:197818ms step_avg:421.79ms
step:480/1500 train_loss:3.9441 train_time:198233ms step_avg:421.77ms
step:481/1500 train_loss:4.0891 train_time:198653ms step_avg:421.77ms
step:482/1500 train_loss:3.9011 train_time:199070ms step_avg:421.76ms
step:483/1500 train_loss:3.7091 train_time:199486ms step_avg:421.75ms
step:484/1500 train_loss:3.9935 train_time:199902ms step_avg:421.73ms
step:485/1500 train_loss:3.8394 train_time:200320ms step_avg:421.73ms
step:486/1500 train_loss:3.8516 train_time:200735ms step_avg:421.71ms
step:487/1500 train_loss:3.7765 train_time:201154ms step_avg:421.71ms
step:488/1500 train_loss:3.8523 train_time:201570ms step_avg:421.70ms
step:489/1500 train_loss:4.0461 train_time:201987ms step_avg:421.69ms
step:490/1500 train_loss:3.8923 train_time:202404ms step_avg:421.68ms
step:491/1500 train_loss:3.7788 train_time:202818ms step_avg:421.66ms
step:492/1500 train_loss:3.7938 train_time:203235ms step_avg:421.65ms
step:493/1500 train_loss:3.9116 train_time:203656ms step_avg:421.65ms
step:494/1500 train_loss:3.7542 train_time:204071ms step_avg:421.63ms
step:495/1500 train_loss:3.8873 train_time:204488ms step_avg:421.62ms
step:496/1500 train_loss:3.8296 train_time:204903ms step_avg:421.61ms
step:497/1500 train_loss:3.7041 train_time:205320ms step_avg:421.60ms
step:498/1500 train_loss:3.9080 train_time:205736ms step_avg:421.59ms
step:499/1500 train_loss:3.9776 train_time:206154ms step_avg:421.58ms
step:500/1500 train_loss:4.0105 train_time:206571ms step_avg:421.57ms
step:500/1500 val_loss:3.8846 train_time:206585ms step_avg:421.60ms
step:501/1500 train_loss:3.9244 train_time:206994ms step_avg:421.58ms
step:502/1500 train_loss:3.9730 train_time:207411ms step_avg:421.57ms
step:503/1500 train_loss:3.9201 train_time:207832ms step_avg:421.57ms
step:504/1500 train_loss:3.9611 train_time:208249ms step_avg:421.56ms
step:505/1500 train_loss:3.9070 train_time:208664ms step_avg:421.54ms
step:506/1500 train_loss:3.9928 train_time:209081ms step_avg:421.53ms
step:507/1500 train_loss:3.8155 train_time:209497ms step_avg:421.52ms
step:508/1500 train_loss:3.9368 train_time:209913ms step_avg:421.51ms
step:509/1500 train_loss:4.0047 train_time:210331ms step_avg:421.51ms
step:510/1500 train_loss:3.9501 train_time:210749ms step_avg:421.50ms
step:511/1500 train_loss:3.7557 train_time:211167ms step_avg:421.49ms
step:512/1500 train_loss:3.9612 train_time:211584ms step_avg:421.48ms
step:513/1500 train_loss:3.8990 train_time:212001ms step_avg:421.47ms
step:514/1500 train_loss:3.8516 train_time:212416ms step_avg:421.46ms
step:515/1500 train_loss:3.9236 train_time:212832ms step_avg:421.45ms
step:516/1500 train_loss:3.9169 train_time:213248ms step_avg:421.44ms
step:517/1500 train_loss:4.2445 train_time:213664ms step_avg:421.43ms
step:518/1500 train_loss:3.8541 train_time:214078ms step_avg:421.41ms
step:519/1500 train_loss:3.9628 train_time:214494ms step_avg:421.40ms
step:520/1500 train_loss:3.8600 train_time:214910ms step_avg:421.39ms
step:521/1500 train_loss:3.8631 train_time:215329ms step_avg:421.39ms
step:522/1500 train_loss:3.8130 train_time:215747ms step_avg:421.38ms
step:523/1500 train_loss:3.8260 train_time:216163ms step_avg:421.37ms
step:524/1500 train_loss:4.4490 train_time:216579ms step_avg:421.36ms
step:525/1500 train_loss:3.9202 train_time:216994ms step_avg:421.35ms
step:526/1500 train_loss:3.8575 train_time:217410ms step_avg:421.34ms
step:527/1500 train_loss:3.8716 train_time:217830ms step_avg:421.33ms
step:528/1500 train_loss:3.8227 train_time:218246ms step_avg:421.32ms
step:529/1500 train_loss:3.7980 train_time:218662ms step_avg:421.31ms
step:530/1500 train_loss:4.0158 train_time:219078ms step_avg:421.30ms
step:531/1500 train_loss:3.8152 train_time:219493ms step_avg:421.29ms
step:532/1500 train_loss:4.0961 train_time:219909ms step_avg:421.28ms
step:533/1500 train_loss:3.9014 train_time:220328ms step_avg:421.28ms
step:534/1500 train_loss:3.8263 train_time:220744ms step_avg:421.27ms
step:535/1500 train_loss:3.8550 train_time:221159ms step_avg:421.26ms
step:536/1500 train_loss:3.7901 train_time:221575ms step_avg:421.25ms
step:537/1500 train_loss:3.9139 train_time:221993ms step_avg:421.24ms
step:538/1500 train_loss:3.9075 train_time:222409ms step_avg:421.23ms
step:539/1500 train_loss:3.8021 train_time:222828ms step_avg:421.22ms
step:540/1500 train_loss:4.3025 train_time:223244ms step_avg:421.22ms
step:541/1500 train_loss:3.8410 train_time:223660ms step_avg:421.21ms
step:542/1500 train_loss:3.9535 train_time:224078ms step_avg:421.20ms
step:543/1500 train_loss:3.7789 train_time:224493ms step_avg:421.19ms
step:544/1500 train_loss:3.7538 train_time:224908ms step_avg:421.18ms
step:545/1500 train_loss:3.8318 train_time:225326ms step_avg:421.17ms
step:546/1500 train_loss:3.7638 train_time:225742ms step_avg:421.16ms
step:547/1500 train_loss:3.8105 train_time:226159ms step_avg:421.15ms
step:548/1500 train_loss:3.8221 train_time:226578ms step_avg:421.15ms
step:549/1500 train_loss:3.7919 train_time:226995ms step_avg:421.14ms
step:550/1500 train_loss:3.8939 train_time:227410ms step_avg:421.13ms
step:551/1500 train_loss:3.7779 train_time:227831ms step_avg:421.13ms
step:552/1500 train_loss:3.7914 train_time:228248ms step_avg:421.12ms
step:553/1500 train_loss:4.1239 train_time:228665ms step_avg:421.11ms
step:554/1500 train_loss:3.9226 train_time:229080ms step_avg:421.10ms
step:555/1500 train_loss:3.8827 train_time:229498ms step_avg:421.10ms
step:556/1500 train_loss:3.8204 train_time:229914ms step_avg:421.09ms
step:557/1500 train_loss:3.8588 train_time:230331ms step_avg:421.08ms
step:558/1500 train_loss:3.5176 train_time:230747ms step_avg:421.07ms
step:559/1500 train_loss:3.7764 train_time:231163ms step_avg:421.06ms
step:560/1500 train_loss:3.8219 train_time:231580ms step_avg:421.06ms
step:561/1500 train_loss:3.8648 train_time:231995ms step_avg:421.04ms
step:562/1500 train_loss:3.7805 train_time:232413ms step_avg:421.04ms
step:563/1500 train_loss:3.7186 train_time:232830ms step_avg:421.03ms
step:564/1500 train_loss:3.9315 train_time:233247ms step_avg:421.02ms
step:565/1500 train_loss:3.7400 train_time:233663ms step_avg:421.01ms
step:566/1500 train_loss:3.8565 train_time:234080ms step_avg:421.01ms
step:567/1500 train_loss:3.8069 train_time:235108ms step_avg:422.10ms
step:568/1500 train_loss:3.7575 train_time:235526ms step_avg:422.09ms
step:569/1500 train_loss:3.8568 train_time:235942ms step_avg:422.08ms
step:570/1500 train_loss:3.8267 train_time:236480ms step_avg:422.28ms
step:571/1500 train_loss:3.8478 train_time:236895ms step_avg:422.27ms
step:572/1500 train_loss:3.9374 train_time:237312ms step_avg:422.26ms
step:573/1500 train_loss:3.8858 train_time:237732ms step_avg:422.26ms
step:574/1500 train_loss:3.9000 train_time:238147ms step_avg:422.25ms
step:575/1500 train_loss:3.9439 train_time:238565ms step_avg:422.24ms
step:576/1500 train_loss:3.9000 train_time:238981ms step_avg:422.23ms
step:577/1500 train_loss:3.9216 train_time:239397ms step_avg:422.22ms
step:578/1500 train_loss:3.8482 train_time:239814ms step_avg:422.21ms
step:579/1500 train_loss:3.8398 train_time:240231ms step_avg:422.20ms
step:580/1500 train_loss:3.8275 train_time:240648ms step_avg:422.19ms
step:581/1500 train_loss:3.7683 train_time:241064ms step_avg:422.18ms
step:582/1500 train_loss:3.8004 train_time:241478ms step_avg:422.16ms
step:583/1500 train_loss:4.0224 train_time:241895ms step_avg:422.15ms
step:584/1500 train_loss:3.7944 train_time:242309ms step_avg:422.14ms
step:585/1500 train_loss:3.7549 train_time:242729ms step_avg:422.14ms
step:586/1500 train_loss:3.9434 train_time:243147ms step_avg:422.13ms
step:587/1500 train_loss:3.6989 train_time:243564ms step_avg:422.12ms
step:588/1500 train_loss:3.8379 train_time:243980ms step_avg:422.11ms
step:589/1500 train_loss:3.8171 train_time:244395ms step_avg:422.10ms
step:590/1500 train_loss:4.1673 train_time:244811ms step_avg:422.09ms
step:591/1500 train_loss:3.9518 train_time:245230ms step_avg:422.08ms
step:592/1500 train_loss:3.6847 train_time:245647ms step_avg:422.07ms
step:593/1500 train_loss:3.7021 train_time:246062ms step_avg:422.06ms
step:594/1500 train_loss:3.6853 train_time:246476ms step_avg:422.05ms
step:595/1500 train_loss:3.7289 train_time:246894ms step_avg:422.04ms
step:596/1500 train_loss:4.1019 train_time:247311ms step_avg:422.03ms
step:597/1500 train_loss:3.8114 train_time:247730ms step_avg:422.03ms
step:598/1500 train_loss:3.7486 train_time:248146ms step_avg:422.02ms
step:599/1500 train_loss:3.8263 train_time:248563ms step_avg:422.01ms
step:600/1500 train_loss:3.6465 train_time:248978ms step_avg:422.00ms
step:601/1500 train_loss:3.7635 train_time:249394ms step_avg:421.99ms
step:602/1500 train_loss:3.7998 train_time:249809ms step_avg:421.97ms
step:603/1500 train_loss:3.8242 train_time:250229ms step_avg:421.97ms
step:604/1500 train_loss:3.9468 train_time:250646ms step_avg:421.96ms
step:605/1500 train_loss:3.7992 train_time:251061ms step_avg:421.95ms
step:606/1500 train_loss:3.7801 train_time:251479ms step_avg:421.94ms
step:607/1500 train_loss:3.7327 train_time:251896ms step_avg:421.94ms
step:608/1500 train_loss:3.9865 train_time:252314ms step_avg:421.93ms
step:609/1500 train_loss:3.8123 train_time:252731ms step_avg:421.92ms
step:610/1500 train_loss:3.7820 train_time:253148ms step_avg:421.91ms
step:611/1500 train_loss:3.8828 train_time:253563ms step_avg:421.90ms
step:612/1500 train_loss:3.7825 train_time:253980ms step_avg:421.89ms
step:613/1500 train_loss:3.7674 train_time:254395ms step_avg:421.88ms
step:614/1500 train_loss:3.9273 train_time:254812ms step_avg:421.87ms
step:615/1500 train_loss:3.8832 train_time:255230ms step_avg:421.87ms
step:616/1500 train_loss:3.8624 train_time:255647ms step_avg:421.86ms
step:617/1500 train_loss:3.7810 train_time:256064ms step_avg:421.85ms
step:618/1500 train_loss:3.7349 train_time:256480ms step_avg:421.84ms
step:619/1500 train_loss:3.8447 train_time:256898ms step_avg:421.84ms
step:620/1500 train_loss:3.7386 train_time:257315ms step_avg:421.83ms
step:621/1500 train_loss:3.7550 train_time:257732ms step_avg:421.82ms
step:622/1500 train_loss:4.0669 train_time:258149ms step_avg:421.81ms
step:623/1500 train_loss:3.7525 train_time:258564ms step_avg:421.80ms
step:624/1500 train_loss:3.7839 train_time:258980ms step_avg:421.79ms
step:625/1500 train_loss:3.8678 train_time:259396ms step_avg:421.78ms
step:625/1500 val_loss:3.7903 train_time:259409ms step_avg:421.80ms
step:626/1500 train_loss:3.8780 train_time:259816ms step_avg:421.78ms
step:627/1500 train_loss:3.9107 train_time:260232ms step_avg:421.77ms
step:628/1500 train_loss:3.8921 train_time:260648ms step_avg:421.76ms
step:629/1500 train_loss:3.9364 train_time:261062ms step_avg:421.75ms
step:630/1500 train_loss:3.7573 train_time:261478ms step_avg:421.74ms
step:631/1500 train_loss:3.8850 train_time:261895ms step_avg:421.73ms
step:632/1500 train_loss:3.9189 train_time:262311ms step_avg:421.72ms
step:633/1500 train_loss:3.8193 train_time:262726ms step_avg:421.71ms
step:634/1500 train_loss:3.7524 train_time:263141ms step_avg:421.70ms
step:635/1500 train_loss:3.8486 train_time:263558ms step_avg:421.69ms
step:636/1500 train_loss:4.1076 train_time:263973ms step_avg:421.68ms
step:637/1500 train_loss:3.6977 train_time:264389ms step_avg:421.67ms
step:638/1500 train_loss:3.5142 train_time:264809ms step_avg:421.67ms
step:639/1500 train_loss:3.7440 train_time:265225ms step_avg:421.66ms
step:640/1500 train_loss:3.7859 train_time:265640ms step_avg:421.65ms
step:641/1500 train_loss:3.7359 train_time:266055ms step_avg:421.64ms
step:642/1500 train_loss:3.7386 train_time:266471ms step_avg:421.63ms
step:643/1500 train_loss:3.7807 train_time:266887ms step_avg:421.62ms
step:644/1500 train_loss:3.7962 train_time:267306ms step_avg:421.62ms
step:645/1500 train_loss:3.7193 train_time:267722ms step_avg:421.61ms
step:646/1500 train_loss:3.9397 train_time:268138ms step_avg:421.60ms
step:647/1500 train_loss:3.8307 train_time:268554ms step_avg:421.59ms
step:648/1500 train_loss:3.8299 train_time:268970ms step_avg:421.58ms
step:649/1500 train_loss:3.8660 train_time:269386ms step_avg:421.57ms
step:650/1500 train_loss:3.9228 train_time:269805ms step_avg:421.57ms
step:651/1500 train_loss:3.7828 train_time:270220ms step_avg:421.56ms
step:652/1500 train_loss:3.9267 train_time:270636ms step_avg:421.55ms
step:653/1500 train_loss:3.7452 train_time:271051ms step_avg:421.54ms
step:654/1500 train_loss:3.8244 train_time:271467ms step_avg:421.53ms
step:655/1500 train_loss:3.5924 train_time:271884ms step_avg:421.53ms
step:656/1500 train_loss:3.7364 train_time:272300ms step_avg:421.52ms
step:657/1500 train_loss:3.7432 train_time:272718ms step_avg:421.51ms
step:658/1500 train_loss:3.6689 train_time:273134ms step_avg:421.50ms
step:659/1500 train_loss:3.8540 train_time:273551ms step_avg:421.50ms
step:660/1500 train_loss:3.7516 train_time:273967ms step_avg:421.49ms
step:661/1500 train_loss:3.8473 train_time:274382ms step_avg:421.48ms
step:662/1500 train_loss:3.9197 train_time:274799ms step_avg:421.47ms
step:663/1500 train_loss:3.8264 train_time:275215ms step_avg:421.46ms
step:664/1500 train_loss:3.7056 train_time:275632ms step_avg:421.46ms
step:665/1500 train_loss:3.7926 train_time:276047ms step_avg:421.45ms
step:666/1500 train_loss:3.6586 train_time:276462ms step_avg:421.44ms
step:667/1500 train_loss:3.9475 train_time:276879ms step_avg:421.43ms
step:668/1500 train_loss:3.7745 train_time:277296ms step_avg:421.42ms
step:669/1500 train_loss:3.7917 train_time:277713ms step_avg:421.42ms
step:670/1500 train_loss:3.6398 train_time:278129ms step_avg:421.41ms
step:671/1500 train_loss:3.7587 train_time:278546ms step_avg:421.40ms
step:672/1500 train_loss:3.7176 train_time:278963ms step_avg:421.39ms
step:673/1500 train_loss:3.7368 train_time:279377ms step_avg:421.38ms
step:674/1500 train_loss:4.0187 train_time:279794ms step_avg:421.38ms
step:675/1500 train_loss:3.8073 train_time:280209ms step_avg:421.37ms
step:676/1500 train_loss:3.8693 train_time:280625ms step_avg:421.36ms
step:677/1500 train_loss:3.6527 train_time:281042ms step_avg:421.35ms
step:678/1500 train_loss:3.7559 train_time:281458ms step_avg:421.34ms
step:679/1500 train_loss:3.7019 train_time:281874ms step_avg:421.34ms
step:680/1500 train_loss:3.8367 train_time:282289ms step_avg:421.33ms
step:681/1500 train_loss:3.7419 train_time:282708ms step_avg:421.32ms
step:682/1500 train_loss:3.7724 train_time:283124ms step_avg:421.32ms
step:683/1500 train_loss:3.8516 train_time:283539ms step_avg:421.31ms
step:684/1500 train_loss:3.8912 train_time:283954ms step_avg:421.30ms
step:685/1500 train_loss:3.7957 train_time:284370ms step_avg:421.29ms
step:686/1500 train_loss:3.8660 train_time:284785ms step_avg:421.28ms
step:687/1500 train_loss:3.7882 train_time:285205ms step_avg:421.28ms
step:688/1500 train_loss:3.8377 train_time:285622ms step_avg:421.27ms
step:689/1500 train_loss:3.4491 train_time:286039ms step_avg:421.27ms
step:690/1500 train_loss:3.5795 train_time:286456ms step_avg:421.26ms
step:691/1500 train_loss:3.7123 train_time:286872ms step_avg:421.25ms
step:692/1500 train_loss:3.5926 train_time:287290ms step_avg:421.25ms
step:693/1500 train_loss:3.8040 train_time:287709ms step_avg:421.24ms
step:694/1500 train_loss:3.8231 train_time:288125ms step_avg:421.24ms
step:695/1500 train_loss:3.7106 train_time:288542ms step_avg:421.23ms
step:696/1500 train_loss:3.6948 train_time:288958ms step_avg:421.22ms
step:697/1500 train_loss:4.0156 train_time:289375ms step_avg:421.21ms
step:698/1500 train_loss:3.7604 train_time:289791ms step_avg:421.21ms
step:699/1500 train_loss:3.8032 train_time:290207ms step_avg:421.20ms
step:700/1500 train_loss:3.9604 train_time:290623ms step_avg:421.19ms
step:701/1500 train_loss:3.7344 train_time:291039ms step_avg:421.19ms
step:702/1500 train_loss:3.6951 train_time:291458ms step_avg:421.18ms
step:703/1500 train_loss:3.6783 train_time:291874ms step_avg:421.17ms
step:704/1500 train_loss:3.6417 train_time:292292ms step_avg:421.17ms
step:705/1500 train_loss:3.7193 train_time:292710ms step_avg:421.17ms
step:706/1500 train_loss:3.7245 train_time:293125ms step_avg:421.16ms
step:707/1500 train_loss:3.7309 train_time:293541ms step_avg:421.15ms
step:708/1500 train_loss:3.8052 train_time:293959ms step_avg:421.14ms
step:709/1500 train_loss:3.7531 train_time:294374ms step_avg:421.14ms
step:710/1500 train_loss:3.7364 train_time:294799ms step_avg:421.14ms
step:711/1500 train_loss:3.7004 train_time:295215ms step_avg:421.13ms
step:712/1500 train_loss:3.7479 train_time:295632ms step_avg:421.13ms
step:713/1500 train_loss:3.8047 train_time:296050ms step_avg:421.12ms
step:714/1500 train_loss:3.8114 train_time:296465ms step_avg:421.12ms
step:715/1500 train_loss:3.7254 train_time:296882ms step_avg:421.11ms
step:716/1500 train_loss:3.7252 train_time:297298ms step_avg:421.10ms
step:717/1500 train_loss:3.7475 train_time:297714ms step_avg:421.10ms
step:718/1500 train_loss:3.8873 train_time:298130ms step_avg:421.09ms
step:719/1500 train_loss:3.7501 train_time:298547ms step_avg:421.08ms
step:720/1500 train_loss:3.8204 train_time:298963ms step_avg:421.07ms
step:721/1500 train_loss:3.9943 train_time:299378ms step_avg:421.07ms
step:722/1500 train_loss:3.6192 train_time:299796ms step_avg:421.06ms
step:723/1500 train_loss:3.8807 train_time:300211ms step_avg:421.05ms
step:724/1500 train_loss:3.9374 train_time:300627ms step_avg:421.05ms
step:725/1500 train_loss:3.7201 train_time:301045ms step_avg:421.04ms
step:726/1500 train_loss:3.8005 train_time:301460ms step_avg:421.03ms
step:727/1500 train_loss:3.6997 train_time:301875ms step_avg:421.03ms
step:728/1500 train_loss:3.7156 train_time:302291ms step_avg:421.02ms
step:729/1500 train_loss:3.8966 train_time:302710ms step_avg:421.02ms
step:730/1500 train_loss:3.8343 train_time:303126ms step_avg:421.01ms
step:731/1500 train_loss:3.8364 train_time:303543ms step_avg:421.00ms
step:732/1500 train_loss:3.7200 train_time:303959ms step_avg:421.00ms
step:733/1500 train_loss:3.7426 train_time:304374ms step_avg:420.99ms
step:734/1500 train_loss:3.9865 train_time:304791ms step_avg:420.98ms
step:735/1500 train_loss:3.7125 train_time:305209ms step_avg:420.98ms
step:736/1500 train_loss:3.7759 train_time:305626ms step_avg:420.97ms
step:737/1500 train_loss:3.8962 train_time:306042ms step_avg:420.97ms
step:738/1500 train_loss:3.8133 train_time:306456ms step_avg:420.96ms
step:739/1500 train_loss:3.7618 train_time:306874ms step_avg:420.95ms
step:740/1500 train_loss:3.6583 train_time:307289ms step_avg:420.94ms
step:741/1500 train_loss:4.2912 train_time:307732ms step_avg:420.97ms
step:742/1500 train_loss:3.6479 train_time:308149ms step_avg:420.97ms
step:743/1500 train_loss:3.7318 train_time:308565ms step_avg:420.96ms
step:744/1500 train_loss:3.7361 train_time:308979ms step_avg:420.95ms
step:745/1500 train_loss:3.7982 train_time:309395ms step_avg:420.95ms
step:746/1500 train_loss:3.7647 train_time:309811ms step_avg:420.94ms
step:747/1500 train_loss:3.7547 train_time:310227ms step_avg:420.93ms
step:748/1500 train_loss:3.7895 train_time:310643ms step_avg:420.92ms
step:749/1500 train_loss:3.7129 train_time:311059ms step_avg:420.92ms
step:750/1500 train_loss:3.7161 train_time:311476ms step_avg:420.91ms
step:750/1500 val_loss:3.7248 train_time:311490ms step_avg:420.93ms
step:751/1500 train_loss:3.7485 train_time:311896ms step_avg:420.91ms
step:752/1500 train_loss:3.7140 train_time:312313ms step_avg:420.91ms
step:753/1500 train_loss:3.7566 train_time:312728ms step_avg:420.90ms
step:754/1500 train_loss:3.7714 train_time:313144ms step_avg:420.89ms
step:755/1500 train_loss:3.7436 train_time:313559ms step_avg:420.88ms
step:756/1500 train_loss:3.8184 train_time:314546ms step_avg:421.64ms
step:757/1500 train_loss:3.6423 train_time:314963ms step_avg:421.64ms
step:758/1500 train_loss:3.8845 train_time:315379ms step_avg:421.63ms
step:759/1500 train_loss:3.7971 train_time:315795ms step_avg:421.62ms
step:760/1500 train_loss:3.7332 train_time:316331ms step_avg:421.77ms
step:761/1500 train_loss:3.8471 train_time:316747ms step_avg:421.77ms
step:762/1500 train_loss:3.5540 train_time:317163ms step_avg:421.76ms
step:763/1500 train_loss:3.7009 train_time:317579ms step_avg:421.75ms
step:764/1500 train_loss:3.8242 train_time:317995ms step_avg:421.74ms
step:765/1500 train_loss:3.4726 train_time:318410ms step_avg:421.73ms
step:766/1500 train_loss:3.8976 train_time:318826ms step_avg:421.73ms
step:767/1500 train_loss:3.7465 train_time:319239ms step_avg:421.72ms
step:768/1500 train_loss:3.7115 train_time:319655ms step_avg:421.71ms
step:769/1500 train_loss:3.7310 train_time:320070ms step_avg:421.70ms
step:770/1500 train_loss:3.7503 train_time:320489ms step_avg:421.70ms
step:771/1500 train_loss:3.8066 train_time:320905ms step_avg:421.69ms
step:772/1500 train_loss:4.0355 train_time:321321ms step_avg:421.68ms
step:773/1500 train_loss:3.6106 train_time:321738ms step_avg:421.67ms
step:774/1500 train_loss:3.8049 train_time:322153ms step_avg:421.67ms
step:775/1500 train_loss:3.7929 train_time:322569ms step_avg:421.66ms
step:776/1500 train_loss:3.7534 train_time:322990ms step_avg:421.66ms
step:777/1500 train_loss:3.5672 train_time:323406ms step_avg:421.65ms
step:778/1500 train_loss:3.5586 train_time:323821ms step_avg:421.64ms
step:779/1500 train_loss:3.6330 train_time:324238ms step_avg:421.64ms
step:780/1500 train_loss:3.7210 train_time:324654ms step_avg:421.63ms
step:781/1500 train_loss:3.7476 train_time:325070ms step_avg:421.62ms
step:782/1500 train_loss:3.8117 train_time:325491ms step_avg:421.62ms
step:783/1500 train_loss:3.7217 train_time:325907ms step_avg:421.61ms
step:784/1500 train_loss:3.7232 train_time:326323ms step_avg:421.61ms
step:785/1500 train_loss:3.7289 train_time:326740ms step_avg:421.60ms
step:786/1500 train_loss:3.7031 train_time:327155ms step_avg:421.59ms
step:787/1500 train_loss:3.6059 train_time:327573ms step_avg:421.59ms
step:788/1500 train_loss:3.8565 train_time:327991ms step_avg:421.58ms
step:789/1500 train_loss:3.6495 train_time:328407ms step_avg:421.57ms
step:790/1500 train_loss:3.7114 train_time:328823ms step_avg:421.57ms
step:791/1500 train_loss:3.7782 train_time:329240ms step_avg:421.56ms
step:792/1500 train_loss:3.9080 train_time:329657ms step_avg:421.56ms
step:793/1500 train_loss:3.9132 train_time:330073ms step_avg:421.55ms
step:794/1500 train_loss:3.6166 train_time:330491ms step_avg:421.54ms
step:795/1500 train_loss:3.7544 train_time:330909ms step_avg:421.54ms
step:796/1500 train_loss:3.8115 train_time:331327ms step_avg:421.54ms
step:797/1500 train_loss:3.9173 train_time:331744ms step_avg:421.53ms
step:798/1500 train_loss:3.6662 train_time:332160ms step_avg:421.52ms
step:799/1500 train_loss:3.8096 train_time:332577ms step_avg:421.52ms
step:800/1500 train_loss:3.7056 train_time:332992ms step_avg:421.51ms
step:801/1500 train_loss:3.6926 train_time:333410ms step_avg:421.50ms
step:802/1500 train_loss:3.7856 train_time:333825ms step_avg:421.50ms
step:803/1500 train_loss:3.6436 train_time:334242ms step_avg:421.49ms
step:804/1500 train_loss:3.6588 train_time:334657ms step_avg:421.48ms
step:805/1500 train_loss:3.7790 train_time:335075ms step_avg:421.48ms
step:806/1500 train_loss:3.6806 train_time:335490ms step_avg:421.47ms
step:807/1500 train_loss:3.6952 train_time:335907ms step_avg:421.46ms
step:808/1500 train_loss:3.7922 train_time:336325ms step_avg:421.46ms
step:809/1500 train_loss:3.7057 train_time:336742ms step_avg:421.45ms
step:810/1500 train_loss:3.6343 train_time:337161ms step_avg:421.45ms
step:811/1500 train_loss:3.7195 train_time:337578ms step_avg:421.45ms
step:812/1500 train_loss:3.7477 train_time:337992ms step_avg:421.44ms
step:813/1500 train_loss:3.7445 train_time:338409ms step_avg:421.43ms
step:814/1500 train_loss:3.7759 train_time:338825ms step_avg:421.42ms
step:815/1500 train_loss:3.7257 train_time:339241ms step_avg:421.42ms
step:816/1500 train_loss:3.7093 train_time:339658ms step_avg:421.41ms
step:817/1500 train_loss:3.8218 train_time:340074ms step_avg:421.40ms
step:818/1500 train_loss:3.9057 train_time:340491ms step_avg:421.40ms
step:819/1500 train_loss:3.6740 train_time:340907ms step_avg:421.39ms
step:820/1500 train_loss:3.8722 train_time:341335ms step_avg:421.40ms
step:821/1500 train_loss:3.6576 train_time:341750ms step_avg:421.39ms
step:822/1500 train_loss:3.6986 train_time:342166ms step_avg:421.39ms
step:823/1500 train_loss:3.8195 train_time:342583ms step_avg:421.38ms
step:824/1500 train_loss:3.7345 train_time:342999ms step_avg:421.37ms
step:825/1500 train_loss:3.6654 train_time:343414ms step_avg:421.37ms
step:826/1500 train_loss:3.7632 train_time:343830ms step_avg:421.36ms
step:827/1500 train_loss:3.6512 train_time:344247ms step_avg:421.36ms
step:828/1500 train_loss:3.8838 train_time:344687ms step_avg:421.38ms
step:829/1500 train_loss:3.7678 train_time:345102ms step_avg:421.37ms
step:830/1500 train_loss:3.8258 train_time:345519ms step_avg:421.36ms
step:831/1500 train_loss:3.6867 train_time:345933ms step_avg:421.36ms
step:832/1500 train_loss:3.7325 train_time:346350ms step_avg:421.35ms
step:833/1500 train_loss:3.6614 train_time:346766ms step_avg:421.34ms
step:834/1500 train_loss:3.7939 train_time:347183ms step_avg:421.34ms
step:835/1500 train_loss:3.6248 train_time:347600ms step_avg:421.33ms
step:836/1500 train_loss:3.6066 train_time:348014ms step_avg:421.32ms
step:837/1500 train_loss:3.8705 train_time:348429ms step_avg:421.32ms
step:838/1500 train_loss:3.5673 train_time:348845ms step_avg:421.31ms
step:839/1500 train_loss:3.7404 train_time:349261ms step_avg:421.30ms
step:840/1500 train_loss:3.5812 train_time:349678ms step_avg:421.30ms
step:841/1500 train_loss:3.6222 train_time:350094ms step_avg:421.29ms
step:842/1500 train_loss:3.7076 train_time:350509ms step_avg:421.29ms
step:843/1500 train_loss:3.7242 train_time:350926ms step_avg:421.28ms
step:844/1500 train_loss:3.7299 train_time:351343ms step_avg:421.28ms
step:845/1500 train_loss:3.5781 train_time:351760ms step_avg:421.27ms
step:846/1500 train_loss:3.8149 train_time:352175ms step_avg:421.26ms
step:847/1500 train_loss:3.6800 train_time:352592ms step_avg:421.26ms
step:848/1500 train_loss:3.6347 train_time:353009ms step_avg:421.25ms
step:849/1500 train_loss:3.7790 train_time:353424ms step_avg:421.24ms
step:850/1500 train_loss:3.6480 train_time:353841ms step_avg:421.24ms
step:851/1500 train_loss:3.6047 train_time:354257ms step_avg:421.23ms
step:852/1500 train_loss:3.8836 train_time:354674ms step_avg:421.23ms
step:853/1500 train_loss:3.5991 train_time:355092ms step_avg:421.22ms
step:854/1500 train_loss:3.7100 train_time:355508ms step_avg:421.22ms
step:855/1500 train_loss:3.7915 train_time:355925ms step_avg:421.21ms
step:856/1500 train_loss:3.6729 train_time:356341ms step_avg:421.21ms
step:857/1500 train_loss:3.6978 train_time:356758ms step_avg:421.20ms
step:858/1500 train_loss:3.7489 train_time:357173ms step_avg:421.20ms
step:859/1500 train_loss:3.6332 train_time:357592ms step_avg:421.19ms
step:860/1500 train_loss:3.7035 train_time:358007ms step_avg:421.19ms
step:861/1500 train_loss:3.7403 train_time:358423ms step_avg:421.18ms
step:862/1500 train_loss:3.7906 train_time:358839ms step_avg:421.17ms
step:863/1500 train_loss:3.7419 train_time:359255ms step_avg:421.17ms
step:864/1500 train_loss:3.7242 train_time:359672ms step_avg:421.16ms
step:865/1500 train_loss:3.5431 train_time:360090ms step_avg:421.16ms
step:866/1500 train_loss:3.7338 train_time:360507ms step_avg:421.15ms
step:867/1500 train_loss:4.0119 train_time:360921ms step_avg:421.14ms
step:868/1500 train_loss:3.5965 train_time:361338ms step_avg:421.14ms
step:869/1500 train_loss:3.7824 train_time:361754ms step_avg:421.13ms
step:870/1500 train_loss:3.7581 train_time:362170ms step_avg:421.13ms
step:871/1500 train_loss:3.6021 train_time:362591ms step_avg:421.13ms
step:872/1500 train_loss:3.5550 train_time:363008ms step_avg:421.12ms
step:873/1500 train_loss:3.8081 train_time:363426ms step_avg:421.12ms
step:874/1500 train_loss:3.5981 train_time:363843ms step_avg:421.11ms
step:875/1500 train_loss:3.3276 train_time:364258ms step_avg:421.11ms
step:875/1500 val_loss:3.6716 train_time:364272ms step_avg:421.12ms
step:876/1500 train_loss:3.7892 train_time:364681ms step_avg:421.11ms
step:877/1500 train_loss:3.5930 train_time:365097ms step_avg:421.10ms
step:878/1500 train_loss:3.7684 train_time:365514ms step_avg:421.10ms
step:879/1500 train_loss:3.6270 train_time:365932ms step_avg:421.10ms
step:880/1500 train_loss:3.8107 train_time:366348ms step_avg:421.09ms
step:881/1500 train_loss:3.4713 train_time:366765ms step_avg:421.08ms
step:882/1500 train_loss:3.6423 train_time:367182ms step_avg:421.08ms
step:883/1500 train_loss:3.8394 train_time:367598ms step_avg:421.07ms
step:884/1500 train_loss:3.9924 train_time:368014ms step_avg:421.07ms
step:885/1500 train_loss:3.7118 train_time:368430ms step_avg:421.06ms
step:886/1500 train_loss:3.6286 train_time:368846ms step_avg:421.06ms
step:887/1500 train_loss:3.7284 train_time:369261ms step_avg:421.05ms
step:888/1500 train_loss:4.2259 train_time:369677ms step_avg:421.04ms
step:889/1500 train_loss:3.9948 train_time:370092ms step_avg:421.04ms
step:890/1500 train_loss:3.6694 train_time:370508ms step_avg:421.03ms
step:891/1500 train_loss:3.6775 train_time:370925ms step_avg:421.03ms
step:892/1500 train_loss:3.5061 train_time:371343ms step_avg:421.02ms
step:893/1500 train_loss:3.8520 train_time:371758ms step_avg:421.02ms
step:894/1500 train_loss:3.5754 train_time:372173ms step_avg:421.01ms
step:895/1500 train_loss:3.8262 train_time:372591ms step_avg:421.01ms
step:896/1500 train_loss:3.8378 train_time:373007ms step_avg:421.00ms
step:897/1500 train_loss:3.6365 train_time:373424ms step_avg:421.00ms
step:898/1500 train_loss:3.6808 train_time:373838ms step_avg:420.99ms
step:899/1500 train_loss:3.7357 train_time:374255ms step_avg:420.98ms
step:900/1500 train_loss:3.6189 train_time:374672ms step_avg:420.98ms
step:901/1500 train_loss:3.5617 train_time:375088ms step_avg:420.97ms
step:902/1500 train_loss:3.7758 train_time:375503ms step_avg:420.97ms
step:903/1500 train_loss:3.7800 train_time:375919ms step_avg:420.96ms
step:904/1500 train_loss:3.6773 train_time:376336ms step_avg:420.96ms
step:905/1500 train_loss:3.6449 train_time:376753ms step_avg:420.95ms
step:906/1500 train_loss:3.6384 train_time:377174ms step_avg:420.95ms
step:907/1500 train_loss:3.8597 train_time:377590ms step_avg:420.95ms
step:908/1500 train_loss:3.6513 train_time:378006ms step_avg:420.94ms
step:909/1500 train_loss:3.6951 train_time:378421ms step_avg:420.94ms
step:910/1500 train_loss:3.6046 train_time:378839ms step_avg:420.93ms
step:911/1500 train_loss:3.6921 train_time:379256ms step_avg:420.93ms
step:912/1500 train_loss:3.7707 train_time:379672ms step_avg:420.92ms
step:913/1500 train_loss:3.7546 train_time:380090ms step_avg:420.92ms
step:914/1500 train_loss:3.6240 train_time:380505ms step_avg:420.91ms
step:915/1500 train_loss:3.8800 train_time:380920ms step_avg:420.91ms
step:916/1500 train_loss:3.6726 train_time:381336ms step_avg:420.90ms
step:917/1500 train_loss:3.7737 train_time:381752ms step_avg:420.90ms
step:918/1500 train_loss:3.7364 train_time:382172ms step_avg:420.89ms
step:919/1500 train_loss:4.9715 train_time:382588ms step_avg:420.89ms
step:920/1500 train_loss:3.6553 train_time:383004ms step_avg:420.88ms
step:921/1500 train_loss:3.7173 train_time:383420ms step_avg:420.88ms
step:922/1500 train_loss:3.6803 train_time:383835ms step_avg:420.87ms
step:923/1500 train_loss:3.7264 train_time:384250ms step_avg:420.87ms
step:924/1500 train_loss:3.7359 train_time:384670ms step_avg:420.86ms
step:925/1500 train_loss:3.8311 train_time:385085ms step_avg:420.86ms
step:926/1500 train_loss:3.8019 train_time:385500ms step_avg:420.85ms
step:927/1500 train_loss:3.6997 train_time:385917ms step_avg:420.85ms
step:928/1500 train_loss:3.6924 train_time:386333ms step_avg:420.84ms
step:929/1500 train_loss:3.9179 train_time:386749ms step_avg:420.84ms
step:930/1500 train_loss:3.7611 train_time:387165ms step_avg:420.83ms
step:931/1500 train_loss:3.5455 train_time:387583ms step_avg:420.83ms
step:932/1500 train_loss:3.6330 train_time:387999ms step_avg:420.82ms
step:933/1500 train_loss:3.8188 train_time:388416ms step_avg:420.82ms
step:934/1500 train_loss:3.5282 train_time:388831ms step_avg:420.81ms
step:935/1500 train_loss:3.7154 train_time:389248ms step_avg:420.81ms
step:936/1500 train_loss:3.5917 train_time:389680ms step_avg:420.82ms
step:937/1500 train_loss:3.6536 train_time:390097ms step_avg:420.82ms
step:938/1500 train_loss:3.7534 train_time:390514ms step_avg:420.81ms
step:939/1500 train_loss:3.6787 train_time:390930ms step_avg:420.81ms
step:940/1500 train_loss:3.8353 train_time:391345ms step_avg:420.80ms
step:941/1500 train_loss:3.6289 train_time:391759ms step_avg:420.79ms
step:942/1500 train_loss:3.6880 train_time:392176ms step_avg:420.79ms
step:943/1500 train_loss:3.4916 train_time:392592ms step_avg:420.78ms
step:944/1500 train_loss:3.8392 train_time:393007ms step_avg:420.78ms
step:945/1500 train_loss:3.5540 train_time:393935ms step_avg:421.32ms
step:946/1500 train_loss:3.5655 train_time:394352ms step_avg:421.32ms
step:947/1500 train_loss:5.1856 train_time:394773ms step_avg:421.32ms
step:948/1500 train_loss:3.7384 train_time:395189ms step_avg:421.31ms
step:949/1500 train_loss:3.6427 train_time:395605ms step_avg:421.30ms
step:950/1500 train_loss:3.5337 train_time:396157ms step_avg:421.44ms
step:951/1500 train_loss:3.6012 train_time:396572ms step_avg:421.44ms
step:952/1500 train_loss:3.5466 train_time:396989ms step_avg:421.43ms
step:953/1500 train_loss:3.6195 train_time:397407ms step_avg:421.43ms
step:954/1500 train_loss:3.6988 train_time:397824ms step_avg:421.42ms
step:955/1500 train_loss:3.5835 train_time:398239ms step_avg:421.42ms
step:956/1500 train_loss:3.6118 train_time:398654ms step_avg:421.41ms
step:957/1500 train_loss:3.5848 train_time:399073ms step_avg:421.41ms
step:958/1500 train_loss:3.6402 train_time:399490ms step_avg:421.40ms
step:959/1500 train_loss:3.6403 train_time:399906ms step_avg:421.40ms
step:960/1500 train_loss:3.6514 train_time:400322ms step_avg:421.39ms
step:961/1500 train_loss:3.5318 train_time:400736ms step_avg:421.38ms
step:962/1500 train_loss:3.7926 train_time:401153ms step_avg:421.38ms
step:963/1500 train_loss:3.7373 train_time:401572ms step_avg:421.38ms
step:964/1500 train_loss:3.5529 train_time:401988ms step_avg:421.37ms
step:965/1500 train_loss:3.5877 train_time:402403ms step_avg:421.36ms
step:966/1500 train_loss:3.6252 train_time:402823ms step_avg:421.36ms
step:967/1500 train_loss:3.8486 train_time:403239ms step_avg:421.36ms
step:968/1500 train_loss:3.6710 train_time:403659ms step_avg:421.36ms
step:969/1500 train_loss:3.6592 train_time:404074ms step_avg:421.35ms
step:970/1500 train_loss:3.7144 train_time:404491ms step_avg:421.35ms
step:971/1500 train_loss:3.5315 train_time:404906ms step_avg:421.34ms
step:972/1500 train_loss:3.6821 train_time:405322ms step_avg:421.33ms
step:973/1500 train_loss:3.6295 train_time:405738ms step_avg:421.33ms
step:974/1500 train_loss:3.6800 train_time:406154ms step_avg:421.32ms
step:975/1500 train_loss:3.7524 train_time:406573ms step_avg:421.32ms
step:976/1500 train_loss:3.6252 train_time:406989ms step_avg:421.31ms
step:977/1500 train_loss:3.8224 train_time:407406ms step_avg:421.31ms
step:978/1500 train_loss:3.7078 train_time:407823ms step_avg:421.30ms
step:979/1500 train_loss:3.5273 train_time:408238ms step_avg:421.30ms
step:980/1500 train_loss:3.8236 train_time:408655ms step_avg:421.29ms
step:981/1500 train_loss:3.5616 train_time:409074ms step_avg:421.29ms
step:982/1500 train_loss:3.7257 train_time:409491ms step_avg:421.29ms
step:983/1500 train_loss:3.6983 train_time:409908ms step_avg:421.28ms
step:984/1500 train_loss:3.7004 train_time:410323ms step_avg:421.28ms
step:985/1500 train_loss:3.6597 train_time:410739ms step_avg:421.27ms
step:986/1500 train_loss:3.7293 train_time:411157ms step_avg:421.27ms
step:987/1500 train_loss:3.5473 train_time:411573ms step_avg:421.26ms
step:988/1500 train_loss:3.6363 train_time:411989ms step_avg:421.26ms
step:989/1500 train_loss:3.6302 train_time:412404ms step_avg:421.25ms
step:990/1500 train_loss:3.5734 train_time:412821ms step_avg:421.25ms
step:991/1500 train_loss:3.7900 train_time:413237ms step_avg:421.24ms
step:992/1500 train_loss:3.6076 train_time:413654ms step_avg:421.24ms
step:993/1500 train_loss:3.5865 train_time:414072ms step_avg:421.23ms
step:994/1500 train_loss:3.6492 train_time:414489ms step_avg:421.23ms
step:995/1500 train_loss:3.7428 train_time:414904ms step_avg:421.22ms
step:996/1500 train_loss:3.6844 train_time:415320ms step_avg:421.22ms
step:997/1500 train_loss:3.5974 train_time:415735ms step_avg:421.21ms
step:998/1500 train_loss:3.9464 train_time:416152ms step_avg:421.21ms
step:999/1500 train_loss:3.6041 train_time:416572ms step_avg:421.21ms
step:1000/1500 train_loss:3.7270 train_time:416988ms step_avg:421.20ms
step:1000/1500 val_loss:3.6252 train_time:417002ms step_avg:421.21ms
step:1001/1500 train_loss:3.5974 train_time:417411ms step_avg:421.20ms
step:1002/1500 train_loss:3.6478 train_time:417826ms step_avg:421.20ms
step:1003/1500 train_loss:3.5360 train_time:418244ms step_avg:421.19ms
step:1004/1500 train_loss:3.7182 train_time:418662ms step_avg:421.19ms
step:1005/1500 train_loss:3.7645 train_time:419078ms step_avg:421.18ms
step:1006/1500 train_loss:3.5433 train_time:419494ms step_avg:421.18ms
step:1007/1500 train_loss:3.6208 train_time:419910ms step_avg:421.17ms
step:1008/1500 train_loss:3.5869 train_time:420326ms step_avg:421.17ms
step:1009/1500 train_loss:3.7077 train_time:420744ms step_avg:421.17ms
step:1010/1500 train_loss:3.8149 train_time:421160ms step_avg:421.16ms
step:1011/1500 train_loss:3.7077 train_time:421575ms step_avg:421.15ms
step:1012/1500 train_loss:3.6752 train_time:421991ms step_avg:421.15ms
step:1013/1500 train_loss:3.5364 train_time:422407ms step_avg:421.14ms
step:1014/1500 train_loss:3.6746 train_time:422822ms step_avg:421.14ms
step:1015/1500 train_loss:3.7874 train_time:423239ms step_avg:421.13ms
step:1016/1500 train_loss:3.4926 train_time:423656ms step_avg:421.13ms
step:1017/1500 train_loss:3.5829 train_time:424070ms step_avg:421.12ms
step:1018/1500 train_loss:3.5823 train_time:424488ms step_avg:421.12ms
step:1019/1500 train_loss:3.5312 train_time:424904ms step_avg:421.11ms
step:1020/1500 train_loss:3.6740 train_time:425320ms step_avg:421.11ms
step:1021/1500 train_loss:3.5835 train_time:425736ms step_avg:421.10ms
step:1022/1500 train_loss:3.5168 train_time:426153ms step_avg:421.10ms
step:1023/1500 train_loss:3.6258 train_time:426569ms step_avg:421.10ms
step:1024/1500 train_loss:3.6559 train_time:426985ms step_avg:421.09ms
step:1025/1500 train_loss:3.6362 train_time:427400ms step_avg:421.08ms
step:1026/1500 train_loss:3.6401 train_time:427816ms step_avg:421.08ms
step:1027/1500 train_loss:3.8071 train_time:428233ms step_avg:421.07ms
step:1028/1500 train_loss:3.4815 train_time:428653ms step_avg:421.07ms
step:1029/1500 train_loss:3.5461 train_time:429070ms step_avg:421.07ms
step:1030/1500 train_loss:3.4993 train_time:429485ms step_avg:421.06ms
step:1031/1500 train_loss:3.6706 train_time:429902ms step_avg:421.06ms
step:1032/1500 train_loss:3.6487 train_time:430320ms step_avg:421.06ms
step:1033/1500 train_loss:3.8319 train_time:430735ms step_avg:421.05ms
step:1034/1500 train_loss:3.6462 train_time:431155ms step_avg:421.05ms
step:1035/1500 train_loss:3.5625 train_time:431572ms step_avg:421.05ms
step:1036/1500 train_loss:3.5924 train_time:431989ms step_avg:421.04ms
step:1037/1500 train_loss:3.6454 train_time:432405ms step_avg:421.04ms
step:1038/1500 train_loss:3.9608 train_time:432821ms step_avg:421.03ms
step:1039/1500 train_loss:3.7756 train_time:433238ms step_avg:421.03ms
step:1040/1500 train_loss:3.6742 train_time:433656ms step_avg:421.03ms
step:1041/1500 train_loss:3.5658 train_time:434072ms step_avg:421.02ms
step:1042/1500 train_loss:3.6406 train_time:434486ms step_avg:421.01ms
step:1043/1500 train_loss:3.6698 train_time:434902ms step_avg:421.01ms
step:1044/1500 train_loss:3.6032 train_time:435319ms step_avg:421.01ms
step:1045/1500 train_loss:3.6174 train_time:435734ms step_avg:421.00ms
step:1046/1500 train_loss:3.6877 train_time:436152ms step_avg:421.00ms
step:1047/1500 train_loss:3.5905 train_time:436568ms step_avg:420.99ms
step:1048/1500 train_loss:3.7975 train_time:436985ms step_avg:420.99ms
step:1049/1500 train_loss:3.6496 train_time:437402ms step_avg:420.98ms
step:1050/1500 train_loss:3.5749 train_time:437818ms step_avg:420.98ms
step:1051/1500 train_loss:3.5495 train_time:438235ms step_avg:420.98ms
step:1052/1500 train_loss:3.6677 train_time:438654ms step_avg:420.97ms
step:1053/1500 train_loss:3.5392 train_time:439071ms step_avg:420.97ms
step:1054/1500 train_loss:3.8660 train_time:439487ms step_avg:420.96ms
step:1055/1500 train_loss:3.6987 train_time:439903ms step_avg:420.96ms
step:1056/1500 train_loss:3.5628 train_time:440319ms step_avg:420.96ms
step:1057/1500 train_loss:3.6592 train_time:440735ms step_avg:420.95ms
step:1058/1500 train_loss:3.7379 train_time:441153ms step_avg:420.95ms
step:1059/1500 train_loss:3.4588 train_time:441568ms step_avg:420.94ms
step:1060/1500 train_loss:3.5723 train_time:441985ms step_avg:420.94ms
step:1061/1500 train_loss:3.5989 train_time:442401ms step_avg:420.93ms
step:1062/1500 train_loss:3.5734 train_time:442815ms step_avg:420.93ms
step:1063/1500 train_loss:3.5438 train_time:443231ms step_avg:420.92ms
step:1064/1500 train_loss:3.6445 train_time:443650ms step_avg:420.92ms
step:1065/1500 train_loss:3.5457 train_time:444067ms step_avg:420.92ms
step:1066/1500 train_loss:3.5358 train_time:444482ms step_avg:420.91ms
step:1067/1500 train_loss:3.5635 train_time:444898ms step_avg:420.91ms
step:1068/1500 train_loss:3.4679 train_time:445314ms step_avg:420.90ms
step:1069/1500 train_loss:3.5866 train_time:445730ms step_avg:420.90ms
step:1070/1500 train_loss:3.4602 train_time:446150ms step_avg:420.90ms
step:1071/1500 train_loss:3.7171 train_time:446566ms step_avg:420.89ms
step:1072/1500 train_loss:3.6651 train_time:446982ms step_avg:420.89ms
step:1073/1500 train_loss:3.6121 train_time:447399ms step_avg:420.88ms
step:1074/1500 train_loss:3.6750 train_time:447814ms step_avg:420.88ms
step:1075/1500 train_loss:3.6209 train_time:448231ms step_avg:420.87ms
step:1076/1500 train_loss:3.5632 train_time:448653ms step_avg:420.88ms
step:1077/1500 train_loss:3.9573 train_time:449068ms step_avg:420.87ms
step:1078/1500 train_loss:3.6246 train_time:449485ms step_avg:420.87ms
step:1079/1500 train_loss:3.3394 train_time:449901ms step_avg:420.86ms
step:1080/1500 train_loss:3.6997 train_time:450317ms step_avg:420.86ms
step:1081/1500 train_loss:3.6070 train_time:450734ms step_avg:420.85ms
step:1082/1500 train_loss:3.6634 train_time:451153ms step_avg:420.85ms
step:1083/1500 train_loss:3.7746 train_time:451568ms step_avg:420.85ms
step:1084/1500 train_loss:3.6685 train_time:451982ms step_avg:420.84ms
step:1085/1500 train_loss:3.6352 train_time:452397ms step_avg:420.83ms
step:1086/1500 train_loss:3.6119 train_time:452815ms step_avg:420.83ms
step:1087/1500 train_loss:3.7987 train_time:453232ms step_avg:420.83ms
step:1088/1500 train_loss:3.6852 train_time:453662ms step_avg:420.84ms
step:1089/1500 train_loss:3.5232 train_time:454078ms step_avg:420.83ms
step:1090/1500 train_loss:3.5522 train_time:454494ms step_avg:420.83ms
step:1091/1500 train_loss:3.6645 train_time:454909ms step_avg:420.82ms
step:1092/1500 train_loss:3.4570 train_time:455326ms step_avg:420.82ms
step:1093/1500 train_loss:3.6591 train_time:455742ms step_avg:420.81ms
step:1094/1500 train_loss:3.7909 train_time:456158ms step_avg:420.81ms
step:1095/1500 train_loss:3.6347 train_time:456574ms step_avg:420.81ms
step:1096/1500 train_loss:3.5843 train_time:456991ms step_avg:420.80ms
step:1097/1500 train_loss:3.6036 train_time:457407ms step_avg:420.80ms
step:1098/1500 train_loss:3.6517 train_time:457822ms step_avg:420.79ms
step:1099/1500 train_loss:3.7258 train_time:458239ms step_avg:420.79ms
step:1100/1500 train_loss:3.6822 train_time:458653ms step_avg:420.78ms
step:1101/1500 train_loss:3.6062 train_time:459070ms step_avg:420.78ms
step:1102/1500 train_loss:3.4686 train_time:459485ms step_avg:420.77ms
step:1103/1500 train_loss:3.5436 train_time:459901ms step_avg:420.77ms
step:1104/1500 train_loss:3.6174 train_time:460318ms step_avg:420.77ms
step:1105/1500 train_loss:3.4962 train_time:460735ms step_avg:420.76ms
step:1106/1500 train_loss:4.2534 train_time:461154ms step_avg:420.76ms
step:1107/1500 train_loss:3.3974 train_time:461569ms step_avg:420.76ms
step:1108/1500 train_loss:3.7339 train_time:461986ms step_avg:420.75ms
step:1109/1500 train_loss:3.5225 train_time:462402ms step_avg:420.75ms
step:1110/1500 train_loss:3.6655 train_time:462816ms step_avg:420.74ms
step:1111/1500 train_loss:3.5993 train_time:463234ms step_avg:420.74ms
step:1112/1500 train_loss:3.6455 train_time:463652ms step_avg:420.74ms
step:1113/1500 train_loss:3.7423 train_time:464068ms step_avg:420.73ms
step:1114/1500 train_loss:3.5989 train_time:464485ms step_avg:420.73ms
step:1115/1500 train_loss:3.5439 train_time:464901ms step_avg:420.72ms
step:1116/1500 train_loss:3.4345 train_time:465316ms step_avg:420.72ms
step:1117/1500 train_loss:3.6094 train_time:465731ms step_avg:420.71ms
step:1118/1500 train_loss:3.7567 train_time:466151ms step_avg:420.71ms
step:1119/1500 train_loss:3.8018 train_time:466565ms step_avg:420.71ms
step:1120/1500 train_loss:3.6367 train_time:466981ms step_avg:420.70ms
step:1121/1500 train_loss:3.6639 train_time:467396ms step_avg:420.70ms
step:1122/1500 train_loss:3.5571 train_time:467812ms step_avg:420.69ms
step:1123/1500 train_loss:3.6225 train_time:468228ms step_avg:420.69ms
step:1124/1500 train_loss:3.7611 train_time:468644ms step_avg:420.69ms
step:1125/1500 train_loss:3.5274 train_time:469061ms step_avg:420.68ms
step:1125/1500 val_loss:3.5882 train_time:469074ms step_avg:420.69ms
step:1126/1500 train_loss:3.4184 train_time:469479ms step_avg:420.68ms
step:1127/1500 train_loss:3.6464 train_time:469894ms step_avg:420.67ms
step:1128/1500 train_loss:3.8672 train_time:470310ms step_avg:420.67ms
step:1129/1500 train_loss:3.4090 train_time:470729ms step_avg:420.67ms
step:1130/1500 train_loss:3.7268 train_time:471145ms step_avg:420.66ms
step:1131/1500 train_loss:3.5596 train_time:471559ms step_avg:420.66ms
step:1132/1500 train_loss:3.5837 train_time:471975ms step_avg:420.65ms
step:1133/1500 train_loss:3.5402 train_time:472390ms step_avg:420.65ms
step:1134/1500 train_loss:3.6974 train_time:473388ms step_avg:421.16ms
step:1135/1500 train_loss:3.6295 train_time:473805ms step_avg:421.16ms
step:1136/1500 train_loss:3.6877 train_time:474221ms step_avg:421.16ms
step:1137/1500 train_loss:3.7201 train_time:474637ms step_avg:421.15ms
step:1138/1500 train_loss:3.6341 train_time:475053ms step_avg:421.15ms
step:1139/1500 train_loss:3.5343 train_time:475470ms step_avg:421.14ms
step:1140/1500 train_loss:3.8381 train_time:476014ms step_avg:421.25ms
step:1141/1500 train_loss:3.6385 train_time:476430ms step_avg:421.25ms
step:1142/1500 train_loss:3.7381 train_time:476846ms step_avg:421.24ms
step:1143/1500 train_loss:3.6306 train_time:477262ms step_avg:421.24ms
step:1144/1500 train_loss:3.5425 train_time:477677ms step_avg:421.23ms
step:1145/1500 train_loss:3.6418 train_time:478093ms step_avg:421.23ms
step:1146/1500 train_loss:3.7659 train_time:478509ms step_avg:421.22ms
step:1147/1500 train_loss:3.7341 train_time:478929ms step_avg:421.22ms
step:1148/1500 train_loss:3.6501 train_time:479347ms step_avg:421.22ms
step:1149/1500 train_loss:3.6751 train_time:479765ms step_avg:421.22ms
step:1150/1500 train_loss:3.5217 train_time:480180ms step_avg:421.21ms
step:1151/1500 train_loss:3.5483 train_time:480595ms step_avg:421.20ms
step:1152/1500 train_loss:3.5105 train_time:481009ms step_avg:421.20ms
step:1153/1500 train_loss:3.6484 train_time:481429ms step_avg:421.20ms
step:1154/1500 train_loss:3.6238 train_time:481844ms step_avg:421.19ms
step:1155/1500 train_loss:3.6910 train_time:482261ms step_avg:421.19ms
step:1156/1500 train_loss:3.5427 train_time:482675ms step_avg:421.18ms
step:1157/1500 train_loss:3.7139 train_time:483091ms step_avg:421.18ms
step:1158/1500 train_loss:3.6664 train_time:483509ms step_avg:421.17ms
step:1159/1500 train_loss:3.4768 train_time:483928ms step_avg:421.17ms
step:1160/1500 train_loss:3.5171 train_time:484344ms step_avg:421.17ms
step:1161/1500 train_loss:3.5057 train_time:484761ms step_avg:421.17ms
step:1162/1500 train_loss:3.3006 train_time:485178ms step_avg:421.16ms
step:1163/1500 train_loss:3.6182 train_time:485597ms step_avg:421.16ms
step:1164/1500 train_loss:3.5893 train_time:486013ms step_avg:421.16ms
step:1165/1500 train_loss:3.4587 train_time:486431ms step_avg:421.15ms
step:1166/1500 train_loss:3.4446 train_time:486849ms step_avg:421.15ms
step:1167/1500 train_loss:3.5592 train_time:487264ms step_avg:421.14ms
step:1168/1500 train_loss:3.5702 train_time:487680ms step_avg:421.14ms
step:1169/1500 train_loss:3.8897 train_time:488095ms step_avg:421.13ms
step:1170/1500 train_loss:3.5688 train_time:488512ms step_avg:421.13ms
step:1171/1500 train_loss:3.5802 train_time:488930ms step_avg:421.13ms
step:1172/1500 train_loss:3.4720 train_time:489348ms step_avg:421.13ms
step:1173/1500 train_loss:3.5876 train_time:489763ms step_avg:421.12ms
step:1174/1500 train_loss:3.7190 train_time:490179ms step_avg:421.12ms
step:1175/1500 train_loss:3.5634 train_time:490600ms step_avg:421.12ms
step:1176/1500 train_loss:3.5793 train_time:491015ms step_avg:421.11ms
step:1177/1500 train_loss:3.6305 train_time:491432ms step_avg:421.11ms
step:1178/1500 train_loss:3.6151 train_time:491848ms step_avg:421.10ms
step:1179/1500 train_loss:3.6669 train_time:492264ms step_avg:421.10ms
step:1180/1500 train_loss:3.5771 train_time:492680ms step_avg:421.09ms
step:1181/1500 train_loss:3.5887 train_time:493097ms step_avg:421.09ms
step:1182/1500 train_loss:3.5291 train_time:493512ms step_avg:421.09ms
step:1183/1500 train_loss:3.5626 train_time:493933ms step_avg:421.09ms
step:1184/1500 train_loss:3.5141 train_time:494349ms step_avg:421.08ms
step:1185/1500 train_loss:3.6820 train_time:494764ms step_avg:421.08ms
step:1186/1500 train_loss:3.7444 train_time:495180ms step_avg:421.07ms
step:1187/1500 train_loss:3.5418 train_time:495603ms step_avg:421.07ms
step:1188/1500 train_loss:3.5958 train_time:496019ms step_avg:421.07ms
step:1189/1500 train_loss:3.6156 train_time:496436ms step_avg:421.07ms
step:1190/1500 train_loss:3.4562 train_time:496852ms step_avg:421.06ms
step:1191/1500 train_loss:3.6319 train_time:497269ms step_avg:421.06ms
step:1192/1500 train_loss:3.7802 train_time:497684ms step_avg:421.05ms
step:1193/1500 train_loss:3.5798 train_time:498100ms step_avg:421.05ms
step:1194/1500 train_loss:3.4621 train_time:498517ms step_avg:421.04ms
step:1195/1500 train_loss:3.7618 train_time:498931ms step_avg:421.04ms
step:1196/1500 train_loss:3.5554 train_time:499347ms step_avg:421.03ms
step:1197/1500 train_loss:3.5659 train_time:499763ms step_avg:421.03ms
step:1198/1500 train_loss:3.4678 train_time:500180ms step_avg:421.03ms
step:1199/1500 train_loss:3.4760 train_time:500594ms step_avg:421.02ms
step:1200/1500 train_loss:3.5264 train_time:501012ms step_avg:421.02ms
step:1201/1500 train_loss:3.6136 train_time:501431ms step_avg:421.02ms
step:1202/1500 train_loss:3.6885 train_time:501847ms step_avg:421.01ms
step:1203/1500 train_loss:3.7211 train_time:502261ms step_avg:421.01ms
step:1204/1500 train_loss:3.5940 train_time:502678ms step_avg:421.00ms
step:1205/1500 train_loss:3.5137 train_time:503093ms step_avg:421.00ms
step:1206/1500 train_loss:3.6097 train_time:503510ms step_avg:420.99ms
step:1207/1500 train_loss:3.6540 train_time:503929ms step_avg:420.99ms
step:1208/1500 train_loss:3.7000 train_time:504345ms step_avg:420.99ms
step:1209/1500 train_loss:3.5828 train_time:504762ms step_avg:420.99ms
step:1210/1500 train_loss:3.4459 train_time:505178ms step_avg:420.98ms
step:1211/1500 train_loss:3.4906 train_time:505594ms step_avg:420.98ms
step:1212/1500 train_loss:3.5880 train_time:506010ms step_avg:420.97ms
step:1213/1500 train_loss:3.5954 train_time:506430ms step_avg:420.97ms
step:1214/1500 train_loss:3.6286 train_time:506847ms step_avg:420.97ms
step:1215/1500 train_loss:3.5033 train_time:507262ms step_avg:420.96ms
step:1216/1500 train_loss:3.5821 train_time:507678ms step_avg:420.96ms
step:1217/1500 train_loss:3.5266 train_time:508093ms step_avg:420.95ms
step:1218/1500 train_loss:3.5188 train_time:508508ms step_avg:420.95ms
step:1219/1500 train_loss:3.6108 train_time:508930ms step_avg:420.95ms
step:1220/1500 train_loss:3.4414 train_time:509345ms step_avg:420.95ms
step:1221/1500 train_loss:3.6767 train_time:509775ms step_avg:420.95ms
step:1222/1500 train_loss:3.7064 train_time:510190ms step_avg:420.95ms
step:1223/1500 train_loss:3.6184 train_time:510606ms step_avg:420.94ms
step:1224/1500 train_loss:3.4842 train_time:511022ms step_avg:420.94ms
step:1225/1500 train_loss:3.4743 train_time:511440ms step_avg:420.94ms
step:1226/1500 train_loss:3.5508 train_time:511855ms step_avg:420.93ms
step:1227/1500 train_loss:3.5383 train_time:512269ms step_avg:420.93ms
step:1228/1500 train_loss:3.4790 train_time:512685ms step_avg:420.92ms
step:1229/1500 train_loss:3.6443 train_time:513101ms step_avg:420.92ms
step:1230/1500 train_loss:3.5662 train_time:513518ms step_avg:420.92ms
step:1231/1500 train_loss:3.6208 train_time:513934ms step_avg:420.91ms
step:1232/1500 train_loss:3.7792 train_time:514351ms step_avg:420.91ms
step:1233/1500 train_loss:3.6806 train_time:514766ms step_avg:420.90ms
step:1234/1500 train_loss:3.6165 train_time:515182ms step_avg:420.90ms
step:1235/1500 train_loss:3.7653 train_time:515598ms step_avg:420.90ms
step:1236/1500 train_loss:3.5297 train_time:516014ms step_avg:420.89ms
step:1237/1500 train_loss:3.4949 train_time:516433ms step_avg:420.89ms
step:1238/1500 train_loss:3.4467 train_time:516850ms step_avg:420.89ms
step:1239/1500 train_loss:3.5169 train_time:517266ms step_avg:420.88ms
step:1240/1500 train_loss:3.5343 train_time:517680ms step_avg:420.88ms
step:1241/1500 train_loss:3.5700 train_time:518096ms step_avg:420.87ms
step:1242/1500 train_loss:3.6232 train_time:518512ms step_avg:420.87ms
step:1243/1500 train_loss:3.4925 train_time:518932ms step_avg:420.87ms
step:1244/1500 train_loss:3.5904 train_time:519349ms step_avg:420.87ms
step:1245/1500 train_loss:3.6000 train_time:519764ms step_avg:420.86ms
step:1246/1500 train_loss:3.6072 train_time:520181ms step_avg:420.86ms
step:1247/1500 train_loss:3.4395 train_time:520597ms step_avg:420.85ms
step:1248/1500 train_loss:3.5803 train_time:521013ms step_avg:420.85ms
step:1249/1500 train_loss:3.6271 train_time:521432ms step_avg:420.85ms
step:1250/1500 train_loss:3.6138 train_time:521848ms step_avg:420.85ms
step:1250/1500 val_loss:3.5560 train_time:521862ms step_avg:420.86ms
step:1251/1500 train_loss:3.5041 train_time:522270ms step_avg:420.85ms
step:1252/1500 train_loss:3.7071 train_time:522685ms step_avg:420.84ms
step:1253/1500 train_loss:3.5747 train_time:523100ms step_avg:420.84ms
step:1254/1500 train_loss:3.5041 train_time:523515ms step_avg:420.83ms
step:1255/1500 train_loss:3.6389 train_time:523932ms step_avg:420.83ms
step:1256/1500 train_loss:3.7025 train_time:524348ms step_avg:420.83ms
step:1257/1500 train_loss:3.5115 train_time:524763ms step_avg:420.82ms
step:1258/1500 train_loss:3.5433 train_time:525180ms step_avg:420.82ms
step:1259/1500 train_loss:3.5936 train_time:525595ms step_avg:420.81ms
step:1260/1500 train_loss:3.5348 train_time:526013ms step_avg:420.81ms
step:1261/1500 train_loss:3.3993 train_time:526427ms step_avg:420.81ms
step:1262/1500 train_loss:3.5027 train_time:526843ms step_avg:420.80ms
step:1263/1500 train_loss:3.5784 train_time:527260ms step_avg:420.80ms
step:1264/1500 train_loss:3.4197 train_time:527677ms step_avg:420.79ms
step:1265/1500 train_loss:3.6405 train_time:528094ms step_avg:420.79ms
step:1266/1500 train_loss:3.6215 train_time:528512ms step_avg:420.79ms
step:1267/1500 train_loss:3.6258 train_time:528928ms step_avg:420.79ms
step:1268/1500 train_loss:3.5697 train_time:529343ms step_avg:420.78ms
step:1269/1500 train_loss:3.6042 train_time:529759ms step_avg:420.78ms
step:1270/1500 train_loss:3.4562 train_time:530174ms step_avg:420.77ms
step:1271/1500 train_loss:3.3118 train_time:530590ms step_avg:420.77ms
step:1272/1500 train_loss:3.5848 train_time:531010ms step_avg:420.77ms
step:1273/1500 train_loss:3.5483 train_time:531426ms step_avg:420.76ms
step:1274/1500 train_loss:3.5974 train_time:531843ms step_avg:420.76ms
step:1275/1500 train_loss:3.5518 train_time:532258ms step_avg:420.76ms
step:1276/1500 train_loss:3.6476 train_time:532672ms step_avg:420.75ms
step:1277/1500 train_loss:3.6638 train_time:533088ms step_avg:420.75ms
step:1278/1500 train_loss:3.6221 train_time:533504ms step_avg:420.74ms
step:1279/1500 train_loss:3.6213 train_time:533920ms step_avg:420.74ms
step:1280/1500 train_loss:3.4508 train_time:534337ms step_avg:420.74ms
step:1281/1500 train_loss:3.5612 train_time:534754ms step_avg:420.73ms
step:1282/1500 train_loss:3.6320 train_time:535170ms step_avg:420.73ms
step:1283/1500 train_loss:3.6641 train_time:535586ms step_avg:420.73ms
step:1284/1500 train_loss:3.5539 train_time:536004ms step_avg:420.73ms
step:1285/1500 train_loss:3.5767 train_time:536420ms step_avg:420.72ms
step:1286/1500 train_loss:3.5636 train_time:536836ms step_avg:420.72ms
step:1287/1500 train_loss:3.5378 train_time:537252ms step_avg:420.71ms
step:1288/1500 train_loss:3.6725 train_time:537668ms step_avg:420.71ms
step:1289/1500 train_loss:3.5019 train_time:538085ms step_avg:420.71ms
step:1290/1500 train_loss:3.5903 train_time:538502ms step_avg:420.70ms
step:1291/1500 train_loss:3.6605 train_time:538918ms step_avg:420.70ms
step:1292/1500 train_loss:3.5867 train_time:539333ms step_avg:420.70ms
step:1293/1500 train_loss:3.6869 train_time:539750ms step_avg:420.69ms
step:1294/1500 train_loss:3.7064 train_time:540166ms step_avg:420.69ms
step:1295/1500 train_loss:3.6687 train_time:540582ms step_avg:420.69ms
step:1296/1500 train_loss:3.4747 train_time:540999ms step_avg:420.68ms
step:1297/1500 train_loss:3.5628 train_time:541415ms step_avg:420.68ms
step:1298/1500 train_loss:3.4622 train_time:541833ms step_avg:420.68ms
step:1299/1500 train_loss:3.5288 train_time:542249ms step_avg:420.67ms
step:1300/1500 train_loss:3.6026 train_time:542663ms step_avg:420.67ms
step:1301/1500 train_loss:3.6126 train_time:543079ms step_avg:420.67ms
step:1302/1500 train_loss:3.6123 train_time:543496ms step_avg:420.66ms
step:1303/1500 train_loss:3.7670 train_time:543914ms step_avg:420.66ms
step:1304/1500 train_loss:3.5432 train_time:544329ms step_avg:420.66ms
step:1305/1500 train_loss:3.7375 train_time:544745ms step_avg:420.65ms
step:1306/1500 train_loss:3.4698 train_time:545161ms step_avg:420.65ms
step:1307/1500 train_loss:3.6617 train_time:545576ms step_avg:420.64ms
step:1308/1500 train_loss:3.6617 train_time:545992ms step_avg:420.64ms
step:1309/1500 train_loss:3.5239 train_time:546412ms step_avg:420.64ms
step:1310/1500 train_loss:3.4945 train_time:546829ms step_avg:420.64ms
step:1311/1500 train_loss:3.4953 train_time:547246ms step_avg:420.64ms
step:1312/1500 train_loss:3.4924 train_time:547663ms step_avg:420.63ms
step:1313/1500 train_loss:3.6002 train_time:548079ms step_avg:420.63ms
step:1314/1500 train_loss:3.5504 train_time:548496ms step_avg:420.63ms
step:1315/1500 train_loss:3.2716 train_time:548913ms step_avg:420.62ms
step:1316/1500 train_loss:3.5059 train_time:549329ms step_avg:420.62ms
step:1317/1500 train_loss:3.5863 train_time:549746ms step_avg:420.62ms
step:1318/1500 train_loss:3.6058 train_time:550163ms step_avg:420.61ms
step:1319/1500 train_loss:3.4960 train_time:550580ms step_avg:420.61ms
step:1320/1500 train_loss:3.6271 train_time:550996ms step_avg:420.61ms
step:1321/1500 train_loss:3.6823 train_time:551414ms step_avg:420.61ms
step:1322/1500 train_loss:3.5668 train_time:551829ms step_avg:420.60ms
step:1323/1500 train_loss:3.5132 train_time:552736ms step_avg:420.97ms
step:1324/1500 train_loss:3.5425 train_time:553155ms step_avg:420.97ms
step:1325/1500 train_loss:3.6369 train_time:553570ms step_avg:420.97ms
step:1326/1500 train_loss:3.6950 train_time:553985ms step_avg:420.96ms
step:1327/1500 train_loss:3.4462 train_time:554402ms step_avg:420.96ms
step:1328/1500 train_loss:3.3670 train_time:554819ms step_avg:420.96ms
step:1329/1500 train_loss:3.6910 train_time:555234ms step_avg:420.95ms
step:1330/1500 train_loss:3.5335 train_time:555784ms step_avg:421.05ms
step:1331/1500 train_loss:3.6420 train_time:556199ms step_avg:421.04ms
step:1332/1500 train_loss:3.5525 train_time:556615ms step_avg:421.04ms
step:1333/1500 train_loss:3.9517 train_time:557031ms step_avg:421.04ms
step:1334/1500 train_loss:3.6621 train_time:557447ms step_avg:421.03ms
step:1335/1500 train_loss:3.5674 train_time:557862ms step_avg:421.03ms
step:1336/1500 train_loss:3.5090 train_time:558280ms step_avg:421.03ms
step:1337/1500 train_loss:3.5070 train_time:558695ms step_avg:421.02ms
step:1338/1500 train_loss:3.7662 train_time:559111ms step_avg:421.02ms
step:1339/1500 train_loss:3.6988 train_time:559527ms step_avg:421.01ms
step:1340/1500 train_loss:3.5419 train_time:559944ms step_avg:421.01ms
step:1341/1500 train_loss:3.5017 train_time:560357ms step_avg:421.00ms
step:1342/1500 train_loss:3.8091 train_time:560772ms step_avg:421.00ms
step:1343/1500 train_loss:3.5748 train_time:561189ms step_avg:421.00ms
step:1344/1500 train_loss:3.5782 train_time:561608ms step_avg:421.00ms
step:1345/1500 train_loss:3.6287 train_time:562025ms step_avg:420.99ms
step:1346/1500 train_loss:3.5988 train_time:562442ms step_avg:420.99ms
step:1347/1500 train_loss:3.5031 train_time:562858ms step_avg:420.99ms
step:1348/1500 train_loss:3.4572 train_time:563275ms step_avg:420.98ms
step:1349/1500 train_loss:3.5484 train_time:563690ms step_avg:420.98ms
step:1350/1500 train_loss:3.4770 train_time:564108ms step_avg:420.98ms
step:1351/1500 train_loss:3.6053 train_time:564524ms step_avg:420.97ms
step:1352/1500 train_loss:3.4608 train_time:564944ms step_avg:420.97ms
step:1353/1500 train_loss:3.5198 train_time:565360ms step_avg:420.97ms
step:1354/1500 train_loss:3.6227 train_time:565776ms step_avg:420.96ms
step:1355/1500 train_loss:3.4710 train_time:566193ms step_avg:420.96ms
step:1356/1500 train_loss:3.3898 train_time:566613ms step_avg:420.96ms
step:1357/1500 train_loss:3.7352 train_time:567076ms step_avg:420.99ms
step:1358/1500 train_loss:3.6715 train_time:567491ms step_avg:420.99ms
step:1359/1500 train_loss:3.3895 train_time:567909ms step_avg:420.99ms
step:1360/1500 train_loss:3.6590 train_time:568327ms step_avg:420.98ms
step:1361/1500 train_loss:3.5493 train_time:568743ms step_avg:420.98ms
step:1362/1500 train_loss:3.3908 train_time:569159ms step_avg:420.98ms
step:1363/1500 train_loss:3.5903 train_time:569576ms step_avg:420.97ms
step:1364/1500 train_loss:3.4881 train_time:569992ms step_avg:420.97ms
step:1365/1500 train_loss:3.5078 train_time:570411ms step_avg:420.97ms
step:1366/1500 train_loss:3.5268 train_time:570827ms step_avg:420.96ms
step:1367/1500 train_loss:3.6287 train_time:571243ms step_avg:420.96ms
step:1368/1500 train_loss:3.6181 train_time:571658ms step_avg:420.96ms
step:1369/1500 train_loss:3.5625 train_time:572074ms step_avg:420.95ms
step:1370/1500 train_loss:3.4822 train_time:572490ms step_avg:420.95ms
step:1371/1500 train_loss:3.8059 train_time:572909ms step_avg:420.95ms
step:1372/1500 train_loss:3.5411 train_time:573325ms step_avg:420.94ms
step:1373/1500 train_loss:3.5816 train_time:573740ms step_avg:420.94ms
step:1374/1500 train_loss:3.5775 train_time:574157ms step_avg:420.94ms
step:1375/1500 train_loss:3.3719 train_time:574574ms step_avg:420.93ms
step:1375/1500 val_loss:3.5315 train_time:574587ms step_avg:420.94ms
step:1376/1500 train_loss:3.7607 train_time:574990ms step_avg:420.93ms
step:1377/1500 train_loss:3.5558 train_time:575406ms step_avg:420.93ms
step:1378/1500 train_loss:3.7011 train_time:575821ms step_avg:420.92ms
step:1379/1500 train_loss:3.7282 train_time:576238ms step_avg:420.92ms
step:1380/1500 train_loss:3.3627 train_time:576653ms step_avg:420.91ms
step:1381/1500 train_loss:3.5314 train_time:577069ms step_avg:420.91ms
step:1382/1500 train_loss:3.9616 train_time:577486ms step_avg:420.91ms
step:1383/1500 train_loss:3.4447 train_time:577902ms step_avg:420.90ms
step:1384/1500 train_loss:3.6085 train_time:578319ms step_avg:420.90ms
step:1385/1500 train_loss:3.6781 train_time:578733ms step_avg:420.90ms
step:1386/1500 train_loss:3.5958 train_time:579149ms step_avg:420.89ms
step:1387/1500 train_loss:3.5734 train_time:579564ms step_avg:420.89ms
step:1388/1500 train_loss:3.4167 train_time:579981ms step_avg:420.89ms
step:1389/1500 train_loss:3.5585 train_time:580397ms step_avg:420.88ms
step:1390/1500 train_loss:3.5312 train_time:580813ms step_avg:420.88ms
step:1391/1500 train_loss:3.7970 train_time:581229ms step_avg:420.88ms
step:1392/1500 train_loss:3.5066 train_time:581645ms step_avg:420.87ms
step:1393/1500 train_loss:3.5014 train_time:582060ms step_avg:420.87ms
step:1394/1500 train_loss:3.4672 train_time:582476ms step_avg:420.86ms
step:1395/1500 train_loss:3.7475 train_time:582892ms step_avg:420.86ms
step:1396/1500 train_loss:3.6414 train_time:583307ms step_avg:420.86ms
step:1397/1500 train_loss:3.6488 train_time:583723ms step_avg:420.85ms
step:1398/1500 train_loss:3.5164 train_time:584140ms step_avg:420.85ms
step:1399/1500 train_loss:3.4894 train_time:584556ms step_avg:420.85ms
step:1400/1500 train_loss:3.5526 train_time:584973ms step_avg:420.84ms
step:1401/1500 train_loss:3.5280 train_time:585390ms step_avg:420.84ms
step:1402/1500 train_loss:3.5531 train_time:585807ms step_avg:420.84ms
step:1403/1500 train_loss:3.5183 train_time:586223ms step_avg:420.83ms
step:1404/1500 train_loss:3.7433 train_time:586640ms step_avg:420.83ms
step:1405/1500 train_loss:3.4896 train_time:587056ms step_avg:420.83ms
step:1406/1500 train_loss:3.5334 train_time:587471ms step_avg:420.82ms
step:1407/1500 train_loss:3.5320 train_time:587888ms step_avg:420.82ms
step:1408/1500 train_loss:3.3983 train_time:588303ms step_avg:420.82ms
step:1409/1500 train_loss:3.5241 train_time:588719ms step_avg:420.81ms
step:1410/1500 train_loss:3.5033 train_time:589135ms step_avg:420.81ms
step:1411/1500 train_loss:3.5007 train_time:589549ms step_avg:420.81ms
step:1412/1500 train_loss:3.5854 train_time:589965ms step_avg:420.80ms
step:1413/1500 train_loss:3.5287 train_time:590384ms step_avg:420.80ms
step:1414/1500 train_loss:3.5726 train_time:590801ms step_avg:420.80ms
step:1415/1500 train_loss:3.5624 train_time:591217ms step_avg:420.80ms
step:1416/1500 train_loss:3.6397 train_time:591632ms step_avg:420.79ms
step:1417/1500 train_loss:3.4445 train_time:592049ms step_avg:420.79ms
step:1418/1500 train_loss:3.5095 train_time:592465ms step_avg:420.78ms
step:1419/1500 train_loss:3.6037 train_time:592885ms step_avg:420.78ms
step:1420/1500 train_loss:3.6291 train_time:593301ms step_avg:420.78ms
step:1421/1500 train_loss:3.6074 train_time:593717ms step_avg:420.78ms
step:1422/1500 train_loss:3.5877 train_time:594133ms step_avg:420.77ms
step:1423/1500 train_loss:3.5629 train_time:594549ms step_avg:420.77ms
step:1424/1500 train_loss:3.5567 train_time:594963ms step_avg:420.77ms
step:1425/1500 train_loss:3.5630 train_time:595379ms step_avg:420.76ms
step:1426/1500 train_loss:3.4336 train_time:595795ms step_avg:420.76ms
step:1427/1500 train_loss:3.5396 train_time:596214ms step_avg:420.76ms
step:1428/1500 train_loss:3.4899 train_time:596631ms step_avg:420.76ms
step:1429/1500 train_loss:3.6002 train_time:597047ms step_avg:420.75ms
step:1430/1500 train_loss:3.5676 train_time:597465ms step_avg:420.75ms
step:1431/1500 train_loss:3.4927 train_time:597881ms step_avg:420.75ms
step:1432/1500 train_loss:3.5361 train_time:598297ms step_avg:420.74ms
step:1433/1500 train_loss:3.5750 train_time:598713ms step_avg:420.74ms
step:1434/1500 train_loss:3.3885 train_time:599129ms step_avg:420.74ms
step:1435/1500 train_loss:3.5495 train_time:599546ms step_avg:420.73ms
step:1436/1500 train_loss:3.3654 train_time:599962ms step_avg:420.73ms
step:1437/1500 train_loss:3.4415 train_time:600378ms step_avg:420.73ms
step:1438/1500 train_loss:3.6280 train_time:600795ms step_avg:420.72ms
step:1439/1500 train_loss:3.5921 train_time:601211ms step_avg:420.72ms
step:1440/1500 train_loss:3.5363 train_time:601626ms step_avg:420.72ms
step:1441/1500 train_loss:3.3977 train_time:602041ms step_avg:420.71ms
step:1442/1500 train_loss:3.5681 train_time:602457ms step_avg:420.71ms
step:1443/1500 train_loss:3.6265 train_time:602873ms step_avg:420.71ms
step:1444/1500 train_loss:3.7099 train_time:603290ms step_avg:420.70ms
step:1445/1500 train_loss:3.6657 train_time:603707ms step_avg:420.70ms
step:1446/1500 train_loss:3.5570 train_time:604124ms step_avg:420.70ms
step:1447/1500 train_loss:3.4290 train_time:604539ms step_avg:420.70ms
step:1448/1500 train_loss:3.5018 train_time:604955ms step_avg:420.69ms
step:1449/1500 train_loss:3.5235 train_time:605371ms step_avg:420.69ms
step:1450/1500 train_loss:3.6353 train_time:605788ms step_avg:420.69ms
step:1451/1500 train_loss:3.6265 train_time:606205ms step_avg:420.68ms
step:1452/1500 train_loss:3.4431 train_time:606621ms step_avg:420.68ms
step:1453/1500 train_loss:3.5650 train_time:607039ms step_avg:420.68ms
step:1454/1500 train_loss:3.4777 train_time:607456ms step_avg:420.68ms
step:1455/1500 train_loss:3.5049 train_time:607872ms step_avg:420.67ms
step:1456/1500 train_loss:3.5562 train_time:608288ms step_avg:420.67ms
step:1457/1500 train_loss:3.4915 train_time:608705ms step_avg:420.67ms
step:1458/1500 train_loss:3.3839 train_time:609121ms step_avg:420.66ms
step:1459/1500 train_loss:3.6267 train_time:609536ms step_avg:420.66ms
step:1460/1500 train_loss:3.4961 train_time:609952ms step_avg:420.66ms
step:1461/1500 train_loss:3.5471 train_time:610369ms step_avg:420.65ms
step:1462/1500 train_loss:3.6738 train_time:610787ms step_avg:420.65ms
step:1463/1500 train_loss:3.4950 train_time:611204ms step_avg:420.65ms
step:1464/1500 train_loss:3.6833 train_time:611620ms step_avg:420.65ms
step:1465/1500 train_loss:3.5760 train_time:612036ms step_avg:420.64ms
step:1466/1500 train_loss:3.5733 train_time:612452ms step_avg:420.64ms
step:1467/1500 train_loss:3.5037 train_time:612869ms step_avg:420.64ms
step:1468/1500 train_loss:3.6571 train_time:613286ms step_avg:420.64ms
step:1469/1500 train_loss:3.5257 train_time:613702ms step_avg:420.63ms
step:1470/1500 train_loss:3.5014 train_time:614120ms step_avg:420.63ms
step:1471/1500 train_loss:3.5499 train_time:614534ms step_avg:420.63ms
step:1472/1500 train_loss:3.4787 train_time:614951ms step_avg:420.62ms
step:1473/1500 train_loss:3.5748 train_time:615366ms step_avg:420.62ms
step:1474/1500 train_loss:3.6518 train_time:615786ms step_avg:420.62ms
step:1475/1500 train_loss:3.5357 train_time:616202ms step_avg:420.62ms
step:1476/1500 train_loss:3.3665 train_time:616618ms step_avg:420.61ms
step:1477/1500 train_loss:3.4832 train_time:617034ms step_avg:420.61ms
step:1478/1500 train_loss:3.4520 train_time:617451ms step_avg:420.61ms
step:1479/1500 train_loss:3.5465 train_time:617866ms step_avg:420.60ms
step:1480/1500 train_loss:3.6218 train_time:618285ms step_avg:420.60ms
step:1481/1500 train_loss:3.4924 train_time:618701ms step_avg:420.60ms
step:1482/1500 train_loss:3.6664 train_time:619118ms step_avg:420.60ms
step:1483/1500 train_loss:3.6010 train_time:619535ms step_avg:420.59ms
step:1484/1500 train_loss:3.5016 train_time:619950ms step_avg:420.59ms
step:1485/1500 train_loss:3.4809 train_time:620366ms step_avg:420.59ms
step:1486/1500 train_loss:3.4938 train_time:620787ms step_avg:420.59ms
step:1487/1500 train_loss:3.4623 train_time:621202ms step_avg:420.58ms
step:1488/1500 train_loss:3.5496 train_time:621618ms step_avg:420.58ms
step:1489/1500 train_loss:3.4661 train_time:622033ms step_avg:420.58ms
step:1490/1500 train_loss:3.5490 train_time:622449ms step_avg:420.57ms
step:1491/1500 train_loss:3.4834 train_time:622865ms step_avg:420.57ms
step:1492/1500 train_loss:3.4129 train_time:623283ms step_avg:420.57ms
step:1493/1500 train_loss:3.4843 train_time:623700ms step_avg:420.57ms
step:1494/1500 train_loss:3.6675 train_time:624116ms step_avg:420.56ms
step:1495/1500 train_loss:3.5150 train_time:624532ms step_avg:420.56ms
step:1496/1500 train_loss:3.2727 train_time:624948ms step_avg:420.56ms
step:1497/1500 train_loss:3.5823 train_time:625364ms step_avg:420.55ms
step:1498/1500 train_loss:3.5434 train_time:625781ms step_avg:420.55ms
step:1499/1500 train_loss:3.5851 train_time:626197ms step_avg:420.55ms
step:1500/1500 train_loss:3.5431 train_time:626613ms step_avg:420.55ms
step:1500/1500 val_loss:3.5165 train_time:626626ms step_avg:420.55ms
