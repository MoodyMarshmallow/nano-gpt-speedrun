====================================================================================================
# NOTE: record from https://github.com/KellerJordan/modded-nanogpt/blob/master/records/track_1_short/2024-10-14_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt
# ====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
import json
import dataclasses
import subprocess
import csv
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \\sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=3e-4, momentum=0.95, nesterov=True, backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]
            for p in group['params']:
                g = p.grad
                if g is None:
                    continue
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.mul_(momentum).add_(g)
                if group['nesterov']:
                    g = g.add(buf, alpha=momentum)
                if g.size(0) == 3 * g.size(1): # split grouped QKV parameters
                    g = torch.cat([zeropower_backend(g1, steps=group['backend_steps']) for g1 in g.split(g.size(1))])
                    scale = g.size(1)**0.5
                else:
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    scale = max(g.size(0), g.size(1))**0.5 # scale to have update.square().mean() == 1
                p.data.add_(g, alpha=-lr * scale)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

def _apply_gate_act(logits: torch.Tensor, kind: str) -> torch.Tensor:
    if kind == "sigmoid":
        return torch.sigmoid(logits)
    if kind == "ns_sigmoid":
        return 0.5 + 0.5 * torch.sigmoid(logits)
    raise ValueError(f"unknown gate_act={kind}")

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.attn_gate = getattr(config, "attn_gate", "none")
        self.gate_pos = getattr(config, "gate_pos", "sdpa")
        self.gate_act = getattr(config, "gate_act", "sigmoid")
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)
        if self.attn_gate == "headwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_head, bias=False)
            self.gate_param = None
        elif self.attn_gate == "elementwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_embd, bias=False)
            self.gate_param = None
        elif self.attn_gate == "const":
            self.c_gate = None
            self.gate_param = nn.Parameter(torch.zeros(self.n_head, self.head_dim))
        else:
            self.c_gate = None
            self.gate_param = None

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        if self.attn_gate != "none" and self.gate_pos == "value":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            v = v * gate
        cos, sin = self.rotary(q)
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2) # (B, T, n_head, head_dim)
        if self.attn_gate != "none" and self.gate_pos == "sdpa":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            y = y * gate
        y = y.contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768
    attn_gate : str = "none"
    gate_pos : str = "sdpa"
    gate_act : str = "sigmoid"

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying

    def forward(self, idx, targets=None, return_logits=True):

        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8*64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 5100 # number of iterations to run
    learning_rate : float = 0.0036
    warmup_iters : int = 0
    warmdown_iters : int = 1450 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    seed : int = 1337
    attn_gate : str = "none" # none|headwise|elementwise|const
    gate_pos : str = "sdpa" # sdpa|value
    gate_act : str = "sigmoid" # sigmoid|ns_sigmoid
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

def apply_env_overrides():
    # environment-variable overrides allow quick sweeps without editing code
    args.learning_rate = float(os.environ.get("LR", args.learning_rate))
    args.seed = int(os.environ.get("SEED", args.seed))
    args.attn_gate = os.environ.get("ATTNGATE", args.attn_gate)
    args.gate_pos = os.environ.get("GATEPOS", args.gate_pos)
    args.gate_act = os.environ.get("GATEACT", args.gate_act)
    args.num_iterations = int(os.environ.get("NUM_ITER", args.num_iterations))
    args.val_loss_every = int(os.environ.get("VAL_EVERY", args.val_loss_every))

def get_git_commit():
    try:
        return subprocess.check_output(["git", "rev-parse", "HEAD"], text=True).strip()
    except Exception:
        return "unknown"

apply_env_overrides()
torch.manual_seed(args.seed)
torch.cuda.manual_seed_all(args.seed)
np.random.seed(args.seed)

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.
git_commit = get_git_commit() if master_process else "unknown"

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(
    vocab_size=num_vocab,
    n_layer=12,
    n_head=6,
    n_embd=768,
    attn_gate=args.attn_gate,
    gate_pos=args.gate_pos,
    gate_act=args.gate_act,
))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
optimizer1 = torch.optim.AdamW(raw_model.lm_head.parameters(), lr=args.learning_rate, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer2 = Muon(raw_model.transformer.h.parameters(), lr=0.1*args.learning_rate, momentum=0.95)
optimizers = [optimizer1, optimizer2]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        f.write(f"git_commit: {git_commit}\n")
        f.write(f"seed: {args.seed}\n")
        f.write("hyperparameters:\n")
        f.write(json.dumps(dataclasses.asdict(args), indent=2))
        f.write("\n")
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')

training_time_ms = 0
best_val_loss = float("inf")
final_val_loss = None
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        val_loss_item = val_loss.item()
        final_val_loss = val_loss_item
        best_val_loss = min(best_val_loss, val_loss_item)
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms\n')
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            _, loss = model(x, y, return_logits=False)
            train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process:
        approx_time = training_time_ms + 1000 * (time.time() - t0)
        print(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")
        with open(logfile, "a") as f:
            f.write(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms\n")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")
    timed_steps_final = max(args.num_iterations - 9, 1)
    ms_per_step = training_time_ms / timed_steps_final
    os.makedirs("experiments", exist_ok=True)
    results_path = os.path.join("experiments", "results.csv")
    fieldnames = [
        "run_id",
        "date",
        "git_commit",
        "seed",
        "attn_gate",
        "gate_pos",
        "gate_act",
        "learning_rate",
        "batch_size",
        "device_batch_size",
        "sequence_length",
        "num_iterations",
        "warmdown_iters",
        "final_val_loss",
        "best_val_loss",
        "train_time_ms",
        "ms_per_step",
        "gpu_name",
        "n_gpus",
        "runpod_instance",
        "notes",
    ]
    final_loss_value = final_val_loss if final_val_loss is not None else float("nan")
    best_loss_value = best_val_loss if best_val_loss < float("inf") else float("nan")
    row = {
        "run_id": run_id,
        "date": time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime()),
        "git_commit": git_commit,
        "seed": args.seed,
        "attn_gate": args.attn_gate,
        "gate_pos": args.gate_pos,
        "gate_act": args.gate_act,
        "learning_rate": args.learning_rate,
        "batch_size": args.batch_size,
        "device_batch_size": args.device_batch_size,
        "sequence_length": args.sequence_length,
        "num_iterations": args.num_iterations,
        "warmdown_iters": args.warmdown_iters,
        "final_val_loss": final_loss_value,
        "best_val_loss": best_loss_value,
        "train_time_ms": training_time_ms,
        "ms_per_step": ms_per_step,
        "gpu_name": torch.cuda.get_device_name(ddp_local_rank),
        "n_gpus": ddp_world_size,
        "runpod_instance": os.environ.get("RUNPOD_INSTANCE_TYPE", "unknown"),
        "notes": "",
    }
    write_header = not os.path.exists(results_path)
    with open(results_path, "a", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if write_header:
            writer.writeheader()
        writer.writerow(row)
====================================================================================================
git_commit: 21aae13b20675947154a15b640706eb3a47e5fcd
seed: 1338
hyperparameters:
{
  "input_bin": "data/fineweb10B/fineweb_train_*.bin",
  "input_val_bin": "data/fineweb10B/fineweb_val_*.bin",
  "batch_size": 512,
  "device_batch_size": 64,
  "sequence_length": 1024,
  "num_iterations": 1500,
  "learning_rate": 0.0036,
  "warmup_iters": 0,
  "warmdown_iters": 1450,
  "weight_decay": 0,
  "seed": 1338,
  "attn_gate": "headwise",
  "gate_pos": "sdpa",
  "gate_act": "ns_sigmoid",
  "val_loss_every": 125,
  "val_tokens": 10485760,
  "save_every": 0
}
Running pytorch 2.8.0+cu128 compiled for CUDA 12.8
nvidia-smi:
Sun Dec  7 11:03:17 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:00:07.0 Off |                    0 |
| N/A   46C    P0            142W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          On  |   00000000:00:08.0 Off |                    0 |
| N/A   48C    P0            120W /  300W |    2182MiB /  81920MiB |     16%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100 80GB PCIe          On  |   00000000:00:09.0 Off |                    0 |
| N/A   44C    P0            108W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100 80GB PCIe          On  |   00000000:00:0A.0 Off |                    0 |
| N/A   45C    P0            143W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100 80GB PCIe          On  |   00000000:00:0B.0 Off |                    0 |
| N/A   48C    P0            116W /  300W |    2182MiB /  81920MiB |     18%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100 80GB PCIe          On  |   00000000:00:0C.0 Off |                    0 |
| N/A   45C    P0            110W /  300W |    2182MiB /  81920MiB |     16%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100 80GB PCIe          On  |   00000000:00:0D.0 Off |                    0 |
| N/A   48C    P0            119W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100 80GB PCIe          On  |   00000000:00:0E.0 Off |                    0 |
| N/A   47C    P0            139W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1500 val_loss:16.0067 train_time:322ms step_avg:nanms
step:1/1500 train_loss:16.0023 train_time:52003ms step_avg:nanms
step:2/1500 train_loss:9.5365 train_time:53439ms step_avg:nanms
step:3/1500 train_loss:8.6691 train_time:53847ms step_avg:nanms
step:4/1500 train_loss:7.9095 train_time:54253ms step_avg:nanms
step:5/1500 train_loss:7.4474 train_time:54658ms step_avg:nanms
step:6/1500 train_loss:7.4633 train_time:55062ms step_avg:nanms
step:7/1500 train_loss:7.0805 train_time:55466ms step_avg:nanms
step:8/1500 train_loss:7.4204 train_time:55873ms step_avg:nanms
step:9/1500 train_loss:7.2728 train_time:56280ms step_avg:nanms
step:10/1500 train_loss:6.9806 train_time:56686ms step_avg:nanms
step:11/1500 train_loss:6.8500 train_time:393ms step_avg:nanms
step:12/1500 train_loss:6.7631 train_time:800ms step_avg:nanms
step:13/1500 train_loss:6.5821 train_time:1208ms step_avg:402.72ms
step:14/1500 train_loss:6.5717 train_time:1616ms step_avg:404.11ms
step:15/1500 train_loss:6.5367 train_time:2023ms step_avg:404.67ms
step:16/1500 train_loss:6.4664 train_time:2430ms step_avg:405.05ms
step:17/1500 train_loss:6.4880 train_time:2837ms step_avg:405.31ms
step:18/1500 train_loss:6.5134 train_time:3246ms step_avg:405.77ms
step:19/1500 train_loss:6.3377 train_time:3653ms step_avg:405.90ms
step:20/1500 train_loss:6.3651 train_time:4060ms step_avg:406.04ms
step:21/1500 train_loss:6.0298 train_time:4467ms step_avg:406.11ms
step:22/1500 train_loss:6.3926 train_time:4873ms step_avg:406.11ms
step:23/1500 train_loss:6.5967 train_time:5281ms step_avg:406.25ms
step:24/1500 train_loss:6.2870 train_time:5688ms step_avg:406.30ms
step:25/1500 train_loss:6.4242 train_time:6097ms step_avg:406.45ms
step:26/1500 train_loss:6.1368 train_time:6505ms step_avg:406.55ms
step:27/1500 train_loss:6.0644 train_time:6912ms step_avg:406.59ms
step:28/1500 train_loss:6.2015 train_time:7319ms step_avg:406.62ms
step:29/1500 train_loss:5.8829 train_time:7728ms step_avg:406.75ms
step:30/1500 train_loss:6.1594 train_time:8136ms step_avg:406.79ms
step:31/1500 train_loss:5.9911 train_time:8544ms step_avg:406.86ms
step:32/1500 train_loss:5.9699 train_time:8951ms step_avg:406.86ms
step:33/1500 train_loss:5.7991 train_time:9358ms step_avg:406.85ms
step:34/1500 train_loss:6.0713 train_time:9763ms step_avg:406.80ms
step:35/1500 train_loss:6.0080 train_time:10170ms step_avg:406.80ms
step:36/1500 train_loss:6.1495 train_time:10577ms step_avg:406.83ms
step:37/1500 train_loss:6.0839 train_time:10984ms step_avg:406.81ms
step:38/1500 train_loss:5.9876 train_time:11392ms step_avg:406.84ms
step:39/1500 train_loss:5.8667 train_time:11799ms step_avg:406.88ms
step:40/1500 train_loss:5.8857 train_time:12208ms step_avg:406.92ms
step:41/1500 train_loss:5.8005 train_time:12615ms step_avg:406.93ms
step:42/1500 train_loss:5.8216 train_time:13022ms step_avg:406.93ms
step:43/1500 train_loss:5.7024 train_time:13430ms step_avg:406.98ms
step:44/1500 train_loss:5.8068 train_time:13839ms step_avg:407.02ms
step:45/1500 train_loss:5.7758 train_time:14248ms step_avg:407.10ms
step:46/1500 train_loss:5.9429 train_time:14656ms step_avg:407.10ms
step:47/1500 train_loss:5.7275 train_time:15064ms step_avg:407.13ms
step:48/1500 train_loss:5.6032 train_time:15472ms step_avg:407.16ms
step:49/1500 train_loss:5.8046 train_time:15881ms step_avg:407.19ms
step:50/1500 train_loss:5.6810 train_time:16288ms step_avg:407.20ms
step:51/1500 train_loss:5.8281 train_time:16695ms step_avg:407.19ms
step:52/1500 train_loss:5.6893 train_time:17103ms step_avg:407.21ms
step:53/1500 train_loss:5.5522 train_time:17510ms step_avg:407.21ms
step:54/1500 train_loss:5.6944 train_time:17918ms step_avg:407.22ms
step:55/1500 train_loss:5.5646 train_time:18327ms step_avg:407.26ms
step:56/1500 train_loss:5.9110 train_time:18735ms step_avg:407.27ms
step:57/1500 train_loss:5.5606 train_time:19142ms step_avg:407.27ms
step:58/1500 train_loss:5.4322 train_time:19550ms step_avg:407.29ms
step:59/1500 train_loss:5.5712 train_time:19957ms step_avg:407.28ms
step:60/1500 train_loss:5.5403 train_time:20364ms step_avg:407.28ms
step:61/1500 train_loss:5.6475 train_time:20773ms step_avg:407.31ms
step:62/1500 train_loss:5.4129 train_time:21179ms step_avg:407.29ms
step:63/1500 train_loss:5.5117 train_time:21585ms step_avg:407.26ms
step:64/1500 train_loss:5.4933 train_time:21991ms step_avg:407.24ms
step:65/1500 train_loss:5.1899 train_time:22400ms step_avg:407.27ms
step:66/1500 train_loss:5.3087 train_time:22809ms step_avg:407.30ms
step:67/1500 train_loss:5.4602 train_time:23218ms step_avg:407.34ms
step:68/1500 train_loss:5.3401 train_time:23625ms step_avg:407.32ms
step:69/1500 train_loss:5.5978 train_time:24032ms step_avg:407.32ms
step:70/1500 train_loss:5.2365 train_time:24441ms step_avg:407.35ms
step:71/1500 train_loss:5.2654 train_time:24849ms step_avg:407.36ms
step:72/1500 train_loss:5.4648 train_time:25257ms step_avg:407.37ms
step:73/1500 train_loss:5.4035 train_time:25665ms step_avg:407.38ms
step:74/1500 train_loss:5.2765 train_time:26073ms step_avg:407.39ms
step:75/1500 train_loss:5.4069 train_time:26481ms step_avg:407.40ms
step:76/1500 train_loss:5.3693 train_time:26889ms step_avg:407.40ms
step:77/1500 train_loss:5.3353 train_time:27297ms step_avg:407.42ms
step:78/1500 train_loss:5.4310 train_time:27704ms step_avg:407.41ms
step:79/1500 train_loss:5.5045 train_time:28111ms step_avg:407.41ms
step:80/1500 train_loss:5.2735 train_time:28522ms step_avg:407.46ms
step:81/1500 train_loss:5.3892 train_time:28931ms step_avg:407.47ms
step:82/1500 train_loss:5.1453 train_time:29338ms step_avg:407.47ms
step:83/1500 train_loss:5.3341 train_time:29746ms step_avg:407.48ms
step:84/1500 train_loss:5.2787 train_time:30154ms step_avg:407.49ms
step:85/1500 train_loss:5.2586 train_time:30561ms step_avg:407.49ms
step:86/1500 train_loss:5.1135 train_time:30969ms step_avg:407.49ms
step:87/1500 train_loss:5.3334 train_time:31377ms step_avg:407.50ms
step:88/1500 train_loss:5.2389 train_time:31785ms step_avg:407.49ms
step:89/1500 train_loss:5.2886 train_time:32193ms step_avg:407.50ms
step:90/1500 train_loss:5.2449 train_time:32601ms step_avg:407.51ms
step:91/1500 train_loss:5.1798 train_time:33011ms step_avg:407.54ms
step:92/1500 train_loss:5.1585 train_time:33418ms step_avg:407.54ms
step:93/1500 train_loss:5.2984 train_time:33825ms step_avg:407.53ms
step:94/1500 train_loss:5.1169 train_time:34232ms step_avg:407.52ms
step:95/1500 train_loss:5.1296 train_time:34641ms step_avg:407.54ms
step:96/1500 train_loss:5.1579 train_time:35050ms step_avg:407.55ms
step:97/1500 train_loss:5.0788 train_time:35459ms step_avg:407.58ms
step:98/1500 train_loss:5.1607 train_time:35868ms step_avg:407.59ms
step:99/1500 train_loss:5.0798 train_time:36276ms step_avg:407.60ms
step:100/1500 train_loss:5.1985 train_time:36684ms step_avg:407.60ms
step:101/1500 train_loss:5.1722 train_time:37094ms step_avg:407.63ms
step:102/1500 train_loss:5.0775 train_time:37502ms step_avg:407.63ms
step:103/1500 train_loss:5.1670 train_time:37911ms step_avg:407.65ms
step:104/1500 train_loss:5.1224 train_time:38319ms step_avg:407.65ms
step:105/1500 train_loss:4.9836 train_time:38729ms step_avg:407.68ms
step:106/1500 train_loss:5.0767 train_time:39138ms step_avg:407.69ms
step:107/1500 train_loss:5.2926 train_time:39546ms step_avg:407.69ms
step:108/1500 train_loss:5.0422 train_time:39953ms step_avg:407.68ms
step:109/1500 train_loss:4.8460 train_time:40361ms step_avg:407.69ms
step:110/1500 train_loss:5.0289 train_time:40770ms step_avg:407.70ms
step:111/1500 train_loss:5.0060 train_time:41179ms step_avg:407.71ms
step:112/1500 train_loss:4.9717 train_time:41588ms step_avg:407.72ms
step:113/1500 train_loss:5.0799 train_time:41997ms step_avg:407.74ms
step:114/1500 train_loss:5.0134 train_time:42403ms step_avg:407.73ms
step:115/1500 train_loss:4.8625 train_time:42810ms step_avg:407.72ms
step:116/1500 train_loss:5.0160 train_time:43220ms step_avg:407.73ms
step:117/1500 train_loss:4.9249 train_time:43629ms step_avg:407.75ms
step:118/1500 train_loss:4.8773 train_time:44037ms step_avg:407.75ms
step:119/1500 train_loss:5.0420 train_time:44445ms step_avg:407.75ms
step:120/1500 train_loss:4.9941 train_time:44853ms step_avg:407.76ms
step:121/1500 train_loss:4.9148 train_time:45262ms step_avg:407.77ms
step:122/1500 train_loss:4.8147 train_time:45670ms step_avg:407.77ms
step:123/1500 train_loss:4.9417 train_time:46080ms step_avg:407.79ms
step:124/1500 train_loss:4.7867 train_time:46489ms step_avg:407.80ms
step:125/1500 train_loss:5.0940 train_time:46899ms step_avg:407.82ms
step:125/1500 val_loss:4.9271 train_time:46911ms step_avg:407.92ms
step:126/1500 train_loss:4.9766 train_time:47304ms step_avg:407.79ms
step:127/1500 train_loss:4.9163 train_time:47711ms step_avg:407.79ms
step:128/1500 train_loss:4.9794 train_time:48119ms step_avg:407.79ms
step:129/1500 train_loss:4.8534 train_time:48526ms step_avg:407.78ms
step:130/1500 train_loss:5.1658 train_time:48933ms step_avg:407.78ms
step:131/1500 train_loss:4.9143 train_time:49342ms step_avg:407.78ms
step:132/1500 train_loss:4.9260 train_time:49751ms step_avg:407.79ms
step:133/1500 train_loss:4.8768 train_time:50159ms step_avg:407.80ms
step:134/1500 train_loss:4.9162 train_time:50566ms step_avg:407.79ms
step:135/1500 train_loss:4.8039 train_time:50974ms step_avg:407.79ms
step:136/1500 train_loss:4.9343 train_time:51384ms step_avg:407.81ms
step:137/1500 train_loss:4.7013 train_time:51792ms step_avg:407.81ms
step:138/1500 train_loss:4.8618 train_time:52200ms step_avg:407.81ms
step:139/1500 train_loss:4.8156 train_time:52608ms step_avg:407.81ms
step:140/1500 train_loss:4.8504 train_time:53018ms step_avg:407.83ms
step:141/1500 train_loss:4.9174 train_time:53425ms step_avg:407.82ms
step:142/1500 train_loss:4.7893 train_time:53833ms step_avg:407.82ms
step:143/1500 train_loss:4.8390 train_time:54240ms step_avg:407.82ms
step:144/1500 train_loss:4.7016 train_time:54649ms step_avg:407.83ms
step:145/1500 train_loss:4.8395 train_time:55059ms step_avg:407.84ms
step:146/1500 train_loss:4.7943 train_time:55466ms step_avg:407.84ms
step:147/1500 train_loss:4.6644 train_time:55875ms step_avg:407.85ms
step:148/1500 train_loss:4.8112 train_time:56284ms step_avg:407.86ms
step:149/1500 train_loss:4.8180 train_time:56692ms step_avg:407.85ms
step:150/1500 train_loss:4.8399 train_time:57101ms step_avg:407.87ms
step:151/1500 train_loss:4.8767 train_time:57509ms step_avg:407.87ms
step:152/1500 train_loss:4.7579 train_time:57917ms step_avg:407.87ms
step:153/1500 train_loss:4.7597 train_time:58326ms step_avg:407.87ms
step:154/1500 train_loss:4.8527 train_time:58735ms step_avg:407.88ms
step:155/1500 train_loss:4.8033 train_time:59142ms step_avg:407.88ms
step:156/1500 train_loss:4.7683 train_time:59549ms step_avg:407.87ms
step:157/1500 train_loss:4.7928 train_time:59957ms step_avg:407.87ms
step:158/1500 train_loss:4.9055 train_time:60365ms step_avg:407.87ms
step:159/1500 train_loss:4.6915 train_time:60774ms step_avg:407.88ms
step:160/1500 train_loss:4.7651 train_time:61183ms step_avg:407.89ms
step:161/1500 train_loss:4.6044 train_time:61590ms step_avg:407.88ms
step:162/1500 train_loss:4.7790 train_time:61998ms step_avg:407.88ms
step:163/1500 train_loss:4.8069 train_time:62407ms step_avg:407.89ms
step:164/1500 train_loss:4.7973 train_time:62815ms step_avg:407.89ms
step:165/1500 train_loss:4.6110 train_time:63224ms step_avg:407.90ms
step:166/1500 train_loss:4.7273 train_time:63633ms step_avg:407.90ms
step:167/1500 train_loss:4.8702 train_time:64042ms step_avg:407.91ms
step:168/1500 train_loss:4.6519 train_time:64451ms step_avg:407.91ms
step:169/1500 train_loss:4.7548 train_time:64861ms step_avg:407.93ms
step:170/1500 train_loss:4.6023 train_time:65269ms step_avg:407.93ms
step:171/1500 train_loss:4.4986 train_time:65678ms step_avg:407.94ms
step:172/1500 train_loss:4.6654 train_time:66087ms step_avg:407.94ms
step:173/1500 train_loss:4.6346 train_time:66497ms step_avg:407.95ms
step:174/1500 train_loss:4.6990 train_time:66905ms step_avg:407.96ms
step:175/1500 train_loss:4.8495 train_time:67313ms step_avg:407.96ms
step:176/1500 train_loss:4.7003 train_time:67722ms step_avg:407.96ms
step:177/1500 train_loss:4.5600 train_time:68132ms step_avg:407.97ms
step:178/1500 train_loss:4.5213 train_time:68539ms step_avg:407.97ms
step:179/1500 train_loss:4.5987 train_time:68948ms step_avg:407.98ms
step:180/1500 train_loss:4.5993 train_time:69356ms step_avg:407.97ms
step:181/1500 train_loss:4.6008 train_time:69765ms step_avg:407.98ms
step:182/1500 train_loss:4.7265 train_time:70173ms step_avg:407.99ms
step:183/1500 train_loss:4.5945 train_time:70582ms step_avg:407.99ms
step:184/1500 train_loss:4.5541 train_time:70991ms step_avg:407.99ms
step:185/1500 train_loss:4.5607 train_time:71400ms step_avg:408.00ms
step:186/1500 train_loss:4.6747 train_time:71809ms step_avg:408.00ms
step:187/1500 train_loss:4.5943 train_time:72218ms step_avg:408.01ms
step:188/1500 train_loss:4.7771 train_time:72627ms step_avg:408.02ms
step:189/1500 train_loss:4.6040 train_time:73796ms step_avg:412.27ms
step:190/1500 train_loss:4.5309 train_time:74389ms step_avg:413.27ms
step:191/1500 train_loss:4.6723 train_time:74799ms step_avg:413.26ms
step:192/1500 train_loss:4.5241 train_time:75208ms step_avg:413.23ms
step:193/1500 train_loss:4.4399 train_time:75618ms step_avg:413.21ms
step:194/1500 train_loss:4.6652 train_time:76028ms step_avg:413.19ms
step:195/1500 train_loss:4.5909 train_time:76436ms step_avg:413.17ms
step:196/1500 train_loss:4.7774 train_time:76845ms step_avg:413.14ms
step:197/1500 train_loss:4.6409 train_time:77252ms step_avg:413.11ms
step:198/1500 train_loss:4.4892 train_time:77662ms step_avg:413.10ms
step:199/1500 train_loss:4.5597 train_time:78071ms step_avg:413.07ms
step:200/1500 train_loss:4.4382 train_time:78481ms step_avg:413.06ms
step:201/1500 train_loss:4.5268 train_time:78889ms step_avg:413.03ms
step:202/1500 train_loss:4.4293 train_time:79297ms step_avg:413.01ms
step:203/1500 train_loss:4.6704 train_time:79706ms step_avg:412.99ms
step:204/1500 train_loss:4.5308 train_time:80114ms step_avg:412.96ms
step:205/1500 train_loss:4.5758 train_time:80524ms step_avg:412.94ms
step:206/1500 train_loss:4.6821 train_time:80932ms step_avg:412.92ms
step:207/1500 train_loss:4.3450 train_time:81341ms step_avg:412.90ms
step:208/1500 train_loss:4.4978 train_time:81749ms step_avg:412.87ms
step:209/1500 train_loss:4.4750 train_time:82158ms step_avg:412.85ms
step:210/1500 train_loss:4.6320 train_time:82567ms step_avg:412.83ms
step:211/1500 train_loss:4.5511 train_time:82975ms step_avg:412.81ms
step:212/1500 train_loss:4.4307 train_time:83382ms step_avg:412.78ms
step:213/1500 train_loss:4.5558 train_time:83791ms step_avg:412.76ms
step:214/1500 train_loss:4.4151 train_time:84199ms step_avg:412.74ms
step:215/1500 train_loss:4.4737 train_time:84606ms step_avg:412.71ms
step:216/1500 train_loss:4.3434 train_time:85016ms step_avg:412.70ms
step:217/1500 train_loss:4.4464 train_time:85422ms step_avg:412.67ms
step:218/1500 train_loss:4.4085 train_time:85830ms step_avg:412.65ms
step:219/1500 train_loss:4.4364 train_time:86237ms step_avg:412.62ms
step:220/1500 train_loss:4.4341 train_time:86647ms step_avg:412.60ms
step:221/1500 train_loss:4.4574 train_time:87056ms step_avg:412.59ms
step:222/1500 train_loss:4.4788 train_time:87465ms step_avg:412.57ms
step:223/1500 train_loss:4.4000 train_time:87874ms step_avg:412.56ms
step:224/1500 train_loss:4.3979 train_time:88283ms step_avg:412.54ms
step:225/1500 train_loss:4.6126 train_time:88693ms step_avg:412.52ms
step:226/1500 train_loss:4.2640 train_time:89102ms step_avg:412.51ms
step:227/1500 train_loss:4.3256 train_time:89510ms step_avg:412.49ms
step:228/1500 train_loss:4.3323 train_time:89919ms step_avg:412.47ms
step:229/1500 train_loss:4.4829 train_time:90329ms step_avg:412.46ms
step:230/1500 train_loss:4.2883 train_time:90738ms step_avg:412.45ms
step:231/1500 train_loss:4.4118 train_time:91146ms step_avg:412.42ms
step:232/1500 train_loss:4.2699 train_time:91553ms step_avg:412.40ms
step:233/1500 train_loss:4.2913 train_time:91961ms step_avg:412.38ms
step:234/1500 train_loss:4.4540 train_time:92370ms step_avg:412.37ms
step:235/1500 train_loss:4.3375 train_time:92780ms step_avg:412.35ms
step:236/1500 train_loss:4.2406 train_time:93187ms step_avg:412.33ms
step:237/1500 train_loss:4.4383 train_time:93597ms step_avg:412.32ms
step:238/1500 train_loss:4.4080 train_time:94006ms step_avg:412.31ms
step:239/1500 train_loss:4.2692 train_time:94414ms step_avg:412.29ms
step:240/1500 train_loss:4.4306 train_time:94822ms step_avg:412.27ms
step:241/1500 train_loss:4.4251 train_time:95231ms step_avg:412.26ms
step:242/1500 train_loss:4.3017 train_time:95640ms step_avg:412.24ms
step:243/1500 train_loss:4.4720 train_time:96049ms step_avg:412.23ms
step:244/1500 train_loss:4.3267 train_time:96457ms step_avg:412.21ms
step:245/1500 train_loss:4.3579 train_time:96864ms step_avg:412.19ms
step:246/1500 train_loss:4.4381 train_time:97274ms step_avg:412.18ms
step:247/1500 train_loss:4.3730 train_time:97682ms step_avg:412.16ms
step:248/1500 train_loss:4.3123 train_time:98091ms step_avg:412.15ms
step:249/1500 train_loss:4.4348 train_time:98500ms step_avg:412.13ms
step:250/1500 train_loss:4.2139 train_time:98909ms step_avg:412.12ms
step:250/1500 val_loss:4.3109 train_time:98921ms step_avg:412.17ms
step:251/1500 train_loss:4.2641 train_time:99313ms step_avg:412.09ms
step:252/1500 train_loss:4.3769 train_time:99722ms step_avg:412.07ms
step:253/1500 train_loss:4.4116 train_time:100128ms step_avg:412.05ms
step:254/1500 train_loss:4.2409 train_time:100538ms step_avg:412.04ms
step:255/1500 train_loss:4.1881 train_time:100948ms step_avg:412.03ms
step:256/1500 train_loss:4.3706 train_time:101356ms step_avg:412.02ms
step:257/1500 train_loss:4.2764 train_time:101764ms step_avg:412.00ms
step:258/1500 train_loss:4.2868 train_time:102172ms step_avg:411.98ms
step:259/1500 train_loss:4.2534 train_time:102580ms step_avg:411.97ms
step:260/1500 train_loss:4.2968 train_time:102989ms step_avg:411.96ms
step:261/1500 train_loss:4.3403 train_time:103400ms step_avg:411.95ms
step:262/1500 train_loss:4.2976 train_time:103808ms step_avg:411.94ms
step:263/1500 train_loss:4.2643 train_time:104215ms step_avg:411.92ms
step:264/1500 train_loss:4.1741 train_time:104624ms step_avg:411.90ms
step:265/1500 train_loss:4.2657 train_time:105031ms step_avg:411.89ms
step:266/1500 train_loss:4.1284 train_time:105439ms step_avg:411.87ms
step:267/1500 train_loss:4.1879 train_time:105848ms step_avg:411.86ms
step:268/1500 train_loss:4.1997 train_time:106257ms step_avg:411.85ms
step:269/1500 train_loss:4.2132 train_time:106664ms step_avg:411.83ms
step:270/1500 train_loss:4.1269 train_time:107073ms step_avg:411.82ms
step:271/1500 train_loss:4.3544 train_time:107481ms step_avg:411.80ms
step:272/1500 train_loss:4.2605 train_time:107888ms step_avg:411.79ms
step:273/1500 train_loss:4.1707 train_time:108296ms step_avg:411.77ms
step:274/1500 train_loss:4.2177 train_time:108704ms step_avg:411.76ms
step:275/1500 train_loss:4.2951 train_time:109112ms step_avg:411.74ms
step:276/1500 train_loss:4.3166 train_time:109523ms step_avg:411.74ms
step:277/1500 train_loss:4.4897 train_time:109931ms step_avg:411.73ms
step:278/1500 train_loss:4.2765 train_time:110342ms step_avg:411.72ms
step:279/1500 train_loss:4.3520 train_time:110749ms step_avg:411.70ms
step:280/1500 train_loss:4.2480 train_time:111157ms step_avg:411.69ms
step:281/1500 train_loss:4.3692 train_time:111567ms step_avg:411.68ms
step:282/1500 train_loss:4.2110 train_time:111977ms step_avg:411.68ms
step:283/1500 train_loss:4.2241 train_time:112384ms step_avg:411.66ms
step:284/1500 train_loss:4.1528 train_time:112793ms step_avg:411.65ms
step:285/1500 train_loss:4.3021 train_time:113202ms step_avg:411.64ms
step:286/1500 train_loss:4.3084 train_time:113611ms step_avg:411.63ms
step:287/1500 train_loss:4.3349 train_time:114019ms step_avg:411.62ms
step:288/1500 train_loss:4.1670 train_time:114426ms step_avg:411.61ms
step:289/1500 train_loss:4.2558 train_time:114834ms step_avg:411.59ms
step:290/1500 train_loss:4.1243 train_time:115244ms step_avg:411.59ms
step:291/1500 train_loss:4.1069 train_time:115652ms step_avg:411.57ms
step:292/1500 train_loss:4.2003 train_time:116061ms step_avg:411.56ms
step:293/1500 train_loss:4.1070 train_time:116468ms step_avg:411.55ms
step:294/1500 train_loss:4.1512 train_time:116877ms step_avg:411.54ms
step:295/1500 train_loss:4.1971 train_time:117285ms step_avg:411.53ms
step:296/1500 train_loss:4.0787 train_time:117694ms step_avg:411.52ms
step:297/1500 train_loss:4.0922 train_time:118103ms step_avg:411.51ms
step:298/1500 train_loss:4.0943 train_time:118511ms step_avg:411.50ms
step:299/1500 train_loss:4.2011 train_time:118921ms step_avg:411.49ms
step:300/1500 train_loss:4.0688 train_time:119328ms step_avg:411.48ms
step:301/1500 train_loss:4.2109 train_time:119736ms step_avg:411.46ms
step:302/1500 train_loss:4.2127 train_time:120146ms step_avg:411.46ms
step:303/1500 train_loss:4.1598 train_time:120554ms step_avg:411.45ms
step:304/1500 train_loss:4.2139 train_time:120962ms step_avg:411.44ms
step:305/1500 train_loss:4.1904 train_time:121369ms step_avg:411.42ms
step:306/1500 train_loss:4.6727 train_time:121776ms step_avg:411.41ms
step:307/1500 train_loss:4.1637 train_time:122185ms step_avg:411.40ms
step:308/1500 train_loss:4.0716 train_time:122592ms step_avg:411.38ms
step:309/1500 train_loss:4.2281 train_time:123000ms step_avg:411.37ms
step:310/1500 train_loss:4.0781 train_time:123409ms step_avg:411.36ms
step:311/1500 train_loss:4.3072 train_time:123819ms step_avg:411.36ms
step:312/1500 train_loss:4.1621 train_time:124227ms step_avg:411.35ms
step:313/1500 train_loss:4.0971 train_time:124636ms step_avg:411.34ms
step:314/1500 train_loss:4.1876 train_time:125046ms step_avg:411.34ms
step:315/1500 train_loss:4.3100 train_time:125454ms step_avg:411.33ms
step:316/1500 train_loss:4.1807 train_time:125862ms step_avg:411.31ms
step:317/1500 train_loss:4.0141 train_time:126269ms step_avg:411.30ms
step:318/1500 train_loss:4.0896 train_time:126678ms step_avg:411.29ms
step:319/1500 train_loss:4.1316 train_time:127086ms step_avg:411.28ms
step:320/1500 train_loss:4.1068 train_time:127495ms step_avg:411.27ms
step:321/1500 train_loss:4.2210 train_time:127903ms step_avg:411.26ms
step:322/1500 train_loss:4.1703 train_time:128312ms step_avg:411.26ms
step:323/1500 train_loss:4.1382 train_time:128721ms step_avg:411.25ms
step:324/1500 train_loss:4.2197 train_time:129131ms step_avg:411.24ms
step:325/1500 train_loss:4.1788 train_time:129538ms step_avg:411.23ms
step:326/1500 train_loss:4.2502 train_time:129946ms step_avg:411.22ms
step:327/1500 train_loss:4.1049 train_time:130355ms step_avg:411.21ms
step:328/1500 train_loss:4.5892 train_time:130764ms step_avg:411.21ms
step:329/1500 train_loss:4.2875 train_time:131171ms step_avg:411.19ms
step:330/1500 train_loss:4.0247 train_time:131579ms step_avg:411.18ms
step:331/1500 train_loss:3.9699 train_time:131988ms step_avg:411.18ms
step:332/1500 train_loss:4.1885 train_time:132395ms step_avg:411.17ms
step:333/1500 train_loss:4.1113 train_time:132804ms step_avg:411.16ms
step:334/1500 train_loss:4.0952 train_time:133211ms step_avg:411.15ms
step:335/1500 train_loss:4.0494 train_time:133618ms step_avg:411.13ms
step:336/1500 train_loss:4.2221 train_time:134028ms step_avg:411.13ms
step:337/1500 train_loss:4.1695 train_time:134437ms step_avg:411.12ms
step:338/1500 train_loss:4.6492 train_time:134847ms step_avg:411.12ms
step:339/1500 train_loss:4.1516 train_time:135254ms step_avg:411.11ms
step:340/1500 train_loss:4.0972 train_time:135663ms step_avg:411.10ms
step:341/1500 train_loss:4.1349 train_time:136071ms step_avg:411.09ms
step:342/1500 train_loss:4.0472 train_time:136480ms step_avg:411.09ms
step:343/1500 train_loss:4.0180 train_time:136889ms step_avg:411.08ms
step:344/1500 train_loss:4.0656 train_time:137298ms step_avg:411.07ms
step:345/1500 train_loss:4.2045 train_time:137706ms step_avg:411.06ms
step:346/1500 train_loss:4.0469 train_time:138115ms step_avg:411.06ms
step:347/1500 train_loss:3.9794 train_time:138524ms step_avg:411.05ms
step:348/1500 train_loss:4.0244 train_time:138931ms step_avg:411.04ms
step:349/1500 train_loss:4.0606 train_time:139340ms step_avg:411.03ms
step:350/1500 train_loss:4.0255 train_time:139751ms step_avg:411.03ms
step:351/1500 train_loss:3.7488 train_time:140161ms step_avg:411.03ms
step:352/1500 train_loss:4.0193 train_time:140568ms step_avg:411.02ms
step:353/1500 train_loss:4.3444 train_time:140975ms step_avg:411.01ms
step:354/1500 train_loss:3.8682 train_time:141382ms step_avg:410.99ms
step:355/1500 train_loss:4.1273 train_time:141792ms step_avg:410.99ms
step:356/1500 train_loss:3.9901 train_time:142202ms step_avg:410.99ms
step:357/1500 train_loss:4.0867 train_time:142611ms step_avg:410.98ms
step:358/1500 train_loss:4.0390 train_time:143020ms step_avg:410.98ms
step:359/1500 train_loss:4.0483 train_time:143428ms step_avg:410.97ms
step:360/1500 train_loss:4.0823 train_time:143837ms step_avg:410.96ms
step:361/1500 train_loss:3.6642 train_time:144244ms step_avg:410.95ms
step:362/1500 train_loss:4.2187 train_time:144653ms step_avg:410.95ms
step:363/1500 train_loss:4.1157 train_time:145063ms step_avg:410.94ms
step:364/1500 train_loss:4.0433 train_time:145470ms step_avg:410.93ms
step:365/1500 train_loss:3.9469 train_time:145878ms step_avg:410.92ms
step:366/1500 train_loss:4.1148 train_time:146286ms step_avg:410.92ms
step:367/1500 train_loss:4.0707 train_time:146694ms step_avg:410.91ms
step:368/1500 train_loss:4.0538 train_time:147103ms step_avg:410.90ms
step:369/1500 train_loss:4.0408 train_time:147510ms step_avg:410.89ms
step:370/1500 train_loss:3.9361 train_time:147919ms step_avg:410.89ms
step:371/1500 train_loss:4.0819 train_time:148327ms step_avg:410.88ms
step:372/1500 train_loss:3.9569 train_time:148735ms step_avg:410.87ms
step:373/1500 train_loss:3.8895 train_time:149142ms step_avg:410.86ms
step:374/1500 train_loss:4.1060 train_time:149552ms step_avg:410.86ms
step:375/1500 train_loss:4.0353 train_time:149960ms step_avg:410.85ms
step:375/1500 val_loss:4.0260 train_time:149973ms step_avg:410.89ms
step:376/1500 train_loss:4.0032 train_time:150365ms step_avg:410.83ms
step:377/1500 train_loss:4.0645 train_time:150773ms step_avg:410.83ms
step:378/1500 train_loss:3.9779 train_time:151821ms step_avg:412.56ms
step:379/1500 train_loss:4.0373 train_time:152232ms step_avg:412.55ms
step:380/1500 train_loss:4.0736 train_time:152816ms step_avg:413.02ms
step:381/1500 train_loss:4.1429 train_time:153226ms step_avg:413.01ms
step:382/1500 train_loss:4.0403 train_time:153634ms step_avg:413.00ms
step:383/1500 train_loss:4.0139 train_time:154042ms step_avg:412.98ms
step:384/1500 train_loss:3.9867 train_time:154450ms step_avg:412.97ms
step:385/1500 train_loss:4.0641 train_time:154859ms step_avg:412.96ms
step:386/1500 train_loss:3.9731 train_time:155268ms step_avg:412.95ms
step:387/1500 train_loss:4.0836 train_time:155676ms step_avg:412.93ms
step:388/1500 train_loss:4.2709 train_time:156083ms step_avg:412.92ms
step:389/1500 train_loss:3.9933 train_time:156490ms step_avg:412.90ms
step:390/1500 train_loss:3.9890 train_time:156898ms step_avg:412.89ms
step:391/1500 train_loss:4.0844 train_time:157306ms step_avg:412.88ms
step:392/1500 train_loss:4.0067 train_time:157713ms step_avg:412.86ms
step:393/1500 train_loss:4.1095 train_time:158122ms step_avg:412.85ms
step:394/1500 train_loss:3.9467 train_time:158531ms step_avg:412.84ms
step:395/1500 train_loss:4.0832 train_time:158938ms step_avg:412.83ms
step:396/1500 train_loss:3.8322 train_time:159347ms step_avg:412.82ms
step:397/1500 train_loss:4.0274 train_time:159756ms step_avg:412.81ms
step:398/1500 train_loss:4.0746 train_time:160165ms step_avg:412.80ms
step:399/1500 train_loss:4.0829 train_time:160573ms step_avg:412.78ms
step:400/1500 train_loss:3.9757 train_time:160980ms step_avg:412.77ms
step:401/1500 train_loss:4.0333 train_time:161390ms step_avg:412.76ms
step:402/1500 train_loss:4.0967 train_time:161802ms step_avg:412.76ms
step:403/1500 train_loss:4.0371 train_time:162211ms step_avg:412.75ms
step:404/1500 train_loss:4.1405 train_time:162618ms step_avg:412.74ms
step:405/1500 train_loss:3.8905 train_time:163026ms step_avg:412.72ms
step:406/1500 train_loss:3.9827 train_time:163434ms step_avg:412.71ms
step:407/1500 train_loss:4.2694 train_time:163842ms step_avg:412.70ms
step:408/1500 train_loss:3.9895 train_time:164251ms step_avg:412.69ms
step:409/1500 train_loss:4.0082 train_time:164660ms step_avg:412.68ms
step:410/1500 train_loss:4.0516 train_time:165068ms step_avg:412.67ms
step:411/1500 train_loss:3.9354 train_time:165476ms step_avg:412.66ms
step:412/1500 train_loss:3.9544 train_time:165884ms step_avg:412.65ms
step:413/1500 train_loss:4.3690 train_time:166296ms step_avg:412.64ms
step:414/1500 train_loss:3.8261 train_time:166705ms step_avg:412.64ms
step:415/1500 train_loss:4.2016 train_time:167113ms step_avg:412.62ms
step:416/1500 train_loss:3.9531 train_time:167523ms step_avg:412.62ms
step:417/1500 train_loss:3.9503 train_time:167933ms step_avg:412.61ms
step:418/1500 train_loss:4.1448 train_time:168340ms step_avg:412.60ms
step:419/1500 train_loss:3.8775 train_time:168749ms step_avg:412.59ms
step:420/1500 train_loss:3.9903 train_time:169157ms step_avg:412.58ms
step:421/1500 train_loss:3.9135 train_time:169568ms step_avg:412.57ms
step:422/1500 train_loss:3.8353 train_time:169976ms step_avg:412.56ms
step:423/1500 train_loss:3.9725 train_time:170384ms step_avg:412.55ms
step:424/1500 train_loss:4.0538 train_time:170791ms step_avg:412.54ms
step:425/1500 train_loss:3.8133 train_time:171199ms step_avg:412.53ms
step:426/1500 train_loss:4.0006 train_time:171609ms step_avg:412.52ms
step:427/1500 train_loss:3.8744 train_time:172017ms step_avg:412.51ms
step:428/1500 train_loss:4.0896 train_time:172431ms step_avg:412.51ms
step:429/1500 train_loss:4.0112 train_time:172838ms step_avg:412.50ms
step:430/1500 train_loss:3.9415 train_time:173246ms step_avg:412.49ms
step:431/1500 train_loss:3.9113 train_time:173654ms step_avg:412.48ms
step:432/1500 train_loss:3.8142 train_time:174063ms step_avg:412.47ms
step:433/1500 train_loss:3.9437 train_time:174470ms step_avg:412.46ms
step:434/1500 train_loss:4.0095 train_time:174878ms step_avg:412.45ms
step:435/1500 train_loss:3.9489 train_time:175286ms step_avg:412.44ms
step:436/1500 train_loss:4.0047 train_time:175694ms step_avg:412.43ms
step:437/1500 train_loss:4.0079 train_time:176104ms step_avg:412.42ms
step:438/1500 train_loss:3.8969 train_time:176511ms step_avg:412.41ms
step:439/1500 train_loss:3.9051 train_time:176920ms step_avg:412.40ms
step:440/1500 train_loss:3.8896 train_time:177329ms step_avg:412.39ms
step:441/1500 train_loss:4.0713 train_time:177738ms step_avg:412.38ms
step:442/1500 train_loss:3.9456 train_time:178147ms step_avg:412.38ms
step:443/1500 train_loss:3.9327 train_time:178554ms step_avg:412.37ms
step:444/1500 train_loss:3.8314 train_time:178962ms step_avg:412.36ms
step:445/1500 train_loss:4.0976 train_time:179372ms step_avg:412.35ms
step:446/1500 train_loss:4.0283 train_time:179780ms step_avg:412.34ms
step:447/1500 train_loss:4.0134 train_time:180188ms step_avg:412.33ms
step:448/1500 train_loss:3.9342 train_time:180595ms step_avg:412.32ms
step:449/1500 train_loss:4.0343 train_time:181003ms step_avg:412.31ms
step:450/1500 train_loss:3.8547 train_time:181411ms step_avg:412.30ms
step:451/1500 train_loss:3.9030 train_time:181821ms step_avg:412.29ms
step:452/1500 train_loss:3.7633 train_time:182230ms step_avg:412.28ms
step:453/1500 train_loss:3.8868 train_time:182639ms step_avg:412.28ms
step:454/1500 train_loss:3.8653 train_time:183047ms step_avg:412.27ms
step:455/1500 train_loss:3.8153 train_time:183457ms step_avg:412.26ms
step:456/1500 train_loss:4.0340 train_time:183864ms step_avg:412.25ms
step:457/1500 train_loss:3.9013 train_time:184273ms step_avg:412.24ms
step:458/1500 train_loss:3.9703 train_time:184680ms step_avg:412.23ms
step:459/1500 train_loss:4.0156 train_time:185089ms step_avg:412.22ms
step:460/1500 train_loss:3.8202 train_time:185497ms step_avg:412.22ms
step:461/1500 train_loss:3.9821 train_time:185906ms step_avg:412.21ms
step:462/1500 train_loss:3.8770 train_time:186315ms step_avg:412.20ms
step:463/1500 train_loss:3.9013 train_time:186724ms step_avg:412.19ms
step:464/1500 train_loss:3.9651 train_time:187133ms step_avg:412.19ms
step:465/1500 train_loss:3.9020 train_time:187540ms step_avg:412.18ms
step:466/1500 train_loss:3.9044 train_time:187949ms step_avg:412.17ms
step:467/1500 train_loss:3.9893 train_time:188357ms step_avg:412.16ms
step:468/1500 train_loss:4.0131 train_time:188767ms step_avg:412.15ms
step:469/1500 train_loss:3.9802 train_time:189175ms step_avg:412.15ms
step:470/1500 train_loss:3.8701 train_time:189584ms step_avg:412.14ms
step:471/1500 train_loss:3.9529 train_time:189992ms step_avg:412.13ms
step:472/1500 train_loss:4.0093 train_time:190399ms step_avg:412.12ms
step:473/1500 train_loss:3.9557 train_time:190808ms step_avg:412.11ms
step:474/1500 train_loss:3.9051 train_time:191216ms step_avg:412.10ms
step:475/1500 train_loss:3.7610 train_time:191624ms step_avg:412.10ms
step:476/1500 train_loss:4.1950 train_time:192031ms step_avg:412.08ms
step:477/1500 train_loss:3.9530 train_time:192440ms step_avg:412.08ms
step:478/1500 train_loss:3.7608 train_time:192848ms step_avg:412.07ms
step:479/1500 train_loss:3.9953 train_time:193256ms step_avg:412.06ms
step:480/1500 train_loss:3.9476 train_time:193664ms step_avg:412.05ms
step:481/1500 train_loss:4.0943 train_time:194072ms step_avg:412.04ms
step:482/1500 train_loss:3.9073 train_time:194481ms step_avg:412.04ms
step:483/1500 train_loss:3.7119 train_time:194888ms step_avg:412.03ms
step:484/1500 train_loss:3.9933 train_time:195296ms step_avg:412.02ms
step:485/1500 train_loss:3.8426 train_time:195703ms step_avg:412.01ms
step:486/1500 train_loss:3.8522 train_time:196112ms step_avg:412.00ms
step:487/1500 train_loss:3.7798 train_time:196521ms step_avg:411.99ms
step:488/1500 train_loss:3.8541 train_time:196930ms step_avg:411.99ms
step:489/1500 train_loss:4.0543 train_time:197337ms step_avg:411.98ms
step:490/1500 train_loss:3.8975 train_time:197746ms step_avg:411.97ms
step:491/1500 train_loss:3.7866 train_time:198156ms step_avg:411.97ms
step:492/1500 train_loss:3.8013 train_time:198565ms step_avg:411.96ms
step:493/1500 train_loss:3.9119 train_time:198975ms step_avg:411.96ms
step:494/1500 train_loss:3.7645 train_time:199383ms step_avg:411.95ms
step:495/1500 train_loss:3.8883 train_time:199792ms step_avg:411.94ms
step:496/1500 train_loss:3.8312 train_time:200201ms step_avg:411.94ms
step:497/1500 train_loss:3.7172 train_time:200610ms step_avg:411.93ms
step:498/1500 train_loss:3.9182 train_time:201019ms step_avg:411.92ms
step:499/1500 train_loss:3.9868 train_time:201428ms step_avg:411.92ms
step:500/1500 train_loss:4.0057 train_time:201836ms step_avg:411.91ms
step:500/1500 val_loss:3.8886 train_time:201849ms step_avg:411.94ms
step:501/1500 train_loss:3.9238 train_time:202241ms step_avg:411.90ms
step:502/1500 train_loss:3.9777 train_time:202649ms step_avg:411.89ms
step:503/1500 train_loss:3.9183 train_time:203057ms step_avg:411.88ms
step:504/1500 train_loss:3.9621 train_time:203465ms step_avg:411.87ms
step:505/1500 train_loss:3.9105 train_time:203873ms step_avg:411.86ms
step:506/1500 train_loss:4.0008 train_time:204282ms step_avg:411.86ms
step:507/1500 train_loss:3.8185 train_time:204690ms step_avg:411.85ms
step:508/1500 train_loss:3.9397 train_time:205099ms step_avg:411.85ms
step:509/1500 train_loss:4.0174 train_time:205507ms step_avg:411.84ms
step:510/1500 train_loss:3.9512 train_time:205916ms step_avg:411.83ms
step:511/1500 train_loss:3.7616 train_time:206322ms step_avg:411.82ms
step:512/1500 train_loss:3.9683 train_time:206731ms step_avg:411.81ms
step:513/1500 train_loss:3.9049 train_time:207138ms step_avg:411.81ms
step:514/1500 train_loss:3.8569 train_time:207547ms step_avg:411.80ms
step:515/1500 train_loss:3.9423 train_time:207956ms step_avg:411.79ms
step:516/1500 train_loss:3.9244 train_time:208363ms step_avg:411.79ms
step:517/1500 train_loss:4.2614 train_time:208770ms step_avg:411.78ms
step:518/1500 train_loss:3.8623 train_time:209178ms step_avg:411.77ms
step:519/1500 train_loss:3.9637 train_time:209586ms step_avg:411.76ms
step:520/1500 train_loss:3.8605 train_time:209995ms step_avg:411.75ms
step:521/1500 train_loss:3.8618 train_time:210403ms step_avg:411.75ms
step:522/1500 train_loss:3.8206 train_time:210811ms step_avg:411.74ms
step:523/1500 train_loss:3.8325 train_time:211220ms step_avg:411.73ms
step:524/1500 train_loss:4.4589 train_time:211628ms step_avg:411.73ms
step:525/1500 train_loss:3.9235 train_time:212036ms step_avg:411.72ms
step:526/1500 train_loss:3.8594 train_time:212444ms step_avg:411.71ms
step:527/1500 train_loss:3.8732 train_time:212852ms step_avg:411.71ms
step:528/1500 train_loss:3.8322 train_time:213260ms step_avg:411.70ms
step:529/1500 train_loss:3.8024 train_time:213668ms step_avg:411.69ms
step:530/1500 train_loss:4.0233 train_time:214076ms step_avg:411.69ms
step:531/1500 train_loss:3.8178 train_time:214485ms step_avg:411.68ms
step:532/1500 train_loss:4.0942 train_time:214893ms step_avg:411.67ms
step:533/1500 train_loss:3.9092 train_time:215302ms step_avg:411.67ms
step:534/1500 train_loss:3.8374 train_time:215710ms step_avg:411.66ms
step:535/1500 train_loss:3.8583 train_time:216118ms step_avg:411.65ms
step:536/1500 train_loss:3.7995 train_time:216525ms step_avg:411.64ms
step:537/1500 train_loss:3.9230 train_time:216932ms step_avg:411.64ms
step:538/1500 train_loss:3.9087 train_time:217341ms step_avg:411.63ms
step:539/1500 train_loss:3.8187 train_time:217750ms step_avg:411.63ms
step:540/1500 train_loss:4.2991 train_time:218157ms step_avg:411.62ms
step:541/1500 train_loss:3.8457 train_time:218565ms step_avg:411.61ms
step:542/1500 train_loss:3.9595 train_time:218973ms step_avg:411.60ms
step:543/1500 train_loss:3.7861 train_time:219382ms step_avg:411.60ms
step:544/1500 train_loss:3.7627 train_time:219789ms step_avg:411.59ms
step:545/1500 train_loss:3.8411 train_time:220196ms step_avg:411.58ms
step:546/1500 train_loss:3.7682 train_time:220604ms step_avg:411.57ms
step:547/1500 train_loss:3.8135 train_time:221011ms step_avg:411.57ms
step:548/1500 train_loss:3.8296 train_time:221419ms step_avg:411.56ms
step:549/1500 train_loss:3.8035 train_time:221828ms step_avg:411.56ms
step:550/1500 train_loss:3.8993 train_time:222236ms step_avg:411.55ms
step:551/1500 train_loss:3.7872 train_time:222645ms step_avg:411.54ms
step:552/1500 train_loss:3.7992 train_time:223053ms step_avg:411.54ms
step:553/1500 train_loss:4.1356 train_time:223462ms step_avg:411.53ms
step:554/1500 train_loss:3.9288 train_time:223873ms step_avg:411.53ms
step:555/1500 train_loss:3.8880 train_time:224282ms step_avg:411.53ms
step:556/1500 train_loss:3.8237 train_time:224691ms step_avg:411.52ms
step:557/1500 train_loss:3.8613 train_time:225098ms step_avg:411.51ms
step:558/1500 train_loss:3.5226 train_time:225507ms step_avg:411.51ms
step:559/1500 train_loss:3.7862 train_time:225915ms step_avg:411.50ms
step:560/1500 train_loss:3.8248 train_time:226324ms step_avg:411.50ms
step:561/1500 train_loss:3.8766 train_time:226732ms step_avg:411.49ms
step:562/1500 train_loss:3.7826 train_time:227140ms step_avg:411.49ms
step:563/1500 train_loss:3.7236 train_time:227548ms step_avg:411.48ms
step:564/1500 train_loss:3.9365 train_time:227957ms step_avg:411.48ms
step:565/1500 train_loss:3.7447 train_time:228365ms step_avg:411.47ms
step:566/1500 train_loss:3.8625 train_time:228774ms step_avg:411.46ms
step:567/1500 train_loss:3.8177 train_time:230009ms step_avg:412.94ms
step:568/1500 train_loss:3.7603 train_time:230418ms step_avg:412.94ms
step:569/1500 train_loss:3.8600 train_time:230826ms step_avg:412.93ms
step:570/1500 train_loss:3.8339 train_time:231411ms step_avg:413.23ms
step:571/1500 train_loss:3.8598 train_time:231824ms step_avg:413.23ms
step:572/1500 train_loss:3.9399 train_time:232232ms step_avg:413.22ms
step:573/1500 train_loss:3.8931 train_time:232639ms step_avg:413.21ms
step:574/1500 train_loss:3.9016 train_time:233047ms step_avg:413.20ms
step:575/1500 train_loss:3.9486 train_time:233456ms step_avg:413.20ms
step:576/1500 train_loss:3.9041 train_time:233863ms step_avg:413.19ms
step:577/1500 train_loss:3.9307 train_time:234270ms step_avg:413.18ms
step:578/1500 train_loss:3.8552 train_time:234679ms step_avg:413.17ms
step:579/1500 train_loss:3.8480 train_time:235090ms step_avg:413.16ms
step:580/1500 train_loss:3.8321 train_time:235497ms step_avg:413.15ms
step:581/1500 train_loss:3.7738 train_time:235906ms step_avg:413.14ms
step:582/1500 train_loss:3.8047 train_time:236313ms step_avg:413.13ms
step:583/1500 train_loss:4.0266 train_time:236722ms step_avg:413.13ms
step:584/1500 train_loss:3.7999 train_time:237131ms step_avg:413.12ms
step:585/1500 train_loss:3.7624 train_time:237538ms step_avg:413.11ms
step:586/1500 train_loss:3.9520 train_time:237946ms step_avg:413.10ms
step:587/1500 train_loss:3.7069 train_time:238355ms step_avg:413.09ms
step:588/1500 train_loss:3.8398 train_time:238762ms step_avg:413.08ms
step:589/1500 train_loss:3.8238 train_time:239169ms step_avg:413.07ms
step:590/1500 train_loss:4.1758 train_time:239577ms step_avg:413.06ms
step:591/1500 train_loss:3.9537 train_time:239984ms step_avg:413.05ms
step:592/1500 train_loss:3.6956 train_time:240391ms step_avg:413.04ms
step:593/1500 train_loss:3.7086 train_time:240799ms step_avg:413.04ms
step:594/1500 train_loss:3.6999 train_time:241207ms step_avg:413.02ms
step:595/1500 train_loss:3.7373 train_time:241614ms step_avg:413.01ms
step:596/1500 train_loss:4.1084 train_time:242021ms step_avg:413.00ms
step:597/1500 train_loss:3.8243 train_time:242429ms step_avg:413.00ms
step:598/1500 train_loss:3.7538 train_time:242837ms step_avg:412.99ms
step:599/1500 train_loss:3.8310 train_time:243245ms step_avg:412.98ms
step:600/1500 train_loss:3.6453 train_time:243653ms step_avg:412.97ms
step:601/1500 train_loss:3.7684 train_time:244061ms step_avg:412.96ms
step:602/1500 train_loss:3.8073 train_time:244469ms step_avg:412.95ms
step:603/1500 train_loss:3.8316 train_time:244877ms step_avg:412.95ms
step:604/1500 train_loss:3.9523 train_time:245286ms step_avg:412.94ms
step:605/1500 train_loss:3.8080 train_time:245694ms step_avg:412.93ms
step:606/1500 train_loss:3.7899 train_time:246101ms step_avg:412.92ms
step:607/1500 train_loss:3.7395 train_time:246522ms step_avg:412.93ms
step:608/1500 train_loss:3.9872 train_time:246929ms step_avg:412.92ms
step:609/1500 train_loss:3.8154 train_time:247336ms step_avg:412.92ms
step:610/1500 train_loss:3.7890 train_time:247743ms step_avg:412.91ms
step:611/1500 train_loss:3.8919 train_time:248151ms step_avg:412.90ms
step:612/1500 train_loss:3.7961 train_time:248557ms step_avg:412.89ms
step:613/1500 train_loss:3.7774 train_time:248964ms step_avg:412.88ms
step:614/1500 train_loss:3.9404 train_time:249371ms step_avg:412.87ms
step:615/1500 train_loss:3.8909 train_time:249778ms step_avg:412.86ms
step:616/1500 train_loss:3.8569 train_time:250188ms step_avg:412.85ms
step:617/1500 train_loss:3.7918 train_time:250596ms step_avg:412.84ms
step:618/1500 train_loss:3.7459 train_time:251005ms step_avg:412.84ms
step:619/1500 train_loss:3.8540 train_time:251414ms step_avg:412.83ms
step:620/1500 train_loss:3.7407 train_time:251822ms step_avg:412.82ms
step:621/1500 train_loss:3.7618 train_time:252230ms step_avg:412.81ms
step:622/1500 train_loss:4.0812 train_time:252638ms step_avg:412.81ms
step:623/1500 train_loss:3.7584 train_time:253047ms step_avg:412.80ms
step:624/1500 train_loss:3.7881 train_time:253456ms step_avg:412.79ms
step:625/1500 train_loss:3.8708 train_time:253865ms step_avg:412.79ms
step:625/1500 val_loss:3.7976 train_time:253878ms step_avg:412.81ms
step:626/1500 train_loss:3.8908 train_time:254268ms step_avg:412.77ms
step:627/1500 train_loss:3.9217 train_time:254677ms step_avg:412.77ms
step:628/1500 train_loss:3.8977 train_time:255086ms step_avg:412.76ms
step:629/1500 train_loss:3.9443 train_time:255495ms step_avg:412.75ms
step:630/1500 train_loss:3.7614 train_time:255904ms step_avg:412.75ms
step:631/1500 train_loss:3.8908 train_time:256313ms step_avg:412.74ms
step:632/1500 train_loss:3.9259 train_time:256722ms step_avg:412.74ms
step:633/1500 train_loss:3.8253 train_time:257129ms step_avg:412.73ms
step:634/1500 train_loss:3.7585 train_time:257536ms step_avg:412.72ms
step:635/1500 train_loss:3.8556 train_time:257944ms step_avg:412.71ms
step:636/1500 train_loss:4.1161 train_time:258354ms step_avg:412.71ms
step:637/1500 train_loss:3.7019 train_time:258763ms step_avg:412.70ms
step:638/1500 train_loss:3.5219 train_time:259171ms step_avg:412.69ms
step:639/1500 train_loss:3.7535 train_time:259578ms step_avg:412.68ms
step:640/1500 train_loss:3.7900 train_time:259985ms step_avg:412.67ms
step:641/1500 train_loss:3.7428 train_time:260394ms step_avg:412.67ms
step:642/1500 train_loss:3.7412 train_time:260801ms step_avg:412.66ms
step:643/1500 train_loss:3.7878 train_time:261209ms step_avg:412.65ms
step:644/1500 train_loss:3.8015 train_time:261619ms step_avg:412.65ms
step:645/1500 train_loss:3.7260 train_time:262026ms step_avg:412.64ms
step:646/1500 train_loss:3.9462 train_time:262435ms step_avg:412.63ms
step:647/1500 train_loss:3.8401 train_time:262844ms step_avg:412.63ms
step:648/1500 train_loss:3.8377 train_time:263253ms step_avg:412.62ms
step:649/1500 train_loss:3.8722 train_time:263662ms step_avg:412.62ms
step:650/1500 train_loss:3.9247 train_time:264070ms step_avg:412.61ms
step:651/1500 train_loss:3.7910 train_time:264477ms step_avg:412.60ms
step:652/1500 train_loss:3.9332 train_time:264887ms step_avg:412.60ms
step:653/1500 train_loss:3.7538 train_time:265296ms step_avg:412.59ms
step:654/1500 train_loss:3.8288 train_time:265704ms step_avg:412.58ms
step:655/1500 train_loss:3.5966 train_time:266111ms step_avg:412.58ms
step:656/1500 train_loss:3.7428 train_time:266520ms step_avg:412.57ms
step:657/1500 train_loss:3.7551 train_time:266929ms step_avg:412.56ms
step:658/1500 train_loss:3.6830 train_time:267337ms step_avg:412.56ms
step:659/1500 train_loss:3.8597 train_time:267746ms step_avg:412.55ms
step:660/1500 train_loss:3.7601 train_time:268154ms step_avg:412.54ms
step:661/1500 train_loss:3.8517 train_time:268563ms step_avg:412.54ms
step:662/1500 train_loss:3.9191 train_time:268970ms step_avg:412.53ms
step:663/1500 train_loss:3.8327 train_time:269377ms step_avg:412.52ms
step:664/1500 train_loss:3.7177 train_time:269786ms step_avg:412.52ms
step:665/1500 train_loss:3.7961 train_time:270194ms step_avg:412.51ms
step:666/1500 train_loss:3.6674 train_time:270601ms step_avg:412.50ms
step:667/1500 train_loss:3.9551 train_time:271008ms step_avg:412.49ms
step:668/1500 train_loss:3.7888 train_time:271415ms step_avg:412.49ms
step:669/1500 train_loss:3.8006 train_time:271823ms step_avg:412.48ms
step:670/1500 train_loss:3.6514 train_time:272230ms step_avg:412.47ms
step:671/1500 train_loss:3.7654 train_time:272639ms step_avg:412.46ms
step:672/1500 train_loss:3.7236 train_time:273049ms step_avg:412.46ms
step:673/1500 train_loss:3.7423 train_time:273457ms step_avg:412.45ms
step:674/1500 train_loss:4.0178 train_time:273865ms step_avg:412.45ms
step:675/1500 train_loss:3.8112 train_time:274273ms step_avg:412.44ms
step:676/1500 train_loss:3.8808 train_time:274682ms step_avg:412.44ms
step:677/1500 train_loss:3.6555 train_time:275089ms step_avg:412.43ms
step:678/1500 train_loss:3.7639 train_time:275497ms step_avg:412.42ms
step:679/1500 train_loss:3.7112 train_time:275906ms step_avg:412.42ms
step:680/1500 train_loss:3.8468 train_time:276314ms step_avg:412.41ms
step:681/1500 train_loss:3.7522 train_time:276721ms step_avg:412.40ms
step:682/1500 train_loss:3.7902 train_time:277130ms step_avg:412.40ms
step:683/1500 train_loss:3.8541 train_time:277539ms step_avg:412.39ms
step:684/1500 train_loss:3.9004 train_time:277948ms step_avg:412.39ms
step:685/1500 train_loss:3.8015 train_time:278357ms step_avg:412.38ms
step:686/1500 train_loss:3.8692 train_time:278764ms step_avg:412.37ms
step:687/1500 train_loss:3.7985 train_time:279172ms step_avg:412.37ms
step:688/1500 train_loss:3.8454 train_time:279584ms step_avg:412.37ms
step:689/1500 train_loss:3.4736 train_time:279992ms step_avg:412.36ms
step:690/1500 train_loss:3.5827 train_time:280401ms step_avg:412.35ms
step:691/1500 train_loss:3.7178 train_time:280809ms step_avg:412.35ms
step:692/1500 train_loss:3.5955 train_time:281216ms step_avg:412.34ms
step:693/1500 train_loss:3.8097 train_time:281623ms step_avg:412.33ms
step:694/1500 train_loss:3.8281 train_time:282031ms step_avg:412.33ms
step:695/1500 train_loss:3.7168 train_time:282440ms step_avg:412.32ms
step:696/1500 train_loss:3.7066 train_time:282848ms step_avg:412.31ms
step:697/1500 train_loss:4.0209 train_time:283255ms step_avg:412.31ms
step:698/1500 train_loss:3.7660 train_time:283664ms step_avg:412.30ms
step:699/1500 train_loss:3.8088 train_time:284072ms step_avg:412.30ms
step:700/1500 train_loss:3.9616 train_time:284479ms step_avg:412.29ms
step:701/1500 train_loss:3.7383 train_time:284888ms step_avg:412.28ms
step:702/1500 train_loss:3.7007 train_time:285296ms step_avg:412.28ms
step:703/1500 train_loss:3.6800 train_time:285704ms step_avg:412.27ms
step:704/1500 train_loss:3.6497 train_time:286113ms step_avg:412.27ms
step:705/1500 train_loss:3.7365 train_time:286520ms step_avg:412.26ms
step:706/1500 train_loss:3.7269 train_time:286928ms step_avg:412.25ms
step:707/1500 train_loss:3.7421 train_time:287336ms step_avg:412.25ms
step:708/1500 train_loss:3.8058 train_time:287745ms step_avg:412.24ms
step:709/1500 train_loss:3.7612 train_time:288153ms step_avg:412.24ms
step:710/1500 train_loss:3.7422 train_time:288562ms step_avg:412.23ms
step:711/1500 train_loss:3.7076 train_time:288972ms step_avg:412.23ms
step:712/1500 train_loss:3.7596 train_time:289381ms step_avg:412.22ms
step:713/1500 train_loss:3.8174 train_time:289788ms step_avg:412.22ms
step:714/1500 train_loss:3.8199 train_time:290196ms step_avg:412.21ms
step:715/1500 train_loss:3.7303 train_time:290604ms step_avg:412.20ms
step:716/1500 train_loss:3.7350 train_time:291014ms step_avg:412.20ms
step:717/1500 train_loss:3.7521 train_time:291424ms step_avg:412.20ms
step:718/1500 train_loss:3.8938 train_time:291832ms step_avg:412.19ms
step:719/1500 train_loss:3.7550 train_time:292240ms step_avg:412.19ms
step:720/1500 train_loss:3.8347 train_time:292649ms step_avg:412.18ms
step:721/1500 train_loss:4.0051 train_time:293058ms step_avg:412.18ms
step:722/1500 train_loss:3.6295 train_time:293466ms step_avg:412.17ms
step:723/1500 train_loss:3.8893 train_time:293874ms step_avg:412.17ms
step:724/1500 train_loss:3.9461 train_time:294283ms step_avg:412.16ms
step:725/1500 train_loss:3.7306 train_time:294692ms step_avg:412.16ms
step:726/1500 train_loss:3.8092 train_time:295100ms step_avg:412.15ms
step:727/1500 train_loss:3.7031 train_time:295507ms step_avg:412.14ms
step:728/1500 train_loss:3.7230 train_time:295915ms step_avg:412.14ms
step:729/1500 train_loss:3.8996 train_time:296323ms step_avg:412.13ms
step:730/1500 train_loss:3.8393 train_time:296732ms step_avg:412.13ms
step:731/1500 train_loss:3.8368 train_time:297140ms step_avg:412.12ms
step:732/1500 train_loss:3.7308 train_time:297548ms step_avg:412.12ms
step:733/1500 train_loss:3.7448 train_time:297956ms step_avg:412.11ms
step:734/1500 train_loss:3.9939 train_time:298364ms step_avg:412.10ms
step:735/1500 train_loss:3.7231 train_time:298771ms step_avg:412.10ms
step:736/1500 train_loss:3.7820 train_time:299181ms step_avg:412.09ms
step:737/1500 train_loss:3.9034 train_time:299587ms step_avg:412.09ms
step:738/1500 train_loss:3.8201 train_time:299995ms step_avg:412.08ms
step:739/1500 train_loss:3.7633 train_time:300403ms step_avg:412.08ms
step:740/1500 train_loss:3.6623 train_time:300812ms step_avg:412.07ms
step:741/1500 train_loss:4.3071 train_time:301221ms step_avg:412.07ms
step:742/1500 train_loss:3.6607 train_time:301628ms step_avg:412.06ms
step:743/1500 train_loss:3.7415 train_time:302036ms step_avg:412.05ms
step:744/1500 train_loss:3.7467 train_time:302444ms step_avg:412.05ms
step:745/1500 train_loss:3.8057 train_time:302853ms step_avg:412.04ms
step:746/1500 train_loss:3.7699 train_time:303259ms step_avg:412.04ms
step:747/1500 train_loss:3.7660 train_time:303668ms step_avg:412.03ms
step:748/1500 train_loss:3.7944 train_time:304077ms step_avg:412.03ms
step:749/1500 train_loss:3.7254 train_time:304486ms step_avg:412.02ms
step:750/1500 train_loss:3.7241 train_time:304894ms step_avg:412.02ms
step:750/1500 val_loss:3.7327 train_time:304907ms step_avg:412.04ms
step:751/1500 train_loss:3.7592 train_time:305298ms step_avg:412.01ms
step:752/1500 train_loss:3.7215 train_time:305707ms step_avg:412.00ms
step:753/1500 train_loss:3.7617 train_time:306113ms step_avg:412.00ms
step:754/1500 train_loss:3.7807 train_time:306521ms step_avg:411.99ms
step:755/1500 train_loss:3.7541 train_time:306930ms step_avg:411.99ms
step:756/1500 train_loss:3.8278 train_time:307865ms step_avg:412.69ms
step:757/1500 train_loss:3.6569 train_time:308274ms step_avg:412.68ms
step:758/1500 train_loss:3.8958 train_time:308683ms step_avg:412.68ms
step:759/1500 train_loss:3.8079 train_time:309092ms step_avg:412.67ms
step:760/1500 train_loss:3.7443 train_time:309671ms step_avg:412.89ms
step:761/1500 train_loss:3.8547 train_time:310080ms step_avg:412.89ms
step:762/1500 train_loss:3.5603 train_time:310488ms step_avg:412.88ms
step:763/1500 train_loss:3.7160 train_time:310896ms step_avg:412.88ms
step:764/1500 train_loss:3.8274 train_time:311305ms step_avg:412.87ms
step:765/1500 train_loss:3.4770 train_time:311713ms step_avg:412.86ms
step:766/1500 train_loss:3.9046 train_time:312122ms step_avg:412.86ms
step:767/1500 train_loss:3.7456 train_time:312530ms step_avg:412.85ms
step:768/1500 train_loss:3.7226 train_time:312940ms step_avg:412.85ms
step:769/1500 train_loss:3.7378 train_time:313347ms step_avg:412.84ms
step:770/1500 train_loss:3.7539 train_time:313754ms step_avg:412.83ms
step:771/1500 train_loss:3.8131 train_time:314162ms step_avg:412.83ms
step:772/1500 train_loss:4.0400 train_time:314573ms step_avg:412.82ms
step:773/1500 train_loss:3.6185 train_time:314978ms step_avg:412.82ms
step:774/1500 train_loss:3.8091 train_time:315388ms step_avg:412.81ms
step:775/1500 train_loss:3.8023 train_time:315795ms step_avg:412.80ms
step:776/1500 train_loss:3.7662 train_time:316203ms step_avg:412.80ms
step:777/1500 train_loss:3.5734 train_time:316611ms step_avg:412.79ms
step:778/1500 train_loss:3.5630 train_time:317021ms step_avg:412.79ms
step:779/1500 train_loss:3.6373 train_time:317429ms step_avg:412.78ms
step:780/1500 train_loss:3.7308 train_time:317838ms step_avg:412.78ms
step:781/1500 train_loss:3.7619 train_time:318248ms step_avg:412.77ms
step:782/1500 train_loss:3.8172 train_time:318656ms step_avg:412.77ms
step:783/1500 train_loss:3.7388 train_time:319066ms step_avg:412.76ms
step:784/1500 train_loss:3.7276 train_time:319473ms step_avg:412.76ms
step:785/1500 train_loss:3.7412 train_time:319883ms step_avg:412.75ms
step:786/1500 train_loss:3.7155 train_time:320293ms step_avg:412.75ms
step:787/1500 train_loss:3.6110 train_time:320701ms step_avg:412.74ms
step:788/1500 train_loss:3.8685 train_time:321108ms step_avg:412.74ms
step:789/1500 train_loss:3.6617 train_time:321516ms step_avg:412.73ms
step:790/1500 train_loss:3.7198 train_time:321925ms step_avg:412.72ms
step:791/1500 train_loss:3.7878 train_time:322339ms step_avg:412.73ms
step:792/1500 train_loss:3.9171 train_time:322747ms step_avg:412.72ms
step:793/1500 train_loss:3.9226 train_time:323155ms step_avg:412.71ms
step:794/1500 train_loss:3.6276 train_time:323564ms step_avg:412.71ms
step:795/1500 train_loss:3.7630 train_time:323971ms step_avg:412.70ms
step:796/1500 train_loss:3.8205 train_time:324380ms step_avg:412.70ms
step:797/1500 train_loss:3.9140 train_time:324788ms step_avg:412.69ms
step:798/1500 train_loss:3.6708 train_time:325198ms step_avg:412.69ms
step:799/1500 train_loss:3.8180 train_time:325607ms step_avg:412.68ms
step:800/1500 train_loss:3.7189 train_time:326013ms step_avg:412.67ms
step:801/1500 train_loss:3.6997 train_time:326421ms step_avg:412.67ms
step:802/1500 train_loss:3.7897 train_time:326828ms step_avg:412.66ms
step:803/1500 train_loss:3.6518 train_time:327235ms step_avg:412.65ms
step:804/1500 train_loss:3.6708 train_time:327644ms step_avg:412.65ms
step:805/1500 train_loss:3.7906 train_time:328054ms step_avg:412.65ms
step:806/1500 train_loss:3.6879 train_time:328463ms step_avg:412.64ms
step:807/1500 train_loss:3.7014 train_time:328872ms step_avg:412.64ms
step:808/1500 train_loss:3.8014 train_time:329280ms step_avg:412.63ms
step:809/1500 train_loss:3.7178 train_time:329690ms step_avg:412.63ms
step:810/1500 train_loss:3.6402 train_time:330098ms step_avg:412.62ms
step:811/1500 train_loss:3.7278 train_time:330504ms step_avg:412.61ms
step:812/1500 train_loss:3.7529 train_time:330912ms step_avg:412.61ms
step:813/1500 train_loss:3.7552 train_time:331320ms step_avg:412.60ms
step:814/1500 train_loss:3.7909 train_time:331729ms step_avg:412.60ms
step:815/1500 train_loss:3.7345 train_time:332139ms step_avg:412.59ms
step:816/1500 train_loss:3.7195 train_time:332546ms step_avg:412.59ms
step:817/1500 train_loss:3.8217 train_time:332954ms step_avg:412.58ms
step:818/1500 train_loss:3.9170 train_time:333363ms step_avg:412.58ms
step:819/1500 train_loss:3.6813 train_time:333771ms step_avg:412.57ms
step:820/1500 train_loss:3.8806 train_time:334180ms step_avg:412.57ms
step:821/1500 train_loss:3.6639 train_time:334588ms step_avg:412.56ms
step:822/1500 train_loss:3.7068 train_time:334995ms step_avg:412.56ms
step:823/1500 train_loss:3.8280 train_time:335405ms step_avg:412.55ms
step:824/1500 train_loss:3.7406 train_time:335814ms step_avg:412.55ms
step:825/1500 train_loss:3.6733 train_time:336221ms step_avg:412.54ms
step:826/1500 train_loss:3.7737 train_time:336630ms step_avg:412.54ms
step:827/1500 train_loss:3.6554 train_time:337038ms step_avg:412.53ms
step:828/1500 train_loss:3.8934 train_time:337445ms step_avg:412.52ms
step:829/1500 train_loss:3.7771 train_time:337853ms step_avg:412.52ms
step:830/1500 train_loss:3.8292 train_time:338262ms step_avg:412.51ms
step:831/1500 train_loss:3.6912 train_time:338672ms step_avg:412.51ms
step:832/1500 train_loss:3.7416 train_time:339080ms step_avg:412.51ms
step:833/1500 train_loss:3.6736 train_time:339487ms step_avg:412.50ms
step:834/1500 train_loss:3.8046 train_time:339896ms step_avg:412.50ms
step:835/1500 train_loss:3.6339 train_time:340306ms step_avg:412.49ms
step:836/1500 train_loss:3.6153 train_time:340715ms step_avg:412.49ms
step:837/1500 train_loss:3.8770 train_time:341122ms step_avg:412.48ms
step:838/1500 train_loss:3.5771 train_time:341530ms step_avg:412.48ms
step:839/1500 train_loss:3.7487 train_time:341939ms step_avg:412.47ms
step:840/1500 train_loss:3.5935 train_time:342346ms step_avg:412.47ms
step:841/1500 train_loss:3.6303 train_time:342754ms step_avg:412.46ms
step:842/1500 train_loss:3.7196 train_time:343162ms step_avg:412.45ms
step:843/1500 train_loss:3.7373 train_time:343571ms step_avg:412.45ms
step:844/1500 train_loss:3.7356 train_time:343979ms step_avg:412.44ms
step:845/1500 train_loss:3.5877 train_time:344387ms step_avg:412.44ms
step:846/1500 train_loss:3.8199 train_time:344793ms step_avg:412.43ms
step:847/1500 train_loss:3.6912 train_time:345202ms step_avg:412.43ms
step:848/1500 train_loss:3.6446 train_time:345613ms step_avg:412.43ms
step:849/1500 train_loss:3.7835 train_time:346021ms step_avg:412.42ms
step:850/1500 train_loss:3.6548 train_time:346428ms step_avg:412.41ms
step:851/1500 train_loss:3.6050 train_time:346836ms step_avg:412.41ms
step:852/1500 train_loss:3.8980 train_time:347243ms step_avg:412.40ms
step:853/1500 train_loss:3.6101 train_time:347653ms step_avg:412.40ms
step:854/1500 train_loss:3.7229 train_time:348062ms step_avg:412.40ms
step:855/1500 train_loss:3.8064 train_time:348471ms step_avg:412.39ms
step:856/1500 train_loss:3.6800 train_time:348880ms step_avg:412.39ms
step:857/1500 train_loss:3.7048 train_time:349289ms step_avg:412.38ms
step:858/1500 train_loss:3.7549 train_time:349698ms step_avg:412.38ms
step:859/1500 train_loss:3.6405 train_time:350107ms step_avg:412.38ms
step:860/1500 train_loss:3.7179 train_time:350515ms step_avg:412.37ms
step:861/1500 train_loss:3.7453 train_time:350924ms step_avg:412.37ms
step:862/1500 train_loss:3.7975 train_time:351332ms step_avg:412.36ms
step:863/1500 train_loss:3.7490 train_time:351741ms step_avg:412.36ms
step:864/1500 train_loss:3.7299 train_time:352150ms step_avg:412.35ms
step:865/1500 train_loss:3.5522 train_time:352560ms step_avg:412.35ms
step:866/1500 train_loss:3.7454 train_time:352968ms step_avg:412.35ms
step:867/1500 train_loss:4.0225 train_time:353378ms step_avg:412.34ms
step:868/1500 train_loss:3.6066 train_time:353785ms step_avg:412.34ms
step:869/1500 train_loss:3.7910 train_time:354194ms step_avg:412.33ms
step:870/1500 train_loss:3.7690 train_time:354603ms step_avg:412.33ms
step:871/1500 train_loss:3.6075 train_time:355012ms step_avg:412.33ms
step:872/1500 train_loss:3.5649 train_time:355420ms step_avg:412.32ms
step:873/1500 train_loss:3.8176 train_time:355828ms step_avg:412.32ms
step:874/1500 train_loss:3.6091 train_time:356236ms step_avg:412.31ms
step:875/1500 train_loss:3.3355 train_time:356643ms step_avg:412.30ms
step:875/1500 val_loss:3.6805 train_time:356655ms step_avg:412.32ms
step:876/1500 train_loss:3.7912 train_time:357047ms step_avg:412.29ms
step:877/1500 train_loss:3.6048 train_time:357456ms step_avg:412.29ms
step:878/1500 train_loss:3.7800 train_time:357863ms step_avg:412.28ms
step:879/1500 train_loss:3.6323 train_time:358271ms step_avg:412.28ms
step:880/1500 train_loss:3.8178 train_time:358678ms step_avg:412.27ms
step:881/1500 train_loss:3.4794 train_time:359085ms step_avg:412.27ms
step:882/1500 train_loss:3.6514 train_time:359493ms step_avg:412.26ms
step:883/1500 train_loss:3.8454 train_time:359901ms step_avg:412.26ms
step:884/1500 train_loss:4.0015 train_time:360309ms step_avg:412.25ms
step:885/1500 train_loss:3.7252 train_time:360717ms step_avg:412.25ms
step:886/1500 train_loss:3.6410 train_time:361124ms step_avg:412.24ms
step:887/1500 train_loss:3.7363 train_time:361533ms step_avg:412.24ms
step:888/1500 train_loss:4.2275 train_time:361940ms step_avg:412.23ms
step:889/1500 train_loss:3.9988 train_time:362348ms step_avg:412.23ms
step:890/1500 train_loss:3.6777 train_time:362757ms step_avg:412.22ms
step:891/1500 train_loss:3.6906 train_time:363164ms step_avg:412.22ms
step:892/1500 train_loss:3.5159 train_time:363572ms step_avg:412.21ms
step:893/1500 train_loss:3.8631 train_time:363980ms step_avg:412.21ms
step:894/1500 train_loss:3.5848 train_time:364389ms step_avg:412.21ms
step:895/1500 train_loss:3.8315 train_time:364797ms step_avg:412.20ms
step:896/1500 train_loss:3.8497 train_time:365205ms step_avg:412.20ms
step:897/1500 train_loss:3.6467 train_time:365613ms step_avg:412.19ms
step:898/1500 train_loss:3.6914 train_time:366020ms step_avg:412.18ms
step:899/1500 train_loss:3.7413 train_time:366426ms step_avg:412.18ms
step:900/1500 train_loss:3.6344 train_time:366835ms step_avg:412.17ms
step:901/1500 train_loss:3.5775 train_time:367242ms step_avg:412.17ms
step:902/1500 train_loss:3.7794 train_time:367649ms step_avg:412.16ms
step:903/1500 train_loss:3.7900 train_time:368056ms step_avg:412.16ms
step:904/1500 train_loss:3.6882 train_time:368464ms step_avg:412.15ms
step:905/1500 train_loss:3.6502 train_time:368873ms step_avg:412.15ms
step:906/1500 train_loss:3.6483 train_time:369282ms step_avg:412.14ms
step:907/1500 train_loss:3.8681 train_time:369689ms step_avg:412.14ms
step:908/1500 train_loss:3.6627 train_time:370096ms step_avg:412.13ms
step:909/1500 train_loss:3.7093 train_time:370510ms step_avg:412.14ms
step:910/1500 train_loss:3.6089 train_time:370915ms step_avg:412.13ms
step:911/1500 train_loss:3.7021 train_time:371322ms step_avg:412.12ms
step:912/1500 train_loss:3.7795 train_time:371730ms step_avg:412.12ms
step:913/1500 train_loss:3.7653 train_time:372138ms step_avg:412.11ms
step:914/1500 train_loss:3.6394 train_time:372545ms step_avg:412.11ms
step:915/1500 train_loss:3.8892 train_time:372955ms step_avg:412.10ms
step:916/1500 train_loss:3.6834 train_time:373363ms step_avg:412.10ms
step:917/1500 train_loss:3.7790 train_time:373770ms step_avg:412.10ms
step:918/1500 train_loss:3.7515 train_time:374179ms step_avg:412.09ms
step:919/1500 train_loss:4.9772 train_time:374586ms step_avg:412.09ms
step:920/1500 train_loss:3.6642 train_time:374994ms step_avg:412.08ms
step:921/1500 train_loss:3.7246 train_time:375403ms step_avg:412.08ms
step:922/1500 train_loss:3.6869 train_time:375811ms step_avg:412.07ms
step:923/1500 train_loss:3.7383 train_time:376218ms step_avg:412.07ms
step:924/1500 train_loss:3.7475 train_time:376626ms step_avg:412.06ms
step:925/1500 train_loss:3.8384 train_time:377036ms step_avg:412.06ms
step:926/1500 train_loss:3.8114 train_time:377444ms step_avg:412.06ms
step:927/1500 train_loss:3.7081 train_time:377853ms step_avg:412.05ms
step:928/1500 train_loss:3.7000 train_time:378264ms step_avg:412.05ms
step:929/1500 train_loss:3.9222 train_time:378671ms step_avg:412.05ms
step:930/1500 train_loss:3.7655 train_time:379082ms step_avg:412.05ms
step:931/1500 train_loss:3.5540 train_time:379490ms step_avg:412.04ms
step:932/1500 train_loss:3.6433 train_time:379899ms step_avg:412.04ms
step:933/1500 train_loss:3.8231 train_time:380307ms step_avg:412.03ms
step:934/1500 train_loss:3.5363 train_time:380717ms step_avg:412.03ms
step:935/1500 train_loss:3.7305 train_time:381125ms step_avg:412.03ms
step:936/1500 train_loss:3.6040 train_time:381533ms step_avg:412.02ms
step:937/1500 train_loss:3.6711 train_time:381942ms step_avg:412.02ms
step:938/1500 train_loss:3.7685 train_time:382351ms step_avg:412.02ms
step:939/1500 train_loss:3.6902 train_time:382759ms step_avg:412.01ms
step:940/1500 train_loss:3.8447 train_time:383186ms step_avg:412.03ms
step:941/1500 train_loss:3.6367 train_time:383600ms step_avg:412.03ms
step:942/1500 train_loss:3.6972 train_time:384013ms step_avg:412.03ms
step:943/1500 train_loss:3.4984 train_time:384424ms step_avg:412.03ms
step:944/1500 train_loss:3.8549 train_time:384836ms step_avg:412.03ms
step:945/1500 train_loss:3.5608 train_time:386039ms step_avg:412.88ms
step:946/1500 train_loss:3.5776 train_time:386451ms step_avg:412.87ms
step:947/1500 train_loss:5.1961 train_time:386862ms step_avg:412.87ms
step:948/1500 train_loss:3.7518 train_time:387275ms step_avg:412.87ms
step:949/1500 train_loss:3.6465 train_time:387686ms step_avg:412.87ms
step:950/1500 train_loss:3.5386 train_time:388284ms step_avg:413.07ms
step:951/1500 train_loss:3.6097 train_time:388698ms step_avg:413.07ms
step:952/1500 train_loss:3.5529 train_time:389093ms step_avg:413.05ms
step:953/1500 train_loss:3.6321 train_time:389499ms step_avg:413.04ms
step:954/1500 train_loss:3.7057 train_time:389908ms step_avg:413.04ms
step:955/1500 train_loss:3.5909 train_time:390316ms step_avg:413.03ms
step:956/1500 train_loss:3.6276 train_time:390723ms step_avg:413.03ms
step:957/1500 train_loss:3.5909 train_time:391131ms step_avg:413.02ms
step:958/1500 train_loss:3.6534 train_time:391558ms step_avg:413.04ms
step:959/1500 train_loss:3.6474 train_time:391971ms step_avg:413.04ms
step:960/1500 train_loss:3.6576 train_time:392383ms step_avg:413.03ms
step:961/1500 train_loss:3.5446 train_time:392795ms step_avg:413.03ms
step:962/1500 train_loss:3.8049 train_time:393207ms step_avg:413.03ms
step:963/1500 train_loss:3.7517 train_time:393620ms step_avg:413.03ms
step:964/1500 train_loss:3.5885 train_time:394031ms step_avg:413.03ms
step:965/1500 train_loss:3.6015 train_time:394448ms step_avg:413.03ms
step:966/1500 train_loss:3.6336 train_time:394861ms step_avg:413.03ms
step:967/1500 train_loss:3.8556 train_time:395273ms step_avg:413.03ms
step:968/1500 train_loss:3.6830 train_time:395684ms step_avg:413.03ms
step:969/1500 train_loss:3.6706 train_time:396096ms step_avg:413.03ms
step:970/1500 train_loss:3.7260 train_time:396506ms step_avg:413.03ms
step:971/1500 train_loss:3.5406 train_time:396915ms step_avg:413.02ms
step:972/1500 train_loss:3.6986 train_time:397328ms step_avg:413.02ms
step:973/1500 train_loss:3.6370 train_time:397739ms step_avg:413.02ms
step:974/1500 train_loss:3.6930 train_time:398151ms step_avg:413.02ms
step:975/1500 train_loss:3.7627 train_time:398563ms step_avg:413.02ms
step:976/1500 train_loss:3.6336 train_time:398974ms step_avg:413.02ms
step:977/1500 train_loss:3.8315 train_time:399387ms step_avg:413.02ms
step:978/1500 train_loss:3.7212 train_time:399799ms step_avg:413.02ms
step:979/1500 train_loss:3.5397 train_time:400209ms step_avg:413.01ms
step:980/1500 train_loss:3.8339 train_time:400622ms step_avg:413.01ms
step:981/1500 train_loss:3.5725 train_time:401034ms step_avg:413.01ms
step:982/1500 train_loss:3.7351 train_time:401450ms step_avg:413.01ms
step:983/1500 train_loss:3.7114 train_time:401862ms step_avg:413.01ms
step:984/1500 train_loss:3.7100 train_time:402274ms step_avg:413.01ms
step:985/1500 train_loss:3.6682 train_time:402685ms step_avg:413.01ms
step:986/1500 train_loss:3.7422 train_time:403095ms step_avg:413.01ms
step:987/1500 train_loss:3.5634 train_time:403505ms step_avg:413.00ms
step:988/1500 train_loss:3.6479 train_time:403917ms step_avg:413.00ms
step:989/1500 train_loss:3.6191 train_time:404328ms step_avg:413.00ms
step:990/1500 train_loss:3.5821 train_time:404740ms step_avg:413.00ms
step:991/1500 train_loss:3.8022 train_time:405152ms step_avg:413.00ms
step:992/1500 train_loss:3.6234 train_time:405564ms step_avg:413.00ms
step:993/1500 train_loss:3.5972 train_time:405975ms step_avg:413.00ms
step:994/1500 train_loss:3.6633 train_time:406387ms step_avg:412.99ms
step:995/1500 train_loss:3.7521 train_time:406799ms step_avg:412.99ms
step:996/1500 train_loss:3.6948 train_time:407211ms step_avg:412.99ms
step:997/1500 train_loss:3.6043 train_time:407623ms step_avg:412.99ms
step:998/1500 train_loss:3.9548 train_time:408034ms step_avg:412.99ms
step:999/1500 train_loss:3.6165 train_time:408449ms step_avg:412.99ms
step:1000/1500 train_loss:3.7388 train_time:408861ms step_avg:412.99ms
step:1000/1500 val_loss:3.6352 train_time:408864ms step_avg:412.99ms
step:1001/1500 train_loss:3.6042 train_time:409273ms step_avg:412.99ms
step:1002/1500 train_loss:3.6580 train_time:409684ms step_avg:412.99ms
step:1003/1500 train_loss:3.5422 train_time:410103ms step_avg:412.99ms
step:1004/1500 train_loss:3.7251 train_time:410515ms step_avg:412.99ms
step:1005/1500 train_loss:3.7825 train_time:410928ms step_avg:412.99ms
step:1006/1500 train_loss:3.5493 train_time:411341ms step_avg:412.99ms
step:1007/1500 train_loss:3.6363 train_time:411734ms step_avg:412.97ms
step:1008/1500 train_loss:3.6013 train_time:412143ms step_avg:412.97ms
step:1009/1500 train_loss:3.7230 train_time:412552ms step_avg:412.96ms
step:1010/1500 train_loss:3.8295 train_time:412960ms step_avg:412.96ms
step:1011/1500 train_loss:3.7167 train_time:413368ms step_avg:412.95ms
step:1012/1500 train_loss:3.6816 train_time:413776ms step_avg:412.95ms
step:1013/1500 train_loss:3.5472 train_time:414185ms step_avg:412.95ms
step:1014/1500 train_loss:3.6872 train_time:414591ms step_avg:412.94ms
step:1015/1500 train_loss:3.8002 train_time:415000ms step_avg:412.94ms
step:1016/1500 train_loss:3.5023 train_time:415408ms step_avg:412.93ms
step:1017/1500 train_loss:3.5919 train_time:415815ms step_avg:412.92ms
step:1018/1500 train_loss:3.5915 train_time:416223ms step_avg:412.92ms
step:1019/1500 train_loss:3.5454 train_time:416631ms step_avg:412.91ms
step:1020/1500 train_loss:3.6827 train_time:417039ms step_avg:412.91ms
step:1021/1500 train_loss:3.5977 train_time:417447ms step_avg:412.90ms
step:1022/1500 train_loss:3.5273 train_time:417855ms step_avg:412.90ms
step:1023/1500 train_loss:3.6354 train_time:418265ms step_avg:412.90ms
step:1024/1500 train_loss:3.6647 train_time:418674ms step_avg:412.89ms
step:1025/1500 train_loss:3.6428 train_time:419083ms step_avg:412.89ms
step:1026/1500 train_loss:3.6536 train_time:419490ms step_avg:412.88ms
step:1027/1500 train_loss:3.8112 train_time:419899ms step_avg:412.88ms
step:1028/1500 train_loss:3.4957 train_time:420306ms step_avg:412.87ms
step:1029/1500 train_loss:3.5542 train_time:420714ms step_avg:412.87ms
step:1030/1500 train_loss:3.5082 train_time:421123ms step_avg:412.87ms
step:1031/1500 train_loss:3.6798 train_time:421531ms step_avg:412.86ms
step:1032/1500 train_loss:3.6602 train_time:421938ms step_avg:412.86ms
step:1033/1500 train_loss:3.8418 train_time:422346ms step_avg:412.85ms
step:1034/1500 train_loss:3.6563 train_time:422754ms step_avg:412.85ms
step:1035/1500 train_loss:3.5750 train_time:423162ms step_avg:412.84ms
step:1036/1500 train_loss:3.6024 train_time:423570ms step_avg:412.84ms
step:1037/1500 train_loss:3.6552 train_time:423977ms step_avg:412.83ms
step:1038/1500 train_loss:3.9684 train_time:424386ms step_avg:412.83ms
step:1039/1500 train_loss:3.7852 train_time:424794ms step_avg:412.82ms
step:1040/1500 train_loss:3.6802 train_time:425201ms step_avg:412.82ms
step:1041/1500 train_loss:3.5787 train_time:425609ms step_avg:412.81ms
step:1042/1500 train_loss:3.6464 train_time:426018ms step_avg:412.81ms
step:1043/1500 train_loss:3.6789 train_time:426425ms step_avg:412.80ms
step:1044/1500 train_loss:3.6149 train_time:426833ms step_avg:412.80ms
step:1045/1500 train_loss:3.6260 train_time:427241ms step_avg:412.79ms
step:1046/1500 train_loss:3.7032 train_time:427648ms step_avg:412.79ms
step:1047/1500 train_loss:3.6043 train_time:428055ms step_avg:412.78ms
step:1048/1500 train_loss:3.8104 train_time:428463ms step_avg:412.78ms
step:1049/1500 train_loss:3.6592 train_time:428872ms step_avg:412.77ms
step:1050/1500 train_loss:3.5871 train_time:429280ms step_avg:412.77ms
step:1051/1500 train_loss:3.5597 train_time:429687ms step_avg:412.76ms
step:1052/1500 train_loss:3.6777 train_time:430094ms step_avg:412.76ms
step:1053/1500 train_loss:3.5495 train_time:430501ms step_avg:412.75ms
step:1054/1500 train_loss:3.8743 train_time:430911ms step_avg:412.75ms
step:1055/1500 train_loss:3.7042 train_time:431320ms step_avg:412.75ms
step:1056/1500 train_loss:3.5677 train_time:431728ms step_avg:412.74ms
step:1057/1500 train_loss:3.6621 train_time:432136ms step_avg:412.74ms
step:1058/1500 train_loss:3.7498 train_time:432545ms step_avg:412.73ms
step:1059/1500 train_loss:3.4687 train_time:432955ms step_avg:412.73ms
step:1060/1500 train_loss:3.5858 train_time:433364ms step_avg:412.73ms
step:1061/1500 train_loss:3.6110 train_time:433774ms step_avg:412.72ms
step:1062/1500 train_loss:3.5809 train_time:434224ms step_avg:412.76ms
step:1063/1500 train_loss:3.5591 train_time:434634ms step_avg:412.76ms
step:1064/1500 train_loss:3.6574 train_time:435041ms step_avg:412.75ms
step:1065/1500 train_loss:3.5603 train_time:435449ms step_avg:412.75ms
step:1066/1500 train_loss:3.5443 train_time:435857ms step_avg:412.74ms
step:1067/1500 train_loss:3.5727 train_time:436264ms step_avg:412.74ms
step:1068/1500 train_loss:3.4780 train_time:436671ms step_avg:412.73ms
step:1069/1500 train_loss:3.5945 train_time:437080ms step_avg:412.73ms
step:1070/1500 train_loss:3.4620 train_time:437489ms step_avg:412.73ms
step:1071/1500 train_loss:3.7233 train_time:437897ms step_avg:412.72ms
step:1072/1500 train_loss:3.6733 train_time:438306ms step_avg:412.72ms
step:1073/1500 train_loss:3.6282 train_time:438713ms step_avg:412.71ms
step:1074/1500 train_loss:3.6872 train_time:439123ms step_avg:412.71ms
step:1075/1500 train_loss:3.6312 train_time:439530ms step_avg:412.70ms
step:1076/1500 train_loss:3.5726 train_time:439938ms step_avg:412.70ms
step:1077/1500 train_loss:3.9666 train_time:440347ms step_avg:412.70ms
step:1078/1500 train_loss:3.6398 train_time:440755ms step_avg:412.69ms
step:1079/1500 train_loss:3.3484 train_time:441163ms step_avg:412.69ms
step:1080/1500 train_loss:3.7051 train_time:441570ms step_avg:412.68ms
step:1081/1500 train_loss:3.6197 train_time:441979ms step_avg:412.68ms
step:1082/1500 train_loss:3.6787 train_time:442387ms step_avg:412.67ms
step:1083/1500 train_loss:3.7854 train_time:442795ms step_avg:412.67ms
step:1084/1500 train_loss:3.6794 train_time:443205ms step_avg:412.67ms
step:1085/1500 train_loss:3.6434 train_time:443612ms step_avg:412.66ms
step:1086/1500 train_loss:3.6103 train_time:444020ms step_avg:412.66ms
step:1087/1500 train_loss:3.8121 train_time:444427ms step_avg:412.65ms
step:1088/1500 train_loss:3.6952 train_time:444836ms step_avg:412.65ms
step:1089/1500 train_loss:3.5347 train_time:445244ms step_avg:412.64ms
step:1090/1500 train_loss:3.5588 train_time:445652ms step_avg:412.64ms
step:1091/1500 train_loss:3.6719 train_time:446061ms step_avg:412.64ms
step:1092/1500 train_loss:3.4641 train_time:446471ms step_avg:412.63ms
step:1093/1500 train_loss:3.6677 train_time:446878ms step_avg:412.63ms
step:1094/1500 train_loss:3.8021 train_time:447286ms step_avg:412.63ms
step:1095/1500 train_loss:3.6385 train_time:447693ms step_avg:412.62ms
step:1096/1500 train_loss:3.5858 train_time:448101ms step_avg:412.62ms
step:1097/1500 train_loss:3.6156 train_time:448507ms step_avg:412.61ms
step:1098/1500 train_loss:3.6592 train_time:448917ms step_avg:412.61ms
step:1099/1500 train_loss:3.7358 train_time:449326ms step_avg:412.60ms
step:1100/1500 train_loss:3.6961 train_time:449735ms step_avg:412.60ms
step:1101/1500 train_loss:3.6190 train_time:450142ms step_avg:412.60ms
step:1102/1500 train_loss:3.4768 train_time:450550ms step_avg:412.59ms
step:1103/1500 train_loss:3.5576 train_time:450958ms step_avg:412.59ms
step:1104/1500 train_loss:3.6268 train_time:451368ms step_avg:412.58ms
step:1105/1500 train_loss:3.5059 train_time:451775ms step_avg:412.58ms
step:1106/1500 train_loss:4.2591 train_time:452184ms step_avg:412.58ms
step:1107/1500 train_loss:3.4138 train_time:452591ms step_avg:412.57ms
step:1108/1500 train_loss:3.7492 train_time:453000ms step_avg:412.57ms
step:1109/1500 train_loss:3.5341 train_time:453407ms step_avg:412.56ms
step:1110/1500 train_loss:3.6750 train_time:453814ms step_avg:412.56ms
step:1111/1500 train_loss:3.6095 train_time:454223ms step_avg:412.55ms
step:1112/1500 train_loss:3.6501 train_time:454632ms step_avg:412.55ms
step:1113/1500 train_loss:3.7485 train_time:455041ms step_avg:412.55ms
step:1114/1500 train_loss:3.6011 train_time:455447ms step_avg:412.54ms
step:1115/1500 train_loss:3.5531 train_time:455855ms step_avg:412.54ms
step:1116/1500 train_loss:3.4458 train_time:456262ms step_avg:412.53ms
step:1117/1500 train_loss:3.6193 train_time:456672ms step_avg:412.53ms
step:1118/1500 train_loss:3.7678 train_time:457082ms step_avg:412.53ms
step:1119/1500 train_loss:3.8096 train_time:457491ms step_avg:412.53ms
step:1120/1500 train_loss:3.6493 train_time:457898ms step_avg:412.52ms
step:1121/1500 train_loss:3.6761 train_time:458306ms step_avg:412.52ms
step:1122/1500 train_loss:3.5692 train_time:458714ms step_avg:412.51ms
step:1123/1500 train_loss:3.6331 train_time:459122ms step_avg:412.51ms
step:1124/1500 train_loss:3.7688 train_time:459529ms step_avg:412.50ms
step:1125/1500 train_loss:3.5334 train_time:459938ms step_avg:412.50ms
step:1125/1500 val_loss:3.5982 train_time:459952ms step_avg:412.51ms
step:1126/1500 train_loss:3.4325 train_time:460343ms step_avg:412.49ms
step:1127/1500 train_loss:3.6547 train_time:460752ms step_avg:412.49ms
step:1128/1500 train_loss:3.8743 train_time:461160ms step_avg:412.49ms
step:1129/1500 train_loss:3.4190 train_time:461569ms step_avg:412.48ms
step:1130/1500 train_loss:3.7344 train_time:461977ms step_avg:412.48ms
step:1131/1500 train_loss:3.5688 train_time:462386ms step_avg:412.48ms
step:1132/1500 train_loss:3.5944 train_time:462796ms step_avg:412.47ms
step:1133/1500 train_loss:3.5470 train_time:463204ms step_avg:412.47ms
step:1134/1500 train_loss:3.7071 train_time:464231ms step_avg:413.02ms
step:1135/1500 train_loss:3.6470 train_time:464640ms step_avg:413.01ms
step:1136/1500 train_loss:3.6952 train_time:465050ms step_avg:413.01ms
step:1137/1500 train_loss:3.7330 train_time:465458ms step_avg:413.01ms
step:1138/1500 train_loss:3.6385 train_time:465868ms step_avg:413.00ms
step:1139/1500 train_loss:3.5416 train_time:466277ms step_avg:413.00ms
step:1140/1500 train_loss:3.8525 train_time:466861ms step_avg:413.15ms
step:1141/1500 train_loss:3.6482 train_time:467272ms step_avg:413.15ms
step:1142/1500 train_loss:3.7516 train_time:467679ms step_avg:413.14ms
step:1143/1500 train_loss:3.6397 train_time:468087ms step_avg:413.14ms
step:1144/1500 train_loss:3.5450 train_time:468496ms step_avg:413.14ms
step:1145/1500 train_loss:3.6513 train_time:468903ms step_avg:413.13ms
step:1146/1500 train_loss:3.7743 train_time:469311ms step_avg:413.13ms
step:1147/1500 train_loss:3.7430 train_time:469721ms step_avg:413.12ms
step:1148/1500 train_loss:3.6568 train_time:470129ms step_avg:413.12ms
step:1149/1500 train_loss:3.6811 train_time:470537ms step_avg:413.11ms
step:1150/1500 train_loss:3.5318 train_time:470946ms step_avg:413.11ms
step:1151/1500 train_loss:3.5533 train_time:471355ms step_avg:413.11ms
step:1152/1500 train_loss:3.5181 train_time:471766ms step_avg:413.10ms
step:1153/1500 train_loss:3.6640 train_time:472174ms step_avg:413.10ms
step:1154/1500 train_loss:3.6330 train_time:472584ms step_avg:413.10ms
step:1155/1500 train_loss:3.7013 train_time:472991ms step_avg:413.09ms
step:1156/1500 train_loss:3.5447 train_time:473399ms step_avg:413.09ms
step:1157/1500 train_loss:3.7224 train_time:473808ms step_avg:413.08ms
step:1158/1500 train_loss:3.6768 train_time:474217ms step_avg:413.08ms
step:1159/1500 train_loss:3.4896 train_time:474624ms step_avg:413.08ms
step:1160/1500 train_loss:3.5233 train_time:475033ms step_avg:413.07ms
step:1161/1500 train_loss:3.5180 train_time:475439ms step_avg:413.07ms
step:1162/1500 train_loss:3.3112 train_time:475847ms step_avg:413.06ms
step:1163/1500 train_loss:3.6322 train_time:476256ms step_avg:413.06ms
step:1164/1500 train_loss:3.6012 train_time:476665ms step_avg:413.05ms
step:1165/1500 train_loss:3.4657 train_time:477073ms step_avg:413.05ms
step:1166/1500 train_loss:3.4589 train_time:477482ms step_avg:413.05ms
step:1167/1500 train_loss:3.5659 train_time:477889ms step_avg:413.04ms
step:1168/1500 train_loss:3.5781 train_time:478297ms step_avg:413.04ms
step:1169/1500 train_loss:3.8982 train_time:478707ms step_avg:413.03ms
step:1170/1500 train_loss:3.5755 train_time:479115ms step_avg:413.03ms
step:1171/1500 train_loss:3.5881 train_time:479523ms step_avg:413.03ms
step:1172/1500 train_loss:3.4882 train_time:479931ms step_avg:413.02ms
step:1173/1500 train_loss:3.5942 train_time:480339ms step_avg:413.02ms
step:1174/1500 train_loss:3.7251 train_time:480748ms step_avg:413.01ms
step:1175/1500 train_loss:3.5732 train_time:481156ms step_avg:413.01ms
step:1176/1500 train_loss:3.5910 train_time:481564ms step_avg:413.00ms
step:1177/1500 train_loss:3.6412 train_time:481972ms step_avg:413.00ms
step:1178/1500 train_loss:3.6255 train_time:482381ms step_avg:413.00ms
step:1179/1500 train_loss:3.6825 train_time:482789ms step_avg:412.99ms
step:1180/1500 train_loss:3.5881 train_time:483197ms step_avg:412.99ms
step:1181/1500 train_loss:3.5926 train_time:483606ms step_avg:412.99ms
step:1182/1500 train_loss:3.5369 train_time:484013ms step_avg:412.98ms
step:1183/1500 train_loss:3.5740 train_time:484421ms step_avg:412.98ms
step:1184/1500 train_loss:3.5269 train_time:484830ms step_avg:412.97ms
step:1185/1500 train_loss:3.6921 train_time:485239ms step_avg:412.97ms
step:1186/1500 train_loss:3.7529 train_time:485647ms step_avg:412.97ms
step:1187/1500 train_loss:3.5520 train_time:486055ms step_avg:412.96ms
step:1188/1500 train_loss:3.6042 train_time:486463ms step_avg:412.96ms
step:1189/1500 train_loss:3.6219 train_time:486869ms step_avg:412.95ms
step:1190/1500 train_loss:3.4699 train_time:487278ms step_avg:412.95ms
step:1191/1500 train_loss:3.6464 train_time:487686ms step_avg:412.94ms
step:1192/1500 train_loss:3.7830 train_time:488095ms step_avg:412.94ms
step:1193/1500 train_loss:3.5847 train_time:488502ms step_avg:412.94ms
step:1194/1500 train_loss:3.4712 train_time:488910ms step_avg:412.93ms
step:1195/1500 train_loss:3.7703 train_time:489318ms step_avg:412.93ms
step:1196/1500 train_loss:3.5657 train_time:489727ms step_avg:412.92ms
step:1197/1500 train_loss:3.5746 train_time:490135ms step_avg:412.92ms
step:1198/1500 train_loss:3.4736 train_time:490543ms step_avg:412.91ms
step:1199/1500 train_loss:3.4855 train_time:490950ms step_avg:412.91ms
step:1200/1500 train_loss:3.5370 train_time:491360ms step_avg:412.91ms
step:1201/1500 train_loss:3.6210 train_time:491767ms step_avg:412.90ms
step:1202/1500 train_loss:3.6974 train_time:492176ms step_avg:412.90ms
step:1203/1500 train_loss:3.7382 train_time:492585ms step_avg:412.90ms
step:1204/1500 train_loss:3.6057 train_time:492995ms step_avg:412.89ms
step:1205/1500 train_loss:3.5219 train_time:493403ms step_avg:412.89ms
step:1206/1500 train_loss:3.6182 train_time:493811ms step_avg:412.89ms
step:1207/1500 train_loss:3.6590 train_time:494219ms step_avg:412.88ms
step:1208/1500 train_loss:3.7061 train_time:494629ms step_avg:412.88ms
step:1209/1500 train_loss:3.5910 train_time:495038ms step_avg:412.88ms
step:1210/1500 train_loss:3.4477 train_time:495446ms step_avg:412.87ms
step:1211/1500 train_loss:3.4954 train_time:495854ms step_avg:412.87ms
step:1212/1500 train_loss:3.6035 train_time:496265ms step_avg:412.87ms
step:1213/1500 train_loss:3.6094 train_time:496674ms step_avg:412.86ms
step:1214/1500 train_loss:3.6430 train_time:497082ms step_avg:412.86ms
step:1215/1500 train_loss:3.5216 train_time:497489ms step_avg:412.85ms
step:1216/1500 train_loss:3.5910 train_time:497897ms step_avg:412.85ms
step:1217/1500 train_loss:3.5340 train_time:498305ms step_avg:412.85ms
step:1218/1500 train_loss:3.5286 train_time:498713ms step_avg:412.84ms
step:1219/1500 train_loss:3.6187 train_time:499134ms step_avg:412.85ms
step:1220/1500 train_loss:3.4538 train_time:499542ms step_avg:412.84ms
step:1221/1500 train_loss:3.6893 train_time:499950ms step_avg:412.84ms
step:1222/1500 train_loss:3.7171 train_time:500359ms step_avg:412.84ms
step:1223/1500 train_loss:3.6291 train_time:500769ms step_avg:412.84ms
step:1224/1500 train_loss:3.4948 train_time:501176ms step_avg:412.83ms
step:1225/1500 train_loss:3.4885 train_time:501584ms step_avg:412.83ms
step:1226/1500 train_loss:3.5652 train_time:501991ms step_avg:412.82ms
step:1227/1500 train_loss:3.5438 train_time:502400ms step_avg:412.82ms
step:1228/1500 train_loss:3.4855 train_time:502809ms step_avg:412.82ms
step:1229/1500 train_loss:3.6579 train_time:503217ms step_avg:412.81ms
step:1230/1500 train_loss:3.5757 train_time:503624ms step_avg:412.81ms
step:1231/1500 train_loss:3.6355 train_time:504033ms step_avg:412.80ms
step:1232/1500 train_loss:3.7887 train_time:504441ms step_avg:412.80ms
step:1233/1500 train_loss:3.6877 train_time:504848ms step_avg:412.79ms
step:1234/1500 train_loss:3.6303 train_time:505256ms step_avg:412.79ms
step:1235/1500 train_loss:3.7746 train_time:505664ms step_avg:412.79ms
step:1236/1500 train_loss:3.5416 train_time:506072ms step_avg:412.78ms
step:1237/1500 train_loss:3.5028 train_time:506482ms step_avg:412.78ms
step:1238/1500 train_loss:3.4608 train_time:506891ms step_avg:412.78ms
step:1239/1500 train_loss:3.5215 train_time:507299ms step_avg:412.77ms
step:1240/1500 train_loss:3.5389 train_time:507709ms step_avg:412.77ms
step:1241/1500 train_loss:3.5841 train_time:508118ms step_avg:412.77ms
step:1242/1500 train_loss:3.6316 train_time:508525ms step_avg:412.76ms
step:1243/1500 train_loss:3.5072 train_time:508933ms step_avg:412.76ms
step:1244/1500 train_loss:3.6002 train_time:509341ms step_avg:412.76ms
step:1245/1500 train_loss:3.6091 train_time:509750ms step_avg:412.75ms
step:1246/1500 train_loss:3.6162 train_time:510160ms step_avg:412.75ms
step:1247/1500 train_loss:3.4455 train_time:510567ms step_avg:412.75ms
step:1248/1500 train_loss:3.5900 train_time:510975ms step_avg:412.74ms
step:1249/1500 train_loss:3.6445 train_time:511384ms step_avg:412.74ms
step:1250/1500 train_loss:3.6208 train_time:511793ms step_avg:412.74ms
step:1250/1500 val_loss:3.5661 train_time:511805ms step_avg:412.75ms
step:1251/1500 train_loss:3.5161 train_time:512197ms step_avg:412.73ms
step:1252/1500 train_loss:3.7222 train_time:512605ms step_avg:412.73ms
step:1253/1500 train_loss:3.5827 train_time:513012ms step_avg:412.72ms
step:1254/1500 train_loss:3.5133 train_time:513421ms step_avg:412.72ms
step:1255/1500 train_loss:3.6503 train_time:513829ms step_avg:412.71ms
step:1256/1500 train_loss:3.7118 train_time:514238ms step_avg:412.71ms
step:1257/1500 train_loss:3.5240 train_time:514646ms step_avg:412.71ms
step:1258/1500 train_loss:3.5531 train_time:515055ms step_avg:412.70ms
step:1259/1500 train_loss:3.6033 train_time:515462ms step_avg:412.70ms
step:1260/1500 train_loss:3.5425 train_time:515872ms step_avg:412.70ms
step:1261/1500 train_loss:3.4106 train_time:516279ms step_avg:412.69ms
step:1262/1500 train_loss:3.5083 train_time:516687ms step_avg:412.69ms
step:1263/1500 train_loss:3.5815 train_time:517096ms step_avg:412.69ms
step:1264/1500 train_loss:3.4305 train_time:517504ms step_avg:412.68ms
step:1265/1500 train_loss:3.6454 train_time:517913ms step_avg:412.68ms
step:1266/1500 train_loss:3.6285 train_time:518320ms step_avg:412.67ms
step:1267/1500 train_loss:3.6394 train_time:518728ms step_avg:412.67ms
step:1268/1500 train_loss:3.5782 train_time:519135ms step_avg:412.67ms
step:1269/1500 train_loss:3.6150 train_time:519544ms step_avg:412.66ms
step:1270/1500 train_loss:3.4749 train_time:519951ms step_avg:412.66ms
step:1271/1500 train_loss:3.3177 train_time:520360ms step_avg:412.66ms
step:1272/1500 train_loss:3.5975 train_time:520768ms step_avg:412.65ms
step:1273/1500 train_loss:3.5538 train_time:521176ms step_avg:412.65ms
step:1274/1500 train_loss:3.6064 train_time:521583ms step_avg:412.65ms
step:1275/1500 train_loss:3.5608 train_time:521991ms step_avg:412.64ms
step:1276/1500 train_loss:3.6559 train_time:522400ms step_avg:412.64ms
step:1277/1500 train_loss:3.6739 train_time:522810ms step_avg:412.64ms
step:1278/1500 train_loss:3.6339 train_time:523216ms step_avg:412.63ms
step:1279/1500 train_loss:3.6293 train_time:523625ms step_avg:412.63ms
step:1280/1500 train_loss:3.4571 train_time:524033ms step_avg:412.62ms
step:1281/1500 train_loss:3.5676 train_time:524442ms step_avg:412.62ms
step:1282/1500 train_loss:3.6370 train_time:524851ms step_avg:412.62ms
step:1283/1500 train_loss:3.6743 train_time:525260ms step_avg:412.62ms
step:1284/1500 train_loss:3.5660 train_time:525668ms step_avg:412.61ms
step:1285/1500 train_loss:3.5887 train_time:526076ms step_avg:412.61ms
step:1286/1500 train_loss:3.5736 train_time:526483ms step_avg:412.60ms
step:1287/1500 train_loss:3.5472 train_time:526891ms step_avg:412.60ms
step:1288/1500 train_loss:3.6813 train_time:527301ms step_avg:412.60ms
step:1289/1500 train_loss:3.5160 train_time:527710ms step_avg:412.60ms
step:1290/1500 train_loss:3.5983 train_time:528118ms step_avg:412.59ms
step:1291/1500 train_loss:3.6748 train_time:528525ms step_avg:412.59ms
step:1292/1500 train_loss:3.5963 train_time:528933ms step_avg:412.58ms
step:1293/1500 train_loss:3.6976 train_time:529342ms step_avg:412.58ms
step:1294/1500 train_loss:3.7175 train_time:529749ms step_avg:412.58ms
step:1295/1500 train_loss:3.6751 train_time:530158ms step_avg:412.57ms
step:1296/1500 train_loss:3.4827 train_time:530565ms step_avg:412.57ms
step:1297/1500 train_loss:3.5745 train_time:530973ms step_avg:412.57ms
step:1298/1500 train_loss:3.4703 train_time:531382ms step_avg:412.56ms
step:1299/1500 train_loss:3.5394 train_time:531792ms step_avg:412.56ms
step:1300/1500 train_loss:3.6087 train_time:532202ms step_avg:412.56ms
step:1301/1500 train_loss:3.6234 train_time:532609ms step_avg:412.56ms
step:1302/1500 train_loss:3.6238 train_time:533018ms step_avg:412.55ms
step:1303/1500 train_loss:3.7786 train_time:533427ms step_avg:412.55ms
step:1304/1500 train_loss:3.5554 train_time:533837ms step_avg:412.55ms
step:1305/1500 train_loss:3.7518 train_time:534246ms step_avg:412.55ms
step:1306/1500 train_loss:3.4773 train_time:534655ms step_avg:412.54ms
step:1307/1500 train_loss:3.6752 train_time:535063ms step_avg:412.54ms
step:1308/1500 train_loss:3.6736 train_time:535471ms step_avg:412.54ms
step:1309/1500 train_loss:3.5322 train_time:535878ms step_avg:412.53ms
step:1310/1500 train_loss:3.5072 train_time:536287ms step_avg:412.53ms
step:1311/1500 train_loss:3.5036 train_time:536694ms step_avg:412.52ms
step:1312/1500 train_loss:3.4982 train_time:537103ms step_avg:412.52ms
step:1313/1500 train_loss:3.6117 train_time:537510ms step_avg:412.52ms
step:1314/1500 train_loss:3.5646 train_time:537918ms step_avg:412.51ms
step:1315/1500 train_loss:3.2835 train_time:538327ms step_avg:412.51ms
step:1316/1500 train_loss:3.5103 train_time:538736ms step_avg:412.51ms
step:1317/1500 train_loss:3.5970 train_time:539144ms step_avg:412.50ms
step:1318/1500 train_loss:3.6190 train_time:539552ms step_avg:412.50ms
step:1319/1500 train_loss:3.5048 train_time:539962ms step_avg:412.50ms
step:1320/1500 train_loss:3.6332 train_time:540370ms step_avg:412.50ms
step:1321/1500 train_loss:3.6889 train_time:540778ms step_avg:412.49ms
step:1322/1500 train_loss:3.5772 train_time:541187ms step_avg:412.49ms
step:1323/1500 train_loss:3.5271 train_time:542432ms step_avg:413.12ms
step:1324/1500 train_loss:3.5510 train_time:542842ms step_avg:413.12ms
step:1325/1500 train_loss:3.6452 train_time:543249ms step_avg:413.12ms
step:1326/1500 train_loss:3.7029 train_time:543657ms step_avg:413.11ms
step:1327/1500 train_loss:3.4518 train_time:544066ms step_avg:413.11ms
step:1328/1500 train_loss:3.3818 train_time:544475ms step_avg:413.11ms
step:1329/1500 train_loss:3.6922 train_time:544884ms step_avg:413.10ms
step:1330/1500 train_loss:3.5437 train_time:545473ms step_avg:413.24ms
step:1331/1500 train_loss:3.6573 train_time:545881ms step_avg:413.23ms
step:1332/1500 train_loss:3.5613 train_time:546291ms step_avg:413.23ms
step:1333/1500 train_loss:3.9589 train_time:546698ms step_avg:413.23ms
step:1334/1500 train_loss:3.6674 train_time:547105ms step_avg:413.22ms
step:1335/1500 train_loss:3.5805 train_time:547514ms step_avg:413.22ms
step:1336/1500 train_loss:3.5247 train_time:547923ms step_avg:413.21ms
step:1337/1500 train_loss:3.5154 train_time:548332ms step_avg:413.21ms
step:1338/1500 train_loss:3.7774 train_time:548740ms step_avg:413.21ms
step:1339/1500 train_loss:3.7079 train_time:549148ms step_avg:413.20ms
step:1340/1500 train_loss:3.5524 train_time:549557ms step_avg:413.20ms
step:1341/1500 train_loss:3.5123 train_time:549966ms step_avg:413.20ms
step:1342/1500 train_loss:3.8182 train_time:550374ms step_avg:413.19ms
step:1343/1500 train_loss:3.5919 train_time:550782ms step_avg:413.19ms
step:1344/1500 train_loss:3.5877 train_time:551190ms step_avg:413.19ms
step:1345/1500 train_loss:3.6414 train_time:551598ms step_avg:413.18ms
step:1346/1500 train_loss:3.6039 train_time:552007ms step_avg:413.18ms
step:1347/1500 train_loss:3.5120 train_time:552416ms step_avg:413.18ms
step:1348/1500 train_loss:3.4635 train_time:552825ms step_avg:413.17ms
step:1349/1500 train_loss:3.5605 train_time:553232ms step_avg:413.17ms
step:1350/1500 train_loss:3.4898 train_time:553640ms step_avg:413.16ms
step:1351/1500 train_loss:3.6132 train_time:554047ms step_avg:413.16ms
step:1352/1500 train_loss:3.4701 train_time:554453ms step_avg:413.15ms
step:1353/1500 train_loss:3.5341 train_time:554863ms step_avg:413.15ms
step:1354/1500 train_loss:3.6302 train_time:555272ms step_avg:413.15ms
step:1355/1500 train_loss:3.4747 train_time:555681ms step_avg:413.15ms
step:1356/1500 train_loss:3.4000 train_time:556089ms step_avg:413.14ms
step:1357/1500 train_loss:3.7429 train_time:556497ms step_avg:413.14ms
step:1358/1500 train_loss:3.6786 train_time:556906ms step_avg:413.14ms
step:1359/1500 train_loss:3.3973 train_time:557315ms step_avg:413.13ms
step:1360/1500 train_loss:3.6754 train_time:557723ms step_avg:413.13ms
step:1361/1500 train_loss:3.5568 train_time:558131ms step_avg:413.12ms
step:1362/1500 train_loss:3.4108 train_time:558537ms step_avg:413.12ms
step:1363/1500 train_loss:3.6033 train_time:558945ms step_avg:413.12ms
step:1364/1500 train_loss:3.5010 train_time:559354ms step_avg:413.11ms
step:1365/1500 train_loss:3.5124 train_time:559765ms step_avg:413.11ms
step:1366/1500 train_loss:3.5370 train_time:560173ms step_avg:413.11ms
step:1367/1500 train_loss:3.6374 train_time:560580ms step_avg:413.10ms
step:1368/1500 train_loss:3.6230 train_time:560988ms step_avg:413.10ms
step:1369/1500 train_loss:3.5724 train_time:561396ms step_avg:413.09ms
step:1370/1500 train_loss:3.4867 train_time:561804ms step_avg:413.09ms
step:1371/1500 train_loss:3.8141 train_time:562211ms step_avg:413.09ms
step:1372/1500 train_loss:3.5536 train_time:562619ms step_avg:413.08ms
step:1373/1500 train_loss:3.5906 train_time:563028ms step_avg:413.08ms
step:1374/1500 train_loss:3.5877 train_time:563437ms step_avg:413.08ms
step:1375/1500 train_loss:3.3856 train_time:563846ms step_avg:413.07ms
step:1375/1500 val_loss:3.5416 train_time:563859ms step_avg:413.08ms
step:1376/1500 train_loss:3.7783 train_time:564252ms step_avg:413.07ms
step:1377/1500 train_loss:3.5585 train_time:564659ms step_avg:413.06ms
step:1378/1500 train_loss:3.7052 train_time:565068ms step_avg:413.06ms
step:1379/1500 train_loss:3.7365 train_time:565477ms step_avg:413.06ms
step:1380/1500 train_loss:3.3809 train_time:565885ms step_avg:413.05ms
step:1381/1500 train_loss:3.5484 train_time:566293ms step_avg:413.05ms
step:1382/1500 train_loss:3.9750 train_time:566700ms step_avg:413.05ms
step:1383/1500 train_loss:3.4550 train_time:567109ms step_avg:413.04ms
step:1384/1500 train_loss:3.6221 train_time:567519ms step_avg:413.04ms
step:1385/1500 train_loss:3.6915 train_time:567928ms step_avg:413.04ms
step:1386/1500 train_loss:3.6076 train_time:568336ms step_avg:413.03ms
step:1387/1500 train_loss:3.5882 train_time:568744ms step_avg:413.03ms
step:1388/1500 train_loss:3.4296 train_time:569151ms step_avg:413.03ms
step:1389/1500 train_loss:3.5650 train_time:569560ms step_avg:413.02ms
step:1390/1500 train_loss:3.5432 train_time:569969ms step_avg:413.02ms
step:1391/1500 train_loss:3.7975 train_time:570378ms step_avg:413.02ms
step:1392/1500 train_loss:3.5199 train_time:570785ms step_avg:413.01ms
step:1393/1500 train_loss:3.5108 train_time:571192ms step_avg:413.01ms
step:1394/1500 train_loss:3.4786 train_time:571601ms step_avg:413.01ms
step:1395/1500 train_loss:3.7585 train_time:572009ms step_avg:413.00ms
step:1396/1500 train_loss:3.6484 train_time:572417ms step_avg:413.00ms
step:1397/1500 train_loss:3.6550 train_time:572826ms step_avg:413.00ms
step:1398/1500 train_loss:3.5230 train_time:573232ms step_avg:412.99ms
step:1399/1500 train_loss:3.4986 train_time:573641ms step_avg:412.99ms
step:1400/1500 train_loss:3.5598 train_time:574050ms step_avg:412.99ms
step:1401/1500 train_loss:3.5399 train_time:574457ms step_avg:412.98ms
step:1402/1500 train_loss:3.5644 train_time:574866ms step_avg:412.98ms
step:1403/1500 train_loss:3.5249 train_time:575273ms step_avg:412.97ms
step:1404/1500 train_loss:3.7486 train_time:575681ms step_avg:412.97ms
step:1405/1500 train_loss:3.5005 train_time:576090ms step_avg:412.97ms
step:1406/1500 train_loss:3.5447 train_time:576498ms step_avg:412.96ms
step:1407/1500 train_loss:3.5466 train_time:576906ms step_avg:412.96ms
step:1408/1500 train_loss:3.4116 train_time:577312ms step_avg:412.96ms
step:1409/1500 train_loss:3.5315 train_time:577721ms step_avg:412.95ms
step:1410/1500 train_loss:3.5111 train_time:578129ms step_avg:412.95ms
step:1411/1500 train_loss:3.5091 train_time:578538ms step_avg:412.95ms
step:1412/1500 train_loss:3.6022 train_time:578948ms step_avg:412.94ms
step:1413/1500 train_loss:3.5375 train_time:579355ms step_avg:412.94ms
step:1414/1500 train_loss:3.5879 train_time:579764ms step_avg:412.94ms
step:1415/1500 train_loss:3.5722 train_time:580175ms step_avg:412.94ms
step:1416/1500 train_loss:3.6483 train_time:580582ms step_avg:412.93ms
step:1417/1500 train_loss:3.4591 train_time:580989ms step_avg:412.93ms
step:1418/1500 train_loss:3.5219 train_time:581397ms step_avg:412.92ms
step:1419/1500 train_loss:3.6133 train_time:581805ms step_avg:412.92ms
step:1420/1500 train_loss:3.6484 train_time:582215ms step_avg:412.92ms
step:1421/1500 train_loss:3.6251 train_time:582642ms step_avg:412.93ms
step:1422/1500 train_loss:3.6027 train_time:583053ms step_avg:412.93ms
step:1423/1500 train_loss:3.5749 train_time:583466ms step_avg:412.93ms
step:1424/1500 train_loss:3.5700 train_time:583880ms step_avg:412.93ms
step:1425/1500 train_loss:3.5688 train_time:584294ms step_avg:412.93ms
step:1426/1500 train_loss:3.4374 train_time:584706ms step_avg:412.93ms
step:1427/1500 train_loss:3.5534 train_time:585122ms step_avg:412.93ms
step:1428/1500 train_loss:3.4989 train_time:585535ms step_avg:412.93ms
step:1429/1500 train_loss:3.6094 train_time:585948ms step_avg:412.93ms
step:1430/1500 train_loss:3.5799 train_time:586361ms step_avg:412.93ms
step:1431/1500 train_loss:3.5031 train_time:586776ms step_avg:412.93ms
step:1432/1500 train_loss:3.5497 train_time:587187ms step_avg:412.93ms
step:1433/1500 train_loss:3.5838 train_time:587600ms step_avg:412.93ms
step:1434/1500 train_loss:3.4032 train_time:588018ms step_avg:412.93ms
step:1435/1500 train_loss:3.5595 train_time:588430ms step_avg:412.93ms
step:1436/1500 train_loss:3.3762 train_time:588844ms step_avg:412.93ms
step:1437/1500 train_loss:3.4512 train_time:589256ms step_avg:412.93ms
step:1438/1500 train_loss:3.6427 train_time:589667ms step_avg:412.93ms
step:1439/1500 train_loss:3.5986 train_time:590063ms step_avg:412.92ms
step:1440/1500 train_loss:3.5480 train_time:590471ms step_avg:412.92ms
step:1441/1500 train_loss:3.4125 train_time:590879ms step_avg:412.91ms
step:1442/1500 train_loss:3.5862 train_time:591287ms step_avg:412.91ms
step:1443/1500 train_loss:3.6386 train_time:591695ms step_avg:412.91ms
step:1444/1500 train_loss:3.7131 train_time:592104ms step_avg:412.90ms
step:1445/1500 train_loss:3.6817 train_time:592513ms step_avg:412.90ms
step:1446/1500 train_loss:3.5638 train_time:592922ms step_avg:412.90ms
step:1447/1500 train_loss:3.4364 train_time:593330ms step_avg:412.90ms
step:1448/1500 train_loss:3.5085 train_time:593739ms step_avg:412.89ms
step:1449/1500 train_loss:3.5276 train_time:594146ms step_avg:412.89ms
step:1450/1500 train_loss:3.6462 train_time:594555ms step_avg:412.89ms
step:1451/1500 train_loss:3.6417 train_time:594965ms step_avg:412.88ms
step:1452/1500 train_loss:3.4527 train_time:595374ms step_avg:412.88ms
step:1453/1500 train_loss:3.5722 train_time:595782ms step_avg:412.88ms
step:1454/1500 train_loss:3.4851 train_time:596190ms step_avg:412.87ms
step:1455/1500 train_loss:3.5155 train_time:596597ms step_avg:412.87ms
step:1456/1500 train_loss:3.5642 train_time:597006ms step_avg:412.87ms
step:1457/1500 train_loss:3.4972 train_time:597416ms step_avg:412.86ms
step:1458/1500 train_loss:3.3911 train_time:597825ms step_avg:412.86ms
step:1459/1500 train_loss:3.6379 train_time:598231ms step_avg:412.86ms
step:1460/1500 train_loss:3.5094 train_time:598639ms step_avg:412.85ms
step:1461/1500 train_loss:3.5596 train_time:599048ms step_avg:412.85ms
step:1462/1500 train_loss:3.6830 train_time:599458ms step_avg:412.85ms
step:1463/1500 train_loss:3.5013 train_time:599866ms step_avg:412.85ms
step:1464/1500 train_loss:3.6972 train_time:600273ms step_avg:412.84ms
step:1465/1500 train_loss:3.5871 train_time:600681ms step_avg:412.84ms
step:1466/1500 train_loss:3.5829 train_time:601088ms step_avg:412.84ms
step:1467/1500 train_loss:3.5132 train_time:601498ms step_avg:412.83ms
step:1468/1500 train_loss:3.6623 train_time:601908ms step_avg:412.83ms
step:1469/1500 train_loss:3.5369 train_time:602315ms step_avg:412.83ms
step:1470/1500 train_loss:3.5047 train_time:602723ms step_avg:412.82ms
step:1471/1500 train_loss:3.5593 train_time:603133ms step_avg:412.82ms
step:1472/1500 train_loss:3.4863 train_time:603543ms step_avg:412.82ms
step:1473/1500 train_loss:3.5828 train_time:603950ms step_avg:412.82ms
step:1474/1500 train_loss:3.6633 train_time:604358ms step_avg:412.81ms
step:1475/1500 train_loss:3.5437 train_time:604768ms step_avg:412.81ms
step:1476/1500 train_loss:3.3763 train_time:605177ms step_avg:412.81ms
step:1477/1500 train_loss:3.4932 train_time:605585ms step_avg:412.81ms
step:1478/1500 train_loss:3.4661 train_time:605995ms step_avg:412.80ms
step:1479/1500 train_loss:3.5552 train_time:606405ms step_avg:412.80ms
step:1480/1500 train_loss:3.6373 train_time:606813ms step_avg:412.80ms
step:1481/1500 train_loss:3.5030 train_time:607221ms step_avg:412.79ms
step:1482/1500 train_loss:3.6761 train_time:607629ms step_avg:412.79ms
step:1483/1500 train_loss:3.6146 train_time:608038ms step_avg:412.79ms
step:1484/1500 train_loss:3.5151 train_time:608446ms step_avg:412.79ms
step:1485/1500 train_loss:3.4961 train_time:608855ms step_avg:412.78ms
step:1486/1500 train_loss:3.5004 train_time:609265ms step_avg:412.78ms
step:1487/1500 train_loss:3.4754 train_time:609671ms step_avg:412.78ms
step:1488/1500 train_loss:3.5619 train_time:610081ms step_avg:412.77ms
step:1489/1500 train_loss:3.4767 train_time:610489ms step_avg:412.77ms
step:1490/1500 train_loss:3.5636 train_time:610898ms step_avg:412.77ms
step:1491/1500 train_loss:3.4938 train_time:611307ms step_avg:412.77ms
step:1492/1500 train_loss:3.4271 train_time:611715ms step_avg:412.76ms
step:1493/1500 train_loss:3.4941 train_time:612124ms step_avg:412.76ms
step:1494/1500 train_loss:3.6714 train_time:612534ms step_avg:412.76ms
step:1495/1500 train_loss:3.5243 train_time:612943ms step_avg:412.76ms
step:1496/1500 train_loss:3.2873 train_time:613351ms step_avg:412.75ms
step:1497/1500 train_loss:3.5932 train_time:613760ms step_avg:412.75ms
step:1498/1500 train_loss:3.5484 train_time:614167ms step_avg:412.75ms
step:1499/1500 train_loss:3.5983 train_time:614576ms step_avg:412.74ms
step:1500/1500 train_loss:3.5563 train_time:614984ms step_avg:412.74ms
step:1500/1500 val_loss:3.5267 train_time:614997ms step_avg:412.75ms
