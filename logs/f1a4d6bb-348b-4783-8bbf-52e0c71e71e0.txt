====================================================================================================
# NOTE: record from https://github.com/KellerJordan/modded-nanogpt/blob/master/records/track_1_short/2024-10-14_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt
# ====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
import json
import dataclasses
import subprocess
import csv
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \\sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=3e-4, momentum=0.95, nesterov=True, backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]
            for p in group['params']:
                g = p.grad
                if g is None:
                    continue
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.mul_(momentum).add_(g)
                if group['nesterov']:
                    g = g.add(buf, alpha=momentum)
                if g.size(0) == 3 * g.size(1): # split grouped QKV parameters
                    g = torch.cat([zeropower_backend(g1, steps=group['backend_steps']) for g1 in g.split(g.size(1))])
                    scale = g.size(1)**0.5
                else:
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    scale = max(g.size(0), g.size(1))**0.5 # scale to have update.square().mean() == 1
                p.data.add_(g, alpha=-lr * scale)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

def _apply_gate_act(logits: torch.Tensor, kind: str) -> torch.Tensor:
    if kind == "sigmoid":
        return torch.sigmoid(logits)
    if kind == "ns_sigmoid":
        return 0.5 + 0.5 * torch.sigmoid(logits)
    raise ValueError(f"unknown gate_act={kind}")

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.attn_gate = getattr(config, "attn_gate", "none")
        self.gate_pos = getattr(config, "gate_pos", "sdpa")
        self.gate_act = getattr(config, "gate_act", "sigmoid")
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)
        if self.attn_gate == "headwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_head, bias=False)
            self.gate_param = None
        elif self.attn_gate == "elementwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_embd, bias=False)
            self.gate_param = None
        elif self.attn_gate == "const":
            self.c_gate = None
            self.gate_param = nn.Parameter(torch.zeros(self.n_head, self.head_dim))
        else:
            self.c_gate = None
            self.gate_param = None

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        if self.attn_gate != "none" and self.gate_pos == "value":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            v = v * gate
        cos, sin = self.rotary(q)
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2) # (B, T, n_head, head_dim)
        if self.attn_gate != "none" and self.gate_pos == "sdpa":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            y = y * gate
        y = y.contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768
    attn_gate : str = "none"
    gate_pos : str = "sdpa"
    gate_act : str = "sigmoid"

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying

    def forward(self, idx, targets=None, return_logits=True):

        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8*64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 5100 # number of iterations to run
    learning_rate : float = 0.0036
    warmup_iters : int = 0
    warmdown_iters : int = 1450 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    seed : int = 1337
    attn_gate : str = "none" # none|headwise|elementwise|const
    gate_pos : str = "sdpa" # sdpa|value
    gate_act : str = "sigmoid" # sigmoid|ns_sigmoid
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

def apply_env_overrides():
    # environment-variable overrides allow quick sweeps without editing code
    args.learning_rate = float(os.environ.get("LR", args.learning_rate))
    args.seed = int(os.environ.get("SEED", args.seed))
    args.attn_gate = os.environ.get("ATTNGATE", args.attn_gate)
    args.gate_pos = os.environ.get("GATEPOS", args.gate_pos)
    args.gate_act = os.environ.get("GATEACT", args.gate_act)
    args.num_iterations = int(os.environ.get("NUM_ITER", args.num_iterations))
    args.val_loss_every = int(os.environ.get("VAL_EVERY", args.val_loss_every))

def get_git_commit():
    try:
        return subprocess.check_output(["git", "rev-parse", "HEAD"], text=True).strip()
    except Exception:
        return "unknown"

apply_env_overrides()
torch.manual_seed(args.seed)
torch.cuda.manual_seed_all(args.seed)
np.random.seed(args.seed)

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.
git_commit = get_git_commit() if master_process else "unknown"

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(
    vocab_size=num_vocab,
    n_layer=12,
    n_head=6,
    n_embd=768,
    attn_gate=args.attn_gate,
    gate_pos=args.gate_pos,
    gate_act=args.gate_act,
))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
optimizer1 = torch.optim.AdamW(raw_model.lm_head.parameters(), lr=args.learning_rate, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer2 = Muon(raw_model.transformer.h.parameters(), lr=0.1*args.learning_rate, momentum=0.95)
optimizers = [optimizer1, optimizer2]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        f.write(f"git_commit: {git_commit}\n")
        f.write(f"seed: {args.seed}\n")
        f.write("hyperparameters:\n")
        f.write(json.dumps(dataclasses.asdict(args), indent=2))
        f.write("\n")
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')

training_time_ms = 0
best_val_loss = float("inf")
final_val_loss = None
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        val_loss_item = val_loss.item()
        final_val_loss = val_loss_item
        best_val_loss = min(best_val_loss, val_loss_item)
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms\n')
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            _, loss = model(x, y, return_logits=False)
            train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process:
        approx_time = training_time_ms + 1000 * (time.time() - t0)
        print(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")
        with open(logfile, "a") as f:
            f.write(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms\n")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")
    timed_steps_final = max(args.num_iterations - 9, 1)
    ms_per_step = training_time_ms / timed_steps_final
    os.makedirs("experiments", exist_ok=True)
    results_path = os.path.join("experiments", "results.csv")
    fieldnames = [
        "run_id",
        "date",
        "git_commit",
        "seed",
        "attn_gate",
        "gate_pos",
        "gate_act",
        "learning_rate",
        "batch_size",
        "device_batch_size",
        "sequence_length",
        "num_iterations",
        "warmdown_iters",
        "final_val_loss",
        "best_val_loss",
        "train_time_ms",
        "ms_per_step",
        "gpu_name",
        "n_gpus",
        "runpod_instance",
        "notes",
    ]
    final_loss_value = final_val_loss if final_val_loss is not None else float("nan")
    best_loss_value = best_val_loss if best_val_loss < float("inf") else float("nan")
    row = {
        "run_id": run_id,
        "date": time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime()),
        "git_commit": git_commit,
        "seed": args.seed,
        "attn_gate": args.attn_gate,
        "gate_pos": args.gate_pos,
        "gate_act": args.gate_act,
        "learning_rate": args.learning_rate,
        "batch_size": args.batch_size,
        "device_batch_size": args.device_batch_size,
        "sequence_length": args.sequence_length,
        "num_iterations": args.num_iterations,
        "warmdown_iters": args.warmdown_iters,
        "final_val_loss": final_loss_value,
        "best_val_loss": best_loss_value,
        "train_time_ms": training_time_ms,
        "ms_per_step": ms_per_step,
        "gpu_name": torch.cuda.get_device_name(ddp_local_rank),
        "n_gpus": ddp_world_size,
        "runpod_instance": os.environ.get("RUNPOD_INSTANCE_TYPE", "unknown"),
        "notes": "",
    }
    write_header = not os.path.exists(results_path)
    with open(results_path, "a", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if write_header:
            writer.writeheader()
        writer.writerow(row)
====================================================================================================
git_commit: 21aae13b20675947154a15b640706eb3a47e5fcd
seed: 1337
hyperparameters:
{
  "input_bin": "data/fineweb10B/fineweb_train_*.bin",
  "input_val_bin": "data/fineweb10B/fineweb_val_*.bin",
  "batch_size": 512,
  "device_batch_size": 64,
  "sequence_length": 1024,
  "num_iterations": 1500,
  "learning_rate": 0.0036,
  "warmup_iters": 0,
  "warmdown_iters": 1450,
  "weight_decay": 0,
  "seed": 1337,
  "attn_gate": "none",
  "gate_pos": "sdpa",
  "gate_act": "sigmoid",
  "val_loss_every": 125,
  "val_tokens": 10485760,
  "save_every": 0
}
Running pytorch 2.8.0+cu128 compiled for CUDA 12.8
nvidia-smi:
Sun Dec  7 09:29:39 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:00:07.0 Off |                    0 |
| N/A   35C    P0            110W /  300W |    2180MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          On  |   00000000:00:08.0 Off |                    0 |
| N/A   39C    P0            111W /  300W |    2180MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100 80GB PCIe          On  |   00000000:00:09.0 Off |                    0 |
| N/A   31C    P0            114W /  300W |    2180MiB /  81920MiB |     19%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100 80GB PCIe          On  |   00000000:00:0A.0 Off |                    0 |
| N/A   31C    P0            123W /  300W |    2180MiB /  81920MiB |     10%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100 80GB PCIe          On  |   00000000:00:0B.0 Off |                    0 |
| N/A   30C    P0            105W /  300W |    2180MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100 80GB PCIe          On  |   00000000:00:0C.0 Off |                    0 |
| N/A   29C    P0            107W /  300W |    2180MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100 80GB PCIe          On  |   00000000:00:0D.0 Off |                    0 |
| N/A   33C    P0            142W /  300W |    2180MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100 80GB PCIe          On  |   00000000:00:0E.0 Off |                    0 |
| N/A   31C    P0            105W /  300W |    2180MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1500 val_loss:16.0297 train_time:256ms step_avg:nanms
step:1/1500 train_loss:16.0220 train_time:60592ms step_avg:nanms
step:2/1500 train_loss:9.5340 train_time:61997ms step_avg:nanms
step:3/1500 train_loss:8.7953 train_time:62389ms step_avg:nanms
step:4/1500 train_loss:7.9987 train_time:62781ms step_avg:nanms
step:5/1500 train_loss:7.6899 train_time:63172ms step_avg:nanms
step:6/1500 train_loss:7.4977 train_time:63562ms step_avg:nanms
step:7/1500 train_loss:7.3395 train_time:63952ms step_avg:nanms
step:8/1500 train_loss:7.5856 train_time:64343ms step_avg:nanms
step:9/1500 train_loss:7.5276 train_time:64740ms step_avg:nanms
step:10/1500 train_loss:7.1068 train_time:65132ms step_avg:nanms
step:11/1500 train_loss:6.9802 train_time:379ms step_avg:nanms
step:12/1500 train_loss:6.8802 train_time:771ms step_avg:nanms
step:13/1500 train_loss:6.7100 train_time:1162ms step_avg:387.45ms
step:14/1500 train_loss:6.6904 train_time:1554ms step_avg:388.50ms
step:15/1500 train_loss:6.6388 train_time:1946ms step_avg:389.16ms
step:16/1500 train_loss:6.5592 train_time:2337ms step_avg:389.49ms
step:17/1500 train_loss:6.5667 train_time:2729ms step_avg:389.84ms
step:18/1500 train_loss:6.5833 train_time:3122ms step_avg:390.30ms
step:19/1500 train_loss:6.4022 train_time:3514ms step_avg:390.41ms
step:20/1500 train_loss:6.4195 train_time:3905ms step_avg:390.48ms
step:21/1500 train_loss:6.0894 train_time:4298ms step_avg:390.70ms
step:22/1500 train_loss:6.4534 train_time:4695ms step_avg:391.28ms
step:23/1500 train_loss:6.6533 train_time:5092ms step_avg:391.68ms
step:24/1500 train_loss:6.3370 train_time:5484ms step_avg:391.71ms
step:25/1500 train_loss:6.4612 train_time:5875ms step_avg:391.69ms
step:26/1500 train_loss:6.1819 train_time:6267ms step_avg:391.68ms
step:27/1500 train_loss:6.1017 train_time:6659ms step_avg:391.68ms
step:28/1500 train_loss:6.2351 train_time:7051ms step_avg:391.71ms
step:29/1500 train_loss:5.9107 train_time:7443ms step_avg:391.73ms
step:30/1500 train_loss:6.1944 train_time:7835ms step_avg:391.76ms
step:31/1500 train_loss:6.0279 train_time:8230ms step_avg:391.89ms
step:32/1500 train_loss:5.9981 train_time:8622ms step_avg:391.92ms
step:33/1500 train_loss:5.8286 train_time:9015ms step_avg:391.95ms
step:34/1500 train_loss:6.1119 train_time:9407ms step_avg:391.95ms
step:35/1500 train_loss:6.0495 train_time:9801ms step_avg:392.03ms
step:36/1500 train_loss:6.1904 train_time:10193ms step_avg:392.04ms
step:37/1500 train_loss:6.1258 train_time:10584ms step_avg:392.02ms
step:38/1500 train_loss:6.0177 train_time:10978ms step_avg:392.06ms
step:39/1500 train_loss:5.9083 train_time:11369ms step_avg:392.04ms
step:40/1500 train_loss:5.9221 train_time:11762ms step_avg:392.07ms
step:41/1500 train_loss:5.8369 train_time:12155ms step_avg:392.09ms
step:42/1500 train_loss:5.8563 train_time:12552ms step_avg:392.24ms
step:43/1500 train_loss:5.7382 train_time:12945ms step_avg:392.26ms
step:44/1500 train_loss:5.8478 train_time:13343ms step_avg:392.43ms
step:45/1500 train_loss:5.8060 train_time:13735ms step_avg:392.43ms
step:46/1500 train_loss:5.9458 train_time:14136ms step_avg:392.67ms
step:47/1500 train_loss:5.7542 train_time:14529ms step_avg:392.67ms
step:48/1500 train_loss:5.6312 train_time:14923ms step_avg:392.71ms
step:49/1500 train_loss:5.8439 train_time:15316ms step_avg:392.73ms
step:50/1500 train_loss:5.7188 train_time:15711ms step_avg:392.77ms
step:51/1500 train_loss:5.8619 train_time:16105ms step_avg:392.79ms
step:52/1500 train_loss:5.7286 train_time:16496ms step_avg:392.76ms
step:53/1500 train_loss:5.5766 train_time:16893ms step_avg:392.87ms
step:54/1500 train_loss:5.7190 train_time:17288ms step_avg:392.90ms
step:55/1500 train_loss:5.5998 train_time:17681ms step_avg:392.90ms
step:56/1500 train_loss:5.9450 train_time:18074ms step_avg:392.92ms
step:57/1500 train_loss:5.6146 train_time:18466ms step_avg:392.90ms
step:58/1500 train_loss:5.4617 train_time:18860ms step_avg:392.91ms
step:59/1500 train_loss:5.6075 train_time:19254ms step_avg:392.93ms
step:60/1500 train_loss:5.5775 train_time:19647ms step_avg:392.94ms
step:61/1500 train_loss:5.6766 train_time:20040ms step_avg:392.95ms
step:62/1500 train_loss:5.4456 train_time:20433ms step_avg:392.94ms
step:63/1500 train_loss:5.5496 train_time:20826ms step_avg:392.95ms
step:64/1500 train_loss:5.5289 train_time:21220ms step_avg:392.96ms
step:65/1500 train_loss:5.2263 train_time:21612ms step_avg:392.95ms
step:66/1500 train_loss:5.3497 train_time:22005ms step_avg:392.94ms
step:67/1500 train_loss:5.5024 train_time:22400ms step_avg:392.98ms
step:68/1500 train_loss:5.3745 train_time:22794ms step_avg:393.01ms
step:69/1500 train_loss:5.6345 train_time:23192ms step_avg:393.08ms
step:70/1500 train_loss:5.2847 train_time:23588ms step_avg:393.14ms
step:71/1500 train_loss:5.3108 train_time:23980ms step_avg:393.12ms
step:72/1500 train_loss:5.5094 train_time:24376ms step_avg:393.16ms
step:73/1500 train_loss:5.4342 train_time:24769ms step_avg:393.16ms
step:74/1500 train_loss:5.3125 train_time:25164ms step_avg:393.19ms
step:75/1500 train_loss:5.4513 train_time:25557ms step_avg:393.19ms
step:76/1500 train_loss:5.4303 train_time:25951ms step_avg:393.20ms
step:77/1500 train_loss:5.3805 train_time:26344ms step_avg:393.19ms
step:78/1500 train_loss:5.4628 train_time:26738ms step_avg:393.20ms
step:79/1500 train_loss:5.5290 train_time:27131ms step_avg:393.21ms
step:80/1500 train_loss:5.3101 train_time:27523ms step_avg:393.19ms
step:81/1500 train_loss:5.4235 train_time:27918ms step_avg:393.21ms
step:82/1500 train_loss:5.1965 train_time:28311ms step_avg:393.21ms
step:83/1500 train_loss:5.3727 train_time:28705ms step_avg:393.21ms
step:84/1500 train_loss:5.3204 train_time:29098ms step_avg:393.22ms
step:85/1500 train_loss:5.2987 train_time:29497ms step_avg:393.29ms
step:86/1500 train_loss:5.1560 train_time:29897ms step_avg:393.38ms
step:87/1500 train_loss:5.3755 train_time:30302ms step_avg:393.53ms
step:88/1500 train_loss:5.2787 train_time:30696ms step_avg:393.53ms
step:89/1500 train_loss:5.3396 train_time:31092ms step_avg:393.57ms
step:90/1500 train_loss:5.2901 train_time:31486ms step_avg:393.58ms
step:91/1500 train_loss:5.2245 train_time:31880ms step_avg:393.58ms
step:92/1500 train_loss:5.1921 train_time:32273ms step_avg:393.57ms
step:93/1500 train_loss:5.3323 train_time:32668ms step_avg:393.59ms
step:94/1500 train_loss:5.1503 train_time:33062ms step_avg:393.59ms
step:95/1500 train_loss:5.1621 train_time:33456ms step_avg:393.60ms
step:96/1500 train_loss:5.1996 train_time:33848ms step_avg:393.59ms
step:97/1500 train_loss:5.1090 train_time:34244ms step_avg:393.61ms
step:98/1500 train_loss:5.1923 train_time:34636ms step_avg:393.59ms
step:99/1500 train_loss:5.1099 train_time:35030ms step_avg:393.60ms
step:100/1500 train_loss:5.2357 train_time:35423ms step_avg:393.59ms
step:101/1500 train_loss:5.2115 train_time:35818ms step_avg:393.60ms
step:102/1500 train_loss:5.1183 train_time:36212ms step_avg:393.60ms
step:103/1500 train_loss:5.2083 train_time:36606ms step_avg:393.61ms
step:104/1500 train_loss:5.1550 train_time:36999ms step_avg:393.60ms
step:105/1500 train_loss:5.0187 train_time:37397ms step_avg:393.65ms
step:106/1500 train_loss:5.1150 train_time:37797ms step_avg:393.72ms
step:107/1500 train_loss:5.3149 train_time:38195ms step_avg:393.76ms
step:108/1500 train_loss:5.0880 train_time:38593ms step_avg:393.80ms
step:109/1500 train_loss:4.8758 train_time:38987ms step_avg:393.81ms
step:110/1500 train_loss:5.0612 train_time:39381ms step_avg:393.81ms
step:111/1500 train_loss:5.0385 train_time:39775ms step_avg:393.81ms
step:112/1500 train_loss:5.0087 train_time:40168ms step_avg:393.80ms
step:113/1500 train_loss:5.1209 train_time:40561ms step_avg:393.80ms
step:114/1500 train_loss:5.0468 train_time:40956ms step_avg:393.81ms
step:115/1500 train_loss:4.9002 train_time:41349ms step_avg:393.80ms
step:116/1500 train_loss:5.0538 train_time:41743ms step_avg:393.80ms
step:117/1500 train_loss:4.9579 train_time:42137ms step_avg:393.80ms
step:118/1500 train_loss:4.9068 train_time:42532ms step_avg:393.81ms
step:119/1500 train_loss:5.0662 train_time:42926ms step_avg:393.82ms
step:120/1500 train_loss:5.0184 train_time:43320ms step_avg:393.82ms
step:121/1500 train_loss:4.9571 train_time:43713ms step_avg:393.81ms
step:122/1500 train_loss:4.8587 train_time:44107ms step_avg:393.82ms
step:123/1500 train_loss:4.9740 train_time:44500ms step_avg:393.81ms
step:124/1500 train_loss:4.8086 train_time:44895ms step_avg:393.82ms
step:125/1500 train_loss:5.1280 train_time:45295ms step_avg:393.87ms
step:125/1500 val_loss:4.9596 train_time:45313ms step_avg:394.03ms
step:126/1500 train_loss:5.0060 train_time:45697ms step_avg:393.94ms
step:127/1500 train_loss:4.9511 train_time:46093ms step_avg:393.96ms
step:128/1500 train_loss:5.0128 train_time:46491ms step_avg:393.99ms
step:129/1500 train_loss:4.8866 train_time:46885ms step_avg:393.99ms
step:130/1500 train_loss:5.1855 train_time:47279ms step_avg:393.99ms
step:131/1500 train_loss:4.9401 train_time:47672ms step_avg:393.99ms
step:132/1500 train_loss:4.9487 train_time:48067ms step_avg:393.99ms
step:133/1500 train_loss:4.9003 train_time:48459ms step_avg:393.97ms
step:134/1500 train_loss:4.9428 train_time:48854ms step_avg:393.98ms
step:135/1500 train_loss:4.8275 train_time:49247ms step_avg:393.98ms
step:136/1500 train_loss:4.9559 train_time:49640ms step_avg:393.97ms
step:137/1500 train_loss:4.7338 train_time:50033ms step_avg:393.96ms
step:138/1500 train_loss:4.8947 train_time:50426ms step_avg:393.95ms
step:139/1500 train_loss:4.8370 train_time:50819ms step_avg:393.94ms
step:140/1500 train_loss:4.8757 train_time:51215ms step_avg:393.96ms
step:141/1500 train_loss:4.9392 train_time:51614ms step_avg:394.00ms
step:142/1500 train_loss:4.8140 train_time:52008ms step_avg:394.00ms
step:143/1500 train_loss:4.8781 train_time:52402ms step_avg:394.00ms
step:144/1500 train_loss:4.7376 train_time:52796ms step_avg:394.00ms
step:145/1500 train_loss:4.8627 train_time:53191ms step_avg:394.01ms
step:146/1500 train_loss:4.8215 train_time:53585ms step_avg:394.01ms
step:147/1500 train_loss:4.6950 train_time:53978ms step_avg:394.00ms
step:148/1500 train_loss:4.8476 train_time:54371ms step_avg:393.99ms
step:149/1500 train_loss:4.8414 train_time:54765ms step_avg:393.99ms
step:150/1500 train_loss:4.8686 train_time:55159ms step_avg:393.99ms
step:151/1500 train_loss:4.9014 train_time:55552ms step_avg:393.99ms
step:152/1500 train_loss:4.7940 train_time:55945ms step_avg:393.98ms
step:153/1500 train_loss:4.8006 train_time:56338ms step_avg:393.97ms
step:154/1500 train_loss:4.8816 train_time:56731ms step_avg:393.97ms
step:155/1500 train_loss:4.8361 train_time:57125ms step_avg:393.96ms
step:156/1500 train_loss:4.7953 train_time:57520ms step_avg:393.97ms
step:157/1500 train_loss:4.8196 train_time:57912ms step_avg:393.96ms
step:158/1500 train_loss:4.9421 train_time:58306ms step_avg:393.96ms
step:159/1500 train_loss:4.7217 train_time:58699ms step_avg:393.95ms
step:160/1500 train_loss:4.8018 train_time:59092ms step_avg:393.95ms
step:161/1500 train_loss:4.6257 train_time:59486ms step_avg:393.95ms
step:162/1500 train_loss:4.8064 train_time:59880ms step_avg:393.94ms
step:163/1500 train_loss:4.8397 train_time:60275ms step_avg:393.95ms
step:164/1500 train_loss:4.8254 train_time:60669ms step_avg:393.95ms
step:165/1500 train_loss:4.6408 train_time:61064ms step_avg:393.96ms
step:166/1500 train_loss:4.7585 train_time:61457ms step_avg:393.96ms
step:167/1500 train_loss:4.8985 train_time:61852ms step_avg:393.96ms
step:168/1500 train_loss:4.6809 train_time:62244ms step_avg:393.95ms
step:169/1500 train_loss:4.7775 train_time:62638ms step_avg:393.95ms
step:170/1500 train_loss:4.6327 train_time:63032ms step_avg:393.95ms
step:171/1500 train_loss:4.5344 train_time:63427ms step_avg:393.96ms
step:172/1500 train_loss:4.6894 train_time:63820ms step_avg:393.95ms
step:173/1500 train_loss:4.6726 train_time:64214ms step_avg:393.95ms
step:174/1500 train_loss:4.7248 train_time:64611ms step_avg:393.97ms
step:175/1500 train_loss:4.8770 train_time:65006ms step_avg:393.98ms
step:176/1500 train_loss:4.7334 train_time:65399ms step_avg:393.97ms
step:177/1500 train_loss:4.5864 train_time:65793ms step_avg:393.97ms
step:178/1500 train_loss:4.5531 train_time:66187ms step_avg:393.97ms
step:179/1500 train_loss:4.6268 train_time:66581ms step_avg:393.97ms
step:180/1500 train_loss:4.6296 train_time:66973ms step_avg:393.96ms
step:181/1500 train_loss:4.6309 train_time:67368ms step_avg:393.96ms
step:182/1500 train_loss:4.7636 train_time:67761ms step_avg:393.96ms
step:183/1500 train_loss:4.6230 train_time:68157ms step_avg:393.97ms
step:184/1500 train_loss:4.5779 train_time:68551ms step_avg:393.97ms
step:185/1500 train_loss:4.5863 train_time:68945ms step_avg:393.97ms
step:186/1500 train_loss:4.7056 train_time:69336ms step_avg:393.95ms
step:187/1500 train_loss:4.6222 train_time:69730ms step_avg:393.95ms
step:188/1500 train_loss:4.8023 train_time:70123ms step_avg:393.95ms
step:189/1500 train_loss:4.6418 train_time:70649ms step_avg:394.69ms
step:190/1500 train_loss:4.5643 train_time:71205ms step_avg:395.59ms
step:191/1500 train_loss:4.7004 train_time:71597ms step_avg:395.56ms
step:192/1500 train_loss:4.5435 train_time:71989ms step_avg:395.54ms
step:193/1500 train_loss:4.4657 train_time:72386ms step_avg:395.55ms
step:194/1500 train_loss:4.6949 train_time:72778ms step_avg:395.53ms
step:195/1500 train_loss:4.6263 train_time:73173ms step_avg:395.53ms
step:196/1500 train_loss:4.8161 train_time:73565ms step_avg:395.51ms
step:197/1500 train_loss:4.6791 train_time:73960ms step_avg:395.51ms
step:198/1500 train_loss:4.5183 train_time:74352ms step_avg:395.49ms
step:199/1500 train_loss:4.5937 train_time:74745ms step_avg:395.48ms
step:200/1500 train_loss:4.4669 train_time:75140ms step_avg:395.47ms
step:201/1500 train_loss:4.5577 train_time:75534ms step_avg:395.47ms
step:202/1500 train_loss:4.4603 train_time:75927ms step_avg:395.45ms
step:203/1500 train_loss:4.7080 train_time:76319ms step_avg:395.43ms
step:204/1500 train_loss:4.5727 train_time:76713ms step_avg:395.43ms
step:205/1500 train_loss:4.6015 train_time:77111ms step_avg:395.44ms
step:206/1500 train_loss:4.7212 train_time:77503ms step_avg:395.42ms
step:207/1500 train_loss:4.3734 train_time:77896ms step_avg:395.41ms
step:208/1500 train_loss:4.5358 train_time:78289ms step_avg:395.40ms
step:209/1500 train_loss:4.5068 train_time:78682ms step_avg:395.39ms
step:210/1500 train_loss:4.6715 train_time:79076ms step_avg:395.38ms
step:211/1500 train_loss:4.5872 train_time:79469ms step_avg:395.37ms
step:212/1500 train_loss:4.4655 train_time:79862ms step_avg:395.36ms
step:213/1500 train_loss:4.5770 train_time:80256ms step_avg:395.35ms
step:214/1500 train_loss:4.4478 train_time:80648ms step_avg:395.34ms
step:215/1500 train_loss:4.5201 train_time:81041ms step_avg:395.32ms
step:216/1500 train_loss:4.3841 train_time:81434ms step_avg:395.31ms
step:217/1500 train_loss:4.4748 train_time:81829ms step_avg:395.31ms
step:218/1500 train_loss:4.4505 train_time:82222ms step_avg:395.30ms
step:219/1500 train_loss:4.4723 train_time:82615ms step_avg:395.29ms
step:220/1500 train_loss:4.4687 train_time:83012ms step_avg:395.29ms
step:221/1500 train_loss:4.5058 train_time:83406ms step_avg:395.29ms
step:222/1500 train_loss:4.5216 train_time:83803ms step_avg:395.29ms
step:223/1500 train_loss:4.4486 train_time:84198ms step_avg:395.29ms
step:224/1500 train_loss:4.4470 train_time:84593ms step_avg:395.29ms
step:225/1500 train_loss:4.6462 train_time:84986ms step_avg:395.28ms
step:226/1500 train_loss:4.3370 train_time:85379ms step_avg:395.27ms
step:227/1500 train_loss:4.3649 train_time:85774ms step_avg:395.27ms
step:228/1500 train_loss:4.3736 train_time:86167ms step_avg:395.26ms
step:229/1500 train_loss:4.5314 train_time:86561ms step_avg:395.26ms
step:230/1500 train_loss:4.3315 train_time:86957ms step_avg:395.26ms
step:231/1500 train_loss:4.4656 train_time:87348ms step_avg:395.24ms
step:232/1500 train_loss:4.3297 train_time:87742ms step_avg:395.23ms
step:233/1500 train_loss:4.3323 train_time:88136ms step_avg:395.23ms
step:234/1500 train_loss:4.5198 train_time:88530ms step_avg:395.22ms
step:235/1500 train_loss:4.3898 train_time:88922ms step_avg:395.21ms
step:236/1500 train_loss:4.2872 train_time:89317ms step_avg:395.21ms
step:237/1500 train_loss:4.5025 train_time:89718ms step_avg:395.23ms
step:238/1500 train_loss:4.4518 train_time:90114ms step_avg:395.24ms
step:239/1500 train_loss:4.3241 train_time:90512ms step_avg:395.25ms
step:240/1500 train_loss:4.4781 train_time:90911ms step_avg:395.26ms
step:241/1500 train_loss:4.4655 train_time:91304ms step_avg:395.26ms
step:242/1500 train_loss:4.3428 train_time:91698ms step_avg:395.25ms
step:243/1500 train_loss:4.5204 train_time:92092ms step_avg:395.25ms
step:244/1500 train_loss:4.3600 train_time:92485ms step_avg:395.24ms
step:245/1500 train_loss:4.3977 train_time:92878ms step_avg:395.23ms
step:246/1500 train_loss:4.4826 train_time:93272ms step_avg:395.22ms
step:247/1500 train_loss:4.4123 train_time:93667ms step_avg:395.22ms
step:248/1500 train_loss:4.3535 train_time:94059ms step_avg:395.21ms
step:249/1500 train_loss:4.4855 train_time:94453ms step_avg:395.20ms
step:250/1500 train_loss:4.2469 train_time:94846ms step_avg:395.19ms
step:250/1500 val_loss:4.3515 train_time:94861ms step_avg:395.26ms
step:251/1500 train_loss:4.3003 train_time:95244ms step_avg:395.20ms
step:252/1500 train_loss:4.4117 train_time:95637ms step_avg:395.19ms
step:253/1500 train_loss:4.4530 train_time:96030ms step_avg:395.19ms
step:254/1500 train_loss:4.2859 train_time:96427ms step_avg:395.19ms
step:255/1500 train_loss:4.2326 train_time:96825ms step_avg:395.20ms
step:256/1500 train_loss:4.4066 train_time:97218ms step_avg:395.20ms
step:257/1500 train_loss:4.3250 train_time:97611ms step_avg:395.19ms
step:258/1500 train_loss:4.3355 train_time:98006ms step_avg:395.19ms
step:259/1500 train_loss:4.2921 train_time:98399ms step_avg:395.18ms
step:260/1500 train_loss:4.3292 train_time:98793ms step_avg:395.17ms
step:261/1500 train_loss:4.3714 train_time:99186ms step_avg:395.16ms
step:262/1500 train_loss:4.3345 train_time:99579ms step_avg:395.16ms
step:263/1500 train_loss:4.3034 train_time:99974ms step_avg:395.15ms
step:264/1500 train_loss:4.2190 train_time:100365ms step_avg:395.14ms
step:265/1500 train_loss:4.2958 train_time:100761ms step_avg:395.14ms
step:266/1500 train_loss:4.1542 train_time:101154ms step_avg:395.13ms
step:267/1500 train_loss:4.2228 train_time:101547ms step_avg:395.12ms
step:268/1500 train_loss:4.2396 train_time:101940ms step_avg:395.12ms
step:269/1500 train_loss:4.2418 train_time:102333ms step_avg:395.11ms
step:270/1500 train_loss:4.1632 train_time:102727ms step_avg:395.10ms
step:271/1500 train_loss:4.4022 train_time:103120ms step_avg:395.09ms
step:272/1500 train_loss:4.3020 train_time:103514ms step_avg:395.09ms
step:273/1500 train_loss:4.2063 train_time:103905ms step_avg:395.08ms
step:274/1500 train_loss:4.2532 train_time:104301ms step_avg:395.08ms
step:275/1500 train_loss:4.3303 train_time:104692ms step_avg:395.07ms
step:276/1500 train_loss:4.3499 train_time:105087ms step_avg:395.06ms
step:277/1500 train_loss:4.5293 train_time:105480ms step_avg:395.06ms
step:278/1500 train_loss:4.3152 train_time:105873ms step_avg:395.05ms
step:279/1500 train_loss:4.3956 train_time:106267ms step_avg:395.04ms
step:280/1500 train_loss:4.2867 train_time:107272ms step_avg:397.30ms
step:281/1500 train_loss:4.3943 train_time:107666ms step_avg:397.29ms
step:282/1500 train_loss:4.2331 train_time:108060ms step_avg:397.28ms
step:283/1500 train_loss:4.2734 train_time:108453ms step_avg:397.27ms
step:284/1500 train_loss:4.1877 train_time:108848ms step_avg:397.26ms
step:285/1500 train_loss:4.3392 train_time:109240ms step_avg:397.23ms
step:286/1500 train_loss:4.3460 train_time:109635ms step_avg:397.23ms
step:287/1500 train_loss:4.3705 train_time:110028ms step_avg:397.21ms
step:288/1500 train_loss:4.2002 train_time:110425ms step_avg:397.21ms
step:289/1500 train_loss:4.2902 train_time:110818ms step_avg:397.20ms
step:290/1500 train_loss:4.1485 train_time:111212ms step_avg:397.19ms
step:291/1500 train_loss:4.1444 train_time:111605ms step_avg:397.17ms
step:292/1500 train_loss:4.2294 train_time:111999ms step_avg:397.16ms
step:293/1500 train_loss:4.1411 train_time:112393ms step_avg:397.15ms
step:294/1500 train_loss:4.1883 train_time:112786ms step_avg:397.13ms
step:295/1500 train_loss:4.2220 train_time:113179ms step_avg:397.12ms
step:296/1500 train_loss:4.1022 train_time:113572ms step_avg:397.11ms
step:297/1500 train_loss:4.1193 train_time:113964ms step_avg:397.09ms
step:298/1500 train_loss:4.1252 train_time:114357ms step_avg:397.07ms
step:299/1500 train_loss:4.2379 train_time:114752ms step_avg:397.06ms
step:300/1500 train_loss:4.1054 train_time:115145ms step_avg:397.05ms
step:301/1500 train_loss:4.2444 train_time:115539ms step_avg:397.04ms
step:302/1500 train_loss:4.2509 train_time:115933ms step_avg:397.03ms
step:303/1500 train_loss:4.1943 train_time:116330ms step_avg:397.03ms
step:304/1500 train_loss:4.2407 train_time:116727ms step_avg:397.03ms
step:305/1500 train_loss:4.2276 train_time:117124ms step_avg:397.03ms
step:306/1500 train_loss:4.7098 train_time:117519ms step_avg:397.02ms
step:307/1500 train_loss:4.1935 train_time:117913ms step_avg:397.01ms
step:308/1500 train_loss:4.0974 train_time:118306ms step_avg:397.00ms
step:309/1500 train_loss:4.2580 train_time:118702ms step_avg:397.00ms
step:310/1500 train_loss:4.1034 train_time:119094ms step_avg:396.98ms
step:311/1500 train_loss:4.3342 train_time:119487ms step_avg:396.97ms
step:312/1500 train_loss:4.1890 train_time:119880ms step_avg:396.95ms
step:313/1500 train_loss:4.1236 train_time:120273ms step_avg:396.94ms
step:314/1500 train_loss:4.2294 train_time:120666ms step_avg:396.93ms
step:315/1500 train_loss:4.3360 train_time:121060ms step_avg:396.92ms
step:316/1500 train_loss:4.2158 train_time:121453ms step_avg:396.91ms
step:317/1500 train_loss:4.0494 train_time:121846ms step_avg:396.89ms
step:318/1500 train_loss:4.1193 train_time:122242ms step_avg:396.89ms
step:319/1500 train_loss:4.1562 train_time:122635ms step_avg:396.88ms
step:320/1500 train_loss:4.1374 train_time:123029ms step_avg:396.87ms
step:321/1500 train_loss:4.2495 train_time:123424ms step_avg:396.86ms
step:322/1500 train_loss:4.1958 train_time:123819ms step_avg:396.86ms
step:323/1500 train_loss:4.1610 train_time:124212ms step_avg:396.84ms
step:324/1500 train_loss:4.2504 train_time:124605ms step_avg:396.83ms
step:325/1500 train_loss:4.2132 train_time:124998ms step_avg:396.82ms
step:326/1500 train_loss:4.2725 train_time:125392ms step_avg:396.81ms
step:327/1500 train_loss:4.1359 train_time:125785ms step_avg:396.80ms
step:328/1500 train_loss:4.6227 train_time:126177ms step_avg:396.78ms
step:329/1500 train_loss:4.3110 train_time:126570ms step_avg:396.77ms
step:330/1500 train_loss:4.0581 train_time:126964ms step_avg:396.76ms
step:331/1500 train_loss:3.9994 train_time:127357ms step_avg:396.75ms
step:332/1500 train_loss:4.2154 train_time:127749ms step_avg:396.74ms
step:333/1500 train_loss:4.1367 train_time:128143ms step_avg:396.73ms
step:334/1500 train_loss:4.1180 train_time:128536ms step_avg:396.72ms
step:335/1500 train_loss:4.0790 train_time:128930ms step_avg:396.71ms
step:336/1500 train_loss:4.2511 train_time:129327ms step_avg:396.71ms
step:337/1500 train_loss:4.1945 train_time:129720ms step_avg:396.70ms
step:338/1500 train_loss:4.6704 train_time:130114ms step_avg:396.69ms
step:339/1500 train_loss:4.1748 train_time:130506ms step_avg:396.67ms
step:340/1500 train_loss:4.1287 train_time:130898ms step_avg:396.66ms
step:341/1500 train_loss:4.1638 train_time:131291ms step_avg:396.65ms
step:342/1500 train_loss:4.0832 train_time:131685ms step_avg:396.64ms
step:343/1500 train_loss:4.0417 train_time:132077ms step_avg:396.63ms
step:344/1500 train_loss:4.0955 train_time:132473ms step_avg:396.63ms
step:345/1500 train_loss:4.2285 train_time:132864ms step_avg:396.61ms
step:346/1500 train_loss:4.0726 train_time:133260ms step_avg:396.61ms
step:347/1500 train_loss:4.0007 train_time:133655ms step_avg:396.60ms
step:348/1500 train_loss:4.0458 train_time:134048ms step_avg:396.59ms
step:349/1500 train_loss:4.0898 train_time:134440ms step_avg:396.58ms
step:350/1500 train_loss:4.0429 train_time:134834ms step_avg:396.57ms
step:351/1500 train_loss:3.7712 train_time:135227ms step_avg:396.56ms
step:352/1500 train_loss:4.0397 train_time:135629ms step_avg:396.57ms
step:353/1500 train_loss:4.3795 train_time:136026ms step_avg:396.58ms
step:354/1500 train_loss:3.8897 train_time:136421ms step_avg:396.57ms
step:355/1500 train_loss:4.1534 train_time:136815ms step_avg:396.56ms
step:356/1500 train_loss:4.0183 train_time:137208ms step_avg:396.56ms
step:357/1500 train_loss:4.1190 train_time:137602ms step_avg:396.55ms
step:358/1500 train_loss:4.0729 train_time:137995ms step_avg:396.54ms
step:359/1500 train_loss:4.0758 train_time:138388ms step_avg:396.53ms
step:360/1500 train_loss:4.1494 train_time:138781ms step_avg:396.52ms
step:361/1500 train_loss:3.6988 train_time:139176ms step_avg:396.51ms
step:362/1500 train_loss:4.2479 train_time:139569ms step_avg:396.50ms
step:363/1500 train_loss:4.1391 train_time:139963ms step_avg:396.50ms
step:364/1500 train_loss:4.0661 train_time:140356ms step_avg:396.49ms
step:365/1500 train_loss:3.9747 train_time:140751ms step_avg:396.48ms
step:366/1500 train_loss:4.1379 train_time:141144ms step_avg:396.47ms
step:367/1500 train_loss:4.0961 train_time:141537ms step_avg:396.46ms
step:368/1500 train_loss:4.0769 train_time:141940ms step_avg:396.48ms
step:369/1500 train_loss:4.0720 train_time:142332ms step_avg:396.47ms
step:370/1500 train_loss:3.9634 train_time:142728ms step_avg:396.47ms
step:371/1500 train_loss:4.1092 train_time:143124ms step_avg:396.47ms
step:372/1500 train_loss:3.9860 train_time:143517ms step_avg:396.46ms
step:373/1500 train_loss:3.9139 train_time:143910ms step_avg:396.45ms
step:374/1500 train_loss:4.1295 train_time:144302ms step_avg:396.43ms
step:375/1500 train_loss:4.0556 train_time:144695ms step_avg:396.42ms
step:375/1500 val_loss:4.0520 train_time:144709ms step_avg:396.46ms
step:376/1500 train_loss:4.0311 train_time:145093ms step_avg:396.43ms
step:377/1500 train_loss:4.0898 train_time:145487ms step_avg:396.42ms
step:378/1500 train_loss:4.0045 train_time:146810ms step_avg:398.94ms
step:379/1500 train_loss:4.0622 train_time:147202ms step_avg:398.92ms
step:380/1500 train_loss:4.1029 train_time:147749ms step_avg:399.32ms
step:381/1500 train_loss:4.1616 train_time:148142ms step_avg:399.30ms
step:382/1500 train_loss:4.0699 train_time:148540ms step_avg:399.30ms
step:383/1500 train_loss:4.0423 train_time:148934ms step_avg:399.29ms
step:384/1500 train_loss:4.0090 train_time:149326ms step_avg:399.27ms
step:385/1500 train_loss:4.0825 train_time:149720ms step_avg:399.25ms
step:386/1500 train_loss:3.9962 train_time:150112ms step_avg:399.23ms
step:387/1500 train_loss:4.1128 train_time:150504ms step_avg:399.21ms
step:388/1500 train_loss:4.3043 train_time:150897ms step_avg:399.20ms
step:389/1500 train_loss:4.0166 train_time:151289ms step_avg:399.18ms
step:390/1500 train_loss:4.0033 train_time:151682ms step_avg:399.16ms
step:391/1500 train_loss:4.1096 train_time:152074ms step_avg:399.14ms
step:392/1500 train_loss:4.0227 train_time:152467ms step_avg:399.13ms
step:393/1500 train_loss:4.1351 train_time:152860ms step_avg:399.11ms
step:394/1500 train_loss:3.9664 train_time:153252ms step_avg:399.09ms
step:395/1500 train_loss:4.1050 train_time:153646ms step_avg:399.08ms
step:396/1500 train_loss:3.8459 train_time:154040ms step_avg:399.07ms
step:397/1500 train_loss:4.0477 train_time:154434ms step_avg:399.05ms
step:398/1500 train_loss:4.0983 train_time:154826ms step_avg:399.04ms
step:399/1500 train_loss:4.1065 train_time:155218ms step_avg:399.02ms
step:400/1500 train_loss:3.9995 train_time:155611ms step_avg:399.00ms
step:401/1500 train_loss:4.0501 train_time:156004ms step_avg:398.99ms
step:402/1500 train_loss:4.1196 train_time:156400ms step_avg:398.98ms
step:403/1500 train_loss:4.0545 train_time:156794ms step_avg:398.97ms
step:404/1500 train_loss:4.1593 train_time:157187ms step_avg:398.95ms
step:405/1500 train_loss:3.9118 train_time:157579ms step_avg:398.94ms
step:406/1500 train_loss:4.0037 train_time:157973ms step_avg:398.92ms
step:407/1500 train_loss:4.2938 train_time:158365ms step_avg:398.90ms
step:408/1500 train_loss:4.0161 train_time:158760ms step_avg:398.89ms
step:409/1500 train_loss:4.0327 train_time:159153ms step_avg:398.88ms
step:410/1500 train_loss:4.0812 train_time:159547ms step_avg:398.87ms
step:411/1500 train_loss:3.9582 train_time:159941ms step_avg:398.85ms
step:412/1500 train_loss:3.9748 train_time:160337ms step_avg:398.85ms
step:413/1500 train_loss:4.4014 train_time:160729ms step_avg:398.83ms
step:414/1500 train_loss:3.8366 train_time:161122ms step_avg:398.82ms
step:415/1500 train_loss:4.2247 train_time:161516ms step_avg:398.81ms
step:416/1500 train_loss:3.9720 train_time:161909ms step_avg:398.79ms
step:417/1500 train_loss:3.9724 train_time:162303ms step_avg:398.78ms
step:418/1500 train_loss:4.1699 train_time:162696ms step_avg:398.77ms
step:419/1500 train_loss:3.8931 train_time:163089ms step_avg:398.75ms
step:420/1500 train_loss:4.0085 train_time:163481ms step_avg:398.73ms
step:421/1500 train_loss:3.9336 train_time:163875ms step_avg:398.72ms
step:422/1500 train_loss:3.8511 train_time:164268ms step_avg:398.71ms
step:423/1500 train_loss:3.9855 train_time:164661ms step_avg:398.70ms
step:424/1500 train_loss:4.0753 train_time:165056ms step_avg:398.69ms
step:425/1500 train_loss:3.8311 train_time:165448ms step_avg:398.67ms
step:426/1500 train_loss:4.0201 train_time:165843ms step_avg:398.66ms
step:427/1500 train_loss:3.8957 train_time:166241ms step_avg:398.66ms
step:428/1500 train_loss:4.1105 train_time:166638ms step_avg:398.66ms
step:429/1500 train_loss:4.0280 train_time:167033ms step_avg:398.65ms
step:430/1500 train_loss:3.9604 train_time:167425ms step_avg:398.63ms
step:431/1500 train_loss:3.9306 train_time:167817ms step_avg:398.61ms
step:432/1500 train_loss:3.8349 train_time:168211ms step_avg:398.60ms
step:433/1500 train_loss:3.9667 train_time:168611ms step_avg:398.61ms
step:434/1500 train_loss:4.0259 train_time:169003ms step_avg:398.59ms
step:435/1500 train_loss:3.9695 train_time:169396ms step_avg:398.58ms
step:436/1500 train_loss:4.0222 train_time:169791ms step_avg:398.57ms
step:437/1500 train_loss:4.0311 train_time:170184ms step_avg:398.56ms
step:438/1500 train_loss:3.9089 train_time:170578ms step_avg:398.55ms
step:439/1500 train_loss:3.9328 train_time:170972ms step_avg:398.54ms
step:440/1500 train_loss:3.9003 train_time:171365ms step_avg:398.52ms
step:441/1500 train_loss:4.0888 train_time:171756ms step_avg:398.51ms
step:442/1500 train_loss:3.9697 train_time:172150ms step_avg:398.50ms
step:443/1500 train_loss:3.9549 train_time:172542ms step_avg:398.48ms
step:444/1500 train_loss:3.8412 train_time:172940ms step_avg:398.48ms
step:445/1500 train_loss:4.1171 train_time:173332ms step_avg:398.47ms
step:446/1500 train_loss:4.0464 train_time:173725ms step_avg:398.45ms
step:447/1500 train_loss:4.0394 train_time:174118ms step_avg:398.44ms
step:448/1500 train_loss:3.9523 train_time:174520ms step_avg:398.45ms
step:449/1500 train_loss:4.0528 train_time:174911ms step_avg:398.43ms
step:450/1500 train_loss:3.8828 train_time:175306ms step_avg:398.42ms
step:451/1500 train_loss:3.9158 train_time:175698ms step_avg:398.41ms
step:452/1500 train_loss:3.7887 train_time:176092ms step_avg:398.40ms
step:453/1500 train_loss:3.9121 train_time:176484ms step_avg:398.38ms
step:454/1500 train_loss:3.8785 train_time:176878ms step_avg:398.37ms
step:455/1500 train_loss:3.8397 train_time:177272ms step_avg:398.36ms
step:456/1500 train_loss:4.0486 train_time:177666ms step_avg:398.36ms
step:457/1500 train_loss:3.9228 train_time:178058ms step_avg:398.34ms
step:458/1500 train_loss:3.9935 train_time:178452ms step_avg:398.33ms
step:459/1500 train_loss:4.0352 train_time:178844ms step_avg:398.32ms
step:460/1500 train_loss:3.8337 train_time:179240ms step_avg:398.31ms
step:461/1500 train_loss:4.0043 train_time:179634ms step_avg:398.30ms
step:462/1500 train_loss:3.8949 train_time:180026ms step_avg:398.29ms
step:463/1500 train_loss:3.9161 train_time:180422ms step_avg:398.28ms
step:464/1500 train_loss:3.9768 train_time:180819ms step_avg:398.28ms
step:465/1500 train_loss:3.9189 train_time:181212ms step_avg:398.27ms
step:466/1500 train_loss:3.9205 train_time:181606ms step_avg:398.26ms
step:467/1500 train_loss:4.0159 train_time:181999ms step_avg:398.25ms
step:468/1500 train_loss:4.0298 train_time:182391ms step_avg:398.23ms
step:469/1500 train_loss:4.0019 train_time:182784ms step_avg:398.22ms
step:470/1500 train_loss:3.8933 train_time:183176ms step_avg:398.21ms
step:471/1500 train_loss:3.9777 train_time:183572ms step_avg:398.20ms
step:472/1500 train_loss:4.0306 train_time:183964ms step_avg:398.19ms
step:473/1500 train_loss:3.9662 train_time:184358ms step_avg:398.18ms
step:474/1500 train_loss:3.9243 train_time:184750ms step_avg:398.17ms
step:475/1500 train_loss:3.7772 train_time:185145ms step_avg:398.16ms
step:476/1500 train_loss:4.2149 train_time:185543ms step_avg:398.16ms
step:477/1500 train_loss:3.9676 train_time:185939ms step_avg:398.16ms
step:478/1500 train_loss:3.7707 train_time:186331ms step_avg:398.14ms
step:479/1500 train_loss:4.0155 train_time:186724ms step_avg:398.13ms
step:480/1500 train_loss:3.9658 train_time:187117ms step_avg:398.12ms
step:481/1500 train_loss:4.1128 train_time:187514ms step_avg:398.12ms
step:482/1500 train_loss:3.9221 train_time:187905ms step_avg:398.10ms
step:483/1500 train_loss:3.7293 train_time:188299ms step_avg:398.10ms
step:484/1500 train_loss:4.0120 train_time:188691ms step_avg:398.08ms
step:485/1500 train_loss:3.8644 train_time:189085ms step_avg:398.07ms
step:486/1500 train_loss:3.8690 train_time:189477ms step_avg:398.06ms
step:487/1500 train_loss:3.8019 train_time:189871ms step_avg:398.05ms
step:488/1500 train_loss:3.8671 train_time:190263ms step_avg:398.04ms
step:489/1500 train_loss:4.0673 train_time:190657ms step_avg:398.03ms
step:490/1500 train_loss:3.9143 train_time:191050ms step_avg:398.02ms
step:491/1500 train_loss:3.7995 train_time:191442ms step_avg:398.01ms
step:492/1500 train_loss:3.8171 train_time:191838ms step_avg:398.00ms
step:493/1500 train_loss:3.9352 train_time:192230ms step_avg:397.99ms
step:494/1500 train_loss:3.7715 train_time:192623ms step_avg:397.98ms
step:495/1500 train_loss:3.9100 train_time:193017ms step_avg:397.97ms
step:496/1500 train_loss:3.8483 train_time:193410ms step_avg:397.96ms
step:497/1500 train_loss:3.7379 train_time:193808ms step_avg:397.96ms
step:498/1500 train_loss:3.9268 train_time:194202ms step_avg:397.96ms
step:499/1500 train_loss:3.9962 train_time:194595ms step_avg:397.95ms
step:500/1500 train_loss:4.0248 train_time:194991ms step_avg:397.94ms
step:500/1500 val_loss:3.9054 train_time:195005ms step_avg:397.97ms
step:501/1500 train_loss:3.9422 train_time:195387ms step_avg:397.94ms
step:502/1500 train_loss:4.0008 train_time:195778ms step_avg:397.92ms
step:503/1500 train_loss:3.9369 train_time:196172ms step_avg:397.91ms
step:504/1500 train_loss:3.9785 train_time:196566ms step_avg:397.91ms
step:505/1500 train_loss:3.9239 train_time:196959ms step_avg:397.90ms
step:506/1500 train_loss:4.0104 train_time:197351ms step_avg:397.89ms
step:507/1500 train_loss:3.8350 train_time:197743ms step_avg:397.87ms
step:508/1500 train_loss:3.9521 train_time:198136ms step_avg:397.86ms
step:509/1500 train_loss:4.0313 train_time:198530ms step_avg:397.86ms
step:510/1500 train_loss:3.9720 train_time:198921ms step_avg:397.84ms
step:511/1500 train_loss:3.7775 train_time:199315ms step_avg:397.83ms
step:512/1500 train_loss:3.9780 train_time:199708ms step_avg:397.82ms
step:513/1500 train_loss:3.9197 train_time:200101ms step_avg:397.81ms
step:514/1500 train_loss:3.8747 train_time:200493ms step_avg:397.80ms
step:515/1500 train_loss:3.9531 train_time:200884ms step_avg:397.79ms
step:516/1500 train_loss:3.9383 train_time:201279ms step_avg:397.78ms
step:517/1500 train_loss:4.2718 train_time:201680ms step_avg:397.79ms
step:518/1500 train_loss:3.8773 train_time:202072ms step_avg:397.78ms
step:519/1500 train_loss:3.9825 train_time:202466ms step_avg:397.77ms
step:520/1500 train_loss:3.8792 train_time:202859ms step_avg:397.76ms
step:521/1500 train_loss:3.8796 train_time:203251ms step_avg:397.75ms
step:522/1500 train_loss:3.8319 train_time:203644ms step_avg:397.74ms
step:523/1500 train_loss:3.8456 train_time:204037ms step_avg:397.73ms
step:524/1500 train_loss:4.4768 train_time:204429ms step_avg:397.72ms
step:525/1500 train_loss:3.9395 train_time:204822ms step_avg:397.71ms
step:526/1500 train_loss:3.8770 train_time:205215ms step_avg:397.70ms
step:527/1500 train_loss:3.8903 train_time:205611ms step_avg:397.70ms
step:528/1500 train_loss:3.8460 train_time:206004ms step_avg:397.69ms
step:529/1500 train_loss:3.8195 train_time:206397ms step_avg:397.68ms
step:530/1500 train_loss:4.0382 train_time:206790ms step_avg:397.67ms
step:531/1500 train_loss:3.8341 train_time:207183ms step_avg:397.66ms
step:532/1500 train_loss:4.1136 train_time:207577ms step_avg:397.66ms
step:533/1500 train_loss:3.9266 train_time:207971ms step_avg:397.65ms
step:534/1500 train_loss:3.8493 train_time:208365ms step_avg:397.64ms
step:535/1500 train_loss:3.8762 train_time:208760ms step_avg:397.64ms
step:536/1500 train_loss:3.8050 train_time:209153ms step_avg:397.63ms
step:537/1500 train_loss:3.9373 train_time:209547ms step_avg:397.62ms
step:538/1500 train_loss:3.9273 train_time:209940ms step_avg:397.61ms
step:539/1500 train_loss:3.8266 train_time:210333ms step_avg:397.60ms
step:540/1500 train_loss:4.3190 train_time:210727ms step_avg:397.60ms
step:541/1500 train_loss:3.8565 train_time:211119ms step_avg:397.59ms
step:542/1500 train_loss:3.9750 train_time:211513ms step_avg:397.58ms
step:543/1500 train_loss:3.8010 train_time:211905ms step_avg:397.57ms
step:544/1500 train_loss:3.7761 train_time:212297ms step_avg:397.56ms
step:545/1500 train_loss:3.8558 train_time:212692ms step_avg:397.56ms
step:546/1500 train_loss:3.7886 train_time:213087ms step_avg:397.55ms
step:547/1500 train_loss:3.8325 train_time:213479ms step_avg:397.54ms
step:548/1500 train_loss:3.8451 train_time:213873ms step_avg:397.53ms
step:549/1500 train_loss:3.8216 train_time:214267ms step_avg:397.53ms
step:550/1500 train_loss:3.9154 train_time:214664ms step_avg:397.53ms
step:551/1500 train_loss:3.8067 train_time:215057ms step_avg:397.52ms
step:552/1500 train_loss:3.8142 train_time:215449ms step_avg:397.51ms
step:553/1500 train_loss:4.1469 train_time:215842ms step_avg:397.50ms
step:554/1500 train_loss:3.9439 train_time:216236ms step_avg:397.49ms
step:555/1500 train_loss:3.9061 train_time:216630ms step_avg:397.49ms
step:556/1500 train_loss:3.8436 train_time:217021ms step_avg:397.48ms
step:557/1500 train_loss:3.8756 train_time:217415ms step_avg:397.47ms
step:558/1500 train_loss:3.5403 train_time:217808ms step_avg:397.46ms
step:559/1500 train_loss:3.7979 train_time:218203ms step_avg:397.46ms
step:560/1500 train_loss:3.8431 train_time:218597ms step_avg:397.45ms
step:561/1500 train_loss:3.8903 train_time:218990ms step_avg:397.44ms
step:562/1500 train_loss:3.7963 train_time:219382ms step_avg:397.43ms
step:563/1500 train_loss:3.7416 train_time:219773ms step_avg:397.42ms
step:564/1500 train_loss:3.9522 train_time:220167ms step_avg:397.41ms
step:565/1500 train_loss:3.7628 train_time:220563ms step_avg:397.41ms
step:566/1500 train_loss:3.8823 train_time:220956ms step_avg:397.40ms
step:567/1500 train_loss:3.8303 train_time:222146ms step_avg:398.83ms
step:568/1500 train_loss:3.7804 train_time:222539ms step_avg:398.81ms
step:569/1500 train_loss:3.8701 train_time:222933ms step_avg:398.81ms
step:570/1500 train_loss:3.8453 train_time:223478ms step_avg:399.07ms
step:571/1500 train_loss:3.8704 train_time:223871ms step_avg:399.06ms
step:572/1500 train_loss:3.9552 train_time:224265ms step_avg:399.05ms
step:573/1500 train_loss:3.9039 train_time:224663ms step_avg:399.05ms
step:574/1500 train_loss:3.9122 train_time:225055ms step_avg:399.03ms
step:575/1500 train_loss:3.9663 train_time:225449ms step_avg:399.03ms
step:576/1500 train_loss:3.9126 train_time:225841ms step_avg:399.01ms
step:577/1500 train_loss:3.9368 train_time:226235ms step_avg:399.00ms
step:578/1500 train_loss:3.8700 train_time:226629ms step_avg:398.99ms
step:579/1500 train_loss:3.8565 train_time:227024ms step_avg:398.99ms
step:580/1500 train_loss:3.8452 train_time:227417ms step_avg:398.98ms
step:581/1500 train_loss:3.7874 train_time:227811ms step_avg:398.97ms
step:582/1500 train_loss:3.8139 train_time:228202ms step_avg:398.95ms
step:583/1500 train_loss:4.0408 train_time:228595ms step_avg:398.94ms
step:584/1500 train_loss:3.8144 train_time:228990ms step_avg:398.94ms
step:585/1500 train_loss:3.7730 train_time:229384ms step_avg:398.93ms
step:586/1500 train_loss:3.9653 train_time:229778ms step_avg:398.92ms
step:587/1500 train_loss:3.7141 train_time:230171ms step_avg:398.91ms
step:588/1500 train_loss:3.8522 train_time:230566ms step_avg:398.90ms
step:589/1500 train_loss:3.8393 train_time:230964ms step_avg:398.90ms
step:590/1500 train_loss:4.1839 train_time:231356ms step_avg:398.89ms
step:591/1500 train_loss:3.9704 train_time:231749ms step_avg:398.88ms
step:592/1500 train_loss:3.7068 train_time:232142ms step_avg:398.87ms
step:593/1500 train_loss:3.7237 train_time:232535ms step_avg:398.86ms
step:594/1500 train_loss:3.7049 train_time:232928ms step_avg:398.85ms
step:595/1500 train_loss:3.7500 train_time:233320ms step_avg:398.84ms
step:596/1500 train_loss:4.1231 train_time:233711ms step_avg:398.82ms
step:597/1500 train_loss:3.8390 train_time:234106ms step_avg:398.82ms
step:598/1500 train_loss:3.7717 train_time:234499ms step_avg:398.81ms
step:599/1500 train_loss:3.8444 train_time:234893ms step_avg:398.80ms
step:600/1500 train_loss:3.6599 train_time:235285ms step_avg:398.79ms
step:601/1500 train_loss:3.7816 train_time:235679ms step_avg:398.78ms
step:602/1500 train_loss:3.8176 train_time:236072ms step_avg:398.77ms
step:603/1500 train_loss:3.8393 train_time:236469ms step_avg:398.77ms
step:604/1500 train_loss:3.9641 train_time:236865ms step_avg:398.76ms
step:605/1500 train_loss:3.8210 train_time:237260ms step_avg:398.76ms
step:606/1500 train_loss:3.8045 train_time:237653ms step_avg:398.75ms
step:607/1500 train_loss:3.7518 train_time:238048ms step_avg:398.74ms
step:608/1500 train_loss:4.0025 train_time:238441ms step_avg:398.73ms
step:609/1500 train_loss:3.8324 train_time:238836ms step_avg:398.72ms
step:610/1500 train_loss:3.8052 train_time:239228ms step_avg:398.71ms
step:611/1500 train_loss:3.9004 train_time:239621ms step_avg:398.70ms
step:612/1500 train_loss:3.8071 train_time:240014ms step_avg:398.69ms
step:613/1500 train_loss:3.7872 train_time:240408ms step_avg:398.69ms
step:614/1500 train_loss:3.9546 train_time:240801ms step_avg:398.68ms
step:615/1500 train_loss:3.9058 train_time:241192ms step_avg:398.67ms
step:616/1500 train_loss:3.8751 train_time:241588ms step_avg:398.66ms
step:617/1500 train_loss:3.8026 train_time:241980ms step_avg:398.65ms
step:618/1500 train_loss:3.7582 train_time:242376ms step_avg:398.64ms
step:619/1500 train_loss:3.8661 train_time:242768ms step_avg:398.63ms
step:620/1500 train_loss:3.7563 train_time:243164ms step_avg:398.63ms
step:621/1500 train_loss:3.7739 train_time:243557ms step_avg:398.62ms
step:622/1500 train_loss:4.0864 train_time:243951ms step_avg:398.61ms
step:623/1500 train_loss:3.7677 train_time:244343ms step_avg:398.60ms
step:624/1500 train_loss:3.8050 train_time:244736ms step_avg:398.59ms
step:625/1500 train_loss:3.8835 train_time:245129ms step_avg:398.58ms
step:625/1500 val_loss:3.8103 train_time:245143ms step_avg:398.61ms
step:626/1500 train_loss:3.9012 train_time:245525ms step_avg:398.58ms
step:627/1500 train_loss:3.9278 train_time:245920ms step_avg:398.57ms
step:628/1500 train_loss:3.9110 train_time:246311ms step_avg:398.56ms
step:629/1500 train_loss:3.9549 train_time:246704ms step_avg:398.55ms
step:630/1500 train_loss:3.7787 train_time:247097ms step_avg:398.54ms
step:631/1500 train_loss:3.9053 train_time:247489ms step_avg:398.53ms
step:632/1500 train_loss:3.9383 train_time:247881ms step_avg:398.52ms
step:633/1500 train_loss:3.8397 train_time:248274ms step_avg:398.51ms
step:634/1500 train_loss:3.7738 train_time:248669ms step_avg:398.51ms
step:635/1500 train_loss:3.8681 train_time:249062ms step_avg:398.50ms
step:636/1500 train_loss:4.1279 train_time:249454ms step_avg:398.49ms
step:637/1500 train_loss:3.7162 train_time:249847ms step_avg:398.48ms
step:638/1500 train_loss:3.5369 train_time:250240ms step_avg:398.47ms
step:639/1500 train_loss:3.7681 train_time:250632ms step_avg:398.46ms
step:640/1500 train_loss:3.7973 train_time:251026ms step_avg:398.45ms
step:641/1500 train_loss:3.7571 train_time:251418ms step_avg:398.44ms
step:642/1500 train_loss:3.7540 train_time:251809ms step_avg:398.43ms
step:643/1500 train_loss:3.8000 train_time:252203ms step_avg:398.43ms
step:644/1500 train_loss:3.8192 train_time:252595ms step_avg:398.42ms
step:645/1500 train_loss:3.7382 train_time:252990ms step_avg:398.41ms
step:646/1500 train_loss:3.9535 train_time:253386ms step_avg:398.41ms
step:647/1500 train_loss:3.8493 train_time:253780ms step_avg:398.40ms
step:648/1500 train_loss:3.8535 train_time:254173ms step_avg:398.39ms
step:649/1500 train_loss:3.8808 train_time:254566ms step_avg:398.38ms
step:650/1500 train_loss:3.9445 train_time:254958ms step_avg:398.37ms
step:651/1500 train_loss:3.8020 train_time:255357ms step_avg:398.37ms
step:652/1500 train_loss:3.9468 train_time:255751ms step_avg:398.37ms
step:653/1500 train_loss:3.7670 train_time:256143ms step_avg:398.36ms
step:654/1500 train_loss:3.8453 train_time:256536ms step_avg:398.35ms
step:655/1500 train_loss:3.6114 train_time:256929ms step_avg:398.34ms
step:656/1500 train_loss:3.7515 train_time:257322ms step_avg:398.33ms
step:657/1500 train_loss:3.7606 train_time:257714ms step_avg:398.32ms
step:658/1500 train_loss:3.6909 train_time:258108ms step_avg:398.31ms
step:659/1500 train_loss:3.8702 train_time:258501ms step_avg:398.31ms
step:660/1500 train_loss:3.7705 train_time:258894ms step_avg:398.30ms
step:661/1500 train_loss:3.8665 train_time:259291ms step_avg:398.30ms
step:662/1500 train_loss:3.9344 train_time:259686ms step_avg:398.29ms
step:663/1500 train_loss:3.8535 train_time:260080ms step_avg:398.28ms
step:664/1500 train_loss:3.7286 train_time:260473ms step_avg:398.28ms
step:665/1500 train_loss:3.8129 train_time:260864ms step_avg:398.27ms
step:666/1500 train_loss:3.6806 train_time:261256ms step_avg:398.26ms
step:667/1500 train_loss:3.9672 train_time:261651ms step_avg:398.25ms
step:668/1500 train_loss:3.8017 train_time:262043ms step_avg:398.24ms
step:669/1500 train_loss:3.8124 train_time:262434ms step_avg:398.23ms
step:670/1500 train_loss:3.6587 train_time:262829ms step_avg:398.23ms
step:671/1500 train_loss:3.7739 train_time:263221ms step_avg:398.22ms
step:672/1500 train_loss:3.7379 train_time:263616ms step_avg:398.21ms
step:673/1500 train_loss:3.7550 train_time:264010ms step_avg:398.20ms
step:674/1500 train_loss:4.0377 train_time:264403ms step_avg:398.20ms
step:675/1500 train_loss:3.8246 train_time:264794ms step_avg:398.19ms
step:676/1500 train_loss:3.9021 train_time:265190ms step_avg:398.18ms
step:677/1500 train_loss:3.6712 train_time:265589ms step_avg:398.18ms
step:678/1500 train_loss:3.7756 train_time:265981ms step_avg:398.17ms
step:679/1500 train_loss:3.7227 train_time:266374ms step_avg:398.17ms
step:680/1500 train_loss:3.8567 train_time:266766ms step_avg:398.16ms
step:681/1500 train_loss:3.7601 train_time:267159ms step_avg:398.15ms
step:682/1500 train_loss:3.7962 train_time:267553ms step_avg:398.14ms
step:683/1500 train_loss:3.8651 train_time:267945ms step_avg:398.14ms
step:684/1500 train_loss:3.9182 train_time:268339ms step_avg:398.13ms
step:685/1500 train_loss:3.8072 train_time:268732ms step_avg:398.12ms
step:686/1500 train_loss:3.8836 train_time:269125ms step_avg:398.11ms
step:687/1500 train_loss:3.8103 train_time:269517ms step_avg:398.10ms
step:688/1500 train_loss:3.8569 train_time:269909ms step_avg:398.10ms
step:689/1500 train_loss:3.4829 train_time:270377ms step_avg:398.20ms
step:690/1500 train_loss:3.5957 train_time:270770ms step_avg:398.19ms
step:691/1500 train_loss:3.7322 train_time:271162ms step_avg:398.18ms
step:692/1500 train_loss:3.6142 train_time:271555ms step_avg:398.17ms
step:693/1500 train_loss:3.8216 train_time:271948ms step_avg:398.17ms
step:694/1500 train_loss:3.8361 train_time:272341ms step_avg:398.16ms
step:695/1500 train_loss:3.7328 train_time:272733ms step_avg:398.15ms
step:696/1500 train_loss:3.7165 train_time:273127ms step_avg:398.14ms
step:697/1500 train_loss:4.0362 train_time:273520ms step_avg:398.14ms
step:698/1500 train_loss:3.7770 train_time:273915ms step_avg:398.13ms
step:699/1500 train_loss:3.8238 train_time:274324ms step_avg:398.15ms
step:700/1500 train_loss:3.9728 train_time:274718ms step_avg:398.14ms
step:701/1500 train_loss:3.7524 train_time:275112ms step_avg:398.14ms
step:702/1500 train_loss:3.7172 train_time:275504ms step_avg:398.13ms
step:703/1500 train_loss:3.6933 train_time:275898ms step_avg:398.12ms
step:704/1500 train_loss:3.6570 train_time:276291ms step_avg:398.11ms
step:705/1500 train_loss:3.7456 train_time:276689ms step_avg:398.11ms
step:706/1500 train_loss:3.7403 train_time:277082ms step_avg:398.11ms
step:707/1500 train_loss:3.7539 train_time:277475ms step_avg:398.10ms
step:708/1500 train_loss:3.8222 train_time:277868ms step_avg:398.09ms
step:709/1500 train_loss:3.7715 train_time:278261ms step_avg:398.08ms
step:710/1500 train_loss:3.7562 train_time:278653ms step_avg:398.08ms
step:711/1500 train_loss:3.7183 train_time:279048ms step_avg:398.07ms
step:712/1500 train_loss:3.7664 train_time:279438ms step_avg:398.06ms
step:713/1500 train_loss:3.8197 train_time:279831ms step_avg:398.05ms
step:714/1500 train_loss:3.8354 train_time:280226ms step_avg:398.05ms
step:715/1500 train_loss:3.7418 train_time:280619ms step_avg:398.04ms
step:716/1500 train_loss:3.7487 train_time:281014ms step_avg:398.04ms
step:717/1500 train_loss:3.7581 train_time:281407ms step_avg:398.03ms
step:718/1500 train_loss:3.9032 train_time:281801ms step_avg:398.02ms
step:719/1500 train_loss:3.7689 train_time:282192ms step_avg:398.01ms
step:720/1500 train_loss:3.8391 train_time:282589ms step_avg:398.01ms
step:721/1500 train_loss:4.0145 train_time:282982ms step_avg:398.01ms
step:722/1500 train_loss:3.6370 train_time:283376ms step_avg:398.00ms
step:723/1500 train_loss:3.8980 train_time:283769ms step_avg:397.99ms
step:724/1500 train_loss:3.9591 train_time:284162ms step_avg:397.99ms
step:725/1500 train_loss:3.7422 train_time:284555ms step_avg:397.98ms
step:726/1500 train_loss:3.8210 train_time:284947ms step_avg:397.97ms
step:727/1500 train_loss:3.7135 train_time:285344ms step_avg:397.97ms
step:728/1500 train_loss:3.7356 train_time:285737ms step_avg:397.96ms
step:729/1500 train_loss:3.9100 train_time:286130ms step_avg:397.96ms
step:730/1500 train_loss:3.8574 train_time:286523ms step_avg:397.95ms
step:731/1500 train_loss:3.8532 train_time:286916ms step_avg:397.94ms
step:732/1500 train_loss:3.7403 train_time:287309ms step_avg:397.93ms
step:733/1500 train_loss:3.7624 train_time:287702ms step_avg:397.93ms
step:734/1500 train_loss:4.0008 train_time:288095ms step_avg:397.92ms
step:735/1500 train_loss:3.7351 train_time:288491ms step_avg:397.92ms
step:736/1500 train_loss:3.7931 train_time:288889ms step_avg:397.92ms
step:737/1500 train_loss:3.9192 train_time:289281ms step_avg:397.91ms
step:738/1500 train_loss:3.8333 train_time:289674ms step_avg:397.90ms
step:739/1500 train_loss:3.7734 train_time:290068ms step_avg:397.90ms
step:740/1500 train_loss:3.6713 train_time:290460ms step_avg:397.89ms
step:741/1500 train_loss:4.3145 train_time:290853ms step_avg:397.88ms
step:742/1500 train_loss:3.6718 train_time:291246ms step_avg:397.88ms
step:743/1500 train_loss:3.7487 train_time:291639ms step_avg:397.87ms
step:744/1500 train_loss:3.7557 train_time:292033ms step_avg:397.86ms
step:745/1500 train_loss:3.8163 train_time:292425ms step_avg:397.86ms
step:746/1500 train_loss:3.7884 train_time:292820ms step_avg:397.85ms
step:747/1500 train_loss:3.7698 train_time:293213ms step_avg:397.85ms
step:748/1500 train_loss:3.8023 train_time:293607ms step_avg:397.84ms
step:749/1500 train_loss:3.7300 train_time:294000ms step_avg:397.83ms
step:750/1500 train_loss:3.7331 train_time:294394ms step_avg:397.83ms
step:750/1500 val_loss:3.7428 train_time:294412ms step_avg:397.85ms
step:751/1500 train_loss:3.7666 train_time:294794ms step_avg:397.83ms
step:752/1500 train_loss:3.7295 train_time:295188ms step_avg:397.83ms
step:753/1500 train_loss:3.7724 train_time:295580ms step_avg:397.82ms
step:754/1500 train_loss:3.7914 train_time:295976ms step_avg:397.82ms
step:755/1500 train_loss:3.7580 train_time:296367ms step_avg:397.81ms
step:756/1500 train_loss:3.8371 train_time:297465ms step_avg:398.75ms
step:757/1500 train_loss:3.6650 train_time:297858ms step_avg:398.74ms
step:758/1500 train_loss:3.9045 train_time:298251ms step_avg:398.73ms
step:759/1500 train_loss:3.8189 train_time:298645ms step_avg:398.72ms
step:760/1500 train_loss:3.7497 train_time:299191ms step_avg:398.92ms
step:761/1500 train_loss:3.8601 train_time:299583ms step_avg:398.91ms
step:762/1500 train_loss:3.5720 train_time:299976ms step_avg:398.90ms
step:763/1500 train_loss:3.7245 train_time:300368ms step_avg:398.90ms
step:764/1500 train_loss:3.8384 train_time:300762ms step_avg:398.89ms
step:765/1500 train_loss:3.4833 train_time:301155ms step_avg:398.88ms
step:766/1500 train_loss:3.9203 train_time:301548ms step_avg:398.87ms
step:767/1500 train_loss:3.7584 train_time:301941ms step_avg:398.87ms
step:768/1500 train_loss:3.7243 train_time:302333ms step_avg:398.86ms
step:769/1500 train_loss:3.7449 train_time:302727ms step_avg:398.85ms
step:770/1500 train_loss:3.7690 train_time:303119ms step_avg:398.84ms
step:771/1500 train_loss:3.8249 train_time:303514ms step_avg:398.84ms
step:772/1500 train_loss:4.0519 train_time:303907ms step_avg:398.83ms
step:773/1500 train_loss:3.6294 train_time:304301ms step_avg:398.82ms
step:774/1500 train_loss:3.8212 train_time:304697ms step_avg:398.82ms
step:775/1500 train_loss:3.8086 train_time:305090ms step_avg:398.81ms
step:776/1500 train_loss:3.7775 train_time:305483ms step_avg:398.80ms
step:777/1500 train_loss:3.5748 train_time:305876ms step_avg:398.80ms
step:778/1500 train_loss:3.5781 train_time:306269ms step_avg:398.79ms
step:779/1500 train_loss:3.6520 train_time:306661ms step_avg:398.78ms
step:780/1500 train_loss:3.7408 train_time:307055ms step_avg:398.77ms
step:781/1500 train_loss:3.7686 train_time:307451ms step_avg:398.77ms
step:782/1500 train_loss:3.8329 train_time:307844ms step_avg:398.76ms
step:783/1500 train_loss:3.7445 train_time:308243ms step_avg:398.76ms
step:784/1500 train_loss:3.7452 train_time:308635ms step_avg:398.75ms
step:785/1500 train_loss:3.7488 train_time:309028ms step_avg:398.75ms
step:786/1500 train_loss:3.7240 train_time:309421ms step_avg:398.74ms
step:787/1500 train_loss:3.6256 train_time:309815ms step_avg:398.73ms
step:788/1500 train_loss:3.8916 train_time:310208ms step_avg:398.72ms
step:789/1500 train_loss:3.6711 train_time:310602ms step_avg:398.72ms
step:790/1500 train_loss:3.7387 train_time:310999ms step_avg:398.72ms
step:791/1500 train_loss:3.7951 train_time:311392ms step_avg:398.71ms
step:792/1500 train_loss:3.9296 train_time:311784ms step_avg:398.70ms
step:793/1500 train_loss:3.9358 train_time:312176ms step_avg:398.69ms
step:794/1500 train_loss:3.6484 train_time:312570ms step_avg:398.69ms
step:795/1500 train_loss:3.7705 train_time:312964ms step_avg:398.68ms
step:796/1500 train_loss:3.8283 train_time:313358ms step_avg:398.67ms
step:797/1500 train_loss:3.9242 train_time:313751ms step_avg:398.67ms
step:798/1500 train_loss:3.6847 train_time:314144ms step_avg:398.66ms
step:799/1500 train_loss:3.8321 train_time:314537ms step_avg:398.65ms
step:800/1500 train_loss:3.7248 train_time:314930ms step_avg:398.65ms
step:801/1500 train_loss:3.7068 train_time:315322ms step_avg:398.64ms
step:802/1500 train_loss:3.8081 train_time:315717ms step_avg:398.63ms
step:803/1500 train_loss:3.6648 train_time:316109ms step_avg:398.62ms
step:804/1500 train_loss:3.6793 train_time:316503ms step_avg:398.62ms
step:805/1500 train_loss:3.7982 train_time:316899ms step_avg:398.61ms
step:806/1500 train_loss:3.7014 train_time:317292ms step_avg:398.61ms
step:807/1500 train_loss:3.7133 train_time:317685ms step_avg:398.60ms
step:808/1500 train_loss:3.8117 train_time:318078ms step_avg:398.59ms
step:809/1500 train_loss:3.7247 train_time:318472ms step_avg:398.59ms
step:810/1500 train_loss:3.6508 train_time:318865ms step_avg:398.58ms
step:811/1500 train_loss:3.7397 train_time:319274ms step_avg:398.59ms
step:812/1500 train_loss:3.7708 train_time:319666ms step_avg:398.59ms
step:813/1500 train_loss:3.7589 train_time:320060ms step_avg:398.58ms
step:814/1500 train_loss:3.7959 train_time:320453ms step_avg:398.57ms
step:815/1500 train_loss:3.7401 train_time:320846ms step_avg:398.57ms
step:816/1500 train_loss:3.7260 train_time:321240ms step_avg:398.56ms
step:817/1500 train_loss:3.8303 train_time:321634ms step_avg:398.56ms
step:818/1500 train_loss:3.9294 train_time:322026ms step_avg:398.55ms
step:819/1500 train_loss:3.6907 train_time:322420ms step_avg:398.54ms
step:820/1500 train_loss:3.8928 train_time:322813ms step_avg:398.53ms
step:821/1500 train_loss:3.6711 train_time:323206ms step_avg:398.53ms
step:822/1500 train_loss:3.7167 train_time:323600ms step_avg:398.52ms
step:823/1500 train_loss:3.8375 train_time:323996ms step_avg:398.52ms
step:824/1500 train_loss:3.7508 train_time:324389ms step_avg:398.51ms
step:825/1500 train_loss:3.6803 train_time:324782ms step_avg:398.51ms
step:826/1500 train_loss:3.7742 train_time:325174ms step_avg:398.50ms
step:827/1500 train_loss:3.6646 train_time:325567ms step_avg:398.49ms
step:828/1500 train_loss:3.9017 train_time:325959ms step_avg:398.48ms
step:829/1500 train_loss:3.7856 train_time:326352ms step_avg:398.48ms
step:830/1500 train_loss:3.8460 train_time:326748ms step_avg:398.47ms
step:831/1500 train_loss:3.7003 train_time:327140ms step_avg:398.47ms
step:832/1500 train_loss:3.7550 train_time:327535ms step_avg:398.46ms
step:833/1500 train_loss:3.6806 train_time:327926ms step_avg:398.45ms
step:834/1500 train_loss:3.8137 train_time:328320ms step_avg:398.45ms
step:835/1500 train_loss:3.6482 train_time:328713ms step_avg:398.44ms
step:836/1500 train_loss:3.6270 train_time:329105ms step_avg:398.43ms
step:837/1500 train_loss:3.8900 train_time:329513ms step_avg:398.44ms
step:838/1500 train_loss:3.5824 train_time:329905ms step_avg:398.44ms
step:839/1500 train_loss:3.7599 train_time:330306ms step_avg:398.44ms
step:840/1500 train_loss:3.5941 train_time:330713ms step_avg:398.45ms
step:841/1500 train_loss:3.6408 train_time:331104ms step_avg:398.44ms
step:842/1500 train_loss:3.7258 train_time:331499ms step_avg:398.44ms
step:843/1500 train_loss:3.7478 train_time:331890ms step_avg:398.43ms
step:844/1500 train_loss:3.7453 train_time:332283ms step_avg:398.42ms
step:845/1500 train_loss:3.5933 train_time:332676ms step_avg:398.41ms
step:846/1500 train_loss:3.8304 train_time:333068ms step_avg:398.41ms
step:847/1500 train_loss:3.6972 train_time:333462ms step_avg:398.40ms
step:848/1500 train_loss:3.6557 train_time:333855ms step_avg:398.39ms
step:849/1500 train_loss:3.7969 train_time:334247ms step_avg:398.39ms
step:850/1500 train_loss:3.6626 train_time:334641ms step_avg:398.38ms
step:851/1500 train_loss:3.6160 train_time:335033ms step_avg:398.37ms
step:852/1500 train_loss:3.9043 train_time:335424ms step_avg:398.37ms
step:853/1500 train_loss:3.6166 train_time:335818ms step_avg:398.36ms
step:854/1500 train_loss:3.7289 train_time:336213ms step_avg:398.36ms
step:855/1500 train_loss:3.8137 train_time:336607ms step_avg:398.35ms
step:856/1500 train_loss:3.6961 train_time:337001ms step_avg:398.35ms
step:857/1500 train_loss:3.7143 train_time:337399ms step_avg:398.35ms
step:858/1500 train_loss:3.7645 train_time:337790ms step_avg:398.34ms
step:859/1500 train_loss:3.6494 train_time:338182ms step_avg:398.33ms
step:860/1500 train_loss:3.7185 train_time:338576ms step_avg:398.32ms
step:861/1500 train_loss:3.7557 train_time:338969ms step_avg:398.32ms
step:862/1500 train_loss:3.8096 train_time:339364ms step_avg:398.31ms
step:863/1500 train_loss:3.7565 train_time:339755ms step_avg:398.31ms
step:864/1500 train_loss:3.7377 train_time:340149ms step_avg:398.30ms
step:865/1500 train_loss:3.5618 train_time:340541ms step_avg:398.29ms
step:866/1500 train_loss:3.7538 train_time:340936ms step_avg:398.29ms
step:867/1500 train_loss:4.0304 train_time:341333ms step_avg:398.29ms
step:868/1500 train_loss:3.6152 train_time:341728ms step_avg:398.28ms
step:869/1500 train_loss:3.8023 train_time:342120ms step_avg:398.28ms
step:870/1500 train_loss:3.7717 train_time:342515ms step_avg:398.27ms
step:871/1500 train_loss:3.6158 train_time:342907ms step_avg:398.27ms
step:872/1500 train_loss:3.5731 train_time:343301ms step_avg:398.26ms
step:873/1500 train_loss:3.8265 train_time:343698ms step_avg:398.26ms
step:874/1500 train_loss:3.6139 train_time:344092ms step_avg:398.25ms
step:875/1500 train_loss:3.3436 train_time:344485ms step_avg:398.25ms
step:875/1500 val_loss:3.6899 train_time:344499ms step_avg:398.26ms
step:876/1500 train_loss:3.8051 train_time:344883ms step_avg:398.25ms
step:877/1500 train_loss:3.6103 train_time:345275ms step_avg:398.24ms
step:878/1500 train_loss:3.7886 train_time:345671ms step_avg:398.24ms
step:879/1500 train_loss:3.6439 train_time:346064ms step_avg:398.23ms
step:880/1500 train_loss:3.8291 train_time:346457ms step_avg:398.23ms
step:881/1500 train_loss:3.4926 train_time:346850ms step_avg:398.22ms
step:882/1500 train_loss:3.6635 train_time:347243ms step_avg:398.21ms
step:883/1500 train_loss:3.8536 train_time:347636ms step_avg:398.21ms
step:884/1500 train_loss:4.0132 train_time:348028ms step_avg:398.20ms
step:885/1500 train_loss:3.7349 train_time:348421ms step_avg:398.20ms
step:886/1500 train_loss:3.6530 train_time:348820ms step_avg:398.20ms
step:887/1500 train_loss:3.7450 train_time:349215ms step_avg:398.19ms
step:888/1500 train_loss:4.2401 train_time:349609ms step_avg:398.19ms
step:889/1500 train_loss:4.0064 train_time:350001ms step_avg:398.18ms
step:890/1500 train_loss:3.6864 train_time:350394ms step_avg:398.18ms
step:891/1500 train_loss:3.6967 train_time:350787ms step_avg:398.17ms
step:892/1500 train_loss:3.5252 train_time:351180ms step_avg:398.16ms
step:893/1500 train_loss:3.8663 train_time:351573ms step_avg:398.16ms
step:894/1500 train_loss:3.5926 train_time:351967ms step_avg:398.15ms
step:895/1500 train_loss:3.8421 train_time:352360ms step_avg:398.15ms
step:896/1500 train_loss:3.8616 train_time:352753ms step_avg:398.14ms
step:897/1500 train_loss:3.6577 train_time:353148ms step_avg:398.14ms
step:898/1500 train_loss:3.6995 train_time:353540ms step_avg:398.13ms
step:899/1500 train_loss:3.7484 train_time:353934ms step_avg:398.13ms
step:900/1500 train_loss:3.6388 train_time:354327ms step_avg:398.12ms
step:901/1500 train_loss:3.5850 train_time:354720ms step_avg:398.11ms
step:902/1500 train_loss:3.7935 train_time:355116ms step_avg:398.11ms
step:903/1500 train_loss:3.7960 train_time:355511ms step_avg:398.11ms
step:904/1500 train_loss:3.6991 train_time:355903ms step_avg:398.10ms
step:905/1500 train_loss:3.6654 train_time:356296ms step_avg:398.10ms
step:906/1500 train_loss:3.6556 train_time:356689ms step_avg:398.09ms
step:907/1500 train_loss:3.8788 train_time:357082ms step_avg:398.08ms
step:908/1500 train_loss:3.6717 train_time:357475ms step_avg:398.08ms
step:909/1500 train_loss:3.7165 train_time:357868ms step_avg:398.07ms
step:910/1500 train_loss:3.6217 train_time:358261ms step_avg:398.07ms
step:911/1500 train_loss:3.7110 train_time:358653ms step_avg:398.06ms
step:912/1500 train_loss:3.7875 train_time:359047ms step_avg:398.06ms
step:913/1500 train_loss:3.7696 train_time:359439ms step_avg:398.05ms
step:914/1500 train_loss:3.6458 train_time:359831ms step_avg:398.04ms
step:915/1500 train_loss:3.9005 train_time:360225ms step_avg:398.04ms
step:916/1500 train_loss:3.6914 train_time:360618ms step_avg:398.03ms
step:917/1500 train_loss:3.7886 train_time:361014ms step_avg:398.03ms
step:918/1500 train_loss:3.7599 train_time:361406ms step_avg:398.02ms
step:919/1500 train_loss:5.0042 train_time:361800ms step_avg:398.02ms
step:920/1500 train_loss:3.6765 train_time:362194ms step_avg:398.02ms
step:921/1500 train_loss:3.7319 train_time:362587ms step_avg:398.01ms
step:922/1500 train_loss:3.6955 train_time:362980ms step_avg:398.00ms
step:923/1500 train_loss:3.7446 train_time:363373ms step_avg:398.00ms
step:924/1500 train_loss:3.7571 train_time:363767ms step_avg:397.99ms
step:925/1500 train_loss:3.8439 train_time:364159ms step_avg:397.99ms
step:926/1500 train_loss:3.8232 train_time:364553ms step_avg:397.98ms
step:927/1500 train_loss:3.7159 train_time:364945ms step_avg:397.98ms
step:928/1500 train_loss:3.7053 train_time:365339ms step_avg:397.97ms
step:929/1500 train_loss:3.9310 train_time:365732ms step_avg:397.97ms
step:930/1500 train_loss:3.7800 train_time:366124ms step_avg:397.96ms
step:931/1500 train_loss:3.5631 train_time:366518ms step_avg:397.96ms
step:932/1500 train_loss:3.6543 train_time:366917ms step_avg:397.96ms
step:933/1500 train_loss:3.8308 train_time:367309ms step_avg:397.95ms
step:934/1500 train_loss:3.5550 train_time:367705ms step_avg:397.95ms
step:935/1500 train_loss:3.7342 train_time:368096ms step_avg:397.94ms
step:936/1500 train_loss:3.6115 train_time:368489ms step_avg:397.94ms
step:937/1500 train_loss:3.6737 train_time:368881ms step_avg:397.93ms
step:938/1500 train_loss:3.7708 train_time:369274ms step_avg:397.92ms
step:939/1500 train_loss:3.6995 train_time:369667ms step_avg:397.92ms
step:940/1500 train_loss:3.8539 train_time:370060ms step_avg:397.91ms
step:941/1500 train_loss:3.6472 train_time:370452ms step_avg:397.91ms
step:942/1500 train_loss:3.7072 train_time:370845ms step_avg:397.90ms
step:943/1500 train_loss:3.5086 train_time:371239ms step_avg:397.90ms
step:944/1500 train_loss:3.8623 train_time:371633ms step_avg:397.89ms
step:945/1500 train_loss:3.5736 train_time:372773ms step_avg:398.69ms
step:946/1500 train_loss:3.5812 train_time:373167ms step_avg:398.68ms
step:947/1500 train_loss:5.2053 train_time:373559ms step_avg:398.68ms
step:948/1500 train_loss:3.7560 train_time:373953ms step_avg:398.67ms
step:949/1500 train_loss:3.6625 train_time:374346ms step_avg:398.66ms
step:950/1500 train_loss:3.5504 train_time:374886ms step_avg:398.82ms
step:951/1500 train_loss:3.6124 train_time:375277ms step_avg:398.81ms
step:952/1500 train_loss:3.5647 train_time:375668ms step_avg:398.80ms
step:953/1500 train_loss:3.6386 train_time:376062ms step_avg:398.79ms
step:954/1500 train_loss:3.7156 train_time:376454ms step_avg:398.79ms
step:955/1500 train_loss:3.5983 train_time:376846ms step_avg:398.78ms
step:956/1500 train_loss:3.6353 train_time:377239ms step_avg:398.77ms
step:957/1500 train_loss:3.6031 train_time:377632ms step_avg:398.77ms
step:958/1500 train_loss:3.6584 train_time:378025ms step_avg:398.76ms
step:959/1500 train_loss:3.6553 train_time:378417ms step_avg:398.75ms
step:960/1500 train_loss:3.6662 train_time:378810ms step_avg:398.75ms
step:961/1500 train_loss:3.5496 train_time:379203ms step_avg:398.74ms
step:962/1500 train_loss:3.8122 train_time:379596ms step_avg:398.74ms
step:963/1500 train_loss:3.7585 train_time:379988ms step_avg:398.73ms
step:964/1500 train_loss:3.6124 train_time:380379ms step_avg:398.72ms
step:965/1500 train_loss:3.6050 train_time:380773ms step_avg:398.72ms
step:966/1500 train_loss:3.6419 train_time:381165ms step_avg:398.71ms
step:967/1500 train_loss:3.8669 train_time:381559ms step_avg:398.70ms
step:968/1500 train_loss:3.6976 train_time:381951ms step_avg:398.70ms
step:969/1500 train_loss:3.6791 train_time:382344ms step_avg:398.69ms
step:970/1500 train_loss:3.7330 train_time:382737ms step_avg:398.68ms
step:971/1500 train_loss:3.5450 train_time:383130ms step_avg:398.68ms
step:972/1500 train_loss:3.7025 train_time:383524ms step_avg:398.67ms
step:973/1500 train_loss:3.6507 train_time:383919ms step_avg:398.67ms
step:974/1500 train_loss:3.6967 train_time:384316ms step_avg:398.67ms
step:975/1500 train_loss:3.7760 train_time:384707ms step_avg:398.66ms
step:976/1500 train_loss:3.6431 train_time:385101ms step_avg:398.66ms
step:977/1500 train_loss:3.8420 train_time:385494ms step_avg:398.65ms
step:978/1500 train_loss:3.7274 train_time:385887ms step_avg:398.64ms
step:979/1500 train_loss:3.5518 train_time:386280ms step_avg:398.64ms
step:980/1500 train_loss:3.8433 train_time:386675ms step_avg:398.63ms
step:981/1500 train_loss:3.5775 train_time:387068ms step_avg:398.63ms
step:982/1500 train_loss:3.7427 train_time:387461ms step_avg:398.62ms
step:983/1500 train_loss:3.7208 train_time:387853ms step_avg:398.62ms
step:984/1500 train_loss:3.7215 train_time:388246ms step_avg:398.61ms
step:985/1500 train_loss:3.6796 train_time:388641ms step_avg:398.61ms
step:986/1500 train_loss:3.7536 train_time:389033ms step_avg:398.60ms
step:987/1500 train_loss:3.5708 train_time:389428ms step_avg:398.60ms
step:988/1500 train_loss:3.6497 train_time:389821ms step_avg:398.59ms
step:989/1500 train_loss:3.6308 train_time:390218ms step_avg:398.59ms
step:990/1500 train_loss:3.5938 train_time:390611ms step_avg:398.58ms
step:991/1500 train_loss:3.8094 train_time:391005ms step_avg:398.58ms
step:992/1500 train_loss:3.6288 train_time:391396ms step_avg:398.57ms
step:993/1500 train_loss:3.6073 train_time:391789ms step_avg:398.56ms
step:994/1500 train_loss:3.6674 train_time:392182ms step_avg:398.56ms
step:995/1500 train_loss:3.7608 train_time:392575ms step_avg:398.55ms
step:996/1500 train_loss:3.7082 train_time:392969ms step_avg:398.55ms
step:997/1500 train_loss:3.6105 train_time:393361ms step_avg:398.54ms
step:998/1500 train_loss:3.9693 train_time:393755ms step_avg:398.54ms
step:999/1500 train_loss:3.6207 train_time:394147ms step_avg:398.53ms
step:1000/1500 train_loss:3.7465 train_time:394539ms step_avg:398.52ms
step:1000/1500 val_loss:3.6431 train_time:394553ms step_avg:398.54ms
step:1001/1500 train_loss:3.6156 train_time:394933ms step_avg:398.52ms
step:1002/1500 train_loss:3.6652 train_time:395330ms step_avg:398.52ms
step:1003/1500 train_loss:3.5494 train_time:395727ms step_avg:398.52ms
step:1004/1500 train_loss:3.7401 train_time:396120ms step_avg:398.51ms
step:1005/1500 train_loss:3.7854 train_time:396513ms step_avg:398.51ms
step:1006/1500 train_loss:3.5593 train_time:396906ms step_avg:398.50ms
step:1007/1500 train_loss:3.6443 train_time:397298ms step_avg:398.49ms
step:1008/1500 train_loss:3.6100 train_time:397694ms step_avg:398.49ms
step:1009/1500 train_loss:3.7297 train_time:398086ms step_avg:398.48ms
step:1010/1500 train_loss:3.8303 train_time:398482ms step_avg:398.48ms
step:1011/1500 train_loss:3.7273 train_time:398875ms step_avg:398.48ms
step:1012/1500 train_loss:3.6895 train_time:399268ms step_avg:398.47ms
step:1013/1500 train_loss:3.5542 train_time:399661ms step_avg:398.47ms
step:1014/1500 train_loss:3.6924 train_time:400054ms step_avg:398.46ms
step:1015/1500 train_loss:3.8089 train_time:400448ms step_avg:398.46ms
step:1016/1500 train_loss:3.5116 train_time:400841ms step_avg:398.45ms
step:1017/1500 train_loss:3.6053 train_time:401233ms step_avg:398.44ms
step:1018/1500 train_loss:3.6039 train_time:401630ms step_avg:398.44ms
step:1019/1500 train_loss:3.5492 train_time:402024ms step_avg:398.44ms
step:1020/1500 train_loss:3.6935 train_time:402418ms step_avg:398.43ms
step:1021/1500 train_loss:3.6028 train_time:402813ms step_avg:398.43ms
step:1022/1500 train_loss:3.5388 train_time:403206ms step_avg:398.43ms
step:1023/1500 train_loss:3.6414 train_time:403600ms step_avg:398.42ms
step:1024/1500 train_loss:3.6729 train_time:403994ms step_avg:398.42ms
step:1025/1500 train_loss:3.6483 train_time:404387ms step_avg:398.41ms
step:1026/1500 train_loss:3.6619 train_time:404779ms step_avg:398.40ms
step:1027/1500 train_loss:3.8254 train_time:405172ms step_avg:398.40ms
step:1028/1500 train_loss:3.5034 train_time:405566ms step_avg:398.39ms
step:1029/1500 train_loss:3.5671 train_time:405957ms step_avg:398.39ms
step:1030/1500 train_loss:3.5115 train_time:406350ms step_avg:398.38ms
step:1031/1500 train_loss:3.6869 train_time:406747ms step_avg:398.38ms
step:1032/1500 train_loss:3.6739 train_time:407139ms step_avg:398.37ms
step:1033/1500 train_loss:3.8538 train_time:407531ms step_avg:398.37ms
step:1034/1500 train_loss:3.6633 train_time:407925ms step_avg:398.36ms
step:1035/1500 train_loss:3.5864 train_time:408319ms step_avg:398.36ms
step:1036/1500 train_loss:3.6076 train_time:408711ms step_avg:398.35ms
step:1037/1500 train_loss:3.6668 train_time:409105ms step_avg:398.35ms
step:1038/1500 train_loss:3.9790 train_time:409500ms step_avg:398.35ms
step:1039/1500 train_loss:3.7954 train_time:409893ms step_avg:398.34ms
step:1040/1500 train_loss:3.6900 train_time:410287ms step_avg:398.34ms
step:1041/1500 train_loss:3.5867 train_time:410680ms step_avg:398.33ms
step:1042/1500 train_loss:3.6592 train_time:411075ms step_avg:398.33ms
step:1043/1500 train_loss:3.6984 train_time:411472ms step_avg:398.33ms
step:1044/1500 train_loss:3.6215 train_time:411866ms step_avg:398.32ms
step:1045/1500 train_loss:3.6322 train_time:412258ms step_avg:398.32ms
step:1046/1500 train_loss:3.7106 train_time:412651ms step_avg:398.31ms
step:1047/1500 train_loss:3.6071 train_time:413044ms step_avg:398.31ms
step:1048/1500 train_loss:3.8188 train_time:413436ms step_avg:398.30ms
step:1049/1500 train_loss:3.6685 train_time:413831ms step_avg:398.30ms
step:1050/1500 train_loss:3.5977 train_time:414228ms step_avg:398.30ms
step:1051/1500 train_loss:3.5635 train_time:414621ms step_avg:398.29ms
step:1052/1500 train_loss:3.6883 train_time:415014ms step_avg:398.29ms
step:1053/1500 train_loss:3.5580 train_time:415406ms step_avg:398.28ms
step:1054/1500 train_loss:3.8851 train_time:415799ms step_avg:398.28ms
step:1055/1500 train_loss:3.7170 train_time:416191ms step_avg:398.27ms
step:1056/1500 train_loss:3.5785 train_time:416585ms step_avg:398.26ms
step:1057/1500 train_loss:3.6773 train_time:416976ms step_avg:398.26ms
step:1058/1500 train_loss:3.7538 train_time:417369ms step_avg:398.25ms
step:1059/1500 train_loss:3.4760 train_time:417761ms step_avg:398.25ms
step:1060/1500 train_loss:3.5952 train_time:418155ms step_avg:398.24ms
step:1061/1500 train_loss:3.6220 train_time:418547ms step_avg:398.24ms
step:1062/1500 train_loss:3.5860 train_time:418939ms step_avg:398.23ms
step:1063/1500 train_loss:3.5624 train_time:419332ms step_avg:398.23ms
step:1064/1500 train_loss:3.6605 train_time:419729ms step_avg:398.23ms
step:1065/1500 train_loss:3.5652 train_time:420121ms step_avg:398.22ms
step:1066/1500 train_loss:3.5541 train_time:420514ms step_avg:398.21ms
step:1067/1500 train_loss:3.5750 train_time:420906ms step_avg:398.21ms
step:1068/1500 train_loss:3.4839 train_time:421300ms step_avg:398.20ms
step:1069/1500 train_loss:3.6040 train_time:421692ms step_avg:398.20ms
step:1070/1500 train_loss:3.4818 train_time:422085ms step_avg:398.19ms
step:1071/1500 train_loss:3.7302 train_time:422478ms step_avg:398.19ms
step:1072/1500 train_loss:3.6856 train_time:422871ms step_avg:398.18ms
step:1073/1500 train_loss:3.6295 train_time:423263ms step_avg:398.18ms
step:1074/1500 train_loss:3.6977 train_time:423658ms step_avg:398.17ms
step:1075/1500 train_loss:3.6419 train_time:424051ms step_avg:398.17ms
step:1076/1500 train_loss:3.5839 train_time:424444ms step_avg:398.16ms
step:1077/1500 train_loss:3.9750 train_time:424837ms step_avg:398.16ms
step:1078/1500 train_loss:3.6473 train_time:425229ms step_avg:398.15ms
step:1079/1500 train_loss:3.3615 train_time:425627ms step_avg:398.15ms
step:1080/1500 train_loss:3.7160 train_time:426021ms step_avg:398.15ms
step:1081/1500 train_loss:3.6271 train_time:426414ms step_avg:398.15ms
step:1082/1500 train_loss:3.6937 train_time:426808ms step_avg:398.14ms
step:1083/1500 train_loss:3.7854 train_time:427200ms step_avg:398.14ms
step:1084/1500 train_loss:3.6873 train_time:427594ms step_avg:398.13ms
step:1085/1500 train_loss:3.6563 train_time:427985ms step_avg:398.13ms
step:1086/1500 train_loss:3.6204 train_time:428379ms step_avg:398.12ms
step:1087/1500 train_loss:3.8186 train_time:428771ms step_avg:398.12ms
step:1088/1500 train_loss:3.7074 train_time:429164ms step_avg:398.11ms
step:1089/1500 train_loss:3.5412 train_time:429558ms step_avg:398.11ms
step:1090/1500 train_loss:3.5702 train_time:429950ms step_avg:398.10ms
step:1091/1500 train_loss:3.6803 train_time:430343ms step_avg:398.10ms
step:1092/1500 train_loss:3.4738 train_time:430736ms step_avg:398.09ms
step:1093/1500 train_loss:3.6759 train_time:431131ms step_avg:398.09ms
step:1094/1500 train_loss:3.8098 train_time:431527ms step_avg:398.09ms
step:1095/1500 train_loss:3.6489 train_time:431921ms step_avg:398.08ms
step:1096/1500 train_loss:3.6012 train_time:432314ms step_avg:398.08ms
step:1097/1500 train_loss:3.6243 train_time:432708ms step_avg:398.08ms
step:1098/1500 train_loss:3.6700 train_time:433102ms step_avg:398.07ms
step:1099/1500 train_loss:3.7415 train_time:433495ms step_avg:398.07ms
step:1100/1500 train_loss:3.7012 train_time:433888ms step_avg:398.06ms
step:1101/1500 train_loss:3.6319 train_time:434281ms step_avg:398.06ms
step:1102/1500 train_loss:3.4831 train_time:434676ms step_avg:398.05ms
step:1103/1500 train_loss:3.5653 train_time:435069ms step_avg:398.05ms
step:1104/1500 train_loss:3.6345 train_time:435463ms step_avg:398.05ms
step:1105/1500 train_loss:3.5193 train_time:435855ms step_avg:398.04ms
step:1106/1500 train_loss:4.2675 train_time:436248ms step_avg:398.04ms
step:1107/1500 train_loss:3.4143 train_time:436640ms step_avg:398.03ms
step:1108/1500 train_loss:3.7571 train_time:437032ms step_avg:398.03ms
step:1109/1500 train_loss:3.5386 train_time:437428ms step_avg:398.02ms
step:1110/1500 train_loss:3.6852 train_time:437827ms step_avg:398.02ms
step:1111/1500 train_loss:3.6197 train_time:438220ms step_avg:398.02ms
step:1112/1500 train_loss:3.6609 train_time:438615ms step_avg:398.02ms
step:1113/1500 train_loss:3.7588 train_time:439007ms step_avg:398.01ms
step:1114/1500 train_loss:3.6120 train_time:439400ms step_avg:398.01ms
step:1115/1500 train_loss:3.5605 train_time:439792ms step_avg:398.00ms
step:1116/1500 train_loss:3.4575 train_time:440185ms step_avg:398.00ms
step:1117/1500 train_loss:3.6279 train_time:440578ms step_avg:397.99ms
step:1118/1500 train_loss:3.7730 train_time:440971ms step_avg:397.99ms
step:1119/1500 train_loss:3.8161 train_time:441364ms step_avg:397.98ms
step:1120/1500 train_loss:3.6557 train_time:441755ms step_avg:397.98ms
step:1121/1500 train_loss:3.6796 train_time:442151ms step_avg:397.98ms
step:1122/1500 train_loss:3.5755 train_time:442545ms step_avg:397.97ms
step:1123/1500 train_loss:3.6407 train_time:442939ms step_avg:397.97ms
step:1124/1500 train_loss:3.7724 train_time:443331ms step_avg:397.96ms
step:1125/1500 train_loss:3.5406 train_time:443724ms step_avg:397.96ms
step:1125/1500 val_loss:3.6055 train_time:443739ms step_avg:397.97ms
step:1126/1500 train_loss:3.4419 train_time:444123ms step_avg:397.96ms
step:1127/1500 train_loss:3.6645 train_time:444517ms step_avg:397.96ms
step:1128/1500 train_loss:3.8794 train_time:444910ms step_avg:397.95ms
step:1129/1500 train_loss:3.4268 train_time:445304ms step_avg:397.95ms
step:1130/1500 train_loss:3.7464 train_time:445699ms step_avg:397.95ms
step:1131/1500 train_loss:3.5726 train_time:446092ms step_avg:397.94ms
step:1132/1500 train_loss:3.6054 train_time:446485ms step_avg:397.94ms
step:1133/1500 train_loss:3.5560 train_time:446878ms step_avg:397.93ms
step:1134/1500 train_loss:3.7208 train_time:448026ms step_avg:398.60ms
step:1135/1500 train_loss:3.6494 train_time:448420ms step_avg:398.60ms
step:1136/1500 train_loss:3.7042 train_time:448813ms step_avg:398.59ms
step:1137/1500 train_loss:3.7412 train_time:449207ms step_avg:398.59ms
step:1138/1500 train_loss:3.6543 train_time:449600ms step_avg:398.58ms
step:1139/1500 train_loss:3.5506 train_time:449992ms step_avg:398.58ms
step:1140/1500 train_loss:3.8652 train_time:450532ms step_avg:398.70ms
step:1141/1500 train_loss:3.6622 train_time:450924ms step_avg:398.69ms
step:1142/1500 train_loss:3.7528 train_time:451316ms step_avg:398.69ms
step:1143/1500 train_loss:3.6484 train_time:451709ms step_avg:398.68ms
step:1144/1500 train_loss:3.5589 train_time:452103ms step_avg:398.68ms
step:1145/1500 train_loss:3.6571 train_time:452495ms step_avg:398.67ms
step:1146/1500 train_loss:3.7850 train_time:452888ms step_avg:398.67ms
step:1147/1500 train_loss:3.7503 train_time:453281ms step_avg:398.66ms
step:1148/1500 train_loss:3.6616 train_time:453674ms step_avg:398.66ms
step:1149/1500 train_loss:3.6907 train_time:454068ms step_avg:398.65ms
step:1150/1500 train_loss:3.5347 train_time:454460ms step_avg:398.65ms
step:1151/1500 train_loss:3.5580 train_time:454853ms step_avg:398.64ms
step:1152/1500 train_loss:3.5276 train_time:455244ms step_avg:398.64ms
step:1153/1500 train_loss:3.6724 train_time:455640ms step_avg:398.64ms
step:1154/1500 train_loss:3.6409 train_time:456033ms step_avg:398.63ms
step:1155/1500 train_loss:3.7118 train_time:456426ms step_avg:398.62ms
step:1156/1500 train_loss:3.5617 train_time:456819ms step_avg:398.62ms
step:1157/1500 train_loss:3.7319 train_time:457211ms step_avg:398.61ms
step:1158/1500 train_loss:3.6797 train_time:457604ms step_avg:398.61ms
step:1159/1500 train_loss:3.4948 train_time:457996ms step_avg:398.60ms
step:1160/1500 train_loss:3.5313 train_time:458388ms step_avg:398.60ms
step:1161/1500 train_loss:3.5211 train_time:458781ms step_avg:398.59ms
step:1162/1500 train_loss:3.3227 train_time:459176ms step_avg:398.59ms
step:1163/1500 train_loss:3.6345 train_time:459570ms step_avg:398.59ms
step:1164/1500 train_loss:3.6031 train_time:459964ms step_avg:398.58ms
step:1165/1500 train_loss:3.4753 train_time:460356ms step_avg:398.58ms
step:1166/1500 train_loss:3.4657 train_time:460748ms step_avg:398.57ms
step:1167/1500 train_loss:3.5725 train_time:461145ms step_avg:398.57ms
step:1168/1500 train_loss:3.5857 train_time:461542ms step_avg:398.57ms
step:1169/1500 train_loss:3.9070 train_time:461933ms step_avg:398.56ms
step:1170/1500 train_loss:3.5879 train_time:462325ms step_avg:398.56ms
step:1171/1500 train_loss:3.5962 train_time:462719ms step_avg:398.55ms
step:1172/1500 train_loss:3.4986 train_time:463113ms step_avg:398.55ms
step:1173/1500 train_loss:3.6044 train_time:463506ms step_avg:398.54ms
step:1174/1500 train_loss:3.7355 train_time:463898ms step_avg:398.54ms
step:1175/1500 train_loss:3.5824 train_time:464292ms step_avg:398.53ms
step:1176/1500 train_loss:3.6000 train_time:464685ms step_avg:398.53ms
step:1177/1500 train_loss:3.6508 train_time:465079ms step_avg:398.52ms
step:1178/1500 train_loss:3.6323 train_time:465472ms step_avg:398.52ms
step:1179/1500 train_loss:3.6888 train_time:465865ms step_avg:398.52ms
step:1180/1500 train_loss:3.5971 train_time:466258ms step_avg:398.51ms
step:1181/1500 train_loss:3.6062 train_time:466651ms step_avg:398.51ms
step:1182/1500 train_loss:3.5463 train_time:467045ms step_avg:398.50ms
step:1183/1500 train_loss:3.5813 train_time:467442ms step_avg:398.50ms
step:1184/1500 train_loss:3.5294 train_time:467833ms step_avg:398.49ms
step:1185/1500 train_loss:3.7010 train_time:468227ms step_avg:398.49ms
step:1186/1500 train_loss:3.7579 train_time:468619ms step_avg:398.49ms
step:1187/1500 train_loss:3.5525 train_time:469013ms step_avg:398.48ms
step:1188/1500 train_loss:3.6125 train_time:469408ms step_avg:398.48ms
step:1189/1500 train_loss:3.6333 train_time:469801ms step_avg:398.47ms
step:1190/1500 train_loss:3.4751 train_time:470193ms step_avg:398.47ms
step:1191/1500 train_loss:3.6504 train_time:470585ms step_avg:398.46ms
step:1192/1500 train_loss:3.7912 train_time:470979ms step_avg:398.46ms
step:1193/1500 train_loss:3.5961 train_time:471372ms step_avg:398.45ms
step:1194/1500 train_loss:3.4785 train_time:471765ms step_avg:398.45ms
step:1195/1500 train_loss:3.7828 train_time:472158ms step_avg:398.45ms
step:1196/1500 train_loss:3.5775 train_time:472551ms step_avg:398.44ms
step:1197/1500 train_loss:3.5798 train_time:472944ms step_avg:398.44ms
step:1198/1500 train_loss:3.4816 train_time:473337ms step_avg:398.43ms
step:1199/1500 train_loss:3.4917 train_time:473731ms step_avg:398.43ms
step:1200/1500 train_loss:3.5443 train_time:474124ms step_avg:398.42ms
step:1201/1500 train_loss:3.6294 train_time:474517ms step_avg:398.42ms
step:1202/1500 train_loss:3.6982 train_time:474909ms step_avg:398.41ms
step:1203/1500 train_loss:3.7365 train_time:475304ms step_avg:398.41ms
step:1204/1500 train_loss:3.6153 train_time:475696ms step_avg:398.41ms
step:1205/1500 train_loss:3.5315 train_time:476089ms step_avg:398.40ms
step:1206/1500 train_loss:3.6278 train_time:476481ms step_avg:398.40ms
step:1207/1500 train_loss:3.6676 train_time:476877ms step_avg:398.39ms
step:1208/1500 train_loss:3.7210 train_time:477269ms step_avg:398.39ms
step:1209/1500 train_loss:3.6020 train_time:477661ms step_avg:398.38ms
step:1210/1500 train_loss:3.4598 train_time:478056ms step_avg:398.38ms
step:1211/1500 train_loss:3.5104 train_time:478449ms step_avg:398.38ms
step:1212/1500 train_loss:3.6028 train_time:478846ms step_avg:398.37ms
step:1213/1500 train_loss:3.6181 train_time:479243ms step_avg:398.37ms
step:1214/1500 train_loss:3.6435 train_time:479638ms step_avg:398.37ms
step:1215/1500 train_loss:3.5247 train_time:480031ms step_avg:398.37ms
step:1216/1500 train_loss:3.5971 train_time:480424ms step_avg:398.36ms
step:1217/1500 train_loss:3.5401 train_time:480818ms step_avg:398.36ms
step:1218/1500 train_loss:3.5341 train_time:481211ms step_avg:398.35ms
step:1219/1500 train_loss:3.6287 train_time:481602ms step_avg:398.35ms
step:1220/1500 train_loss:3.4610 train_time:481995ms step_avg:398.34ms
step:1221/1500 train_loss:3.6929 train_time:482389ms step_avg:398.34ms
step:1222/1500 train_loss:3.7239 train_time:482783ms step_avg:398.34ms
step:1223/1500 train_loss:3.6359 train_time:483176ms step_avg:398.33ms
step:1224/1500 train_loss:3.4996 train_time:483569ms step_avg:398.33ms
step:1225/1500 train_loss:3.4977 train_time:483962ms step_avg:398.32ms
step:1226/1500 train_loss:3.5761 train_time:484355ms step_avg:398.32ms
step:1227/1500 train_loss:3.5537 train_time:484746ms step_avg:398.31ms
step:1228/1500 train_loss:3.4911 train_time:485143ms step_avg:398.31ms
step:1229/1500 train_loss:3.6668 train_time:485534ms step_avg:398.31ms
step:1230/1500 train_loss:3.5831 train_time:485930ms step_avg:398.30ms
step:1231/1500 train_loss:3.6402 train_time:486323ms step_avg:398.30ms
step:1232/1500 train_loss:3.7973 train_time:486716ms step_avg:398.29ms
step:1233/1500 train_loss:3.6974 train_time:487109ms step_avg:398.29ms
step:1234/1500 train_loss:3.6314 train_time:487502ms step_avg:398.29ms
step:1235/1500 train_loss:3.7858 train_time:487895ms step_avg:398.28ms
step:1236/1500 train_loss:3.5460 train_time:488287ms step_avg:398.28ms
step:1237/1500 train_loss:3.5124 train_time:488682ms step_avg:398.27ms
step:1238/1500 train_loss:3.4659 train_time:489074ms step_avg:398.27ms
step:1239/1500 train_loss:3.5380 train_time:489466ms step_avg:398.26ms
step:1240/1500 train_loss:3.5480 train_time:489861ms step_avg:398.26ms
step:1241/1500 train_loss:3.5863 train_time:490255ms step_avg:398.26ms
step:1242/1500 train_loss:3.6390 train_time:490648ms step_avg:398.25ms
step:1243/1500 train_loss:3.5122 train_time:491043ms step_avg:398.25ms
step:1244/1500 train_loss:3.6013 train_time:491437ms step_avg:398.25ms
step:1245/1500 train_loss:3.6229 train_time:491830ms step_avg:398.24ms
step:1246/1500 train_loss:3.6233 train_time:492225ms step_avg:398.24ms
step:1247/1500 train_loss:3.4527 train_time:492617ms step_avg:398.24ms
step:1248/1500 train_loss:3.5999 train_time:493013ms step_avg:398.23ms
step:1249/1500 train_loss:3.6509 train_time:493406ms step_avg:398.23ms
step:1250/1500 train_loss:3.6300 train_time:493799ms step_avg:398.22ms
step:1250/1500 val_loss:3.5736 train_time:493814ms step_avg:398.24ms
step:1251/1500 train_loss:3.5263 train_time:494195ms step_avg:398.22ms
step:1252/1500 train_loss:3.7288 train_time:494588ms step_avg:398.22ms
step:1253/1500 train_loss:3.5897 train_time:494980ms step_avg:398.21ms
step:1254/1500 train_loss:3.5216 train_time:495373ms step_avg:398.21ms
step:1255/1500 train_loss:3.6584 train_time:495766ms step_avg:398.21ms
step:1256/1500 train_loss:3.7221 train_time:496159ms step_avg:398.20ms
step:1257/1500 train_loss:3.5285 train_time:496557ms step_avg:398.20ms
step:1258/1500 train_loss:3.5618 train_time:496949ms step_avg:398.20ms
step:1259/1500 train_loss:3.6067 train_time:497342ms step_avg:398.19ms
step:1260/1500 train_loss:3.5572 train_time:497734ms step_avg:398.19ms
step:1261/1500 train_loss:3.4201 train_time:498126ms step_avg:398.18ms
step:1262/1500 train_loss:3.5212 train_time:498519ms step_avg:398.18ms
step:1263/1500 train_loss:3.5951 train_time:498913ms step_avg:398.17ms
step:1264/1500 train_loss:3.4366 train_time:499306ms step_avg:398.17ms
step:1265/1500 train_loss:3.6552 train_time:499700ms step_avg:398.17ms
step:1266/1500 train_loss:3.6397 train_time:500092ms step_avg:398.16ms
step:1267/1500 train_loss:3.6382 train_time:500485ms step_avg:398.16ms
step:1268/1500 train_loss:3.5864 train_time:500879ms step_avg:398.16ms
step:1269/1500 train_loss:3.6244 train_time:501271ms step_avg:398.15ms
step:1270/1500 train_loss:3.4788 train_time:501663ms step_avg:398.15ms
step:1271/1500 train_loss:3.3290 train_time:502060ms step_avg:398.14ms
step:1272/1500 train_loss:3.6040 train_time:502458ms step_avg:398.14ms
step:1273/1500 train_loss:3.5639 train_time:502851ms step_avg:398.14ms
step:1274/1500 train_loss:3.6132 train_time:503243ms step_avg:398.14ms
step:1275/1500 train_loss:3.5673 train_time:503635ms step_avg:398.13ms
step:1276/1500 train_loss:3.6615 train_time:504028ms step_avg:398.13ms
step:1277/1500 train_loss:3.6845 train_time:504421ms step_avg:398.12ms
step:1278/1500 train_loss:3.6432 train_time:504814ms step_avg:398.12ms
step:1279/1500 train_loss:3.6371 train_time:505206ms step_avg:398.11ms
step:1280/1500 train_loss:3.4716 train_time:505599ms step_avg:398.11ms
step:1281/1500 train_loss:3.5806 train_time:505993ms step_avg:398.11ms
step:1282/1500 train_loss:3.6465 train_time:506385ms step_avg:398.10ms
step:1283/1500 train_loss:3.6814 train_time:506778ms step_avg:398.10ms
step:1284/1500 train_loss:3.5737 train_time:507171ms step_avg:398.09ms
step:1285/1500 train_loss:3.5965 train_time:507564ms step_avg:398.09ms
step:1286/1500 train_loss:3.5787 train_time:507958ms step_avg:398.09ms
step:1287/1500 train_loss:3.5509 train_time:508352ms step_avg:398.08ms
step:1288/1500 train_loss:3.6900 train_time:508744ms step_avg:398.08ms
step:1289/1500 train_loss:3.5210 train_time:509137ms step_avg:398.07ms
step:1290/1500 train_loss:3.6049 train_time:509530ms step_avg:398.07ms
step:1291/1500 train_loss:3.6819 train_time:509923ms step_avg:398.07ms
step:1292/1500 train_loss:3.6018 train_time:510316ms step_avg:398.06ms
step:1293/1500 train_loss:3.7063 train_time:510709ms step_avg:398.06ms
step:1294/1500 train_loss:3.7214 train_time:511104ms step_avg:398.06ms
step:1295/1500 train_loss:3.6850 train_time:511497ms step_avg:398.05ms
step:1296/1500 train_loss:3.4952 train_time:511889ms step_avg:398.05ms
step:1297/1500 train_loss:3.5824 train_time:512282ms step_avg:398.04ms
step:1298/1500 train_loss:3.4799 train_time:512676ms step_avg:398.04ms
step:1299/1500 train_loss:3.5470 train_time:513068ms step_avg:398.04ms
step:1300/1500 train_loss:3.6198 train_time:513461ms step_avg:398.03ms
step:1301/1500 train_loss:3.6254 train_time:513857ms step_avg:398.03ms
step:1302/1500 train_loss:3.6306 train_time:514250ms step_avg:398.03ms
step:1303/1500 train_loss:3.7833 train_time:514641ms step_avg:398.02ms
step:1304/1500 train_loss:3.5571 train_time:515034ms step_avg:398.02ms
step:1305/1500 train_loss:3.7591 train_time:515428ms step_avg:398.01ms
step:1306/1500 train_loss:3.4852 train_time:515821ms step_avg:398.01ms
step:1307/1500 train_loss:3.6781 train_time:516216ms step_avg:398.01ms
step:1308/1500 train_loss:3.6795 train_time:516609ms step_avg:398.00ms
step:1309/1500 train_loss:3.5375 train_time:517002ms step_avg:398.00ms
step:1310/1500 train_loss:3.5106 train_time:517395ms step_avg:398.00ms
step:1311/1500 train_loss:3.5143 train_time:517790ms step_avg:397.99ms
step:1312/1500 train_loss:3.5079 train_time:518182ms step_avg:397.99ms
step:1313/1500 train_loss:3.6252 train_time:518574ms step_avg:397.98ms
step:1314/1500 train_loss:3.5703 train_time:518967ms step_avg:397.98ms
step:1315/1500 train_loss:3.2902 train_time:519359ms step_avg:397.98ms
step:1316/1500 train_loss:3.5234 train_time:519754ms step_avg:397.97ms
step:1317/1500 train_loss:3.6035 train_time:520146ms step_avg:397.97ms
step:1318/1500 train_loss:3.6274 train_time:520540ms step_avg:397.97ms
step:1319/1500 train_loss:3.5076 train_time:520934ms step_avg:397.96ms
step:1320/1500 train_loss:3.6427 train_time:521328ms step_avg:397.96ms
step:1321/1500 train_loss:3.6978 train_time:521719ms step_avg:397.95ms
step:1322/1500 train_loss:3.5842 train_time:522112ms step_avg:397.95ms
step:1323/1500 train_loss:3.5347 train_time:523256ms step_avg:398.52ms
step:1324/1500 train_loss:3.5590 train_time:523650ms step_avg:398.52ms
step:1325/1500 train_loss:3.6533 train_time:524042ms step_avg:398.51ms
step:1326/1500 train_loss:3.7109 train_time:524437ms step_avg:398.51ms
step:1327/1500 train_loss:3.4590 train_time:524830ms step_avg:398.50ms
step:1328/1500 train_loss:3.3883 train_time:525223ms step_avg:398.50ms
step:1329/1500 train_loss:3.7054 train_time:525617ms step_avg:398.50ms
step:1330/1500 train_loss:3.5525 train_time:526154ms step_avg:398.60ms
step:1331/1500 train_loss:3.6676 train_time:526545ms step_avg:398.60ms
step:1332/1500 train_loss:3.5723 train_time:526938ms step_avg:398.59ms
step:1333/1500 train_loss:3.9676 train_time:527331ms step_avg:398.59ms
step:1334/1500 train_loss:3.6736 train_time:527723ms step_avg:398.58ms
step:1335/1500 train_loss:3.5860 train_time:528116ms step_avg:398.58ms
step:1336/1500 train_loss:3.5283 train_time:528511ms step_avg:398.58ms
step:1337/1500 train_loss:3.5237 train_time:528904ms step_avg:398.57ms
step:1338/1500 train_loss:3.7815 train_time:529296ms step_avg:398.57ms
step:1339/1500 train_loss:3.7167 train_time:529689ms step_avg:398.56ms
step:1340/1500 train_loss:3.5588 train_time:530081ms step_avg:398.56ms
step:1341/1500 train_loss:3.5228 train_time:530474ms step_avg:398.55ms
step:1342/1500 train_loss:3.8297 train_time:530868ms step_avg:398.55ms
step:1343/1500 train_loss:3.5977 train_time:531261ms step_avg:398.55ms
step:1344/1500 train_loss:3.5956 train_time:531658ms step_avg:398.54ms
step:1345/1500 train_loss:3.6512 train_time:532052ms step_avg:398.54ms
step:1346/1500 train_loss:3.6114 train_time:532445ms step_avg:398.54ms
step:1347/1500 train_loss:3.5217 train_time:532838ms step_avg:398.53ms
step:1348/1500 train_loss:3.4711 train_time:533231ms step_avg:398.53ms
step:1349/1500 train_loss:3.5664 train_time:533624ms step_avg:398.52ms
step:1350/1500 train_loss:3.4954 train_time:534015ms step_avg:398.52ms
step:1351/1500 train_loss:3.6240 train_time:534410ms step_avg:398.52ms
step:1352/1500 train_loss:3.4720 train_time:534802ms step_avg:398.51ms
step:1353/1500 train_loss:3.5388 train_time:535195ms step_avg:398.51ms
step:1354/1500 train_loss:3.6387 train_time:535589ms step_avg:398.50ms
step:1355/1500 train_loss:3.4856 train_time:535982ms step_avg:398.50ms
step:1356/1500 train_loss:3.4101 train_time:536377ms step_avg:398.50ms
step:1357/1500 train_loss:3.7523 train_time:536769ms step_avg:398.49ms
step:1358/1500 train_loss:3.6919 train_time:537163ms step_avg:398.49ms
step:1359/1500 train_loss:3.4106 train_time:537558ms step_avg:398.49ms
step:1360/1500 train_loss:3.6827 train_time:537952ms step_avg:398.48ms
step:1361/1500 train_loss:3.5686 train_time:538344ms step_avg:398.48ms
step:1362/1500 train_loss:3.4157 train_time:538736ms step_avg:398.47ms
step:1363/1500 train_loss:3.6096 train_time:539129ms step_avg:398.47ms
step:1364/1500 train_loss:3.5053 train_time:539522ms step_avg:398.47ms
step:1365/1500 train_loss:3.5263 train_time:539918ms step_avg:398.46ms
step:1366/1500 train_loss:3.5494 train_time:540311ms step_avg:398.46ms
step:1367/1500 train_loss:3.6455 train_time:540706ms step_avg:398.46ms
step:1368/1500 train_loss:3.6333 train_time:541101ms step_avg:398.45ms
step:1369/1500 train_loss:3.5822 train_time:541494ms step_avg:398.45ms
step:1370/1500 train_loss:3.4952 train_time:541886ms step_avg:398.45ms
step:1371/1500 train_loss:3.8225 train_time:542281ms step_avg:398.44ms
step:1372/1500 train_loss:3.5639 train_time:542678ms step_avg:398.44ms
step:1373/1500 train_loss:3.6028 train_time:543071ms step_avg:398.44ms
step:1374/1500 train_loss:3.5920 train_time:543465ms step_avg:398.43ms
step:1375/1500 train_loss:3.3962 train_time:543861ms step_avg:398.43ms
step:1375/1500 val_loss:3.5487 train_time:543879ms step_avg:398.45ms
step:1376/1500 train_loss:3.7818 train_time:544261ms step_avg:398.43ms
step:1377/1500 train_loss:3.5703 train_time:544655ms step_avg:398.43ms
step:1378/1500 train_loss:3.7111 train_time:545048ms step_avg:398.43ms
step:1379/1500 train_loss:3.7383 train_time:545441ms step_avg:398.42ms
step:1380/1500 train_loss:3.3816 train_time:545838ms step_avg:398.42ms
step:1381/1500 train_loss:3.5515 train_time:546230ms step_avg:398.42ms
step:1382/1500 train_loss:3.9759 train_time:546624ms step_avg:398.41ms
step:1383/1500 train_loss:3.4674 train_time:547018ms step_avg:398.41ms
step:1384/1500 train_loss:3.6218 train_time:547411ms step_avg:398.41ms
step:1385/1500 train_loss:3.6956 train_time:547803ms step_avg:398.40ms
step:1386/1500 train_loss:3.6094 train_time:548195ms step_avg:398.40ms
step:1387/1500 train_loss:3.5935 train_time:548588ms step_avg:398.39ms
step:1388/1500 train_loss:3.4381 train_time:548983ms step_avg:398.39ms
step:1389/1500 train_loss:3.5734 train_time:549377ms step_avg:398.39ms
step:1390/1500 train_loss:3.5453 train_time:549772ms step_avg:398.39ms
step:1391/1500 train_loss:3.8105 train_time:550169ms step_avg:398.38ms
step:1392/1500 train_loss:3.5271 train_time:550561ms step_avg:398.38ms
step:1393/1500 train_loss:3.5174 train_time:550953ms step_avg:398.38ms
step:1394/1500 train_loss:3.4854 train_time:551349ms step_avg:398.37ms
step:1395/1500 train_loss:3.7658 train_time:551743ms step_avg:398.37ms
step:1396/1500 train_loss:3.6579 train_time:552135ms step_avg:398.37ms
step:1397/1500 train_loss:3.6641 train_time:552526ms step_avg:398.36ms
step:1398/1500 train_loss:3.5328 train_time:552920ms step_avg:398.36ms
step:1399/1500 train_loss:3.5051 train_time:553322ms step_avg:398.36ms
step:1400/1500 train_loss:3.5698 train_time:553715ms step_avg:398.36ms
step:1401/1500 train_loss:3.5422 train_time:554108ms step_avg:398.35ms
step:1402/1500 train_loss:3.5692 train_time:554502ms step_avg:398.35ms
step:1403/1500 train_loss:3.5353 train_time:554893ms step_avg:398.34ms
step:1404/1500 train_loss:3.7626 train_time:555286ms step_avg:398.34ms
step:1405/1500 train_loss:3.5035 train_time:555679ms step_avg:398.34ms
step:1406/1500 train_loss:3.5539 train_time:556074ms step_avg:398.33ms
step:1407/1500 train_loss:3.5480 train_time:556503ms step_avg:398.36ms
step:1408/1500 train_loss:3.4200 train_time:556895ms step_avg:398.35ms
step:1409/1500 train_loss:3.5330 train_time:557290ms step_avg:398.35ms
step:1410/1500 train_loss:3.5185 train_time:557682ms step_avg:398.34ms
step:1411/1500 train_loss:3.5186 train_time:558077ms step_avg:398.34ms
step:1412/1500 train_loss:3.6078 train_time:558471ms step_avg:398.34ms
step:1413/1500 train_loss:3.5432 train_time:558869ms step_avg:398.34ms
step:1414/1500 train_loss:3.5918 train_time:559263ms step_avg:398.34ms
step:1415/1500 train_loss:3.5796 train_time:559657ms step_avg:398.33ms
step:1416/1500 train_loss:3.6591 train_time:560050ms step_avg:398.33ms
step:1417/1500 train_loss:3.4545 train_time:560444ms step_avg:398.33ms
step:1418/1500 train_loss:3.5303 train_time:560837ms step_avg:398.32ms
step:1419/1500 train_loss:3.6204 train_time:561229ms step_avg:398.32ms
step:1420/1500 train_loss:3.6456 train_time:561622ms step_avg:398.31ms
step:1421/1500 train_loss:3.6295 train_time:562017ms step_avg:398.31ms
step:1422/1500 train_loss:3.6063 train_time:562410ms step_avg:398.31ms
step:1423/1500 train_loss:3.5852 train_time:562802ms step_avg:398.30ms
step:1424/1500 train_loss:3.5729 train_time:563196ms step_avg:398.30ms
step:1425/1500 train_loss:3.5773 train_time:563588ms step_avg:398.30ms
step:1426/1500 train_loss:3.4433 train_time:563982ms step_avg:398.29ms
step:1427/1500 train_loss:3.5555 train_time:564374ms step_avg:398.29ms
step:1428/1500 train_loss:3.5063 train_time:564771ms step_avg:398.29ms
step:1429/1500 train_loss:3.6196 train_time:565170ms step_avg:398.29ms
step:1430/1500 train_loss:3.5852 train_time:565562ms step_avg:398.28ms
step:1431/1500 train_loss:3.5076 train_time:565954ms step_avg:398.28ms
step:1432/1500 train_loss:3.5589 train_time:566349ms step_avg:398.28ms
step:1433/1500 train_loss:3.5948 train_time:566741ms step_avg:398.27ms
step:1434/1500 train_loss:3.4100 train_time:567138ms step_avg:398.27ms
step:1435/1500 train_loss:3.5614 train_time:567530ms step_avg:398.27ms
step:1436/1500 train_loss:3.3857 train_time:567923ms step_avg:398.26ms
step:1437/1500 train_loss:3.4579 train_time:568316ms step_avg:398.26ms
step:1438/1500 train_loss:3.6498 train_time:568709ms step_avg:398.26ms
step:1439/1500 train_loss:3.6081 train_time:569101ms step_avg:398.25ms
step:1440/1500 train_loss:3.5578 train_time:569497ms step_avg:398.25ms
step:1441/1500 train_loss:3.4174 train_time:569889ms step_avg:398.25ms
step:1442/1500 train_loss:3.5929 train_time:570282ms step_avg:398.24ms
step:1443/1500 train_loss:3.6468 train_time:570674ms step_avg:398.24ms
step:1444/1500 train_loss:3.7165 train_time:571073ms step_avg:398.24ms
step:1445/1500 train_loss:3.6856 train_time:571469ms step_avg:398.24ms
step:1446/1500 train_loss:3.5705 train_time:571862ms step_avg:398.23ms
step:1447/1500 train_loss:3.4456 train_time:572256ms step_avg:398.23ms
step:1448/1500 train_loss:3.5201 train_time:572650ms step_avg:398.23ms
step:1449/1500 train_loss:3.5360 train_time:573042ms step_avg:398.22ms
step:1450/1500 train_loss:3.6539 train_time:573435ms step_avg:398.22ms
step:1451/1500 train_loss:3.6468 train_time:573829ms step_avg:398.22ms
step:1452/1500 train_loss:3.4610 train_time:574223ms step_avg:398.21ms
step:1453/1500 train_loss:3.5769 train_time:574616ms step_avg:398.21ms
step:1454/1500 train_loss:3.4917 train_time:575009ms step_avg:398.21ms
step:1455/1500 train_loss:3.5249 train_time:575403ms step_avg:398.20ms
step:1456/1500 train_loss:3.5737 train_time:575795ms step_avg:398.20ms
step:1457/1500 train_loss:3.5024 train_time:576189ms step_avg:398.20ms
step:1458/1500 train_loss:3.4028 train_time:576582ms step_avg:398.19ms
step:1459/1500 train_loss:3.6439 train_time:576974ms step_avg:398.19ms
step:1460/1500 train_loss:3.5124 train_time:577372ms step_avg:398.19ms
step:1461/1500 train_loss:3.5660 train_time:577765ms step_avg:398.18ms
step:1462/1500 train_loss:3.6906 train_time:578159ms step_avg:398.18ms
step:1463/1500 train_loss:3.5085 train_time:578552ms step_avg:398.18ms
step:1464/1500 train_loss:3.6992 train_time:578944ms step_avg:398.17ms
step:1465/1500 train_loss:3.5941 train_time:579338ms step_avg:398.17ms
step:1466/1500 train_loss:3.5988 train_time:579731ms step_avg:398.17ms
step:1467/1500 train_loss:3.5219 train_time:580127ms step_avg:398.17ms
step:1468/1500 train_loss:3.6706 train_time:580520ms step_avg:398.16ms
step:1469/1500 train_loss:3.5424 train_time:580914ms step_avg:398.16ms
step:1470/1500 train_loss:3.5123 train_time:581307ms step_avg:398.16ms
step:1471/1500 train_loss:3.5664 train_time:581700ms step_avg:398.15ms
step:1472/1500 train_loss:3.4935 train_time:582093ms step_avg:398.15ms
step:1473/1500 train_loss:3.5902 train_time:582486ms step_avg:398.15ms
step:1474/1500 train_loss:3.6676 train_time:582880ms step_avg:398.14ms
step:1475/1500 train_loss:3.5552 train_time:583273ms step_avg:398.14ms
step:1476/1500 train_loss:3.3825 train_time:583669ms step_avg:398.14ms
step:1477/1500 train_loss:3.5005 train_time:584061ms step_avg:398.13ms
step:1478/1500 train_loss:3.4732 train_time:584454ms step_avg:398.13ms
step:1479/1500 train_loss:3.5657 train_time:584848ms step_avg:398.13ms
step:1480/1500 train_loss:3.6438 train_time:585241ms step_avg:398.12ms
step:1481/1500 train_loss:3.5153 train_time:585635ms step_avg:398.12ms
step:1482/1500 train_loss:3.6867 train_time:586026ms step_avg:398.12ms
step:1483/1500 train_loss:3.6214 train_time:586419ms step_avg:398.11ms
step:1484/1500 train_loss:3.5185 train_time:586812ms step_avg:398.11ms
step:1485/1500 train_loss:3.4980 train_time:587217ms step_avg:398.11ms
step:1486/1500 train_loss:3.5072 train_time:587608ms step_avg:398.11ms
step:1487/1500 train_loss:3.4823 train_time:588002ms step_avg:398.11ms
step:1488/1500 train_loss:3.5685 train_time:588394ms step_avg:398.10ms
step:1489/1500 train_loss:3.4803 train_time:588786ms step_avg:398.10ms
step:1490/1500 train_loss:3.5698 train_time:589179ms step_avg:398.09ms
step:1491/1500 train_loss:3.4982 train_time:589573ms step_avg:398.09ms
step:1492/1500 train_loss:3.4326 train_time:589968ms step_avg:398.09ms
step:1493/1500 train_loss:3.4993 train_time:590359ms step_avg:398.08ms
step:1494/1500 train_loss:3.6806 train_time:590786ms step_avg:398.10ms
step:1495/1500 train_loss:3.5341 train_time:591179ms step_avg:398.10ms
step:1496/1500 train_loss:3.2942 train_time:591574ms step_avg:398.10ms
step:1497/1500 train_loss:3.5982 train_time:591971ms step_avg:398.10ms
step:1498/1500 train_loss:3.5595 train_time:592364ms step_avg:398.09ms
step:1499/1500 train_loss:3.6011 train_time:592756ms step_avg:398.09ms
step:1500/1500 train_loss:3.5617 train_time:593149ms step_avg:398.09ms
step:1500/1500 val_loss:3.5336 train_time:593163ms step_avg:398.10ms
