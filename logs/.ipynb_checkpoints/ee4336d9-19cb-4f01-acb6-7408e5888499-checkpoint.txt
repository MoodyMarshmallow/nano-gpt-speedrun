====================================================================================================
# NOTE: record from https://github.com/KellerJordan/modded-nanogpt/blob/master/records/track_1_short/2024-10-14_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt
# ====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
import json
import dataclasses
import subprocess
import csv
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \\sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=3e-4, momentum=0.95, nesterov=True, backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]
            for p in group['params']:
                g = p.grad
                if g is None:
                    continue
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.mul_(momentum).add_(g)
                if group['nesterov']:
                    g = g.add(buf, alpha=momentum)
                if g.size(0) == 3 * g.size(1): # split grouped QKV parameters
                    g = torch.cat([zeropower_backend(g1, steps=group['backend_steps']) for g1 in g.split(g.size(1))])
                    scale = g.size(1)**0.5
                else:
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    scale = max(g.size(0), g.size(1))**0.5 # scale to have update.square().mean() == 1
                p.data.add_(g, alpha=-lr * scale)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

def _apply_gate_act(logits: torch.Tensor, kind: str) -> torch.Tensor:
    if kind == "sigmoid":
        return torch.sigmoid(logits)
    if kind == "ns_sigmoid":
        return 0.5 + 0.5 * torch.sigmoid(logits)
    raise ValueError(f"unknown gate_act={kind}")

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.attn_gate = getattr(config, "attn_gate", "none")
        self.gate_pos = getattr(config, "gate_pos", "sdpa")
        self.gate_act = getattr(config, "gate_act", "sigmoid")
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)
        if self.attn_gate == "headwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_head, bias=False)
            self.gate_param = None
        elif self.attn_gate == "elementwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_embd, bias=False)
            self.gate_param = None
        elif self.attn_gate == "const":
            self.c_gate = None
            self.gate_param = nn.Parameter(torch.zeros(self.n_head, self.head_dim))
        else:
            self.c_gate = None
            self.gate_param = None

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        if self.attn_gate != "none" and self.gate_pos == "value":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            v = v * gate
        cos, sin = self.rotary(q)
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2) # (B, T, n_head, head_dim)
        if self.attn_gate != "none" and self.gate_pos == "sdpa":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            y = y * gate
        y = y.contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768
    attn_gate : str = "none"
    gate_pos : str = "sdpa"
    gate_act : str = "sigmoid"

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying

    def forward(self, idx, targets=None, return_logits=True):

        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8*64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 5100 # number of iterations to run
    learning_rate : float = 0.0036
    warmup_iters : int = 0
    warmdown_iters : int = 1450 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    seed : int = 1337
    attn_gate : str = "none" # none|headwise|elementwise|const
    gate_pos : str = "sdpa" # sdpa|value
    gate_act : str = "sigmoid" # sigmoid|ns_sigmoid
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

def apply_env_overrides():
    # environment-variable overrides allow quick sweeps without editing code
    args.learning_rate = float(os.environ.get("LR", args.learning_rate))
    args.seed = int(os.environ.get("SEED", args.seed))
    args.attn_gate = os.environ.get("ATTNGATE", args.attn_gate)
    args.gate_pos = os.environ.get("GATEPOS", args.gate_pos)
    args.gate_act = os.environ.get("GATEACT", args.gate_act)
    args.num_iterations = int(os.environ.get("NUM_ITER", args.num_iterations))
    args.val_loss_every = int(os.environ.get("VAL_EVERY", args.val_loss_every))

def get_git_commit():
    try:
        return subprocess.check_output(["git", "rev-parse", "HEAD"], text=True).strip()
    except Exception:
        return "unknown"

apply_env_overrides()
torch.manual_seed(args.seed)
torch.cuda.manual_seed_all(args.seed)
np.random.seed(args.seed)

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.
git_commit = get_git_commit() if master_process else "unknown"

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(
    vocab_size=num_vocab,
    n_layer=12,
    n_head=6,
    n_embd=768,
    attn_gate=args.attn_gate,
    gate_pos=args.gate_pos,
    gate_act=args.gate_act,
))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
optimizer1 = torch.optim.AdamW(raw_model.lm_head.parameters(), lr=args.learning_rate, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer2 = Muon(raw_model.transformer.h.parameters(), lr=0.1*args.learning_rate, momentum=0.95)
optimizers = [optimizer1, optimizer2]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        f.write(f"git_commit: {git_commit}\n")
        f.write(f"seed: {args.seed}\n")
        f.write("hyperparameters:\n")
        f.write(json.dumps(dataclasses.asdict(args), indent=2))
        f.write("\n")
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')

training_time_ms = 0
best_val_loss = float("inf")
final_val_loss = None
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        val_loss_item = val_loss.item()
        final_val_loss = val_loss_item
        best_val_loss = min(best_val_loss, val_loss_item)
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms\n')
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            _, loss = model(x, y, return_logits=False)
            train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process:
        approx_time = training_time_ms + 1000 * (time.time() - t0)
        print(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")
        with open(logfile, "a") as f:
            f.write(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms\n")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")
    timed_steps_final = max(args.num_iterations - 9, 1)
    ms_per_step = training_time_ms / timed_steps_final
    os.makedirs("experiments", exist_ok=True)
    results_path = os.path.join("experiments", "results.csv")
    fieldnames = [
        "run_id",
        "date",
        "git_commit",
        "seed",
        "attn_gate",
        "gate_pos",
        "gate_act",
        "learning_rate",
        "batch_size",
        "device_batch_size",
        "sequence_length",
        "num_iterations",
        "warmdown_iters",
        "final_val_loss",
        "best_val_loss",
        "train_time_ms",
        "ms_per_step",
        "gpu_name",
        "n_gpus",
        "runpod_instance",
        "notes",
    ]
    final_loss_value = final_val_loss if final_val_loss is not None else float("nan")
    best_loss_value = best_val_loss if best_val_loss < float("inf") else float("nan")
    row = {
        "run_id": run_id,
        "date": time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime()),
        "git_commit": git_commit,
        "seed": args.seed,
        "attn_gate": args.attn_gate,
        "gate_pos": args.gate_pos,
        "gate_act": args.gate_act,
        "learning_rate": args.learning_rate,
        "batch_size": args.batch_size,
        "device_batch_size": args.device_batch_size,
        "sequence_length": args.sequence_length,
        "num_iterations": args.num_iterations,
        "warmdown_iters": args.warmdown_iters,
        "final_val_loss": final_loss_value,
        "best_val_loss": best_loss_value,
        "train_time_ms": training_time_ms,
        "ms_per_step": ms_per_step,
        "gpu_name": torch.cuda.get_device_name(ddp_local_rank),
        "n_gpus": ddp_world_size,
        "runpod_instance": os.environ.get("RUNPOD_INSTANCE_TYPE", "unknown"),
        "notes": "",
    }
    write_header = not os.path.exists(results_path)
    with open(results_path, "a", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if write_header:
            writer.writeheader()
        writer.writerow(row)
====================================================================================================
git_commit: 21aae13b20675947154a15b640706eb3a47e5fcd
seed: 1338
hyperparameters:
{
  "input_bin": "data/fineweb10B/fineweb_train_*.bin",
  "input_val_bin": "data/fineweb10B/fineweb_val_*.bin",
  "batch_size": 512,
  "device_batch_size": 64,
  "sequence_length": 1024,
  "num_iterations": 1500,
  "learning_rate": 0.0036,
  "warmup_iters": 0,
  "warmdown_iters": 1450,
  "weight_decay": 0,
  "seed": 1338,
  "attn_gate": "headwise",
  "gate_pos": "sdpa",
  "gate_act": "sigmoid",
  "val_loss_every": 125,
  "val_tokens": 10485760,
  "save_every": 0
}
Running pytorch 2.8.0+cu128 compiled for CUDA 12.8
nvidia-smi:
Sun Dec  7 10:09:14 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:00:07.0 Off |                    0 |
| N/A   46C    P0            114W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          On  |   00000000:00:08.0 Off |                    0 |
| N/A   48C    P0            118W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100 80GB PCIe          On  |   00000000:00:09.0 Off |                    0 |
| N/A   44C    P0            121W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100 80GB PCIe          On  |   00000000:00:0A.0 Off |                    0 |
| N/A   45C    P0            133W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100 80GB PCIe          On  |   00000000:00:0B.0 Off |                    0 |
| N/A   47C    P0            114W /  300W |    2182MiB /  81920MiB |     11%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100 80GB PCIe          On  |   00000000:00:0C.0 Off |                    0 |
| N/A   45C    P0            111W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100 80GB PCIe          On  |   00000000:00:0D.0 Off |                    0 |
| N/A   46C    P0            119W /  300W |    2182MiB /  81920MiB |     19%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100 80GB PCIe          On  |   00000000:00:0E.0 Off |                    0 |
| N/A   46C    P0            141W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1500 val_loss:16.0067 train_time:257ms step_avg:nanms
step:1/1500 train_loss:16.0023 train_time:58761ms step_avg:nanms
step:2/1500 train_loss:9.5454 train_time:59596ms step_avg:nanms
step:3/1500 train_loss:8.6436 train_time:60004ms step_avg:nanms
step:4/1500 train_loss:7.8705 train_time:60410ms step_avg:nanms
step:5/1500 train_loss:7.4401 train_time:60820ms step_avg:nanms
step:6/1500 train_loss:7.4007 train_time:61224ms step_avg:nanms
step:7/1500 train_loss:7.0055 train_time:61630ms step_avg:nanms
step:8/1500 train_loss:7.3398 train_time:62037ms step_avg:nanms
step:9/1500 train_loss:7.0441 train_time:62445ms step_avg:nanms
step:10/1500 train_loss:6.8448 train_time:62851ms step_avg:nanms
step:11/1500 train_loss:6.7679 train_time:394ms step_avg:nanms
step:12/1500 train_loss:6.6996 train_time:802ms step_avg:nanms
step:13/1500 train_loss:6.5289 train_time:1208ms step_avg:402.83ms
step:14/1500 train_loss:6.5171 train_time:1615ms step_avg:403.73ms
step:15/1500 train_loss:6.4902 train_time:2023ms step_avg:404.51ms
step:16/1500 train_loss:6.4355 train_time:2429ms step_avg:404.82ms
step:17/1500 train_loss:6.4504 train_time:2835ms step_avg:405.07ms
step:18/1500 train_loss:6.4882 train_time:3242ms step_avg:405.27ms
step:19/1500 train_loss:6.3094 train_time:3648ms step_avg:405.34ms
step:20/1500 train_loss:6.3315 train_time:4261ms step_avg:426.08ms
step:21/1500 train_loss:6.0132 train_time:4666ms step_avg:424.19ms
step:22/1500 train_loss:6.3716 train_time:5074ms step_avg:422.79ms
step:23/1500 train_loss:6.5926 train_time:5481ms step_avg:421.61ms
step:24/1500 train_loss:6.2703 train_time:5888ms step_avg:420.55ms
step:25/1500 train_loss:6.4050 train_time:6294ms step_avg:419.62ms
step:26/1500 train_loss:6.1197 train_time:6701ms step_avg:418.83ms
step:27/1500 train_loss:6.0353 train_time:7106ms step_avg:418.01ms
step:28/1500 train_loss:6.1862 train_time:7512ms step_avg:417.32ms
step:29/1500 train_loss:5.8660 train_time:7920ms step_avg:416.83ms
step:30/1500 train_loss:6.1422 train_time:8326ms step_avg:416.30ms
step:31/1500 train_loss:5.9730 train_time:8733ms step_avg:415.85ms
step:32/1500 train_loss:5.9478 train_time:9139ms step_avg:415.43ms
step:33/1500 train_loss:5.7822 train_time:9545ms step_avg:415.02ms
step:34/1500 train_loss:6.0599 train_time:9952ms step_avg:414.68ms
step:35/1500 train_loss:5.9934 train_time:10360ms step_avg:414.38ms
step:36/1500 train_loss:6.1459 train_time:10768ms step_avg:414.14ms
step:37/1500 train_loss:6.0688 train_time:11174ms step_avg:413.84ms
step:38/1500 train_loss:5.9662 train_time:11581ms step_avg:413.60ms
step:39/1500 train_loss:5.8540 train_time:11987ms step_avg:413.36ms
step:40/1500 train_loss:5.8726 train_time:12395ms step_avg:413.15ms
step:41/1500 train_loss:5.7862 train_time:12802ms step_avg:412.98ms
step:42/1500 train_loss:5.8069 train_time:13211ms step_avg:412.84ms
step:43/1500 train_loss:5.6884 train_time:13619ms step_avg:412.70ms
step:44/1500 train_loss:5.7962 train_time:14025ms step_avg:412.50ms
step:45/1500 train_loss:5.7625 train_time:14432ms step_avg:412.35ms
step:46/1500 train_loss:5.9194 train_time:14841ms step_avg:412.25ms
step:47/1500 train_loss:5.7035 train_time:15248ms step_avg:412.10ms
step:48/1500 train_loss:5.5894 train_time:15654ms step_avg:411.95ms
step:49/1500 train_loss:5.7948 train_time:16062ms step_avg:411.84ms
step:50/1500 train_loss:5.6733 train_time:16468ms step_avg:411.70ms
step:51/1500 train_loss:5.8201 train_time:16876ms step_avg:411.62ms
step:52/1500 train_loss:5.6832 train_time:17284ms step_avg:411.52ms
step:53/1500 train_loss:5.5429 train_time:17689ms step_avg:411.38ms
step:54/1500 train_loss:5.6825 train_time:18096ms step_avg:411.28ms
step:55/1500 train_loss:5.5563 train_time:18503ms step_avg:411.19ms
step:56/1500 train_loss:5.8979 train_time:18911ms step_avg:411.11ms
step:57/1500 train_loss:5.5544 train_time:19316ms step_avg:410.98ms
step:58/1500 train_loss:5.4192 train_time:19722ms step_avg:410.88ms
step:59/1500 train_loss:5.5581 train_time:20130ms step_avg:410.83ms
step:60/1500 train_loss:5.5339 train_time:20538ms step_avg:410.77ms
step:61/1500 train_loss:5.6344 train_time:20945ms step_avg:410.69ms
step:62/1500 train_loss:5.4006 train_time:21352ms step_avg:410.62ms
step:63/1500 train_loss:5.5067 train_time:21760ms step_avg:410.57ms
step:64/1500 train_loss:5.4810 train_time:22169ms step_avg:410.54ms
step:65/1500 train_loss:5.2074 train_time:22576ms step_avg:410.47ms
step:66/1500 train_loss:5.2989 train_time:22983ms step_avg:410.41ms
step:67/1500 train_loss:5.4471 train_time:23391ms step_avg:410.37ms
step:68/1500 train_loss:5.3201 train_time:23798ms step_avg:410.31ms
step:69/1500 train_loss:5.5820 train_time:24207ms step_avg:410.29ms
step:70/1500 train_loss:5.2268 train_time:24615ms step_avg:410.25ms
step:71/1500 train_loss:5.2639 train_time:25021ms step_avg:410.18ms
step:72/1500 train_loss:5.4527 train_time:25428ms step_avg:410.14ms
step:73/1500 train_loss:5.3879 train_time:25836ms step_avg:410.09ms
step:74/1500 train_loss:5.2579 train_time:26244ms step_avg:410.06ms
step:75/1500 train_loss:5.3956 train_time:26651ms step_avg:410.02ms
step:76/1500 train_loss:5.3681 train_time:27059ms step_avg:409.99ms
step:77/1500 train_loss:5.3207 train_time:27466ms step_avg:409.94ms
step:78/1500 train_loss:5.4131 train_time:27873ms step_avg:409.90ms
step:79/1500 train_loss:5.5058 train_time:28279ms step_avg:409.85ms
step:80/1500 train_loss:5.2756 train_time:28687ms step_avg:409.81ms
step:81/1500 train_loss:5.3805 train_time:29093ms step_avg:409.76ms
step:82/1500 train_loss:5.1389 train_time:29501ms step_avg:409.73ms
step:83/1500 train_loss:5.3264 train_time:29908ms step_avg:409.70ms
step:84/1500 train_loss:5.2662 train_time:30314ms step_avg:409.65ms
step:85/1500 train_loss:5.2516 train_time:30722ms step_avg:409.63ms
step:86/1500 train_loss:5.1099 train_time:31130ms step_avg:409.61ms
step:87/1500 train_loss:5.3280 train_time:31537ms step_avg:409.57ms
step:88/1500 train_loss:5.2255 train_time:31943ms step_avg:409.53ms
step:89/1500 train_loss:5.2845 train_time:32351ms step_avg:409.50ms
step:90/1500 train_loss:5.2434 train_time:32759ms step_avg:409.49ms
step:91/1500 train_loss:5.1676 train_time:33166ms step_avg:409.46ms
step:92/1500 train_loss:5.1524 train_time:33574ms step_avg:409.44ms
step:93/1500 train_loss:5.2965 train_time:33982ms step_avg:409.43ms
step:94/1500 train_loss:5.1080 train_time:34390ms step_avg:409.41ms
step:95/1500 train_loss:5.1191 train_time:34799ms step_avg:409.40ms
step:96/1500 train_loss:5.1526 train_time:35207ms step_avg:409.38ms
step:97/1500 train_loss:5.0694 train_time:35613ms step_avg:409.35ms
step:98/1500 train_loss:5.1481 train_time:36021ms step_avg:409.33ms
step:99/1500 train_loss:5.0744 train_time:36430ms step_avg:409.32ms
step:100/1500 train_loss:5.1939 train_time:36838ms step_avg:409.31ms
step:101/1500 train_loss:5.1618 train_time:37245ms step_avg:409.29ms
step:102/1500 train_loss:5.0752 train_time:37652ms step_avg:409.26ms
step:103/1500 train_loss:5.1675 train_time:38060ms step_avg:409.25ms
step:104/1500 train_loss:5.1112 train_time:38467ms step_avg:409.22ms
step:105/1500 train_loss:4.9796 train_time:38875ms step_avg:409.21ms
step:106/1500 train_loss:5.0678 train_time:39284ms step_avg:409.21ms
step:107/1500 train_loss:5.2859 train_time:39692ms step_avg:409.19ms
step:108/1500 train_loss:5.0460 train_time:40098ms step_avg:409.17ms
step:109/1500 train_loss:4.8440 train_time:40506ms step_avg:409.15ms
step:110/1500 train_loss:5.0259 train_time:40914ms step_avg:409.14ms
step:111/1500 train_loss:5.0081 train_time:41321ms step_avg:409.12ms
step:112/1500 train_loss:4.9656 train_time:41729ms step_avg:409.11ms
step:113/1500 train_loss:5.0714 train_time:42137ms step_avg:409.10ms
step:114/1500 train_loss:5.0017 train_time:42544ms step_avg:409.07ms
step:115/1500 train_loss:4.8508 train_time:42951ms step_avg:409.06ms
step:116/1500 train_loss:5.0088 train_time:43359ms step_avg:409.05ms
step:117/1500 train_loss:4.9121 train_time:43766ms step_avg:409.03ms
step:118/1500 train_loss:4.8777 train_time:44174ms step_avg:409.02ms
step:119/1500 train_loss:5.0309 train_time:44583ms step_avg:409.02ms
step:120/1500 train_loss:4.9738 train_time:44990ms step_avg:409.00ms
step:121/1500 train_loss:4.9091 train_time:45398ms step_avg:408.99ms
step:122/1500 train_loss:4.8070 train_time:45806ms step_avg:408.98ms
step:123/1500 train_loss:4.9394 train_time:46213ms step_avg:408.97ms
step:124/1500 train_loss:4.7805 train_time:46622ms step_avg:408.96ms
step:125/1500 train_loss:5.0923 train_time:47032ms step_avg:408.97ms
step:125/1500 val_loss:4.9217 train_time:47045ms step_avg:409.08ms
step:126/1500 train_loss:4.9745 train_time:47435ms step_avg:408.93ms
step:127/1500 train_loss:4.9083 train_time:47844ms step_avg:408.92ms
step:128/1500 train_loss:4.9671 train_time:48252ms step_avg:408.92ms
step:129/1500 train_loss:4.8468 train_time:48660ms step_avg:408.91ms
step:130/1500 train_loss:5.1560 train_time:49069ms step_avg:408.91ms
step:131/1500 train_loss:4.9041 train_time:49478ms step_avg:408.91ms
step:132/1500 train_loss:4.9152 train_time:49885ms step_avg:408.89ms
step:133/1500 train_loss:4.8669 train_time:50292ms step_avg:408.88ms
step:134/1500 train_loss:4.9057 train_time:50700ms step_avg:408.87ms
step:135/1500 train_loss:4.7860 train_time:51109ms step_avg:408.87ms
step:136/1500 train_loss:4.9158 train_time:51515ms step_avg:408.85ms
step:137/1500 train_loss:4.6935 train_time:51923ms step_avg:408.84ms
step:138/1500 train_loss:4.8552 train_time:52330ms step_avg:408.83ms
step:139/1500 train_loss:4.8048 train_time:52739ms step_avg:408.83ms
step:140/1500 train_loss:4.8445 train_time:53147ms step_avg:408.82ms
step:141/1500 train_loss:4.9002 train_time:53555ms step_avg:408.82ms
step:142/1500 train_loss:4.7734 train_time:53963ms step_avg:408.81ms
step:143/1500 train_loss:4.8278 train_time:54370ms step_avg:408.79ms
step:144/1500 train_loss:4.6941 train_time:54779ms step_avg:408.80ms
step:145/1500 train_loss:4.8296 train_time:55188ms step_avg:408.80ms
step:146/1500 train_loss:4.7798 train_time:55597ms step_avg:408.80ms
step:147/1500 train_loss:4.6590 train_time:56004ms step_avg:408.79ms
step:148/1500 train_loss:4.8091 train_time:56410ms step_avg:408.77ms
step:149/1500 train_loss:4.8022 train_time:56819ms step_avg:408.77ms
step:150/1500 train_loss:4.8355 train_time:57226ms step_avg:408.76ms
step:151/1500 train_loss:4.8716 train_time:57636ms step_avg:408.77ms
step:152/1500 train_loss:4.7554 train_time:58043ms step_avg:408.75ms
step:153/1500 train_loss:4.7600 train_time:58452ms step_avg:408.75ms
step:154/1500 train_loss:4.8484 train_time:58860ms step_avg:408.75ms
step:155/1500 train_loss:4.7976 train_time:59268ms step_avg:408.74ms
step:156/1500 train_loss:4.7558 train_time:59676ms step_avg:408.74ms
step:157/1500 train_loss:4.7838 train_time:60084ms step_avg:408.74ms
step:158/1500 train_loss:4.8975 train_time:60493ms step_avg:408.74ms
step:159/1500 train_loss:4.6721 train_time:60902ms step_avg:408.74ms
step:160/1500 train_loss:4.7538 train_time:61310ms step_avg:408.73ms
step:161/1500 train_loss:4.5986 train_time:61718ms step_avg:408.73ms
step:162/1500 train_loss:4.7761 train_time:62126ms step_avg:408.73ms
step:163/1500 train_loss:4.8038 train_time:62534ms step_avg:408.72ms
step:164/1500 train_loss:4.7933 train_time:62942ms step_avg:408.71ms
step:165/1500 train_loss:4.5974 train_time:63350ms step_avg:408.71ms
step:166/1500 train_loss:4.7259 train_time:63757ms step_avg:408.70ms
step:167/1500 train_loss:4.8590 train_time:64164ms step_avg:408.69ms
step:168/1500 train_loss:4.6384 train_time:64572ms step_avg:408.69ms
step:169/1500 train_loss:4.7399 train_time:64981ms step_avg:408.68ms
step:170/1500 train_loss:4.5907 train_time:65390ms step_avg:408.69ms
step:171/1500 train_loss:4.4909 train_time:65798ms step_avg:408.69ms
step:172/1500 train_loss:4.6552 train_time:66205ms step_avg:408.67ms
step:173/1500 train_loss:4.6326 train_time:66613ms step_avg:408.67ms
step:174/1500 train_loss:4.6914 train_time:67020ms step_avg:408.66ms
step:175/1500 train_loss:4.8399 train_time:67429ms step_avg:408.66ms
step:176/1500 train_loss:4.6981 train_time:67836ms step_avg:408.65ms
step:177/1500 train_loss:4.5474 train_time:68244ms step_avg:408.65ms
step:178/1500 train_loss:4.5118 train_time:68650ms step_avg:408.63ms
step:179/1500 train_loss:4.5897 train_time:69056ms step_avg:408.62ms
step:180/1500 train_loss:4.5870 train_time:69464ms step_avg:408.61ms
step:181/1500 train_loss:4.5874 train_time:69871ms step_avg:408.60ms
step:182/1500 train_loss:4.7167 train_time:70280ms step_avg:408.60ms
step:183/1500 train_loss:4.5797 train_time:70689ms step_avg:408.60ms
step:184/1500 train_loss:4.5403 train_time:71096ms step_avg:408.60ms
step:185/1500 train_loss:4.5490 train_time:71504ms step_avg:408.59ms
step:186/1500 train_loss:4.6663 train_time:71911ms step_avg:408.59ms
step:187/1500 train_loss:4.5772 train_time:72320ms step_avg:408.59ms
step:188/1500 train_loss:4.7693 train_time:72728ms step_avg:408.59ms
step:189/1500 train_loss:4.5909 train_time:73983ms step_avg:413.31ms
step:190/1500 train_loss:4.5186 train_time:74571ms step_avg:414.28ms
step:191/1500 train_loss:4.6541 train_time:74980ms step_avg:414.26ms
step:192/1500 train_loss:4.4981 train_time:75389ms step_avg:414.22ms
step:193/1500 train_loss:4.4222 train_time:75796ms step_avg:414.19ms
step:194/1500 train_loss:4.6515 train_time:76204ms step_avg:414.15ms
step:195/1500 train_loss:4.5777 train_time:76610ms step_avg:414.11ms
step:196/1500 train_loss:4.7680 train_time:77018ms step_avg:414.08ms
step:197/1500 train_loss:4.6205 train_time:77427ms step_avg:414.05ms
step:198/1500 train_loss:4.4735 train_time:77834ms step_avg:414.01ms
step:199/1500 train_loss:4.5504 train_time:78241ms step_avg:413.97ms
step:200/1500 train_loss:4.4111 train_time:78648ms step_avg:413.94ms
step:201/1500 train_loss:4.5075 train_time:79056ms step_avg:413.91ms
step:202/1500 train_loss:4.4022 train_time:79465ms step_avg:413.88ms
step:203/1500 train_loss:4.6505 train_time:79876ms step_avg:413.86ms
step:204/1500 train_loss:4.4986 train_time:80283ms step_avg:413.83ms
step:205/1500 train_loss:4.5527 train_time:80691ms step_avg:413.80ms
step:206/1500 train_loss:4.6503 train_time:81099ms step_avg:413.77ms
step:207/1500 train_loss:4.3173 train_time:81508ms step_avg:413.75ms
step:208/1500 train_loss:4.4641 train_time:81914ms step_avg:413.71ms
step:209/1500 train_loss:4.4526 train_time:82322ms step_avg:413.68ms
step:210/1500 train_loss:4.6079 train_time:82731ms step_avg:413.65ms
step:211/1500 train_loss:4.5472 train_time:83140ms step_avg:413.63ms
step:212/1500 train_loss:4.4109 train_time:83548ms step_avg:413.60ms
step:213/1500 train_loss:4.5145 train_time:83954ms step_avg:413.57ms
step:214/1500 train_loss:4.3808 train_time:84361ms step_avg:413.53ms
step:215/1500 train_loss:4.4500 train_time:84769ms step_avg:413.51ms
step:216/1500 train_loss:4.3113 train_time:85176ms step_avg:413.48ms
step:217/1500 train_loss:4.4004 train_time:85583ms step_avg:413.44ms
step:218/1500 train_loss:4.3707 train_time:85991ms step_avg:413.42ms
step:219/1500 train_loss:4.4119 train_time:86399ms step_avg:413.39ms
step:220/1500 train_loss:4.4158 train_time:86807ms step_avg:413.37ms
step:221/1500 train_loss:4.4236 train_time:87216ms step_avg:413.35ms
step:222/1500 train_loss:4.4501 train_time:87623ms step_avg:413.32ms
step:223/1500 train_loss:4.3597 train_time:88031ms step_avg:413.29ms
step:224/1500 train_loss:4.3550 train_time:88439ms step_avg:413.27ms
step:225/1500 train_loss:4.5895 train_time:88848ms step_avg:413.25ms
step:226/1500 train_loss:4.2146 train_time:89256ms step_avg:413.22ms
step:227/1500 train_loss:4.2984 train_time:89663ms step_avg:413.20ms
step:228/1500 train_loss:4.3015 train_time:90072ms step_avg:413.17ms
step:229/1500 train_loss:4.4517 train_time:90480ms step_avg:413.15ms
step:230/1500 train_loss:4.2442 train_time:90888ms step_avg:413.13ms
step:231/1500 train_loss:4.3788 train_time:91296ms step_avg:413.10ms
step:232/1500 train_loss:4.2358 train_time:91703ms step_avg:413.08ms
step:233/1500 train_loss:4.2712 train_time:92111ms step_avg:413.05ms
step:234/1500 train_loss:4.4208 train_time:92519ms step_avg:413.03ms
step:235/1500 train_loss:4.3190 train_time:92927ms step_avg:413.01ms
step:236/1500 train_loss:4.2069 train_time:93335ms step_avg:412.99ms
step:237/1500 train_loss:4.4011 train_time:93742ms step_avg:412.96ms
step:238/1500 train_loss:4.3830 train_time:94149ms step_avg:412.93ms
step:239/1500 train_loss:4.2393 train_time:94555ms step_avg:412.90ms
step:240/1500 train_loss:4.3948 train_time:94963ms step_avg:412.88ms
step:241/1500 train_loss:4.3999 train_time:95370ms step_avg:412.86ms
step:242/1500 train_loss:4.2738 train_time:95778ms step_avg:412.84ms
step:243/1500 train_loss:4.4432 train_time:96186ms step_avg:412.81ms
step:244/1500 train_loss:4.3048 train_time:96593ms step_avg:412.79ms
step:245/1500 train_loss:4.3369 train_time:97001ms step_avg:412.77ms
step:246/1500 train_loss:4.4207 train_time:97408ms step_avg:412.75ms
step:247/1500 train_loss:4.3476 train_time:97817ms step_avg:412.73ms
step:248/1500 train_loss:4.2877 train_time:98224ms step_avg:412.70ms
step:249/1500 train_loss:4.4139 train_time:98631ms step_avg:412.68ms
step:250/1500 train_loss:4.1953 train_time:99039ms step_avg:412.66ms
step:250/1500 val_loss:4.2863 train_time:99053ms step_avg:412.72ms
step:251/1500 train_loss:4.2487 train_time:99444ms step_avg:412.63ms
step:252/1500 train_loss:4.3541 train_time:99853ms step_avg:412.61ms
step:253/1500 train_loss:4.3996 train_time:100263ms step_avg:412.61ms
step:254/1500 train_loss:4.2153 train_time:100670ms step_avg:412.58ms
step:255/1500 train_loss:4.1580 train_time:101079ms step_avg:412.57ms
step:256/1500 train_loss:4.3400 train_time:101486ms step_avg:412.54ms
step:257/1500 train_loss:4.2452 train_time:101895ms step_avg:412.53ms
step:258/1500 train_loss:4.2590 train_time:102302ms step_avg:412.51ms
step:259/1500 train_loss:4.2351 train_time:102711ms step_avg:412.50ms
step:260/1500 train_loss:4.2691 train_time:103118ms step_avg:412.47ms
step:261/1500 train_loss:4.3206 train_time:103526ms step_avg:412.45ms
step:262/1500 train_loss:4.2831 train_time:103933ms step_avg:412.43ms
step:263/1500 train_loss:4.2465 train_time:104339ms step_avg:412.41ms
step:264/1500 train_loss:4.1568 train_time:104746ms step_avg:412.39ms
step:265/1500 train_loss:4.2414 train_time:105154ms step_avg:412.37ms
step:266/1500 train_loss:4.1139 train_time:105561ms step_avg:412.35ms
step:267/1500 train_loss:4.1748 train_time:105969ms step_avg:412.33ms
step:268/1500 train_loss:4.1770 train_time:106377ms step_avg:412.31ms
step:269/1500 train_loss:4.1985 train_time:106783ms step_avg:412.29ms
step:270/1500 train_loss:4.1090 train_time:107191ms step_avg:412.27ms
step:271/1500 train_loss:4.3398 train_time:107599ms step_avg:412.26ms
step:272/1500 train_loss:4.2473 train_time:108006ms step_avg:412.24ms
step:273/1500 train_loss:4.1577 train_time:108414ms step_avg:412.22ms
step:274/1500 train_loss:4.2021 train_time:108821ms step_avg:412.20ms
step:275/1500 train_loss:4.2845 train_time:109228ms step_avg:412.18ms
step:276/1500 train_loss:4.2967 train_time:109637ms step_avg:412.17ms
step:277/1500 train_loss:4.4768 train_time:110044ms step_avg:412.15ms
step:278/1500 train_loss:4.2647 train_time:110452ms step_avg:412.13ms
step:279/1500 train_loss:4.3364 train_time:110860ms step_avg:412.12ms
step:280/1500 train_loss:4.2407 train_time:111270ms step_avg:412.11ms
step:281/1500 train_loss:4.3562 train_time:111678ms step_avg:412.10ms
step:282/1500 train_loss:4.1871 train_time:112085ms step_avg:412.08ms
step:283/1500 train_loss:4.2113 train_time:112493ms step_avg:412.06ms
step:284/1500 train_loss:4.1411 train_time:112900ms step_avg:412.04ms
step:285/1500 train_loss:4.2923 train_time:113309ms step_avg:412.03ms
step:286/1500 train_loss:4.2992 train_time:113716ms step_avg:412.01ms
step:287/1500 train_loss:4.3259 train_time:114124ms step_avg:412.00ms
step:288/1500 train_loss:4.1603 train_time:114532ms step_avg:411.99ms
step:289/1500 train_loss:4.2448 train_time:114940ms step_avg:411.97ms
step:290/1500 train_loss:4.1166 train_time:115347ms step_avg:411.95ms
step:291/1500 train_loss:4.0987 train_time:115755ms step_avg:411.94ms
step:292/1500 train_loss:4.1799 train_time:116163ms step_avg:411.93ms
step:293/1500 train_loss:4.0969 train_time:116571ms step_avg:411.91ms
step:294/1500 train_loss:4.1424 train_time:116979ms step_avg:411.90ms
step:295/1500 train_loss:4.1868 train_time:117386ms step_avg:411.88ms
step:296/1500 train_loss:4.0596 train_time:117794ms step_avg:411.87ms
step:297/1500 train_loss:4.0807 train_time:118201ms step_avg:411.85ms
step:298/1500 train_loss:4.0841 train_time:118609ms step_avg:411.84ms
step:299/1500 train_loss:4.1919 train_time:119017ms step_avg:411.82ms
step:300/1500 train_loss:4.0551 train_time:119425ms step_avg:411.81ms
step:301/1500 train_loss:4.1968 train_time:119833ms step_avg:411.80ms
step:302/1500 train_loss:4.2046 train_time:120242ms step_avg:411.79ms
step:303/1500 train_loss:4.1484 train_time:120648ms step_avg:411.77ms
step:304/1500 train_loss:4.1958 train_time:121055ms step_avg:411.75ms
step:305/1500 train_loss:4.1830 train_time:121463ms step_avg:411.74ms
step:306/1500 train_loss:4.6548 train_time:121871ms step_avg:411.73ms
step:307/1500 train_loss:4.1555 train_time:122279ms step_avg:411.71ms
step:308/1500 train_loss:4.0609 train_time:122687ms step_avg:411.70ms
step:309/1500 train_loss:4.2144 train_time:123094ms step_avg:411.69ms
step:310/1500 train_loss:4.0635 train_time:123501ms step_avg:411.67ms
step:311/1500 train_loss:4.2961 train_time:123908ms step_avg:411.65ms
step:312/1500 train_loss:4.1490 train_time:124315ms step_avg:411.64ms
step:313/1500 train_loss:4.0852 train_time:124725ms step_avg:411.63ms
step:314/1500 train_loss:4.1887 train_time:125132ms step_avg:411.62ms
step:315/1500 train_loss:4.2965 train_time:125538ms step_avg:411.60ms
step:316/1500 train_loss:4.1692 train_time:125943ms step_avg:411.58ms
step:317/1500 train_loss:4.0072 train_time:126351ms step_avg:411.57ms
step:318/1500 train_loss:4.0825 train_time:126758ms step_avg:411.55ms
step:319/1500 train_loss:4.1220 train_time:127167ms step_avg:411.54ms
step:320/1500 train_loss:4.1042 train_time:127577ms step_avg:411.54ms
step:321/1500 train_loss:4.2065 train_time:127984ms step_avg:411.52ms
step:322/1500 train_loss:4.1680 train_time:128392ms step_avg:411.51ms
step:323/1500 train_loss:4.1359 train_time:128800ms step_avg:411.50ms
step:324/1500 train_loss:4.2167 train_time:129210ms step_avg:411.50ms
step:325/1500 train_loss:4.1709 train_time:129617ms step_avg:411.48ms
step:326/1500 train_loss:4.2380 train_time:130023ms step_avg:411.47ms
step:327/1500 train_loss:4.1013 train_time:130432ms step_avg:411.46ms
step:328/1500 train_loss:4.5872 train_time:130841ms step_avg:411.45ms
step:329/1500 train_loss:4.2791 train_time:131250ms step_avg:411.44ms
step:330/1500 train_loss:4.0275 train_time:131658ms step_avg:411.43ms
step:331/1500 train_loss:3.9687 train_time:132064ms step_avg:411.42ms
step:332/1500 train_loss:4.1852 train_time:132473ms step_avg:411.41ms
step:333/1500 train_loss:4.1074 train_time:132879ms step_avg:411.39ms
step:334/1500 train_loss:4.0877 train_time:133288ms step_avg:411.38ms
step:335/1500 train_loss:4.0523 train_time:133696ms step_avg:411.37ms
step:336/1500 train_loss:4.2219 train_time:134104ms step_avg:411.36ms
step:337/1500 train_loss:4.1596 train_time:134512ms step_avg:411.35ms
step:338/1500 train_loss:4.6317 train_time:134920ms step_avg:411.34ms
step:339/1500 train_loss:4.1433 train_time:135328ms step_avg:411.33ms
step:340/1500 train_loss:4.0896 train_time:135738ms step_avg:411.33ms
step:341/1500 train_loss:4.1262 train_time:136146ms step_avg:411.32ms
step:342/1500 train_loss:4.0484 train_time:136553ms step_avg:411.30ms
step:343/1500 train_loss:4.0118 train_time:136961ms step_avg:411.29ms
step:344/1500 train_loss:4.0623 train_time:137368ms step_avg:411.28ms
step:345/1500 train_loss:4.1936 train_time:137777ms step_avg:411.27ms
step:346/1500 train_loss:4.0416 train_time:138185ms step_avg:411.26ms
step:347/1500 train_loss:3.9735 train_time:138593ms step_avg:411.26ms
step:348/1500 train_loss:4.0183 train_time:139001ms step_avg:411.25ms
step:349/1500 train_loss:4.0580 train_time:139410ms step_avg:411.24ms
step:350/1500 train_loss:4.0178 train_time:139819ms step_avg:411.23ms
step:351/1500 train_loss:3.7452 train_time:140227ms step_avg:411.22ms
step:352/1500 train_loss:4.0195 train_time:140633ms step_avg:411.21ms
step:353/1500 train_loss:4.3333 train_time:141041ms step_avg:411.20ms
step:354/1500 train_loss:3.8554 train_time:141450ms step_avg:411.19ms
step:355/1500 train_loss:4.1207 train_time:141859ms step_avg:411.19ms
step:356/1500 train_loss:3.9892 train_time:142269ms step_avg:411.18ms
step:357/1500 train_loss:4.0800 train_time:142676ms step_avg:411.17ms
step:358/1500 train_loss:4.0423 train_time:143084ms step_avg:411.16ms
step:359/1500 train_loss:4.0486 train_time:143493ms step_avg:411.16ms
step:360/1500 train_loss:4.0986 train_time:143902ms step_avg:411.15ms
step:361/1500 train_loss:3.6624 train_time:144309ms step_avg:411.14ms
step:362/1500 train_loss:4.2154 train_time:144715ms step_avg:411.12ms
step:363/1500 train_loss:4.1095 train_time:145123ms step_avg:411.11ms
step:364/1500 train_loss:4.0363 train_time:145532ms step_avg:411.11ms
step:365/1500 train_loss:3.9388 train_time:145939ms step_avg:411.10ms
step:366/1500 train_loss:4.1054 train_time:146346ms step_avg:411.08ms
step:367/1500 train_loss:4.0656 train_time:146756ms step_avg:411.08ms
step:368/1500 train_loss:4.0495 train_time:147165ms step_avg:411.08ms
step:369/1500 train_loss:4.0401 train_time:147572ms step_avg:411.06ms
step:370/1500 train_loss:3.9383 train_time:147979ms step_avg:411.05ms
step:371/1500 train_loss:4.0824 train_time:148387ms step_avg:411.05ms
step:372/1500 train_loss:3.9530 train_time:148795ms step_avg:411.04ms
step:373/1500 train_loss:3.8918 train_time:149202ms step_avg:411.02ms
step:374/1500 train_loss:4.1070 train_time:149610ms step_avg:411.02ms
step:375/1500 train_loss:4.0309 train_time:150020ms step_avg:411.01ms
step:375/1500 val_loss:4.0245 train_time:150032ms step_avg:411.05ms
step:376/1500 train_loss:3.9966 train_time:150423ms step_avg:410.99ms
step:377/1500 train_loss:4.0583 train_time:150830ms step_avg:410.98ms
step:378/1500 train_loss:3.9721 train_time:151900ms step_avg:412.77ms
step:379/1500 train_loss:4.0329 train_time:152307ms step_avg:412.76ms
step:380/1500 train_loss:4.0700 train_time:152889ms step_avg:413.21ms
step:381/1500 train_loss:4.1334 train_time:153297ms step_avg:413.20ms
step:382/1500 train_loss:4.0393 train_time:153706ms step_avg:413.19ms
step:383/1500 train_loss:4.0114 train_time:154112ms step_avg:413.17ms
step:384/1500 train_loss:3.9791 train_time:154518ms step_avg:413.15ms
step:385/1500 train_loss:4.0587 train_time:154926ms step_avg:413.14ms
step:386/1500 train_loss:3.9767 train_time:155333ms step_avg:413.12ms
step:387/1500 train_loss:4.0822 train_time:155739ms step_avg:413.10ms
step:388/1500 train_loss:4.2622 train_time:156146ms step_avg:413.09ms
step:389/1500 train_loss:3.9857 train_time:156553ms step_avg:413.07ms
step:390/1500 train_loss:3.9790 train_time:156961ms step_avg:413.06ms
step:391/1500 train_loss:4.0801 train_time:157369ms step_avg:413.04ms
step:392/1500 train_loss:4.0061 train_time:157776ms step_avg:413.03ms
step:393/1500 train_loss:4.1084 train_time:158184ms step_avg:413.01ms
step:394/1500 train_loss:3.9440 train_time:158592ms step_avg:413.00ms
step:395/1500 train_loss:4.0793 train_time:158999ms step_avg:412.98ms
step:396/1500 train_loss:3.8209 train_time:159407ms step_avg:412.97ms
step:397/1500 train_loss:4.0251 train_time:159815ms step_avg:412.96ms
step:398/1500 train_loss:4.0677 train_time:160223ms step_avg:412.95ms
step:399/1500 train_loss:4.0817 train_time:160630ms step_avg:412.93ms
step:400/1500 train_loss:3.9752 train_time:161038ms step_avg:412.92ms
step:401/1500 train_loss:4.0242 train_time:161447ms step_avg:412.91ms
step:402/1500 train_loss:4.0938 train_time:161855ms step_avg:412.90ms
step:403/1500 train_loss:4.0296 train_time:162262ms step_avg:412.88ms
step:404/1500 train_loss:4.1378 train_time:162671ms step_avg:412.87ms
step:405/1500 train_loss:3.8854 train_time:163079ms step_avg:412.86ms
step:406/1500 train_loss:3.9823 train_time:163486ms step_avg:412.84ms
step:407/1500 train_loss:4.2664 train_time:163893ms step_avg:412.83ms
step:408/1500 train_loss:3.9873 train_time:164302ms step_avg:412.82ms
step:409/1500 train_loss:4.0051 train_time:164709ms step_avg:412.81ms
step:410/1500 train_loss:4.0483 train_time:165116ms step_avg:412.79ms
step:411/1500 train_loss:3.9357 train_time:165524ms step_avg:412.78ms
step:412/1500 train_loss:3.9537 train_time:165930ms step_avg:412.76ms
step:413/1500 train_loss:4.3699 train_time:166338ms step_avg:412.75ms
step:414/1500 train_loss:3.8182 train_time:166744ms step_avg:412.73ms
step:415/1500 train_loss:4.1978 train_time:167153ms step_avg:412.72ms
step:416/1500 train_loss:3.9497 train_time:167561ms step_avg:412.71ms
step:417/1500 train_loss:3.9468 train_time:167970ms step_avg:412.70ms
step:418/1500 train_loss:4.1437 train_time:168378ms step_avg:412.69ms
step:419/1500 train_loss:3.8748 train_time:168786ms step_avg:412.68ms
step:420/1500 train_loss:3.9858 train_time:169192ms step_avg:412.66ms
step:421/1500 train_loss:3.9179 train_time:169601ms step_avg:412.65ms
step:422/1500 train_loss:3.8340 train_time:170010ms step_avg:412.65ms
step:423/1500 train_loss:3.9674 train_time:170418ms step_avg:412.64ms
step:424/1500 train_loss:4.0535 train_time:170826ms step_avg:412.62ms
step:425/1500 train_loss:3.8153 train_time:171235ms step_avg:412.61ms
step:426/1500 train_loss:3.9973 train_time:171640ms step_avg:412.60ms
step:427/1500 train_loss:3.8690 train_time:172048ms step_avg:412.58ms
step:428/1500 train_loss:4.0922 train_time:172457ms step_avg:412.58ms
step:429/1500 train_loss:4.0027 train_time:172863ms step_avg:412.56ms
step:430/1500 train_loss:3.9381 train_time:173271ms step_avg:412.55ms
step:431/1500 train_loss:3.9133 train_time:173678ms step_avg:412.54ms
step:432/1500 train_loss:3.8180 train_time:174085ms step_avg:412.52ms
step:433/1500 train_loss:3.9488 train_time:174492ms step_avg:412.51ms
step:434/1500 train_loss:4.0089 train_time:174900ms step_avg:412.50ms
step:435/1500 train_loss:3.9499 train_time:175308ms step_avg:412.49ms
step:436/1500 train_loss:4.0007 train_time:175714ms step_avg:412.47ms
step:437/1500 train_loss:4.0074 train_time:176122ms step_avg:412.46ms
step:438/1500 train_loss:3.8901 train_time:176530ms step_avg:412.45ms
step:439/1500 train_loss:3.9069 train_time:176938ms step_avg:412.44ms
step:440/1500 train_loss:3.8915 train_time:177345ms step_avg:412.43ms
step:441/1500 train_loss:4.0640 train_time:177753ms step_avg:412.42ms
step:442/1500 train_loss:3.9471 train_time:178160ms step_avg:412.41ms
step:443/1500 train_loss:3.9305 train_time:178567ms step_avg:412.39ms
step:444/1500 train_loss:3.8278 train_time:178975ms step_avg:412.38ms
step:445/1500 train_loss:4.0939 train_time:179382ms step_avg:412.37ms
step:446/1500 train_loss:4.0294 train_time:179790ms step_avg:412.36ms
step:447/1500 train_loss:4.0200 train_time:180199ms step_avg:412.36ms
step:448/1500 train_loss:3.9392 train_time:180607ms step_avg:412.34ms
step:449/1500 train_loss:4.0349 train_time:181012ms step_avg:412.33ms
step:450/1500 train_loss:3.8610 train_time:181420ms step_avg:412.32ms
step:451/1500 train_loss:3.9085 train_time:181826ms step_avg:412.30ms
step:452/1500 train_loss:3.7657 train_time:182234ms step_avg:412.29ms
step:453/1500 train_loss:3.8893 train_time:182642ms step_avg:412.29ms
step:454/1500 train_loss:3.8586 train_time:183048ms step_avg:412.27ms
step:455/1500 train_loss:3.8148 train_time:183457ms step_avg:412.26ms
step:456/1500 train_loss:4.0313 train_time:183865ms step_avg:412.25ms
step:457/1500 train_loss:3.9031 train_time:184274ms step_avg:412.25ms
step:458/1500 train_loss:3.9738 train_time:184681ms step_avg:412.23ms
step:459/1500 train_loss:4.0149 train_time:185089ms step_avg:412.23ms
step:460/1500 train_loss:3.8196 train_time:185496ms step_avg:412.21ms
step:461/1500 train_loss:3.9896 train_time:185903ms step_avg:412.20ms
step:462/1500 train_loss:3.8768 train_time:186309ms step_avg:412.19ms
step:463/1500 train_loss:3.9027 train_time:186718ms step_avg:412.18ms
step:464/1500 train_loss:3.9606 train_time:187127ms step_avg:412.17ms
step:465/1500 train_loss:3.8997 train_time:187533ms step_avg:412.16ms
step:466/1500 train_loss:3.9031 train_time:187939ms step_avg:412.15ms
step:467/1500 train_loss:3.9988 train_time:188346ms step_avg:412.13ms
step:468/1500 train_loss:4.0079 train_time:188754ms step_avg:412.13ms
step:469/1500 train_loss:3.9855 train_time:189162ms step_avg:412.12ms
step:470/1500 train_loss:3.8711 train_time:189570ms step_avg:412.11ms
step:471/1500 train_loss:3.9532 train_time:190059ms step_avg:412.28ms
step:472/1500 train_loss:4.0070 train_time:190466ms step_avg:412.26ms
step:473/1500 train_loss:3.9519 train_time:190873ms step_avg:412.25ms
step:474/1500 train_loss:3.8997 train_time:191281ms step_avg:412.24ms
step:475/1500 train_loss:3.7626 train_time:191689ms step_avg:412.23ms
step:476/1500 train_loss:4.2023 train_time:192097ms step_avg:412.23ms
step:477/1500 train_loss:3.9513 train_time:192504ms step_avg:412.21ms
step:478/1500 train_loss:3.7641 train_time:192910ms step_avg:412.20ms
step:479/1500 train_loss:3.9999 train_time:193317ms step_avg:412.19ms
step:480/1500 train_loss:3.9545 train_time:193726ms step_avg:412.18ms
step:481/1500 train_loss:4.0915 train_time:194134ms step_avg:412.17ms
step:482/1500 train_loss:3.9067 train_time:194542ms step_avg:412.17ms
step:483/1500 train_loss:3.7081 train_time:194949ms step_avg:412.16ms
step:484/1500 train_loss:3.9953 train_time:195356ms step_avg:412.14ms
step:485/1500 train_loss:3.8414 train_time:195765ms step_avg:412.14ms
step:486/1500 train_loss:3.8480 train_time:196172ms step_avg:412.13ms
step:487/1500 train_loss:3.7780 train_time:196580ms step_avg:412.12ms
step:488/1500 train_loss:3.8588 train_time:196987ms step_avg:412.11ms
step:489/1500 train_loss:4.0522 train_time:197396ms step_avg:412.10ms
step:490/1500 train_loss:3.8932 train_time:197803ms step_avg:412.09ms
step:491/1500 train_loss:3.7778 train_time:198213ms step_avg:412.09ms
step:492/1500 train_loss:3.7978 train_time:198623ms step_avg:412.08ms
step:493/1500 train_loss:3.9131 train_time:199031ms step_avg:412.07ms
step:494/1500 train_loss:3.7543 train_time:199439ms step_avg:412.07ms
step:495/1500 train_loss:3.8991 train_time:199848ms step_avg:412.06ms
step:496/1500 train_loss:3.8363 train_time:200255ms step_avg:412.05ms
step:497/1500 train_loss:3.7027 train_time:200664ms step_avg:412.04ms
step:498/1500 train_loss:3.9107 train_time:201070ms step_avg:412.03ms
step:499/1500 train_loss:3.9902 train_time:201478ms step_avg:412.02ms
step:500/1500 train_loss:4.0124 train_time:201885ms step_avg:412.01ms
step:500/1500 val_loss:3.8895 train_time:201898ms step_avg:412.04ms
step:501/1500 train_loss:3.9290 train_time:202290ms step_avg:412.00ms
step:502/1500 train_loss:3.9808 train_time:202698ms step_avg:411.99ms
step:503/1500 train_loss:3.9220 train_time:203105ms step_avg:411.98ms
step:504/1500 train_loss:3.9597 train_time:203513ms step_avg:411.97ms
step:505/1500 train_loss:3.9105 train_time:203923ms step_avg:411.97ms
step:506/1500 train_loss:3.9977 train_time:204331ms step_avg:411.96ms
step:507/1500 train_loss:3.8179 train_time:204739ms step_avg:411.95ms
step:508/1500 train_loss:3.9433 train_time:205148ms step_avg:411.94ms
step:509/1500 train_loss:4.0189 train_time:205554ms step_avg:411.93ms
step:510/1500 train_loss:3.9541 train_time:205961ms step_avg:411.92ms
step:511/1500 train_loss:3.7614 train_time:206370ms step_avg:411.92ms
step:512/1500 train_loss:3.9605 train_time:206778ms step_avg:411.91ms
step:513/1500 train_loss:3.9091 train_time:207186ms step_avg:411.90ms
step:514/1500 train_loss:3.8591 train_time:207594ms step_avg:411.89ms
step:515/1500 train_loss:3.9554 train_time:208001ms step_avg:411.88ms
step:516/1500 train_loss:3.9258 train_time:208409ms step_avg:411.87ms
step:517/1500 train_loss:4.2593 train_time:208816ms step_avg:411.87ms
step:518/1500 train_loss:3.8604 train_time:209224ms step_avg:411.86ms
step:519/1500 train_loss:3.9710 train_time:209631ms step_avg:411.85ms
step:520/1500 train_loss:3.8602 train_time:210038ms step_avg:411.84ms
step:521/1500 train_loss:3.8689 train_time:210446ms step_avg:411.83ms
step:522/1500 train_loss:3.8186 train_time:210853ms step_avg:411.82ms
step:523/1500 train_loss:3.8412 train_time:211261ms step_avg:411.82ms
step:524/1500 train_loss:4.4555 train_time:211669ms step_avg:411.81ms
step:525/1500 train_loss:3.9220 train_time:212077ms step_avg:411.80ms
step:526/1500 train_loss:3.8593 train_time:212484ms step_avg:411.79ms
step:527/1500 train_loss:3.8745 train_time:212892ms step_avg:411.78ms
step:528/1500 train_loss:3.8318 train_time:213301ms step_avg:411.78ms
step:529/1500 train_loss:3.8037 train_time:213708ms step_avg:411.77ms
step:530/1500 train_loss:4.0254 train_time:214117ms step_avg:411.76ms
step:531/1500 train_loss:3.8242 train_time:214526ms step_avg:411.76ms
step:532/1500 train_loss:4.0964 train_time:214935ms step_avg:411.75ms
step:533/1500 train_loss:3.9132 train_time:215342ms step_avg:411.74ms
step:534/1500 train_loss:3.8369 train_time:215750ms step_avg:411.74ms
step:535/1500 train_loss:3.8621 train_time:216156ms step_avg:411.73ms
step:536/1500 train_loss:3.7919 train_time:216563ms step_avg:411.72ms
step:537/1500 train_loss:3.9232 train_time:216971ms step_avg:411.71ms
step:538/1500 train_loss:3.9180 train_time:217380ms step_avg:411.70ms
step:539/1500 train_loss:3.8131 train_time:217790ms step_avg:411.70ms
step:540/1500 train_loss:4.3053 train_time:218197ms step_avg:411.69ms
step:541/1500 train_loss:3.8473 train_time:218606ms step_avg:411.69ms
step:542/1500 train_loss:3.9604 train_time:219015ms step_avg:411.68ms
step:543/1500 train_loss:3.7884 train_time:219421ms step_avg:411.67ms
step:544/1500 train_loss:3.7642 train_time:219828ms step_avg:411.66ms
step:545/1500 train_loss:3.8439 train_time:220237ms step_avg:411.66ms
step:546/1500 train_loss:3.7701 train_time:220643ms step_avg:411.65ms
step:547/1500 train_loss:3.8133 train_time:221052ms step_avg:411.64ms
step:548/1500 train_loss:3.8304 train_time:221461ms step_avg:411.64ms
step:549/1500 train_loss:3.7997 train_time:221868ms step_avg:411.63ms
step:550/1500 train_loss:3.9029 train_time:222276ms step_avg:411.62ms
step:551/1500 train_loss:3.7858 train_time:222684ms step_avg:411.62ms
step:552/1500 train_loss:3.8039 train_time:223093ms step_avg:411.61ms
step:553/1500 train_loss:4.1374 train_time:223502ms step_avg:411.61ms
step:554/1500 train_loss:3.9313 train_time:223909ms step_avg:411.60ms
step:555/1500 train_loss:3.8858 train_time:224317ms step_avg:411.59ms
step:556/1500 train_loss:3.8284 train_time:224725ms step_avg:411.58ms
step:557/1500 train_loss:3.8649 train_time:225133ms step_avg:411.58ms
step:558/1500 train_loss:3.5220 train_time:225541ms step_avg:411.57ms
step:559/1500 train_loss:3.7905 train_time:225950ms step_avg:411.57ms
step:560/1500 train_loss:3.8281 train_time:226358ms step_avg:411.56ms
step:561/1500 train_loss:3.8759 train_time:226765ms step_avg:411.55ms
step:562/1500 train_loss:3.7887 train_time:227172ms step_avg:411.54ms
step:563/1500 train_loss:3.7299 train_time:227580ms step_avg:411.54ms
step:564/1500 train_loss:3.9346 train_time:227990ms step_avg:411.53ms
step:565/1500 train_loss:3.7457 train_time:228398ms step_avg:411.53ms
step:566/1500 train_loss:3.8656 train_time:228806ms step_avg:411.52ms
step:567/1500 train_loss:3.8047 train_time:230043ms step_avg:413.00ms
step:568/1500 train_loss:3.7670 train_time:230453ms step_avg:413.00ms
step:569/1500 train_loss:3.8600 train_time:230860ms step_avg:412.99ms
step:570/1500 train_loss:3.8330 train_time:231444ms step_avg:413.29ms
step:571/1500 train_loss:3.8600 train_time:231854ms step_avg:413.29ms
step:572/1500 train_loss:3.9405 train_time:232262ms step_avg:413.28ms
step:573/1500 train_loss:3.8916 train_time:232668ms step_avg:413.26ms
step:574/1500 train_loss:3.9024 train_time:233076ms step_avg:413.26ms
step:575/1500 train_loss:3.9481 train_time:233483ms step_avg:413.24ms
step:576/1500 train_loss:3.9054 train_time:233892ms step_avg:413.24ms
step:577/1500 train_loss:3.9318 train_time:234300ms step_avg:413.23ms
step:578/1500 train_loss:3.8540 train_time:234709ms step_avg:413.22ms
step:579/1500 train_loss:3.8464 train_time:235116ms step_avg:413.21ms
step:580/1500 train_loss:3.8391 train_time:235524ms step_avg:413.20ms
step:581/1500 train_loss:3.7793 train_time:235933ms step_avg:413.19ms
step:582/1500 train_loss:3.8059 train_time:236341ms step_avg:413.18ms
step:583/1500 train_loss:4.0307 train_time:236749ms step_avg:413.17ms
step:584/1500 train_loss:3.8013 train_time:237156ms step_avg:413.16ms
step:585/1500 train_loss:3.7632 train_time:237564ms step_avg:413.16ms
step:586/1500 train_loss:3.9525 train_time:237972ms step_avg:413.15ms
step:587/1500 train_loss:3.7048 train_time:238380ms step_avg:413.14ms
step:588/1500 train_loss:3.8379 train_time:238788ms step_avg:413.13ms
step:589/1500 train_loss:3.8247 train_time:239197ms step_avg:413.12ms
step:590/1500 train_loss:4.1778 train_time:239604ms step_avg:413.11ms
step:591/1500 train_loss:3.9549 train_time:240012ms step_avg:413.10ms
step:592/1500 train_loss:3.6976 train_time:240421ms step_avg:413.09ms
step:593/1500 train_loss:3.7122 train_time:240828ms step_avg:413.08ms
step:594/1500 train_loss:3.6977 train_time:241236ms step_avg:413.08ms
step:595/1500 train_loss:3.7357 train_time:241643ms step_avg:413.07ms
step:596/1500 train_loss:4.1070 train_time:242050ms step_avg:413.05ms
step:597/1500 train_loss:3.8234 train_time:242456ms step_avg:413.04ms
step:598/1500 train_loss:3.7566 train_time:242863ms step_avg:413.03ms
step:599/1500 train_loss:3.8359 train_time:243270ms step_avg:413.02ms
step:600/1500 train_loss:3.6475 train_time:243678ms step_avg:413.01ms
step:601/1500 train_loss:3.7746 train_time:244086ms step_avg:413.00ms
step:602/1500 train_loss:3.8086 train_time:244495ms step_avg:413.00ms
step:603/1500 train_loss:3.8327 train_time:244902ms step_avg:412.99ms
step:604/1500 train_loss:3.9537 train_time:245310ms step_avg:412.98ms
step:605/1500 train_loss:3.8039 train_time:245717ms step_avg:412.97ms
step:606/1500 train_loss:3.7929 train_time:246124ms step_avg:412.96ms
step:607/1500 train_loss:3.7419 train_time:246533ms step_avg:412.95ms
step:608/1500 train_loss:3.9956 train_time:246941ms step_avg:412.95ms
step:609/1500 train_loss:3.8228 train_time:247347ms step_avg:412.93ms
step:610/1500 train_loss:3.7891 train_time:247755ms step_avg:412.92ms
step:611/1500 train_loss:3.8920 train_time:248161ms step_avg:412.91ms
step:612/1500 train_loss:3.7913 train_time:248568ms step_avg:412.90ms
step:613/1500 train_loss:3.7808 train_time:248975ms step_avg:412.89ms
step:614/1500 train_loss:3.9390 train_time:249383ms step_avg:412.89ms
step:615/1500 train_loss:3.8921 train_time:249790ms step_avg:412.88ms
step:616/1500 train_loss:3.8575 train_time:250198ms step_avg:412.87ms
step:617/1500 train_loss:3.7893 train_time:250606ms step_avg:412.86ms
step:618/1500 train_loss:3.7431 train_time:251012ms step_avg:412.85ms
step:619/1500 train_loss:3.8520 train_time:251421ms step_avg:412.84ms
step:620/1500 train_loss:3.7451 train_time:251828ms step_avg:412.83ms
step:621/1500 train_loss:3.7666 train_time:252236ms step_avg:412.83ms
step:622/1500 train_loss:4.0786 train_time:252643ms step_avg:412.82ms
step:623/1500 train_loss:3.7600 train_time:253051ms step_avg:412.81ms
step:624/1500 train_loss:3.7946 train_time:253459ms step_avg:412.80ms
step:625/1500 train_loss:3.8732 train_time:253867ms step_avg:412.79ms
step:625/1500 val_loss:3.7990 train_time:253880ms step_avg:412.81ms
step:626/1500 train_loss:3.8923 train_time:254272ms step_avg:412.78ms
step:627/1500 train_loss:3.9237 train_time:254681ms step_avg:412.77ms
step:628/1500 train_loss:3.8973 train_time:255088ms step_avg:412.76ms
step:629/1500 train_loss:3.9413 train_time:255496ms step_avg:412.76ms
step:630/1500 train_loss:3.7682 train_time:255903ms step_avg:412.75ms
step:631/1500 train_loss:3.8948 train_time:256312ms step_avg:412.74ms
step:632/1500 train_loss:3.9255 train_time:256719ms step_avg:412.73ms
step:633/1500 train_loss:3.8278 train_time:257128ms step_avg:412.73ms
step:634/1500 train_loss:3.7611 train_time:257535ms step_avg:412.72ms
step:635/1500 train_loss:3.8602 train_time:257943ms step_avg:412.71ms
step:636/1500 train_loss:4.1133 train_time:258349ms step_avg:412.70ms
step:637/1500 train_loss:3.7117 train_time:258757ms step_avg:412.69ms
step:638/1500 train_loss:3.5299 train_time:259164ms step_avg:412.68ms
step:639/1500 train_loss:3.7574 train_time:259573ms step_avg:412.68ms
step:640/1500 train_loss:3.7936 train_time:259981ms step_avg:412.67ms
step:641/1500 train_loss:3.7450 train_time:260388ms step_avg:412.66ms
step:642/1500 train_loss:3.7465 train_time:260796ms step_avg:412.65ms
step:643/1500 train_loss:3.7933 train_time:261205ms step_avg:412.65ms
step:644/1500 train_loss:3.8024 train_time:261612ms step_avg:412.64ms
step:645/1500 train_loss:3.7303 train_time:262019ms step_avg:412.63ms
step:646/1500 train_loss:3.9477 train_time:262426ms step_avg:412.62ms
step:647/1500 train_loss:3.8437 train_time:262834ms step_avg:412.61ms
step:648/1500 train_loss:3.8421 train_time:263241ms step_avg:412.60ms
step:649/1500 train_loss:3.8769 train_time:263650ms step_avg:412.60ms
step:650/1500 train_loss:3.9330 train_time:264060ms step_avg:412.59ms
step:651/1500 train_loss:3.7946 train_time:264468ms step_avg:412.59ms
step:652/1500 train_loss:3.9357 train_time:264875ms step_avg:412.58ms
step:653/1500 train_loss:3.7519 train_time:265282ms step_avg:412.57ms
step:654/1500 train_loss:3.8314 train_time:265689ms step_avg:412.56ms
step:655/1500 train_loss:3.6029 train_time:266097ms step_avg:412.55ms
step:656/1500 train_loss:3.7471 train_time:266503ms step_avg:412.54ms
step:657/1500 train_loss:3.7521 train_time:266911ms step_avg:412.54ms
step:658/1500 train_loss:3.6787 train_time:267319ms step_avg:412.53ms
step:659/1500 train_loss:3.8590 train_time:267726ms step_avg:412.52ms
step:660/1500 train_loss:3.7613 train_time:268136ms step_avg:412.52ms
step:661/1500 train_loss:3.8555 train_time:268544ms step_avg:412.51ms
step:662/1500 train_loss:3.9193 train_time:268951ms step_avg:412.50ms
step:663/1500 train_loss:3.8390 train_time:269359ms step_avg:412.49ms
step:664/1500 train_loss:3.7184 train_time:269766ms step_avg:412.49ms
step:665/1500 train_loss:3.7977 train_time:270172ms step_avg:412.48ms
step:666/1500 train_loss:3.6711 train_time:270581ms step_avg:412.47ms
step:667/1500 train_loss:3.9533 train_time:270989ms step_avg:412.46ms
step:668/1500 train_loss:3.7911 train_time:271396ms step_avg:412.46ms
step:669/1500 train_loss:3.8011 train_time:271804ms step_avg:412.45ms
step:670/1500 train_loss:3.6534 train_time:272211ms step_avg:412.44ms
step:671/1500 train_loss:3.7645 train_time:272617ms step_avg:412.43ms
step:672/1500 train_loss:3.7275 train_time:273025ms step_avg:412.42ms
step:673/1500 train_loss:3.7443 train_time:273433ms step_avg:412.42ms
step:674/1500 train_loss:4.0282 train_time:273841ms step_avg:412.41ms
step:675/1500 train_loss:3.8157 train_time:274249ms step_avg:412.40ms
step:676/1500 train_loss:3.8833 train_time:274658ms step_avg:412.40ms
step:677/1500 train_loss:3.6611 train_time:275065ms step_avg:412.39ms
step:678/1500 train_loss:3.7662 train_time:275472ms step_avg:412.38ms
step:679/1500 train_loss:3.7133 train_time:275880ms step_avg:412.38ms
step:680/1500 train_loss:3.8484 train_time:276289ms step_avg:412.37ms
step:681/1500 train_loss:3.7571 train_time:276697ms step_avg:412.36ms
step:682/1500 train_loss:3.7866 train_time:277104ms step_avg:412.36ms
step:683/1500 train_loss:3.8560 train_time:277511ms step_avg:412.35ms
step:684/1500 train_loss:3.9008 train_time:277918ms step_avg:412.34ms
step:685/1500 train_loss:3.8061 train_time:278325ms step_avg:412.33ms
step:686/1500 train_loss:3.8750 train_time:278733ms step_avg:412.33ms
step:687/1500 train_loss:3.8009 train_time:279141ms step_avg:412.32ms
step:688/1500 train_loss:3.8434 train_time:279548ms step_avg:412.31ms
step:689/1500 train_loss:3.4688 train_time:279956ms step_avg:412.31ms
step:690/1500 train_loss:3.5820 train_time:280364ms step_avg:412.30ms
step:691/1500 train_loss:3.7233 train_time:280771ms step_avg:412.29ms
step:692/1500 train_loss:3.5980 train_time:281178ms step_avg:412.28ms
step:693/1500 train_loss:3.8096 train_time:281584ms step_avg:412.28ms
step:694/1500 train_loss:3.8321 train_time:281992ms step_avg:412.27ms
step:695/1500 train_loss:3.7181 train_time:282399ms step_avg:412.26ms
step:696/1500 train_loss:3.7111 train_time:282809ms step_avg:412.26ms
step:697/1500 train_loss:4.0223 train_time:283217ms step_avg:412.25ms
step:698/1500 train_loss:3.7716 train_time:283624ms step_avg:412.24ms
step:699/1500 train_loss:3.8092 train_time:284031ms step_avg:412.24ms
step:700/1500 train_loss:3.9717 train_time:284439ms step_avg:412.23ms
step:701/1500 train_loss:3.7416 train_time:284847ms step_avg:412.22ms
step:702/1500 train_loss:3.7025 train_time:285257ms step_avg:412.22ms
step:703/1500 train_loss:3.6881 train_time:285665ms step_avg:412.22ms
step:704/1500 train_loss:3.6497 train_time:286072ms step_avg:412.21ms
step:705/1500 train_loss:3.7393 train_time:286478ms step_avg:412.20ms
step:706/1500 train_loss:3.7258 train_time:286886ms step_avg:412.19ms
step:707/1500 train_loss:3.7512 train_time:287295ms step_avg:412.19ms
step:708/1500 train_loss:3.8131 train_time:287703ms step_avg:412.18ms
step:709/1500 train_loss:3.7577 train_time:288109ms step_avg:412.17ms
step:710/1500 train_loss:3.7476 train_time:288518ms step_avg:412.17ms
step:711/1500 train_loss:3.7086 train_time:288925ms step_avg:412.16ms
step:712/1500 train_loss:3.7585 train_time:289333ms step_avg:412.15ms
step:713/1500 train_loss:3.8190 train_time:289740ms step_avg:412.15ms
step:714/1500 train_loss:3.8257 train_time:290150ms step_avg:412.14ms
step:715/1500 train_loss:3.7346 train_time:290559ms step_avg:412.14ms
step:716/1500 train_loss:3.7332 train_time:290967ms step_avg:412.13ms
step:717/1500 train_loss:3.7499 train_time:291374ms step_avg:412.13ms
step:718/1500 train_loss:3.8955 train_time:291781ms step_avg:412.12ms
step:719/1500 train_loss:3.7621 train_time:292190ms step_avg:412.12ms
step:720/1500 train_loss:3.8388 train_time:292599ms step_avg:412.11ms
step:721/1500 train_loss:4.0017 train_time:293006ms step_avg:412.10ms
step:722/1500 train_loss:3.6306 train_time:293415ms step_avg:412.10ms
step:723/1500 train_loss:3.8918 train_time:293822ms step_avg:412.09ms
step:724/1500 train_loss:3.9433 train_time:294230ms step_avg:412.09ms
step:725/1500 train_loss:3.7316 train_time:294637ms step_avg:412.08ms
step:726/1500 train_loss:3.8087 train_time:295046ms step_avg:412.08ms
step:727/1500 train_loss:3.7101 train_time:295453ms step_avg:412.07ms
step:728/1500 train_loss:3.7262 train_time:295863ms step_avg:412.07ms
step:729/1500 train_loss:3.8995 train_time:296271ms step_avg:412.06ms
step:730/1500 train_loss:3.8468 train_time:296680ms step_avg:412.06ms
step:731/1500 train_loss:3.8500 train_time:297089ms step_avg:412.05ms
step:732/1500 train_loss:3.7300 train_time:297497ms step_avg:412.05ms
step:733/1500 train_loss:3.7525 train_time:297906ms step_avg:412.04ms
step:734/1500 train_loss:3.9914 train_time:298313ms step_avg:412.03ms
step:735/1500 train_loss:3.7305 train_time:298722ms step_avg:412.03ms
step:736/1500 train_loss:3.7926 train_time:299131ms step_avg:412.03ms
step:737/1500 train_loss:3.9067 train_time:299539ms step_avg:412.02ms
step:738/1500 train_loss:3.8277 train_time:299948ms step_avg:412.02ms
step:739/1500 train_loss:3.7643 train_time:300356ms step_avg:412.01ms
step:740/1500 train_loss:3.6657 train_time:300765ms step_avg:412.01ms
step:741/1500 train_loss:4.3026 train_time:301174ms step_avg:412.00ms
step:742/1500 train_loss:3.6591 train_time:301583ms step_avg:412.00ms
step:743/1500 train_loss:3.7425 train_time:301989ms step_avg:411.99ms
step:744/1500 train_loss:3.7522 train_time:302396ms step_avg:411.98ms
step:745/1500 train_loss:3.8071 train_time:302803ms step_avg:411.98ms
step:746/1500 train_loss:3.7794 train_time:303211ms step_avg:411.97ms
step:747/1500 train_loss:3.7618 train_time:303619ms step_avg:411.97ms
step:748/1500 train_loss:3.8001 train_time:304027ms step_avg:411.96ms
step:749/1500 train_loss:3.7243 train_time:304434ms step_avg:411.95ms
step:750/1500 train_loss:3.7288 train_time:304841ms step_avg:411.95ms
step:750/1500 val_loss:3.7361 train_time:304855ms step_avg:411.97ms
step:751/1500 train_loss:3.7615 train_time:305245ms step_avg:411.94ms
step:752/1500 train_loss:3.7238 train_time:305653ms step_avg:411.93ms
step:753/1500 train_loss:3.7647 train_time:306060ms step_avg:411.92ms
step:754/1500 train_loss:3.7847 train_time:306467ms step_avg:411.92ms
step:755/1500 train_loss:3.7556 train_time:306876ms step_avg:411.91ms
step:756/1500 train_loss:3.8349 train_time:307935ms step_avg:412.78ms
step:757/1500 train_loss:3.6568 train_time:308344ms step_avg:412.78ms
step:758/1500 train_loss:3.8969 train_time:308756ms step_avg:412.77ms
step:759/1500 train_loss:3.8113 train_time:309162ms step_avg:412.77ms
step:760/1500 train_loss:3.7454 train_time:309741ms step_avg:412.99ms
step:761/1500 train_loss:3.8534 train_time:310150ms step_avg:412.98ms
step:762/1500 train_loss:3.5706 train_time:310557ms step_avg:412.97ms
step:763/1500 train_loss:3.7188 train_time:310965ms step_avg:412.97ms
step:764/1500 train_loss:3.8379 train_time:311373ms step_avg:412.96ms
step:765/1500 train_loss:3.4825 train_time:311779ms step_avg:412.95ms
step:766/1500 train_loss:3.9043 train_time:312189ms step_avg:412.95ms
step:767/1500 train_loss:3.7563 train_time:312596ms step_avg:412.94ms
step:768/1500 train_loss:3.7255 train_time:313003ms step_avg:412.93ms
step:769/1500 train_loss:3.7402 train_time:313410ms step_avg:412.93ms
step:770/1500 train_loss:3.7591 train_time:313819ms step_avg:412.92ms
step:771/1500 train_loss:3.8154 train_time:314228ms step_avg:412.91ms
step:772/1500 train_loss:4.0399 train_time:314634ms step_avg:412.91ms
step:773/1500 train_loss:3.6231 train_time:315042ms step_avg:412.90ms
step:774/1500 train_loss:3.8168 train_time:315450ms step_avg:412.89ms
step:775/1500 train_loss:3.7983 train_time:315857ms step_avg:412.88ms
step:776/1500 train_loss:3.7703 train_time:316264ms step_avg:412.88ms
step:777/1500 train_loss:3.5672 train_time:316671ms step_avg:412.87ms
step:778/1500 train_loss:3.5669 train_time:317080ms step_avg:412.86ms
step:779/1500 train_loss:3.6431 train_time:317488ms step_avg:412.86ms
step:780/1500 train_loss:3.7343 train_time:317895ms step_avg:412.85ms
step:781/1500 train_loss:3.7612 train_time:318302ms step_avg:412.84ms
step:782/1500 train_loss:3.8219 train_time:318711ms step_avg:412.84ms
step:783/1500 train_loss:3.7345 train_time:319119ms step_avg:412.83ms
step:784/1500 train_loss:3.7312 train_time:319528ms step_avg:412.83ms
step:785/1500 train_loss:3.7426 train_time:319935ms step_avg:412.82ms
step:786/1500 train_loss:3.7167 train_time:320343ms step_avg:412.81ms
step:787/1500 train_loss:3.6201 train_time:320750ms step_avg:412.81ms
step:788/1500 train_loss:3.8793 train_time:321158ms step_avg:412.80ms
step:789/1500 train_loss:3.6627 train_time:321567ms step_avg:412.79ms
step:790/1500 train_loss:3.7221 train_time:321973ms step_avg:412.79ms
step:791/1500 train_loss:3.7858 train_time:322381ms step_avg:412.78ms
step:792/1500 train_loss:3.9191 train_time:322788ms step_avg:412.77ms
step:793/1500 train_loss:3.9309 train_time:323196ms step_avg:412.77ms
step:794/1500 train_loss:3.6338 train_time:323605ms step_avg:412.76ms
step:795/1500 train_loss:3.7640 train_time:324012ms step_avg:412.75ms
step:796/1500 train_loss:3.8221 train_time:324421ms step_avg:412.75ms
step:797/1500 train_loss:3.9310 train_time:324831ms step_avg:412.75ms
step:798/1500 train_loss:3.6796 train_time:325239ms step_avg:412.74ms
step:799/1500 train_loss:3.8232 train_time:325647ms step_avg:412.73ms
step:800/1500 train_loss:3.7209 train_time:326055ms step_avg:412.73ms
step:801/1500 train_loss:3.7049 train_time:326462ms step_avg:412.72ms
step:802/1500 train_loss:3.7958 train_time:326869ms step_avg:412.71ms
step:803/1500 train_loss:3.6562 train_time:327277ms step_avg:412.71ms
step:804/1500 train_loss:3.6727 train_time:327686ms step_avg:412.70ms
step:805/1500 train_loss:3.7919 train_time:328094ms step_avg:412.70ms
step:806/1500 train_loss:3.6988 train_time:328499ms step_avg:412.69ms
step:807/1500 train_loss:3.7080 train_time:328906ms step_avg:412.68ms
step:808/1500 train_loss:3.8024 train_time:329312ms step_avg:412.67ms
step:809/1500 train_loss:3.7202 train_time:329721ms step_avg:412.67ms
step:810/1500 train_loss:3.6490 train_time:330128ms step_avg:412.66ms
step:811/1500 train_loss:3.7236 train_time:330536ms step_avg:412.65ms
step:812/1500 train_loss:3.7589 train_time:330942ms step_avg:412.65ms
step:813/1500 train_loss:3.7509 train_time:331350ms step_avg:412.64ms
step:814/1500 train_loss:3.7869 train_time:331758ms step_avg:412.63ms
step:815/1500 train_loss:3.7348 train_time:332166ms step_avg:412.63ms
step:816/1500 train_loss:3.7233 train_time:332575ms step_avg:412.62ms
step:817/1500 train_loss:3.8286 train_time:332984ms step_avg:412.62ms
step:818/1500 train_loss:3.9185 train_time:333391ms step_avg:412.61ms
step:819/1500 train_loss:3.6828 train_time:333797ms step_avg:412.60ms
step:820/1500 train_loss:3.8815 train_time:334205ms step_avg:412.60ms
step:821/1500 train_loss:3.6667 train_time:334611ms step_avg:412.59ms
step:822/1500 train_loss:3.7137 train_time:335020ms step_avg:412.59ms
step:823/1500 train_loss:3.8323 train_time:335427ms step_avg:412.58ms
step:824/1500 train_loss:3.7463 train_time:335834ms step_avg:412.57ms
step:825/1500 train_loss:3.6783 train_time:336242ms step_avg:412.57ms
step:826/1500 train_loss:3.7755 train_time:336651ms step_avg:412.56ms
step:827/1500 train_loss:3.6669 train_time:337056ms step_avg:412.55ms
step:828/1500 train_loss:3.8942 train_time:337464ms step_avg:412.55ms
step:829/1500 train_loss:3.7837 train_time:337872ms step_avg:412.54ms
step:830/1500 train_loss:3.8382 train_time:338279ms step_avg:412.53ms
step:831/1500 train_loss:3.6948 train_time:338687ms step_avg:412.53ms
step:832/1500 train_loss:3.7474 train_time:339095ms step_avg:412.52ms
step:833/1500 train_loss:3.6797 train_time:339501ms step_avg:412.52ms
step:834/1500 train_loss:3.8037 train_time:339909ms step_avg:412.51ms
step:835/1500 train_loss:3.6429 train_time:340318ms step_avg:412.51ms
step:836/1500 train_loss:3.6256 train_time:340725ms step_avg:412.50ms
step:837/1500 train_loss:3.8744 train_time:341132ms step_avg:412.49ms
step:838/1500 train_loss:3.5768 train_time:341540ms step_avg:412.49ms
step:839/1500 train_loss:3.7490 train_time:341948ms step_avg:412.48ms
step:840/1500 train_loss:3.5966 train_time:342355ms step_avg:412.48ms
step:841/1500 train_loss:3.6350 train_time:342762ms step_avg:412.47ms
step:842/1500 train_loss:3.7208 train_time:343170ms step_avg:412.46ms
step:843/1500 train_loss:3.7428 train_time:343577ms step_avg:412.46ms
step:844/1500 train_loss:3.7410 train_time:343984ms step_avg:412.45ms
step:845/1500 train_loss:3.5903 train_time:344392ms step_avg:412.45ms
step:846/1500 train_loss:3.8238 train_time:344800ms step_avg:412.44ms
step:847/1500 train_loss:3.6899 train_time:345209ms step_avg:412.44ms
step:848/1500 train_loss:3.6520 train_time:345616ms step_avg:412.43ms
step:849/1500 train_loss:3.7910 train_time:346025ms step_avg:412.43ms
step:850/1500 train_loss:3.6601 train_time:346434ms step_avg:412.42ms
step:851/1500 train_loss:3.6126 train_time:346842ms step_avg:412.42ms
step:852/1500 train_loss:3.8969 train_time:347250ms step_avg:412.41ms
step:853/1500 train_loss:3.6083 train_time:347658ms step_avg:412.41ms
step:854/1500 train_loss:3.7269 train_time:348067ms step_avg:412.40ms
step:855/1500 train_loss:3.8071 train_time:348474ms step_avg:412.40ms
step:856/1500 train_loss:3.6881 train_time:348882ms step_avg:412.39ms
step:857/1500 train_loss:3.7068 train_time:349290ms step_avg:412.39ms
step:858/1500 train_loss:3.7615 train_time:349699ms step_avg:412.38ms
step:859/1500 train_loss:3.6419 train_time:350108ms step_avg:412.38ms
step:860/1500 train_loss:3.7184 train_time:350514ms step_avg:412.37ms
step:861/1500 train_loss:3.7565 train_time:350921ms step_avg:412.36ms
step:862/1500 train_loss:3.8012 train_time:351329ms step_avg:412.36ms
step:863/1500 train_loss:3.7526 train_time:351736ms step_avg:412.35ms
step:864/1500 train_loss:3.7332 train_time:352144ms step_avg:412.35ms
step:865/1500 train_loss:3.5549 train_time:352550ms step_avg:412.34ms
step:866/1500 train_loss:3.7488 train_time:352958ms step_avg:412.33ms
step:867/1500 train_loss:4.0234 train_time:353365ms step_avg:412.33ms
step:868/1500 train_loss:3.6142 train_time:353773ms step_avg:412.32ms
step:869/1500 train_loss:3.7965 train_time:354183ms step_avg:412.32ms
step:870/1500 train_loss:3.7682 train_time:354591ms step_avg:412.32ms
step:871/1500 train_loss:3.6109 train_time:354999ms step_avg:412.31ms
step:872/1500 train_loss:3.5687 train_time:355405ms step_avg:412.30ms
step:873/1500 train_loss:3.8215 train_time:355814ms step_avg:412.30ms
step:874/1500 train_loss:3.6082 train_time:356221ms step_avg:412.29ms
step:875/1500 train_loss:3.3377 train_time:356630ms step_avg:412.29ms
step:875/1500 val_loss:3.6830 train_time:356641ms step_avg:412.30ms
step:876/1500 train_loss:3.8041 train_time:357032ms step_avg:412.28ms
step:877/1500 train_loss:3.6048 train_time:357438ms step_avg:412.27ms
step:878/1500 train_loss:3.7825 train_time:357847ms step_avg:412.27ms
step:879/1500 train_loss:3.6414 train_time:358252ms step_avg:412.26ms
step:880/1500 train_loss:3.8226 train_time:358660ms step_avg:412.25ms
step:881/1500 train_loss:3.4877 train_time:359068ms step_avg:412.25ms
step:882/1500 train_loss:3.6535 train_time:359476ms step_avg:412.24ms
step:883/1500 train_loss:3.8505 train_time:359883ms step_avg:412.24ms
step:884/1500 train_loss:4.0046 train_time:360291ms step_avg:412.23ms
step:885/1500 train_loss:3.7265 train_time:360698ms step_avg:412.23ms
step:886/1500 train_loss:3.6466 train_time:361105ms step_avg:412.22ms
step:887/1500 train_loss:3.7353 train_time:361512ms step_avg:412.21ms
step:888/1500 train_loss:4.2351 train_time:361919ms step_avg:412.21ms
step:889/1500 train_loss:4.0046 train_time:362326ms step_avg:412.20ms
step:890/1500 train_loss:3.6826 train_time:362734ms step_avg:412.20ms
step:891/1500 train_loss:3.6955 train_time:363141ms step_avg:412.19ms
step:892/1500 train_loss:3.5197 train_time:363549ms step_avg:412.19ms
step:893/1500 train_loss:3.8614 train_time:363956ms step_avg:412.18ms
step:894/1500 train_loss:3.5851 train_time:364364ms step_avg:412.18ms
step:895/1500 train_loss:3.8390 train_time:364771ms step_avg:412.17ms
step:896/1500 train_loss:3.8505 train_time:365177ms step_avg:412.16ms
step:897/1500 train_loss:3.6509 train_time:365586ms step_avg:412.16ms
step:898/1500 train_loss:3.6975 train_time:365994ms step_avg:412.16ms
step:899/1500 train_loss:3.7479 train_time:366401ms step_avg:412.15ms
step:900/1500 train_loss:3.6317 train_time:366809ms step_avg:412.14ms
step:901/1500 train_loss:3.5782 train_time:367217ms step_avg:412.14ms
step:902/1500 train_loss:3.7870 train_time:367624ms step_avg:412.13ms
step:903/1500 train_loss:3.7887 train_time:368032ms step_avg:412.13ms
step:904/1500 train_loss:3.6949 train_time:368440ms step_avg:412.13ms
step:905/1500 train_loss:3.6568 train_time:368848ms step_avg:412.12ms
step:906/1500 train_loss:3.6505 train_time:369255ms step_avg:412.12ms
step:907/1500 train_loss:3.8676 train_time:369661ms step_avg:412.11ms
step:908/1500 train_loss:3.6668 train_time:370068ms step_avg:412.10ms
step:909/1500 train_loss:3.7143 train_time:370475ms step_avg:412.10ms
step:910/1500 train_loss:3.6131 train_time:370883ms step_avg:412.09ms
step:911/1500 train_loss:3.7042 train_time:371292ms step_avg:412.09ms
step:912/1500 train_loss:3.7828 train_time:371701ms step_avg:412.09ms
step:913/1500 train_loss:3.7633 train_time:372108ms step_avg:412.08ms
step:914/1500 train_loss:3.6379 train_time:372514ms step_avg:412.07ms
step:915/1500 train_loss:3.8971 train_time:372923ms step_avg:412.07ms
step:916/1500 train_loss:3.6835 train_time:373332ms step_avg:412.07ms
step:917/1500 train_loss:3.7840 train_time:373740ms step_avg:412.06ms
step:918/1500 train_loss:3.7495 train_time:374147ms step_avg:412.06ms
step:919/1500 train_loss:4.9880 train_time:374556ms step_avg:412.05ms
step:920/1500 train_loss:3.6641 train_time:374963ms step_avg:412.05ms
step:921/1500 train_loss:3.7337 train_time:375371ms step_avg:412.04ms
step:922/1500 train_loss:3.6942 train_time:375778ms step_avg:412.04ms
step:923/1500 train_loss:3.7426 train_time:376186ms step_avg:412.03ms
step:924/1500 train_loss:3.7493 train_time:376593ms step_avg:412.03ms
step:925/1500 train_loss:3.8407 train_time:377000ms step_avg:412.02ms
step:926/1500 train_loss:3.8133 train_time:377408ms step_avg:412.02ms
step:927/1500 train_loss:3.7119 train_time:377818ms step_avg:412.01ms
step:928/1500 train_loss:3.7049 train_time:378224ms step_avg:412.01ms
step:929/1500 train_loss:3.9334 train_time:378632ms step_avg:412.00ms
step:930/1500 train_loss:3.7708 train_time:379039ms step_avg:412.00ms
step:931/1500 train_loss:3.5606 train_time:379448ms step_avg:412.00ms
step:932/1500 train_loss:3.6465 train_time:379856ms step_avg:411.99ms
step:933/1500 train_loss:3.8247 train_time:380265ms step_avg:411.99ms
step:934/1500 train_loss:3.5468 train_time:380673ms step_avg:411.98ms
step:935/1500 train_loss:3.7267 train_time:381081ms step_avg:411.98ms
step:936/1500 train_loss:3.6069 train_time:381490ms step_avg:411.98ms
step:937/1500 train_loss:3.6691 train_time:381897ms step_avg:411.97ms
step:938/1500 train_loss:3.7690 train_time:382307ms step_avg:411.97ms
step:939/1500 train_loss:3.6922 train_time:382715ms step_avg:411.96ms
step:940/1500 train_loss:3.8469 train_time:383121ms step_avg:411.96ms
step:941/1500 train_loss:3.6427 train_time:383530ms step_avg:411.96ms
step:942/1500 train_loss:3.7068 train_time:383940ms step_avg:411.95ms
step:943/1500 train_loss:3.5028 train_time:384348ms step_avg:411.95ms
step:944/1500 train_loss:3.8532 train_time:384756ms step_avg:411.94ms
step:945/1500 train_loss:3.5679 train_time:385880ms step_avg:412.71ms
step:946/1500 train_loss:3.5735 train_time:386288ms step_avg:412.70ms
step:947/1500 train_loss:5.2007 train_time:386696ms step_avg:412.70ms
step:948/1500 train_loss:3.7506 train_time:387104ms step_avg:412.69ms
step:949/1500 train_loss:3.6514 train_time:387511ms step_avg:412.69ms
step:950/1500 train_loss:3.5468 train_time:388100ms step_avg:412.87ms
step:951/1500 train_loss:3.6059 train_time:388508ms step_avg:412.87ms
step:952/1500 train_loss:3.5593 train_time:388916ms step_avg:412.86ms
step:953/1500 train_loss:3.6355 train_time:389324ms step_avg:412.86ms
step:954/1500 train_loss:3.7072 train_time:389731ms step_avg:412.85ms
step:955/1500 train_loss:3.5949 train_time:390139ms step_avg:412.85ms
step:956/1500 train_loss:3.6270 train_time:390545ms step_avg:412.84ms
step:957/1500 train_loss:3.6008 train_time:390953ms step_avg:412.83ms
step:958/1500 train_loss:3.6532 train_time:391369ms step_avg:412.84ms
step:959/1500 train_loss:3.6507 train_time:391776ms step_avg:412.83ms
step:960/1500 train_loss:3.6671 train_time:392183ms step_avg:412.82ms
step:961/1500 train_loss:3.5467 train_time:392592ms step_avg:412.82ms
step:962/1500 train_loss:3.8045 train_time:392999ms step_avg:412.81ms
step:963/1500 train_loss:3.7588 train_time:393407ms step_avg:412.81ms
step:964/1500 train_loss:3.6089 train_time:393815ms step_avg:412.80ms
step:965/1500 train_loss:3.6018 train_time:394223ms step_avg:412.80ms
step:966/1500 train_loss:3.6367 train_time:394631ms step_avg:412.79ms
step:967/1500 train_loss:3.8642 train_time:395039ms step_avg:412.79ms
step:968/1500 train_loss:3.6861 train_time:395448ms step_avg:412.78ms
step:969/1500 train_loss:3.6829 train_time:395855ms step_avg:412.78ms
step:970/1500 train_loss:3.7301 train_time:396263ms step_avg:412.77ms
step:971/1500 train_loss:3.5398 train_time:396672ms step_avg:412.77ms
step:972/1500 train_loss:3.6981 train_time:397080ms step_avg:412.76ms
step:973/1500 train_loss:3.6404 train_time:397488ms step_avg:412.76ms
step:974/1500 train_loss:3.6990 train_time:397895ms step_avg:412.75ms
step:975/1500 train_loss:3.7675 train_time:398303ms step_avg:412.75ms
step:976/1500 train_loss:3.6378 train_time:398711ms step_avg:412.74ms
step:977/1500 train_loss:3.8369 train_time:399120ms step_avg:412.74ms
step:978/1500 train_loss:3.7222 train_time:399528ms step_avg:412.74ms
step:979/1500 train_loss:3.5436 train_time:399935ms step_avg:412.73ms
step:980/1500 train_loss:3.8357 train_time:400343ms step_avg:412.72ms
step:981/1500 train_loss:3.5688 train_time:400752ms step_avg:412.72ms
step:982/1500 train_loss:3.7418 train_time:401161ms step_avg:412.72ms
step:983/1500 train_loss:3.7133 train_time:401568ms step_avg:412.71ms
step:984/1500 train_loss:3.7129 train_time:401976ms step_avg:412.71ms
step:985/1500 train_loss:3.6754 train_time:402384ms step_avg:412.70ms
step:986/1500 train_loss:3.7484 train_time:402792ms step_avg:412.70ms
step:987/1500 train_loss:3.5624 train_time:403202ms step_avg:412.69ms
step:988/1500 train_loss:3.6481 train_time:403611ms step_avg:412.69ms
step:989/1500 train_loss:3.6271 train_time:404020ms step_avg:412.69ms
step:990/1500 train_loss:3.5913 train_time:404428ms step_avg:412.68ms
step:991/1500 train_loss:3.8068 train_time:404837ms step_avg:412.68ms
step:992/1500 train_loss:3.6259 train_time:405245ms step_avg:412.67ms
step:993/1500 train_loss:3.6007 train_time:405653ms step_avg:412.67ms
step:994/1500 train_loss:3.6630 train_time:406061ms step_avg:412.66ms
step:995/1500 train_loss:3.7536 train_time:406469ms step_avg:412.66ms
step:996/1500 train_loss:3.6969 train_time:406877ms step_avg:412.65ms
step:997/1500 train_loss:3.6074 train_time:407287ms step_avg:412.65ms
step:998/1500 train_loss:3.9547 train_time:407694ms step_avg:412.65ms
step:999/1500 train_loss:3.6183 train_time:408100ms step_avg:412.64ms
step:1000/1500 train_loss:3.7414 train_time:408509ms step_avg:412.64ms
step:1000/1500 val_loss:3.6381 train_time:408522ms step_avg:412.65ms
step:1001/1500 train_loss:3.6118 train_time:408913ms step_avg:412.63ms
step:1002/1500 train_loss:3.6631 train_time:409322ms step_avg:412.62ms
step:1003/1500 train_loss:3.5460 train_time:409732ms step_avg:412.62ms
step:1004/1500 train_loss:3.7316 train_time:410141ms step_avg:412.62ms
step:1005/1500 train_loss:3.7780 train_time:410549ms step_avg:412.61ms
step:1006/1500 train_loss:3.5532 train_time:410956ms step_avg:412.61ms
step:1007/1500 train_loss:3.6398 train_time:411362ms step_avg:412.60ms
step:1008/1500 train_loss:3.6070 train_time:411771ms step_avg:412.60ms
step:1009/1500 train_loss:3.7268 train_time:412178ms step_avg:412.59ms
step:1010/1500 train_loss:3.8290 train_time:412586ms step_avg:412.59ms
step:1011/1500 train_loss:3.7197 train_time:412994ms step_avg:412.58ms
step:1012/1500 train_loss:3.6858 train_time:413401ms step_avg:412.58ms
step:1013/1500 train_loss:3.5486 train_time:413809ms step_avg:412.57ms
step:1014/1500 train_loss:3.6887 train_time:414216ms step_avg:412.57ms
step:1015/1500 train_loss:3.8000 train_time:414623ms step_avg:412.56ms
step:1016/1500 train_loss:3.5051 train_time:415031ms step_avg:412.56ms
step:1017/1500 train_loss:3.6009 train_time:415439ms step_avg:412.55ms
step:1018/1500 train_loss:3.5988 train_time:415847ms step_avg:412.55ms
step:1019/1500 train_loss:3.5474 train_time:416256ms step_avg:412.54ms
step:1020/1500 train_loss:3.6887 train_time:416663ms step_avg:412.54ms
step:1021/1500 train_loss:3.5930 train_time:417071ms step_avg:412.53ms
step:1022/1500 train_loss:3.5346 train_time:417479ms step_avg:412.53ms
step:1023/1500 train_loss:3.6408 train_time:417886ms step_avg:412.52ms
step:1024/1500 train_loss:3.6696 train_time:418294ms step_avg:412.52ms
step:1025/1500 train_loss:3.6510 train_time:418721ms step_avg:412.53ms
step:1026/1500 train_loss:3.6592 train_time:419115ms step_avg:412.52ms
step:1027/1500 train_loss:3.8172 train_time:419525ms step_avg:412.51ms
step:1028/1500 train_loss:3.4990 train_time:419931ms step_avg:412.51ms
step:1029/1500 train_loss:3.5621 train_time:420340ms step_avg:412.50ms
step:1030/1500 train_loss:3.5152 train_time:420747ms step_avg:412.50ms
step:1031/1500 train_loss:3.6819 train_time:421156ms step_avg:412.49ms
step:1032/1500 train_loss:3.6690 train_time:421565ms step_avg:412.49ms
step:1033/1500 train_loss:3.8457 train_time:421973ms step_avg:412.49ms
step:1034/1500 train_loss:3.6666 train_time:422380ms step_avg:412.48ms
step:1035/1500 train_loss:3.5786 train_time:422787ms step_avg:412.48ms
step:1036/1500 train_loss:3.6033 train_time:423194ms step_avg:412.47ms
step:1037/1500 train_loss:3.6603 train_time:423603ms step_avg:412.47ms
step:1038/1500 train_loss:3.9689 train_time:424013ms step_avg:412.46ms
step:1039/1500 train_loss:3.7902 train_time:424421ms step_avg:412.46ms
step:1040/1500 train_loss:3.6848 train_time:424830ms step_avg:412.46ms
step:1041/1500 train_loss:3.5764 train_time:425237ms step_avg:412.45ms
step:1042/1500 train_loss:3.6520 train_time:425645ms step_avg:412.45ms
step:1043/1500 train_loss:3.6846 train_time:426053ms step_avg:412.44ms
step:1044/1500 train_loss:3.6208 train_time:426462ms step_avg:412.44ms
step:1045/1500 train_loss:3.6332 train_time:426869ms step_avg:412.43ms
step:1046/1500 train_loss:3.7054 train_time:427277ms step_avg:412.43ms
step:1047/1500 train_loss:3.6095 train_time:427684ms step_avg:412.42ms
step:1048/1500 train_loss:3.8117 train_time:428091ms step_avg:412.42ms
step:1049/1500 train_loss:3.6653 train_time:428499ms step_avg:412.41ms
step:1050/1500 train_loss:3.5933 train_time:428906ms step_avg:412.41ms
step:1051/1500 train_loss:3.5599 train_time:429314ms step_avg:412.41ms
step:1052/1500 train_loss:3.6822 train_time:429722ms step_avg:412.40ms
step:1053/1500 train_loss:3.5550 train_time:430130ms step_avg:412.40ms
step:1054/1500 train_loss:3.8778 train_time:430538ms step_avg:412.39ms
step:1055/1500 train_loss:3.7137 train_time:430946ms step_avg:412.39ms
step:1056/1500 train_loss:3.5708 train_time:431353ms step_avg:412.38ms
step:1057/1500 train_loss:3.6724 train_time:431761ms step_avg:412.38ms
step:1058/1500 train_loss:3.7531 train_time:432169ms step_avg:412.38ms
step:1059/1500 train_loss:3.4716 train_time:432576ms step_avg:412.37ms
step:1060/1500 train_loss:3.5963 train_time:432983ms step_avg:412.36ms
step:1061/1500 train_loss:3.6195 train_time:433392ms step_avg:412.36ms
step:1062/1500 train_loss:3.5863 train_time:433800ms step_avg:412.36ms
step:1063/1500 train_loss:3.5604 train_time:434226ms step_avg:412.37ms
step:1064/1500 train_loss:3.6580 train_time:434644ms step_avg:412.38ms
step:1065/1500 train_loss:3.5631 train_time:435057ms step_avg:412.38ms
step:1066/1500 train_loss:3.5498 train_time:435473ms step_avg:412.38ms
step:1067/1500 train_loss:3.5729 train_time:435887ms step_avg:412.38ms
step:1068/1500 train_loss:3.4839 train_time:436304ms step_avg:412.39ms
step:1069/1500 train_loss:3.6008 train_time:436717ms step_avg:412.39ms
step:1070/1500 train_loss:3.4721 train_time:437132ms step_avg:412.39ms
step:1071/1500 train_loss:3.7283 train_time:437547ms step_avg:412.39ms
step:1072/1500 train_loss:3.6770 train_time:437962ms step_avg:412.39ms
step:1073/1500 train_loss:3.6249 train_time:438375ms step_avg:412.39ms
step:1074/1500 train_loss:3.6885 train_time:438789ms step_avg:412.40ms
step:1075/1500 train_loss:3.6366 train_time:439202ms step_avg:412.40ms
step:1076/1500 train_loss:3.5751 train_time:439617ms step_avg:412.40ms
step:1077/1500 train_loss:3.9687 train_time:440032ms step_avg:412.40ms
step:1078/1500 train_loss:3.6398 train_time:440446ms step_avg:412.40ms
step:1079/1500 train_loss:3.3579 train_time:440860ms step_avg:412.40ms
step:1080/1500 train_loss:3.7112 train_time:441274ms step_avg:412.41ms
step:1081/1500 train_loss:3.6238 train_time:441686ms step_avg:412.41ms
step:1082/1500 train_loss:3.6814 train_time:442101ms step_avg:412.41ms
step:1083/1500 train_loss:3.7884 train_time:442514ms step_avg:412.41ms
step:1084/1500 train_loss:3.6837 train_time:442929ms step_avg:412.41ms
step:1085/1500 train_loss:3.6526 train_time:443350ms step_avg:412.42ms
step:1086/1500 train_loss:3.6186 train_time:443763ms step_avg:412.42ms
step:1087/1500 train_loss:3.8136 train_time:444176ms step_avg:412.42ms
step:1088/1500 train_loss:3.7019 train_time:444590ms step_avg:412.42ms
step:1089/1500 train_loss:3.5389 train_time:445005ms step_avg:412.42ms
step:1090/1500 train_loss:3.5627 train_time:445418ms step_avg:412.42ms
step:1091/1500 train_loss:3.6805 train_time:445814ms step_avg:412.41ms
step:1092/1500 train_loss:3.4724 train_time:446222ms step_avg:412.40ms
step:1093/1500 train_loss:3.6677 train_time:446630ms step_avg:412.40ms
step:1094/1500 train_loss:3.8043 train_time:447038ms step_avg:412.40ms
step:1095/1500 train_loss:3.6439 train_time:447445ms step_avg:412.39ms
step:1096/1500 train_loss:3.5919 train_time:447853ms step_avg:412.39ms
step:1097/1500 train_loss:3.6199 train_time:448261ms step_avg:412.38ms
step:1098/1500 train_loss:3.6652 train_time:448670ms step_avg:412.38ms
step:1099/1500 train_loss:3.7413 train_time:449079ms step_avg:412.38ms
step:1100/1500 train_loss:3.6983 train_time:449486ms step_avg:412.37ms
step:1101/1500 train_loss:3.6213 train_time:449893ms step_avg:412.37ms
step:1102/1500 train_loss:3.4830 train_time:450299ms step_avg:412.36ms
step:1103/1500 train_loss:3.5621 train_time:450708ms step_avg:412.36ms
step:1104/1500 train_loss:3.6293 train_time:451116ms step_avg:412.35ms
step:1105/1500 train_loss:3.5114 train_time:451524ms step_avg:412.35ms
step:1106/1500 train_loss:4.2681 train_time:451932ms step_avg:412.35ms
step:1107/1500 train_loss:3.4130 train_time:452337ms step_avg:412.34ms
step:1108/1500 train_loss:3.7503 train_time:452746ms step_avg:412.34ms
step:1109/1500 train_loss:3.5349 train_time:453153ms step_avg:412.33ms
step:1110/1500 train_loss:3.6832 train_time:453562ms step_avg:412.33ms
step:1111/1500 train_loss:3.6140 train_time:453971ms step_avg:412.33ms
step:1112/1500 train_loss:3.6559 train_time:454378ms step_avg:412.32ms
step:1113/1500 train_loss:3.7558 train_time:454785ms step_avg:412.32ms
step:1114/1500 train_loss:3.6100 train_time:455191ms step_avg:412.31ms
step:1115/1500 train_loss:3.5564 train_time:455597ms step_avg:412.30ms
step:1116/1500 train_loss:3.4541 train_time:456003ms step_avg:412.30ms
step:1117/1500 train_loss:3.6261 train_time:456412ms step_avg:412.30ms
step:1118/1500 train_loss:3.7745 train_time:456821ms step_avg:412.29ms
step:1119/1500 train_loss:3.8120 train_time:457228ms step_avg:412.29ms
step:1120/1500 train_loss:3.6506 train_time:457635ms step_avg:412.28ms
step:1121/1500 train_loss:3.6812 train_time:458043ms step_avg:412.28ms
step:1122/1500 train_loss:3.5768 train_time:458450ms step_avg:412.28ms
step:1123/1500 train_loss:3.6419 train_time:458859ms step_avg:412.27ms
step:1124/1500 train_loss:3.7706 train_time:459265ms step_avg:412.27ms
step:1125/1500 train_loss:3.5364 train_time:459674ms step_avg:412.26ms
step:1125/1500 val_loss:3.6020 train_time:459686ms step_avg:412.27ms
step:1126/1500 train_loss:3.4315 train_time:460076ms step_avg:412.25ms
step:1127/1500 train_loss:3.6650 train_time:460485ms step_avg:412.25ms
step:1128/1500 train_loss:3.8764 train_time:460892ms step_avg:412.25ms
step:1129/1500 train_loss:3.4261 train_time:461299ms step_avg:412.24ms
step:1130/1500 train_loss:3.7395 train_time:461706ms step_avg:412.24ms
step:1131/1500 train_loss:3.5761 train_time:462116ms step_avg:412.24ms
step:1132/1500 train_loss:3.5955 train_time:462525ms step_avg:412.23ms
step:1133/1500 train_loss:3.5503 train_time:462931ms step_avg:412.23ms
step:1134/1500 train_loss:3.7131 train_time:464213ms step_avg:413.00ms
step:1135/1500 train_loss:3.6524 train_time:464623ms step_avg:413.00ms
step:1136/1500 train_loss:3.7040 train_time:465032ms step_avg:412.99ms
step:1137/1500 train_loss:3.7328 train_time:465440ms step_avg:412.99ms
step:1138/1500 train_loss:3.6491 train_time:465848ms step_avg:412.99ms
step:1139/1500 train_loss:3.5490 train_time:466256ms step_avg:412.98ms
step:1140/1500 train_loss:3.8595 train_time:466839ms step_avg:413.13ms
step:1141/1500 train_loss:3.6496 train_time:467249ms step_avg:413.13ms
step:1142/1500 train_loss:3.7571 train_time:467658ms step_avg:413.13ms
step:1143/1500 train_loss:3.6450 train_time:468067ms step_avg:413.12ms
step:1144/1500 train_loss:3.5528 train_time:468476ms step_avg:413.12ms
step:1145/1500 train_loss:3.6599 train_time:468884ms step_avg:413.11ms
step:1146/1500 train_loss:3.7791 train_time:469292ms step_avg:413.11ms
step:1147/1500 train_loss:3.7490 train_time:469701ms step_avg:413.11ms
step:1148/1500 train_loss:3.6690 train_time:470109ms step_avg:413.10ms
step:1149/1500 train_loss:3.6900 train_time:470518ms step_avg:413.10ms
step:1150/1500 train_loss:3.5358 train_time:470925ms step_avg:413.09ms
step:1151/1500 train_loss:3.5609 train_time:471332ms step_avg:413.09ms
step:1152/1500 train_loss:3.5223 train_time:471740ms step_avg:413.08ms
step:1153/1500 train_loss:3.6670 train_time:472149ms step_avg:413.08ms
step:1154/1500 train_loss:3.6407 train_time:472555ms step_avg:413.07ms
step:1155/1500 train_loss:3.7075 train_time:472965ms step_avg:413.07ms
step:1156/1500 train_loss:3.5497 train_time:473372ms step_avg:413.06ms
step:1157/1500 train_loss:3.7256 train_time:473779ms step_avg:413.06ms
step:1158/1500 train_loss:3.6766 train_time:474188ms step_avg:413.06ms
step:1159/1500 train_loss:3.4908 train_time:474595ms step_avg:413.05ms
step:1160/1500 train_loss:3.5281 train_time:475002ms step_avg:413.05ms
step:1161/1500 train_loss:3.5199 train_time:475410ms step_avg:413.04ms
step:1162/1500 train_loss:3.3184 train_time:475818ms step_avg:413.04ms
step:1163/1500 train_loss:3.6308 train_time:476226ms step_avg:413.03ms
step:1164/1500 train_loss:3.6047 train_time:476635ms step_avg:413.03ms
step:1165/1500 train_loss:3.4683 train_time:477044ms step_avg:413.02ms
step:1166/1500 train_loss:3.4628 train_time:477450ms step_avg:413.02ms
step:1167/1500 train_loss:3.5718 train_time:477858ms step_avg:413.01ms
step:1168/1500 train_loss:3.5822 train_time:478266ms step_avg:413.01ms
step:1169/1500 train_loss:3.9039 train_time:478673ms step_avg:413.01ms
step:1170/1500 train_loss:3.5818 train_time:479082ms step_avg:413.00ms
step:1171/1500 train_loss:3.5950 train_time:479491ms step_avg:413.00ms
step:1172/1500 train_loss:3.4902 train_time:479899ms step_avg:412.99ms
step:1173/1500 train_loss:3.6030 train_time:480306ms step_avg:412.99ms
step:1174/1500 train_loss:3.7317 train_time:480712ms step_avg:412.98ms
step:1175/1500 train_loss:3.5748 train_time:481120ms step_avg:412.98ms
step:1176/1500 train_loss:3.5913 train_time:481528ms step_avg:412.97ms
step:1177/1500 train_loss:3.6461 train_time:481937ms step_avg:412.97ms
step:1178/1500 train_loss:3.6298 train_time:482344ms step_avg:412.97ms
step:1179/1500 train_loss:3.6897 train_time:482752ms step_avg:412.96ms
step:1180/1500 train_loss:3.5918 train_time:483159ms step_avg:412.96ms
step:1181/1500 train_loss:3.6010 train_time:483566ms step_avg:412.95ms
step:1182/1500 train_loss:3.5393 train_time:483975ms step_avg:412.95ms
step:1183/1500 train_loss:3.5817 train_time:484383ms step_avg:412.94ms
step:1184/1500 train_loss:3.5310 train_time:484790ms step_avg:412.94ms
step:1185/1500 train_loss:3.6956 train_time:485197ms step_avg:412.93ms
step:1186/1500 train_loss:3.7522 train_time:485605ms step_avg:412.93ms
step:1187/1500 train_loss:3.5525 train_time:486013ms step_avg:412.93ms
step:1188/1500 train_loss:3.6104 train_time:486421ms step_avg:412.92ms
step:1189/1500 train_loss:3.6251 train_time:486830ms step_avg:412.92ms
step:1190/1500 train_loss:3.4718 train_time:487238ms step_avg:412.91ms
step:1191/1500 train_loss:3.6481 train_time:487645ms step_avg:412.91ms
step:1192/1500 train_loss:3.7838 train_time:488052ms step_avg:412.90ms
step:1193/1500 train_loss:3.5908 train_time:488459ms step_avg:412.90ms
step:1194/1500 train_loss:3.4794 train_time:488868ms step_avg:412.90ms
step:1195/1500 train_loss:3.7766 train_time:489277ms step_avg:412.89ms
step:1196/1500 train_loss:3.5700 train_time:489684ms step_avg:412.89ms
step:1197/1500 train_loss:3.5786 train_time:490091ms step_avg:412.88ms
step:1198/1500 train_loss:3.4816 train_time:490500ms step_avg:412.88ms
step:1199/1500 train_loss:3.4916 train_time:490908ms step_avg:412.87ms
step:1200/1500 train_loss:3.5437 train_time:491316ms step_avg:412.87ms
step:1201/1500 train_loss:3.6268 train_time:491725ms step_avg:412.87ms
step:1202/1500 train_loss:3.7015 train_time:492131ms step_avg:412.86ms
step:1203/1500 train_loss:3.7416 train_time:492540ms step_avg:412.86ms
step:1204/1500 train_loss:3.6089 train_time:492947ms step_avg:412.85ms
step:1205/1500 train_loss:3.5354 train_time:493356ms step_avg:412.85ms
step:1206/1500 train_loss:3.6234 train_time:493765ms step_avg:412.85ms
step:1207/1500 train_loss:3.6637 train_time:494174ms step_avg:412.84ms
step:1208/1500 train_loss:3.7130 train_time:494582ms step_avg:412.84ms
step:1209/1500 train_loss:3.5994 train_time:494990ms step_avg:412.84ms
step:1210/1500 train_loss:3.4568 train_time:495396ms step_avg:412.83ms
step:1211/1500 train_loss:3.5036 train_time:495803ms step_avg:412.83ms
step:1212/1500 train_loss:3.6043 train_time:496210ms step_avg:412.82ms
step:1213/1500 train_loss:3.6160 train_time:496618ms step_avg:412.82ms
step:1214/1500 train_loss:3.6403 train_time:497026ms step_avg:412.81ms
step:1215/1500 train_loss:3.5208 train_time:497434ms step_avg:412.81ms
step:1216/1500 train_loss:3.5943 train_time:497840ms step_avg:412.80ms
step:1217/1500 train_loss:3.5392 train_time:498248ms step_avg:412.80ms
step:1218/1500 train_loss:3.5326 train_time:498654ms step_avg:412.79ms
step:1219/1500 train_loss:3.6245 train_time:499062ms step_avg:412.79ms
step:1220/1500 train_loss:3.4534 train_time:499470ms step_avg:412.79ms
step:1221/1500 train_loss:3.6975 train_time:499878ms step_avg:412.78ms
step:1222/1500 train_loss:3.7251 train_time:500285ms step_avg:412.78ms
step:1223/1500 train_loss:3.6335 train_time:500695ms step_avg:412.77ms
step:1224/1500 train_loss:3.5021 train_time:501102ms step_avg:412.77ms
step:1225/1500 train_loss:3.4914 train_time:501510ms step_avg:412.77ms
step:1226/1500 train_loss:3.5686 train_time:501920ms step_avg:412.76ms
step:1227/1500 train_loss:3.5482 train_time:502329ms step_avg:412.76ms
step:1228/1500 train_loss:3.4926 train_time:502737ms step_avg:412.76ms
step:1229/1500 train_loss:3.6609 train_time:503145ms step_avg:412.75ms
step:1230/1500 train_loss:3.5810 train_time:503554ms step_avg:412.75ms
step:1231/1500 train_loss:3.6376 train_time:503962ms step_avg:412.75ms
step:1232/1500 train_loss:3.7982 train_time:504370ms step_avg:412.74ms
step:1233/1500 train_loss:3.6937 train_time:504777ms step_avg:412.74ms
step:1234/1500 train_loss:3.6287 train_time:505184ms step_avg:412.73ms
step:1235/1500 train_loss:3.7802 train_time:505591ms step_avg:412.73ms
step:1236/1500 train_loss:3.5405 train_time:506000ms step_avg:412.72ms
step:1237/1500 train_loss:3.5098 train_time:506407ms step_avg:412.72ms
step:1238/1500 train_loss:3.4646 train_time:506816ms step_avg:412.72ms
step:1239/1500 train_loss:3.5371 train_time:507224ms step_avg:412.71ms
step:1240/1500 train_loss:3.5461 train_time:507631ms step_avg:412.71ms
step:1241/1500 train_loss:3.5866 train_time:508038ms step_avg:412.70ms
step:1242/1500 train_loss:3.6381 train_time:508446ms step_avg:412.70ms
step:1243/1500 train_loss:3.5077 train_time:508855ms step_avg:412.70ms
step:1244/1500 train_loss:3.5990 train_time:509263ms step_avg:412.69ms
step:1245/1500 train_loss:3.6172 train_time:509671ms step_avg:412.69ms
step:1246/1500 train_loss:3.6200 train_time:510079ms step_avg:412.69ms
step:1247/1500 train_loss:3.4527 train_time:510487ms step_avg:412.68ms
step:1248/1500 train_loss:3.5974 train_time:510894ms step_avg:412.68ms
step:1249/1500 train_loss:3.6477 train_time:511303ms step_avg:412.67ms
step:1250/1500 train_loss:3.6227 train_time:511711ms step_avg:412.67ms
step:1250/1500 val_loss:3.5703 train_time:511723ms step_avg:412.68ms
step:1251/1500 train_loss:3.5193 train_time:512114ms step_avg:412.66ms
step:1252/1500 train_loss:3.7278 train_time:512522ms step_avg:412.66ms
step:1253/1500 train_loss:3.5879 train_time:512929ms step_avg:412.65ms
step:1254/1500 train_loss:3.5250 train_time:513336ms step_avg:412.65ms
step:1255/1500 train_loss:3.6544 train_time:513744ms step_avg:412.65ms
step:1256/1500 train_loss:3.7156 train_time:514151ms step_avg:412.64ms
step:1257/1500 train_loss:3.5262 train_time:514561ms step_avg:412.64ms
step:1258/1500 train_loss:3.5636 train_time:514968ms step_avg:412.63ms
step:1259/1500 train_loss:3.6065 train_time:515375ms step_avg:412.63ms
step:1260/1500 train_loss:3.5519 train_time:515783ms step_avg:412.63ms
step:1261/1500 train_loss:3.4160 train_time:516192ms step_avg:412.62ms
step:1262/1500 train_loss:3.5135 train_time:516601ms step_avg:412.62ms
step:1263/1500 train_loss:3.5948 train_time:517009ms step_avg:412.62ms
step:1264/1500 train_loss:3.4319 train_time:517417ms step_avg:412.61ms
step:1265/1500 train_loss:3.6560 train_time:517825ms step_avg:412.61ms
step:1266/1500 train_loss:3.6318 train_time:518235ms step_avg:412.61ms
step:1267/1500 train_loss:3.6411 train_time:518643ms step_avg:412.60ms
step:1268/1500 train_loss:3.5854 train_time:519049ms step_avg:412.60ms
step:1269/1500 train_loss:3.6211 train_time:519457ms step_avg:412.59ms
step:1270/1500 train_loss:3.4821 train_time:519866ms step_avg:412.59ms
step:1271/1500 train_loss:3.3261 train_time:520274ms step_avg:412.59ms
step:1272/1500 train_loss:3.6012 train_time:520681ms step_avg:412.58ms
step:1273/1500 train_loss:3.5630 train_time:521089ms step_avg:412.58ms
step:1274/1500 train_loss:3.6060 train_time:521497ms step_avg:412.58ms
step:1275/1500 train_loss:3.5653 train_time:521904ms step_avg:412.57ms
step:1276/1500 train_loss:3.6630 train_time:522311ms step_avg:412.57ms
step:1277/1500 train_loss:3.6822 train_time:522720ms step_avg:412.57ms
step:1278/1500 train_loss:3.6342 train_time:523130ms step_avg:412.56ms
step:1279/1500 train_loss:3.6344 train_time:523536ms step_avg:412.56ms
step:1280/1500 train_loss:3.4666 train_time:523943ms step_avg:412.55ms
step:1281/1500 train_loss:3.5770 train_time:524350ms step_avg:412.55ms
step:1282/1500 train_loss:3.6466 train_time:524756ms step_avg:412.54ms
step:1283/1500 train_loss:3.6788 train_time:525165ms step_avg:412.54ms
step:1284/1500 train_loss:3.5692 train_time:525572ms step_avg:412.54ms
step:1285/1500 train_loss:3.5926 train_time:525981ms step_avg:412.53ms
step:1286/1500 train_loss:3.5756 train_time:526389ms step_avg:412.53ms
step:1287/1500 train_loss:3.5517 train_time:526795ms step_avg:412.53ms
step:1288/1500 train_loss:3.6841 train_time:527204ms step_avg:412.52ms
step:1289/1500 train_loss:3.5178 train_time:527613ms step_avg:412.52ms
step:1290/1500 train_loss:3.6033 train_time:528020ms step_avg:412.52ms
step:1291/1500 train_loss:3.6796 train_time:528429ms step_avg:412.51ms
step:1292/1500 train_loss:3.6017 train_time:528838ms step_avg:412.51ms
step:1293/1500 train_loss:3.7077 train_time:529246ms step_avg:412.51ms
step:1294/1500 train_loss:3.7159 train_time:529655ms step_avg:412.50ms
step:1295/1500 train_loss:3.6821 train_time:530063ms step_avg:412.50ms
step:1296/1500 train_loss:3.4896 train_time:530472ms step_avg:412.50ms
step:1297/1500 train_loss:3.5804 train_time:530880ms step_avg:412.49ms
step:1298/1500 train_loss:3.4752 train_time:531288ms step_avg:412.49ms
step:1299/1500 train_loss:3.5389 train_time:531696ms step_avg:412.49ms
step:1300/1500 train_loss:3.6186 train_time:532104ms step_avg:412.48ms
step:1301/1500 train_loss:3.6248 train_time:532512ms step_avg:412.48ms
step:1302/1500 train_loss:3.6246 train_time:532921ms step_avg:412.48ms
step:1303/1500 train_loss:3.7791 train_time:533330ms step_avg:412.47ms
step:1304/1500 train_loss:3.5608 train_time:533737ms step_avg:412.47ms
step:1305/1500 train_loss:3.7526 train_time:534145ms step_avg:412.47ms
step:1306/1500 train_loss:3.4793 train_time:534554ms step_avg:412.46ms
step:1307/1500 train_loss:3.6781 train_time:534961ms step_avg:412.46ms
step:1308/1500 train_loss:3.6768 train_time:535369ms step_avg:412.46ms
step:1309/1500 train_loss:3.5352 train_time:535777ms step_avg:412.45ms
step:1310/1500 train_loss:3.5069 train_time:536185ms step_avg:412.45ms
step:1311/1500 train_loss:3.5114 train_time:536594ms step_avg:412.45ms
step:1312/1500 train_loss:3.5025 train_time:537002ms step_avg:412.44ms
step:1313/1500 train_loss:3.6196 train_time:537410ms step_avg:412.44ms
step:1314/1500 train_loss:3.5701 train_time:537818ms step_avg:412.44ms
step:1315/1500 train_loss:3.2855 train_time:538227ms step_avg:412.43ms
step:1316/1500 train_loss:3.5168 train_time:538635ms step_avg:412.43ms
step:1317/1500 train_loss:3.6020 train_time:539043ms step_avg:412.43ms
step:1318/1500 train_loss:3.6232 train_time:539451ms step_avg:412.42ms
step:1319/1500 train_loss:3.5092 train_time:539859ms step_avg:412.42ms
step:1320/1500 train_loss:3.6375 train_time:540268ms step_avg:412.42ms
step:1321/1500 train_loss:3.6949 train_time:540675ms step_avg:412.41ms
step:1322/1500 train_loss:3.5792 train_time:541082ms step_avg:412.41ms
step:1323/1500 train_loss:3.5315 train_time:542131ms step_avg:412.90ms
step:1324/1500 train_loss:3.5525 train_time:542540ms step_avg:412.89ms
step:1325/1500 train_loss:3.6521 train_time:542948ms step_avg:412.89ms
step:1326/1500 train_loss:3.7081 train_time:543357ms step_avg:412.89ms
step:1327/1500 train_loss:3.4556 train_time:543764ms step_avg:412.88ms
step:1328/1500 train_loss:3.3846 train_time:544171ms step_avg:412.88ms
step:1329/1500 train_loss:3.7003 train_time:544578ms step_avg:412.87ms
step:1330/1500 train_loss:3.5495 train_time:545167ms step_avg:413.01ms
step:1331/1500 train_loss:3.6621 train_time:545577ms step_avg:413.00ms
step:1332/1500 train_loss:3.5669 train_time:545985ms step_avg:413.00ms
step:1333/1500 train_loss:3.9615 train_time:546393ms step_avg:413.00ms
step:1334/1500 train_loss:3.6729 train_time:546801ms step_avg:412.99ms
step:1335/1500 train_loss:3.5847 train_time:547209ms step_avg:412.99ms
step:1336/1500 train_loss:3.5259 train_time:547618ms step_avg:412.98ms
step:1337/1500 train_loss:3.5219 train_time:548025ms step_avg:412.98ms
step:1338/1500 train_loss:3.7748 train_time:548434ms step_avg:412.98ms
step:1339/1500 train_loss:3.7192 train_time:548841ms step_avg:412.97ms
step:1340/1500 train_loss:3.5565 train_time:549248ms step_avg:412.97ms
step:1341/1500 train_loss:3.5188 train_time:549657ms step_avg:412.97ms
step:1342/1500 train_loss:3.8286 train_time:550064ms step_avg:412.96ms
step:1343/1500 train_loss:3.5980 train_time:550472ms step_avg:412.96ms
step:1344/1500 train_loss:3.5909 train_time:550881ms step_avg:412.95ms
step:1345/1500 train_loss:3.6458 train_time:551288ms step_avg:412.95ms
step:1346/1500 train_loss:3.6091 train_time:551695ms step_avg:412.95ms
step:1347/1500 train_loss:3.5173 train_time:552105ms step_avg:412.94ms
step:1348/1500 train_loss:3.4727 train_time:552514ms step_avg:412.94ms
step:1349/1500 train_loss:3.5665 train_time:552921ms step_avg:412.94ms
step:1350/1500 train_loss:3.4926 train_time:553330ms step_avg:412.93ms
step:1351/1500 train_loss:3.6239 train_time:553738ms step_avg:412.93ms
step:1352/1500 train_loss:3.4728 train_time:554145ms step_avg:412.93ms
step:1353/1500 train_loss:3.5347 train_time:554552ms step_avg:412.92ms
step:1354/1500 train_loss:3.6348 train_time:554962ms step_avg:412.92ms
step:1355/1500 train_loss:3.4835 train_time:555372ms step_avg:412.92ms
step:1356/1500 train_loss:3.4049 train_time:555780ms step_avg:412.91ms
step:1357/1500 train_loss:3.7517 train_time:556188ms step_avg:412.91ms
step:1358/1500 train_loss:3.6849 train_time:556597ms step_avg:412.91ms
step:1359/1500 train_loss:3.4032 train_time:557006ms step_avg:412.90ms
step:1360/1500 train_loss:3.6821 train_time:557414ms step_avg:412.90ms
step:1361/1500 train_loss:3.5634 train_time:557822ms step_avg:412.90ms
step:1362/1500 train_loss:3.4093 train_time:558233ms step_avg:412.89ms
step:1363/1500 train_loss:3.6064 train_time:558641ms step_avg:412.89ms
step:1364/1500 train_loss:3.5092 train_time:559049ms step_avg:412.89ms
step:1365/1500 train_loss:3.5213 train_time:559457ms step_avg:412.88ms
step:1366/1500 train_loss:3.5400 train_time:559867ms step_avg:412.88ms
step:1367/1500 train_loss:3.6389 train_time:560275ms step_avg:412.88ms
step:1368/1500 train_loss:3.6301 train_time:560683ms step_avg:412.87ms
step:1369/1500 train_loss:3.5756 train_time:561091ms step_avg:412.87ms
step:1370/1500 train_loss:3.4937 train_time:561499ms step_avg:412.87ms
step:1371/1500 train_loss:3.8166 train_time:561907ms step_avg:412.86ms
step:1372/1500 train_loss:3.5574 train_time:562315ms step_avg:412.86ms
step:1373/1500 train_loss:3.5990 train_time:562722ms step_avg:412.86ms
step:1374/1500 train_loss:3.5903 train_time:563130ms step_avg:412.85ms
step:1375/1500 train_loss:3.3891 train_time:563538ms step_avg:412.85ms
step:1375/1500 val_loss:3.5459 train_time:563552ms step_avg:412.86ms
step:1376/1500 train_loss:3.7808 train_time:563942ms step_avg:412.84ms
step:1377/1500 train_loss:3.5671 train_time:564348ms step_avg:412.84ms
step:1378/1500 train_loss:3.7126 train_time:564755ms step_avg:412.83ms
step:1379/1500 train_loss:3.7339 train_time:565165ms step_avg:412.83ms
step:1380/1500 train_loss:3.3676 train_time:565572ms step_avg:412.83ms
step:1381/1500 train_loss:3.5547 train_time:565981ms step_avg:412.82ms
step:1382/1500 train_loss:3.9712 train_time:566388ms step_avg:412.82ms
step:1383/1500 train_loss:3.4662 train_time:566795ms step_avg:412.81ms
step:1384/1500 train_loss:3.6264 train_time:567203ms step_avg:412.81ms
step:1385/1500 train_loss:3.6942 train_time:567612ms step_avg:412.81ms
step:1386/1500 train_loss:3.6077 train_time:568020ms step_avg:412.81ms
step:1387/1500 train_loss:3.5941 train_time:568428ms step_avg:412.80ms
step:1388/1500 train_loss:3.4335 train_time:568835ms step_avg:412.80ms
step:1389/1500 train_loss:3.5714 train_time:569243ms step_avg:412.79ms
step:1390/1500 train_loss:3.5488 train_time:569651ms step_avg:412.79ms
step:1391/1500 train_loss:3.8067 train_time:570060ms step_avg:412.79ms
step:1392/1500 train_loss:3.5271 train_time:570467ms step_avg:412.78ms
step:1393/1500 train_loss:3.5139 train_time:570875ms step_avg:412.78ms
step:1394/1500 train_loss:3.4835 train_time:571282ms step_avg:412.78ms
step:1395/1500 train_loss:3.7639 train_time:571691ms step_avg:412.77ms
step:1396/1500 train_loss:3.6517 train_time:572098ms step_avg:412.77ms
step:1397/1500 train_loss:3.6572 train_time:572507ms step_avg:412.77ms
step:1398/1500 train_loss:3.5298 train_time:572915ms step_avg:412.76ms
step:1399/1500 train_loss:3.4970 train_time:573320ms step_avg:412.76ms
step:1400/1500 train_loss:3.5658 train_time:573728ms step_avg:412.75ms
step:1401/1500 train_loss:3.5419 train_time:574135ms step_avg:412.75ms
step:1402/1500 train_loss:3.5689 train_time:574543ms step_avg:412.75ms
step:1403/1500 train_loss:3.5314 train_time:574951ms step_avg:412.74ms
step:1404/1500 train_loss:3.7573 train_time:575358ms step_avg:412.74ms
step:1405/1500 train_loss:3.5068 train_time:575765ms step_avg:412.73ms
step:1406/1500 train_loss:3.5508 train_time:576173ms step_avg:412.73ms
step:1407/1500 train_loss:3.5482 train_time:576582ms step_avg:412.73ms
step:1408/1500 train_loss:3.4192 train_time:576990ms step_avg:412.73ms
step:1409/1500 train_loss:3.5373 train_time:577398ms step_avg:412.72ms
step:1410/1500 train_loss:3.5163 train_time:577806ms step_avg:412.72ms
step:1411/1500 train_loss:3.5090 train_time:578214ms step_avg:412.72ms
step:1412/1500 train_loss:3.6020 train_time:578623ms step_avg:412.71ms
step:1413/1500 train_loss:3.5473 train_time:579032ms step_avg:412.71ms
step:1414/1500 train_loss:3.5904 train_time:579440ms step_avg:412.71ms
step:1415/1500 train_loss:3.5708 train_time:579847ms step_avg:412.70ms
step:1416/1500 train_loss:3.6491 train_time:580255ms step_avg:412.70ms
step:1417/1500 train_loss:3.4582 train_time:580662ms step_avg:412.70ms
step:1418/1500 train_loss:3.5269 train_time:581071ms step_avg:412.69ms
step:1419/1500 train_loss:3.6190 train_time:581480ms step_avg:412.69ms
step:1420/1500 train_loss:3.6383 train_time:581888ms step_avg:412.69ms
step:1421/1500 train_loss:3.6268 train_time:582297ms step_avg:412.68ms
step:1422/1500 train_loss:3.6018 train_time:582705ms step_avg:412.68ms
step:1423/1500 train_loss:3.5788 train_time:583113ms step_avg:412.68ms
step:1424/1500 train_loss:3.5720 train_time:583521ms step_avg:412.67ms
step:1425/1500 train_loss:3.5773 train_time:583929ms step_avg:412.67ms
step:1426/1500 train_loss:3.4439 train_time:584336ms step_avg:412.67ms
step:1427/1500 train_loss:3.5578 train_time:584745ms step_avg:412.66ms
step:1428/1500 train_loss:3.5051 train_time:585153ms step_avg:412.66ms
step:1429/1500 train_loss:3.6149 train_time:585562ms step_avg:412.66ms
step:1430/1500 train_loss:3.5823 train_time:585969ms step_avg:412.65ms
step:1431/1500 train_loss:3.5033 train_time:586379ms step_avg:412.65ms
step:1432/1500 train_loss:3.5518 train_time:586787ms step_avg:412.65ms
step:1433/1500 train_loss:3.5921 train_time:587196ms step_avg:412.65ms
step:1434/1500 train_loss:3.3992 train_time:587605ms step_avg:412.64ms
step:1435/1500 train_loss:3.5558 train_time:588012ms step_avg:412.64ms
step:1436/1500 train_loss:3.3848 train_time:588420ms step_avg:412.64ms
step:1437/1500 train_loss:3.4591 train_time:588828ms step_avg:412.63ms
step:1438/1500 train_loss:3.6472 train_time:589235ms step_avg:412.63ms
step:1439/1500 train_loss:3.6051 train_time:589644ms step_avg:412.63ms
step:1440/1500 train_loss:3.5563 train_time:590053ms step_avg:412.62ms
step:1441/1500 train_loss:3.4128 train_time:590461ms step_avg:412.62ms
step:1442/1500 train_loss:3.5852 train_time:590869ms step_avg:412.62ms
step:1443/1500 train_loss:3.6458 train_time:591279ms step_avg:412.62ms
step:1444/1500 train_loss:3.7260 train_time:591688ms step_avg:412.61ms
step:1445/1500 train_loss:3.6867 train_time:592096ms step_avg:412.61ms
step:1446/1500 train_loss:3.5707 train_time:592504ms step_avg:412.61ms
step:1447/1500 train_loss:3.4395 train_time:592913ms step_avg:412.60ms
step:1448/1500 train_loss:3.5154 train_time:593321ms step_avg:412.60ms
step:1449/1500 train_loss:3.5321 train_time:593731ms step_avg:412.60ms
step:1450/1500 train_loss:3.6506 train_time:594140ms step_avg:412.60ms
step:1451/1500 train_loss:3.6428 train_time:594549ms step_avg:412.59ms
step:1452/1500 train_loss:3.4562 train_time:594957ms step_avg:412.59ms
step:1453/1500 train_loss:3.5787 train_time:595364ms step_avg:412.59ms
step:1454/1500 train_loss:3.4865 train_time:595772ms step_avg:412.58ms
step:1455/1500 train_loss:3.5239 train_time:596180ms step_avg:412.58ms
step:1456/1500 train_loss:3.5732 train_time:596588ms step_avg:412.58ms
step:1457/1500 train_loss:3.5018 train_time:596995ms step_avg:412.57ms
step:1458/1500 train_loss:3.3968 train_time:597402ms step_avg:412.57ms
step:1459/1500 train_loss:3.6429 train_time:597812ms step_avg:412.57ms
step:1460/1500 train_loss:3.5148 train_time:598220ms step_avg:412.57ms
step:1461/1500 train_loss:3.5611 train_time:598628ms step_avg:412.56ms
step:1462/1500 train_loss:3.6891 train_time:599037ms step_avg:412.56ms
step:1463/1500 train_loss:3.5083 train_time:599446ms step_avg:412.56ms
step:1464/1500 train_loss:3.7024 train_time:599854ms step_avg:412.55ms
step:1465/1500 train_loss:3.5900 train_time:600263ms step_avg:412.55ms
step:1466/1500 train_loss:3.5854 train_time:600672ms step_avg:412.55ms
step:1467/1500 train_loss:3.5224 train_time:601081ms step_avg:412.55ms
step:1468/1500 train_loss:3.6710 train_time:601490ms step_avg:412.54ms
step:1469/1500 train_loss:3.5366 train_time:601896ms step_avg:412.54ms
step:1470/1500 train_loss:3.5077 train_time:602303ms step_avg:412.54ms
step:1471/1500 train_loss:3.5642 train_time:602710ms step_avg:412.53ms
step:1472/1500 train_loss:3.4893 train_time:603116ms step_avg:412.53ms
step:1473/1500 train_loss:3.5911 train_time:603524ms step_avg:412.52ms
step:1474/1500 train_loss:3.6688 train_time:603931ms step_avg:412.52ms
step:1475/1500 train_loss:3.5498 train_time:604339ms step_avg:412.52ms
step:1476/1500 train_loss:3.3792 train_time:604747ms step_avg:412.51ms
step:1477/1500 train_loss:3.4969 train_time:605155ms step_avg:412.51ms
step:1478/1500 train_loss:3.4713 train_time:605562ms step_avg:412.51ms
step:1479/1500 train_loss:3.5632 train_time:605970ms step_avg:412.51ms
step:1480/1500 train_loss:3.6421 train_time:606378ms step_avg:412.50ms
step:1481/1500 train_loss:3.5088 train_time:606785ms step_avg:412.50ms
step:1482/1500 train_loss:3.6837 train_time:607194ms step_avg:412.50ms
step:1483/1500 train_loss:3.6184 train_time:607601ms step_avg:412.49ms
step:1484/1500 train_loss:3.5152 train_time:608010ms step_avg:412.49ms
step:1485/1500 train_loss:3.4985 train_time:608418ms step_avg:412.49ms
step:1486/1500 train_loss:3.5032 train_time:608826ms step_avg:412.48ms
step:1487/1500 train_loss:3.4748 train_time:609234ms step_avg:412.48ms
step:1488/1500 train_loss:3.5652 train_time:609641ms step_avg:412.48ms
step:1489/1500 train_loss:3.4814 train_time:610050ms step_avg:412.47ms
step:1490/1500 train_loss:3.5670 train_time:610459ms step_avg:412.47ms
step:1491/1500 train_loss:3.4978 train_time:610867ms step_avg:412.47ms
step:1492/1500 train_loss:3.4295 train_time:611276ms step_avg:412.47ms
step:1493/1500 train_loss:3.4963 train_time:611682ms step_avg:412.46ms
step:1494/1500 train_loss:3.6818 train_time:612089ms step_avg:412.46ms
step:1495/1500 train_loss:3.5277 train_time:612498ms step_avg:412.46ms
step:1496/1500 train_loss:3.2902 train_time:612906ms step_avg:412.45ms
step:1497/1500 train_loss:3.5953 train_time:613313ms step_avg:412.45ms
step:1498/1500 train_loss:3.5500 train_time:613720ms step_avg:412.45ms
step:1499/1500 train_loss:3.5997 train_time:614126ms step_avg:412.44ms
step:1500/1500 train_loss:3.5577 train_time:614535ms step_avg:412.44ms
step:1500/1500 val_loss:3.5312 train_time:614547ms step_avg:412.45ms
