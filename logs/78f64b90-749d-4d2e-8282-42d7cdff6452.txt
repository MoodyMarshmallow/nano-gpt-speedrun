====================================================================================================
# NOTE: record from https://github.com/KellerJordan/modded-nanogpt/blob/master/records/track_1_short/2024-10-14_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt
# ====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
import json
import dataclasses
import subprocess
import csv
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \\sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=3e-4, momentum=0.95, nesterov=True, backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]
            for p in group['params']:
                g = p.grad
                if g is None:
                    continue
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.mul_(momentum).add_(g)
                if group['nesterov']:
                    g = g.add(buf, alpha=momentum)
                if g.size(0) == 3 * g.size(1): # split grouped QKV parameters
                    g = torch.cat([zeropower_backend(g1, steps=group['backend_steps']) for g1 in g.split(g.size(1))])
                    scale = g.size(1)**0.5
                else:
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    scale = max(g.size(0), g.size(1))**0.5 # scale to have update.square().mean() == 1
                p.data.add_(g, alpha=-lr * scale)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

def _apply_gate_act(logits: torch.Tensor, kind: str) -> torch.Tensor:
    if kind == "sigmoid":
        return torch.sigmoid(logits)
    if kind == "ns_sigmoid":
        return 0.5 + 0.5 * torch.sigmoid(logits)
    raise ValueError(f"unknown gate_act={kind}")

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.attn_gate = getattr(config, "attn_gate", "none")
        self.gate_pos = getattr(config, "gate_pos", "sdpa")
        self.gate_act = getattr(config, "gate_act", "sigmoid")
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)
        if self.attn_gate == "headwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_head, bias=False)
            self.gate_param = None
        elif self.attn_gate == "elementwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_embd, bias=False)
            self.gate_param = None
        elif self.attn_gate == "const":
            self.c_gate = None
            self.gate_param = nn.Parameter(torch.zeros(self.n_head, self.head_dim))
        else:
            self.c_gate = None
            self.gate_param = None

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        if self.attn_gate != "none" and self.gate_pos == "value":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            v = v * gate
        cos, sin = self.rotary(q)
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2) # (B, T, n_head, head_dim)
        if self.attn_gate != "none" and self.gate_pos == "sdpa":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            y = y * gate
        y = y.contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768
    attn_gate : str = "none"
    gate_pos : str = "sdpa"
    gate_act : str = "sigmoid"

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying

    def forward(self, idx, targets=None, return_logits=True):

        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8*64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 5100 # number of iterations to run
    learning_rate : float = 0.0036
    warmup_iters : int = 0
    warmdown_iters : int = 1450 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    seed : int = 1337
    attn_gate : str = "none" # none|headwise|elementwise|const
    gate_pos : str = "sdpa" # sdpa|value
    gate_act : str = "sigmoid" # sigmoid|ns_sigmoid
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

def apply_env_overrides():
    # environment-variable overrides allow quick sweeps without editing code
    args.learning_rate = float(os.environ.get("LR", args.learning_rate))
    args.seed = int(os.environ.get("SEED", args.seed))
    args.attn_gate = os.environ.get("ATTNGATE", args.attn_gate)
    args.gate_pos = os.environ.get("GATEPOS", args.gate_pos)
    args.gate_act = os.environ.get("GATEACT", args.gate_act)
    args.num_iterations = int(os.environ.get("NUM_ITER", args.num_iterations))
    args.val_loss_every = int(os.environ.get("VAL_EVERY", args.val_loss_every))

def get_git_commit():
    try:
        return subprocess.check_output(["git", "rev-parse", "HEAD"], text=True).strip()
    except Exception:
        return "unknown"

apply_env_overrides()
torch.manual_seed(args.seed)
torch.cuda.manual_seed_all(args.seed)
np.random.seed(args.seed)

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.
git_commit = get_git_commit() if master_process else "unknown"

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(
    vocab_size=num_vocab,
    n_layer=12,
    n_head=6,
    n_embd=768,
    attn_gate=args.attn_gate,
    gate_pos=args.gate_pos,
    gate_act=args.gate_act,
))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
optimizer1 = torch.optim.AdamW(raw_model.lm_head.parameters(), lr=args.learning_rate, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer2 = Muon(raw_model.transformer.h.parameters(), lr=0.1*args.learning_rate, momentum=0.95)
optimizers = [optimizer1, optimizer2]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        f.write(f"git_commit: {git_commit}\n")
        f.write(f"seed: {args.seed}\n")
        f.write("hyperparameters:\n")
        f.write(json.dumps(dataclasses.asdict(args), indent=2))
        f.write("\n")
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')

training_time_ms = 0
best_val_loss = float("inf")
final_val_loss = None
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        val_loss_item = val_loss.item()
        final_val_loss = val_loss_item
        best_val_loss = min(best_val_loss, val_loss_item)
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms\n')
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            _, loss = model(x, y, return_logits=False)
            train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process:
        approx_time = training_time_ms + 1000 * (time.time() - t0)
        print(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")
        with open(logfile, "a") as f:
            f.write(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms\n")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")
    timed_steps_final = max(args.num_iterations - 9, 1)
    ms_per_step = training_time_ms / timed_steps_final
    os.makedirs("experiments", exist_ok=True)
    results_path = os.path.join("experiments", "results.csv")
    fieldnames = [
        "run_id",
        "date",
        "git_commit",
        "seed",
        "attn_gate",
        "gate_pos",
        "gate_act",
        "learning_rate",
        "batch_size",
        "device_batch_size",
        "sequence_length",
        "num_iterations",
        "warmdown_iters",
        "final_val_loss",
        "best_val_loss",
        "train_time_ms",
        "ms_per_step",
        "gpu_name",
        "n_gpus",
        "runpod_instance",
        "notes",
    ]
    final_loss_value = final_val_loss if final_val_loss is not None else float("nan")
    best_loss_value = best_val_loss if best_val_loss < float("inf") else float("nan")
    row = {
        "run_id": run_id,
        "date": time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime()),
        "git_commit": git_commit,
        "seed": args.seed,
        "attn_gate": args.attn_gate,
        "gate_pos": args.gate_pos,
        "gate_act": args.gate_act,
        "learning_rate": args.learning_rate,
        "batch_size": args.batch_size,
        "device_batch_size": args.device_batch_size,
        "sequence_length": args.sequence_length,
        "num_iterations": args.num_iterations,
        "warmdown_iters": args.warmdown_iters,
        "final_val_loss": final_loss_value,
        "best_val_loss": best_loss_value,
        "train_time_ms": training_time_ms,
        "ms_per_step": ms_per_step,
        "gpu_name": torch.cuda.get_device_name(ddp_local_rank),
        "n_gpus": ddp_world_size,
        "runpod_instance": os.environ.get("RUNPOD_INSTANCE_TYPE", "unknown"),
        "notes": "",
    }
    write_header = not os.path.exists(results_path)
    with open(results_path, "a", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if write_header:
            writer.writeheader()
        writer.writerow(row)
====================================================================================================
git_commit: 21aae13b20675947154a15b640706eb3a47e5fcd
seed: 1338
hyperparameters:
{
  "input_bin": "data/fineweb10B/fineweb_train_*.bin",
  "input_val_bin": "data/fineweb10B/fineweb_val_*.bin",
  "batch_size": 512,
  "device_batch_size": 64,
  "sequence_length": 1024,
  "num_iterations": 1500,
  "learning_rate": 0.0036,
  "warmup_iters": 0,
  "warmdown_iters": 1450,
  "weight_decay": 0,
  "seed": 1338,
  "attn_gate": "elementwise",
  "gate_pos": "sdpa",
  "gate_act": "sigmoid",
  "val_loss_every": 125,
  "val_tokens": 10485760,
  "save_every": 0
}
Running pytorch 2.8.0+cu128 compiled for CUDA 12.8
nvidia-smi:
Sun Dec  7 10:36:41 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:00:07.0 Off |                    0 |
| N/A   46C    P0            114W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          On  |   00000000:00:08.0 Off |                    0 |
| N/A   48C    P0            146W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100 80GB PCIe          On  |   00000000:00:09.0 Off |                    0 |
| N/A   44C    P0            133W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100 80GB PCIe          On  |   00000000:00:0A.0 Off |                    0 |
| N/A   45C    P0            131W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100 80GB PCIe          On  |   00000000:00:0B.0 Off |                    0 |
| N/A   48C    P0            115W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100 80GB PCIe          On  |   00000000:00:0C.0 Off |                    0 |
| N/A   44C    P0            110W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100 80GB PCIe          On  |   00000000:00:0D.0 Off |                    0 |
| N/A   47C    P0            118W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100 80GB PCIe          On  |   00000000:00:0E.0 Off |                    0 |
| N/A   46C    P0            134W /  300W |    2276MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1500 val_loss:16.0275 train_time:242ms step_avg:nanms
step:1/1500 train_loss:16.0292 train_time:42956ms step_avg:nanms
step:2/1500 train_loss:9.4841 train_time:44313ms step_avg:nanms
step:3/1500 train_loss:8.5955 train_time:44733ms step_avg:nanms
step:4/1500 train_loss:7.9236 train_time:45153ms step_avg:nanms
step:5/1500 train_loss:7.4572 train_time:45576ms step_avg:nanms
step:6/1500 train_loss:7.3256 train_time:45997ms step_avg:nanms
step:7/1500 train_loss:7.0060 train_time:46418ms step_avg:nanms
step:8/1500 train_loss:7.3086 train_time:46842ms step_avg:nanms
step:9/1500 train_loss:7.0514 train_time:47264ms step_avg:nanms
step:10/1500 train_loss:6.8239 train_time:47687ms step_avg:nanms
step:11/1500 train_loss:6.8101 train_time:420ms step_avg:nanms
step:12/1500 train_loss:6.7250 train_time:843ms step_avg:nanms
step:13/1500 train_loss:6.5356 train_time:1265ms step_avg:421.78ms
step:14/1500 train_loss:6.5237 train_time:1689ms step_avg:422.14ms
step:15/1500 train_loss:6.4945 train_time:2115ms step_avg:422.93ms
step:16/1500 train_loss:6.4414 train_time:2539ms step_avg:423.21ms
step:17/1500 train_loss:6.4500 train_time:2964ms step_avg:423.36ms
step:18/1500 train_loss:6.4883 train_time:3387ms step_avg:423.34ms
step:19/1500 train_loss:6.3087 train_time:3811ms step_avg:423.46ms
step:20/1500 train_loss:6.3336 train_time:4234ms step_avg:423.43ms
step:21/1500 train_loss:6.0166 train_time:4658ms step_avg:423.48ms
step:22/1500 train_loss:6.3773 train_time:5088ms step_avg:424.00ms
step:23/1500 train_loss:6.5849 train_time:5511ms step_avg:423.94ms
step:24/1500 train_loss:6.2729 train_time:5935ms step_avg:423.90ms
step:25/1500 train_loss:6.4059 train_time:6358ms step_avg:423.89ms
step:26/1500 train_loss:6.1119 train_time:6786ms step_avg:424.10ms
step:27/1500 train_loss:6.0375 train_time:7209ms step_avg:424.09ms
step:28/1500 train_loss:6.1876 train_time:7629ms step_avg:423.84ms
step:29/1500 train_loss:5.8623 train_time:8052ms step_avg:423.79ms
step:30/1500 train_loss:6.1415 train_time:8474ms step_avg:423.72ms
step:31/1500 train_loss:5.9747 train_time:8896ms step_avg:423.62ms
step:32/1500 train_loss:5.9434 train_time:9318ms step_avg:423.53ms
step:33/1500 train_loss:5.7841 train_time:9740ms step_avg:423.46ms
step:34/1500 train_loss:6.0729 train_time:10162ms step_avg:423.40ms
step:35/1500 train_loss:6.0082 train_time:10587ms step_avg:423.46ms
step:36/1500 train_loss:6.1472 train_time:11009ms step_avg:423.42ms
step:37/1500 train_loss:6.0872 train_time:11432ms step_avg:423.41ms
step:38/1500 train_loss:5.9757 train_time:11855ms step_avg:423.38ms
step:39/1500 train_loss:5.8681 train_time:12277ms step_avg:423.35ms
step:40/1500 train_loss:5.8741 train_time:12700ms step_avg:423.35ms
step:41/1500 train_loss:5.7992 train_time:13121ms step_avg:423.26ms
step:42/1500 train_loss:5.8218 train_time:13543ms step_avg:423.23ms
step:43/1500 train_loss:5.6977 train_time:13965ms step_avg:423.20ms
step:44/1500 train_loss:5.8090 train_time:14388ms step_avg:423.17ms
step:45/1500 train_loss:5.7688 train_time:14810ms step_avg:423.14ms
step:46/1500 train_loss:5.9309 train_time:15234ms step_avg:423.16ms
step:47/1500 train_loss:5.7242 train_time:15655ms step_avg:423.12ms
step:48/1500 train_loss:5.5947 train_time:16083ms step_avg:423.24ms
step:49/1500 train_loss:5.8044 train_time:16505ms step_avg:423.20ms
step:50/1500 train_loss:5.6903 train_time:16927ms step_avg:423.17ms
step:51/1500 train_loss:5.8289 train_time:17350ms step_avg:423.16ms
step:52/1500 train_loss:5.6952 train_time:17770ms step_avg:423.11ms
step:53/1500 train_loss:5.5547 train_time:18192ms step_avg:423.06ms
step:54/1500 train_loss:5.6894 train_time:18614ms step_avg:423.04ms
step:55/1500 train_loss:5.5686 train_time:19036ms step_avg:423.02ms
step:56/1500 train_loss:5.9079 train_time:19459ms step_avg:423.02ms
step:57/1500 train_loss:5.5657 train_time:19885ms step_avg:423.08ms
step:58/1500 train_loss:5.4351 train_time:20305ms step_avg:423.03ms
step:59/1500 train_loss:5.5747 train_time:20728ms step_avg:423.02ms
step:60/1500 train_loss:5.5498 train_time:21150ms step_avg:422.99ms
step:61/1500 train_loss:5.6546 train_time:21572ms step_avg:422.99ms
step:62/1500 train_loss:5.4277 train_time:21995ms step_avg:422.97ms
step:63/1500 train_loss:5.5288 train_time:22416ms step_avg:422.94ms
step:64/1500 train_loss:5.5072 train_time:22837ms step_avg:422.91ms
step:65/1500 train_loss:5.1761 train_time:23260ms step_avg:422.91ms
step:66/1500 train_loss:5.3171 train_time:23686ms step_avg:422.97ms
step:67/1500 train_loss:5.4691 train_time:24109ms step_avg:422.97ms
step:68/1500 train_loss:5.3486 train_time:24533ms step_avg:422.98ms
step:69/1500 train_loss:5.6101 train_time:24954ms step_avg:422.95ms
step:70/1500 train_loss:5.2519 train_time:25378ms step_avg:422.96ms
step:71/1500 train_loss:5.2739 train_time:25799ms step_avg:422.94ms
step:72/1500 train_loss:5.4775 train_time:26226ms step_avg:423.00ms
step:73/1500 train_loss:5.4187 train_time:26647ms step_avg:422.97ms
step:74/1500 train_loss:5.2881 train_time:27070ms step_avg:422.96ms
step:75/1500 train_loss:5.4145 train_time:27491ms step_avg:422.93ms
step:76/1500 train_loss:5.4024 train_time:27913ms step_avg:422.92ms
step:77/1500 train_loss:5.3435 train_time:28335ms step_avg:422.91ms
step:78/1500 train_loss:5.4403 train_time:28757ms step_avg:422.90ms
step:79/1500 train_loss:5.5121 train_time:29185ms step_avg:422.98ms
step:80/1500 train_loss:5.2894 train_time:29607ms step_avg:422.96ms
step:81/1500 train_loss:5.3971 train_time:30030ms step_avg:422.96ms
step:82/1500 train_loss:5.1659 train_time:30452ms step_avg:422.94ms
step:83/1500 train_loss:5.3439 train_time:30876ms step_avg:422.96ms
step:84/1500 train_loss:5.2942 train_time:31302ms step_avg:423.00ms
step:85/1500 train_loss:5.2750 train_time:31723ms step_avg:422.98ms
step:86/1500 train_loss:5.1368 train_time:32146ms step_avg:422.98ms
step:87/1500 train_loss:5.3509 train_time:32571ms step_avg:423.00ms
step:88/1500 train_loss:5.2555 train_time:32995ms step_avg:423.01ms
step:89/1500 train_loss:5.3079 train_time:33416ms step_avg:422.99ms
step:90/1500 train_loss:5.2689 train_time:33838ms step_avg:422.98ms
step:91/1500 train_loss:5.1944 train_time:34261ms step_avg:422.98ms
step:92/1500 train_loss:5.1713 train_time:34685ms step_avg:422.98ms
step:93/1500 train_loss:5.3105 train_time:35107ms step_avg:422.97ms
step:94/1500 train_loss:5.1228 train_time:35530ms step_avg:422.97ms
step:95/1500 train_loss:5.1421 train_time:35953ms step_avg:422.97ms
step:96/1500 train_loss:5.1721 train_time:36375ms step_avg:422.97ms
step:97/1500 train_loss:5.0876 train_time:36797ms step_avg:422.96ms
step:98/1500 train_loss:5.1672 train_time:37222ms step_avg:422.98ms
step:99/1500 train_loss:5.0922 train_time:37646ms step_avg:422.99ms
step:100/1500 train_loss:5.2090 train_time:38070ms step_avg:423.00ms
step:101/1500 train_loss:5.1844 train_time:38492ms step_avg:422.98ms
step:102/1500 train_loss:5.0750 train_time:38916ms step_avg:423.00ms
step:103/1500 train_loss:5.1768 train_time:39338ms step_avg:422.99ms
step:104/1500 train_loss:5.1338 train_time:39760ms step_avg:422.98ms
step:105/1500 train_loss:4.9907 train_time:40187ms step_avg:423.02ms
step:106/1500 train_loss:5.0849 train_time:40609ms step_avg:423.02ms
step:107/1500 train_loss:5.2846 train_time:41032ms step_avg:423.01ms
step:108/1500 train_loss:5.0585 train_time:41457ms step_avg:423.03ms
step:109/1500 train_loss:4.8560 train_time:41883ms step_avg:423.06ms
step:110/1500 train_loss:5.0436 train_time:42306ms step_avg:423.06ms
step:111/1500 train_loss:5.0273 train_time:42728ms step_avg:423.05ms
step:112/1500 train_loss:4.9848 train_time:43149ms step_avg:423.03ms
step:113/1500 train_loss:5.1019 train_time:43572ms step_avg:423.03ms
step:114/1500 train_loss:5.0183 train_time:43996ms step_avg:423.03ms
step:115/1500 train_loss:4.8765 train_time:44417ms step_avg:423.02ms
step:116/1500 train_loss:5.0308 train_time:44838ms step_avg:423.00ms
step:117/1500 train_loss:4.9462 train_time:45261ms step_avg:423.00ms
step:118/1500 train_loss:4.8891 train_time:45687ms step_avg:423.02ms
step:119/1500 train_loss:5.0462 train_time:46109ms step_avg:423.02ms
step:120/1500 train_loss:4.9935 train_time:46533ms step_avg:423.02ms
step:121/1500 train_loss:4.9272 train_time:46956ms step_avg:423.03ms
step:122/1500 train_loss:4.8284 train_time:47383ms step_avg:423.06ms
step:123/1500 train_loss:4.9497 train_time:47806ms step_avg:423.06ms
step:124/1500 train_loss:4.8009 train_time:48229ms step_avg:423.06ms
step:125/1500 train_loss:5.1156 train_time:48652ms step_avg:423.06ms
step:125/1500 val_loss:4.9363 train_time:48656ms step_avg:423.09ms
step:126/1500 train_loss:4.9849 train_time:49079ms step_avg:423.09ms
step:127/1500 train_loss:4.9246 train_time:49502ms step_avg:423.10ms
step:128/1500 train_loss:4.9872 train_time:49925ms step_avg:423.10ms
step:129/1500 train_loss:4.8628 train_time:50349ms step_avg:423.10ms
step:130/1500 train_loss:5.1752 train_time:50773ms step_avg:423.11ms
step:131/1500 train_loss:4.9183 train_time:51198ms step_avg:423.13ms
step:132/1500 train_loss:4.9282 train_time:51622ms step_avg:423.13ms
step:133/1500 train_loss:4.8868 train_time:52044ms step_avg:423.13ms
step:134/1500 train_loss:4.9223 train_time:52465ms step_avg:423.11ms
step:135/1500 train_loss:4.8057 train_time:52888ms step_avg:423.10ms
step:136/1500 train_loss:4.9409 train_time:53314ms step_avg:423.13ms
step:137/1500 train_loss:4.7103 train_time:53737ms step_avg:423.13ms
step:138/1500 train_loss:4.8707 train_time:54162ms step_avg:423.14ms
step:139/1500 train_loss:4.8209 train_time:54585ms step_avg:423.14ms
step:140/1500 train_loss:4.8546 train_time:55008ms step_avg:423.14ms
step:141/1500 train_loss:4.9157 train_time:55436ms step_avg:423.18ms
step:142/1500 train_loss:4.7991 train_time:55861ms step_avg:423.19ms
step:143/1500 train_loss:4.8519 train_time:56284ms step_avg:423.19ms
step:144/1500 train_loss:4.7171 train_time:56707ms step_avg:423.18ms
step:145/1500 train_loss:4.8520 train_time:57129ms step_avg:423.17ms
step:146/1500 train_loss:4.7974 train_time:57552ms step_avg:423.18ms
step:147/1500 train_loss:4.6722 train_time:57974ms step_avg:423.17ms
step:148/1500 train_loss:4.8274 train_time:58398ms step_avg:423.18ms
step:149/1500 train_loss:4.8164 train_time:58820ms step_avg:423.17ms
step:150/1500 train_loss:4.8387 train_time:59244ms step_avg:423.17ms
step:151/1500 train_loss:4.8869 train_time:59668ms step_avg:423.18ms
step:152/1500 train_loss:4.7772 train_time:60092ms step_avg:423.18ms
step:153/1500 train_loss:4.7706 train_time:60515ms step_avg:423.18ms
step:154/1500 train_loss:4.8607 train_time:60939ms step_avg:423.18ms
step:155/1500 train_loss:4.8180 train_time:61363ms step_avg:423.19ms
step:156/1500 train_loss:4.7636 train_time:61787ms step_avg:423.20ms
step:157/1500 train_loss:4.7959 train_time:62211ms step_avg:423.20ms
step:158/1500 train_loss:4.9183 train_time:62640ms step_avg:423.24ms
step:159/1500 train_loss:4.7081 train_time:63062ms step_avg:423.24ms
step:160/1500 train_loss:4.7754 train_time:63485ms step_avg:423.23ms
step:161/1500 train_loss:4.6058 train_time:63907ms step_avg:423.23ms
step:162/1500 train_loss:4.7855 train_time:64335ms step_avg:423.25ms
step:163/1500 train_loss:4.8136 train_time:64758ms step_avg:423.25ms
step:164/1500 train_loss:4.8021 train_time:65180ms step_avg:423.25ms
step:165/1500 train_loss:4.6156 train_time:65606ms step_avg:423.26ms
step:166/1500 train_loss:4.7348 train_time:66028ms step_avg:423.25ms
step:167/1500 train_loss:4.8739 train_time:66449ms step_avg:423.24ms
step:168/1500 train_loss:4.6628 train_time:66873ms step_avg:423.24ms
step:169/1500 train_loss:4.7621 train_time:67296ms step_avg:423.25ms
step:170/1500 train_loss:4.6148 train_time:67719ms step_avg:423.24ms
step:171/1500 train_loss:4.5144 train_time:68143ms step_avg:423.25ms
step:172/1500 train_loss:4.6772 train_time:68565ms step_avg:423.24ms
step:173/1500 train_loss:4.6528 train_time:68989ms step_avg:423.25ms
step:174/1500 train_loss:4.7066 train_time:69413ms step_avg:423.25ms
step:175/1500 train_loss:4.8583 train_time:69836ms step_avg:423.25ms
step:176/1500 train_loss:4.7035 train_time:70260ms step_avg:423.25ms
step:177/1500 train_loss:4.5714 train_time:70682ms step_avg:423.25ms
step:178/1500 train_loss:4.5307 train_time:71104ms step_avg:423.24ms
step:179/1500 train_loss:4.6109 train_time:71525ms step_avg:423.23ms
step:180/1500 train_loss:4.6098 train_time:71949ms step_avg:423.23ms
step:181/1500 train_loss:4.6051 train_time:72372ms step_avg:423.23ms
step:182/1500 train_loss:4.7339 train_time:72795ms step_avg:423.23ms
step:183/1500 train_loss:4.6068 train_time:73218ms step_avg:423.22ms
step:184/1500 train_loss:4.5473 train_time:73639ms step_avg:423.21ms
step:185/1500 train_loss:4.5688 train_time:74062ms step_avg:423.21ms
step:186/1500 train_loss:4.6873 train_time:74486ms step_avg:423.22ms
step:187/1500 train_loss:4.6033 train_time:74908ms step_avg:423.21ms
step:188/1500 train_loss:4.7851 train_time:75340ms step_avg:423.26ms
step:189/1500 train_loss:4.6126 train_time:76598ms step_avg:427.92ms
step:190/1500 train_loss:4.5318 train_time:77204ms step_avg:428.91ms
step:191/1500 train_loss:4.6806 train_time:77626ms step_avg:428.87ms
step:192/1500 train_loss:4.5260 train_time:78048ms step_avg:428.83ms
step:193/1500 train_loss:4.4503 train_time:78471ms step_avg:428.80ms
step:194/1500 train_loss:4.6836 train_time:78892ms step_avg:428.76ms
step:195/1500 train_loss:4.5964 train_time:79315ms step_avg:428.73ms
step:196/1500 train_loss:4.7873 train_time:79740ms step_avg:428.71ms
step:197/1500 train_loss:4.6543 train_time:80161ms step_avg:428.67ms
step:198/1500 train_loss:4.4956 train_time:80584ms step_avg:428.64ms
step:199/1500 train_loss:4.5740 train_time:81006ms step_avg:428.60ms
step:200/1500 train_loss:4.4419 train_time:81428ms step_avg:428.57ms
step:201/1500 train_loss:4.5348 train_time:81851ms step_avg:428.54ms
step:202/1500 train_loss:4.4303 train_time:82273ms step_avg:428.51ms
step:203/1500 train_loss:4.6825 train_time:82696ms step_avg:428.48ms
step:204/1500 train_loss:4.5439 train_time:83119ms step_avg:428.45ms
step:205/1500 train_loss:4.5805 train_time:83544ms step_avg:428.43ms
step:206/1500 train_loss:4.6897 train_time:83965ms step_avg:428.39ms
step:207/1500 train_loss:4.3524 train_time:84388ms step_avg:428.37ms
step:208/1500 train_loss:4.5140 train_time:84812ms step_avg:428.34ms
step:209/1500 train_loss:4.4825 train_time:85237ms step_avg:428.33ms
step:210/1500 train_loss:4.6494 train_time:85659ms step_avg:428.30ms
step:211/1500 train_loss:4.5731 train_time:86083ms step_avg:428.27ms
step:212/1500 train_loss:4.4461 train_time:86504ms step_avg:428.24ms
step:213/1500 train_loss:4.5531 train_time:86929ms step_avg:428.22ms
step:214/1500 train_loss:4.4176 train_time:87352ms step_avg:428.20ms
step:215/1500 train_loss:4.4901 train_time:87775ms step_avg:428.17ms
step:216/1500 train_loss:4.3505 train_time:88198ms step_avg:428.15ms
step:217/1500 train_loss:4.4490 train_time:88620ms step_avg:428.12ms
step:218/1500 train_loss:4.4203 train_time:89043ms step_avg:428.09ms
step:219/1500 train_loss:4.4513 train_time:89465ms step_avg:428.06ms
step:220/1500 train_loss:4.4373 train_time:89888ms step_avg:428.04ms
step:221/1500 train_loss:4.4672 train_time:90310ms step_avg:428.01ms
step:222/1500 train_loss:4.4857 train_time:90738ms step_avg:428.01ms
step:223/1500 train_loss:4.4132 train_time:91162ms step_avg:427.99ms
step:224/1500 train_loss:4.4139 train_time:91585ms step_avg:427.97ms
step:225/1500 train_loss:4.6199 train_time:92007ms step_avg:427.94ms
step:226/1500 train_loss:4.2792 train_time:92435ms step_avg:427.94ms
step:227/1500 train_loss:4.3338 train_time:92859ms step_avg:427.92ms
step:228/1500 train_loss:4.3432 train_time:93282ms step_avg:427.90ms
step:229/1500 train_loss:4.4947 train_time:93704ms step_avg:427.87ms
step:230/1500 train_loss:4.2924 train_time:94127ms step_avg:427.85ms
step:231/1500 train_loss:4.4279 train_time:94549ms step_avg:427.82ms
step:232/1500 train_loss:4.2831 train_time:94971ms step_avg:427.80ms
step:233/1500 train_loss:4.3031 train_time:95394ms step_avg:427.77ms
step:234/1500 train_loss:4.4684 train_time:95817ms step_avg:427.75ms
step:235/1500 train_loss:4.3511 train_time:96240ms step_avg:427.73ms
step:236/1500 train_loss:4.2573 train_time:96664ms step_avg:427.72ms
step:237/1500 train_loss:4.4558 train_time:97086ms step_avg:427.69ms
step:238/1500 train_loss:4.4156 train_time:97509ms step_avg:427.67ms
step:239/1500 train_loss:4.2837 train_time:97939ms step_avg:427.68ms
step:240/1500 train_loss:4.4289 train_time:98363ms step_avg:427.66ms
step:241/1500 train_loss:4.4284 train_time:98786ms step_avg:427.65ms
step:242/1500 train_loss:4.3103 train_time:99208ms step_avg:427.62ms
step:243/1500 train_loss:4.4893 train_time:99638ms step_avg:427.63ms
step:244/1500 train_loss:4.3265 train_time:100061ms step_avg:427.61ms
step:245/1500 train_loss:4.3680 train_time:100484ms step_avg:427.59ms
step:246/1500 train_loss:4.4490 train_time:100908ms step_avg:427.57ms
step:247/1500 train_loss:4.3797 train_time:101335ms step_avg:427.57ms
step:248/1500 train_loss:4.3181 train_time:101756ms step_avg:427.55ms
step:249/1500 train_loss:4.4420 train_time:102180ms step_avg:427.53ms
step:250/1500 train_loss:4.2222 train_time:102603ms step_avg:427.51ms
step:250/1500 val_loss:4.3166 train_time:102607ms step_avg:427.53ms
step:251/1500 train_loss:4.2757 train_time:103028ms step_avg:427.50ms
step:252/1500 train_loss:4.3840 train_time:103451ms step_avg:427.48ms
step:253/1500 train_loss:4.4225 train_time:103873ms step_avg:427.46ms
step:254/1500 train_loss:4.2387 train_time:104296ms step_avg:427.44ms
step:255/1500 train_loss:4.1966 train_time:104718ms step_avg:427.42ms
step:256/1500 train_loss:4.3727 train_time:105140ms step_avg:427.40ms
step:257/1500 train_loss:4.2813 train_time:105562ms step_avg:427.38ms
step:258/1500 train_loss:4.2936 train_time:105985ms step_avg:427.36ms
step:259/1500 train_loss:4.2627 train_time:106405ms step_avg:427.33ms
step:260/1500 train_loss:4.3055 train_time:106828ms step_avg:427.31ms
step:261/1500 train_loss:4.3462 train_time:107249ms step_avg:427.29ms
step:262/1500 train_loss:4.2967 train_time:107671ms step_avg:427.27ms
step:263/1500 train_loss:4.2694 train_time:108097ms step_avg:427.26ms
step:264/1500 train_loss:4.1752 train_time:108518ms step_avg:427.24ms
step:265/1500 train_loss:4.2695 train_time:108938ms step_avg:427.21ms
step:266/1500 train_loss:4.1311 train_time:109361ms step_avg:427.19ms
step:267/1500 train_loss:4.1973 train_time:109786ms step_avg:427.18ms
step:268/1500 train_loss:4.2009 train_time:110208ms step_avg:427.16ms
step:269/1500 train_loss:4.2125 train_time:110631ms step_avg:427.15ms
step:270/1500 train_loss:4.1295 train_time:111053ms step_avg:427.13ms
step:271/1500 train_loss:4.3634 train_time:111475ms step_avg:427.11ms
step:272/1500 train_loss:4.2619 train_time:111897ms step_avg:427.09ms
step:273/1500 train_loss:4.1706 train_time:112319ms step_avg:427.07ms
step:274/1500 train_loss:4.2213 train_time:112744ms step_avg:427.06ms
step:275/1500 train_loss:4.3011 train_time:113165ms step_avg:427.04ms
step:276/1500 train_loss:4.3107 train_time:113586ms step_avg:427.02ms
step:277/1500 train_loss:4.5027 train_time:114009ms step_avg:427.00ms
step:278/1500 train_loss:4.2897 train_time:114432ms step_avg:426.99ms
step:279/1500 train_loss:4.3602 train_time:114854ms step_avg:426.97ms
step:280/1500 train_loss:4.2519 train_time:115276ms step_avg:426.95ms
step:281/1500 train_loss:4.4033 train_time:115699ms step_avg:426.93ms
step:282/1500 train_loss:4.2028 train_time:116122ms step_avg:426.92ms
step:283/1500 train_loss:4.2288 train_time:116544ms step_avg:426.90ms
step:284/1500 train_loss:4.1544 train_time:116966ms step_avg:426.88ms
step:285/1500 train_loss:4.3003 train_time:117389ms step_avg:426.87ms
step:286/1500 train_loss:4.3072 train_time:117812ms step_avg:426.85ms
step:287/1500 train_loss:4.3365 train_time:118234ms step_avg:426.84ms
step:288/1500 train_loss:4.1664 train_time:118656ms step_avg:426.82ms
step:289/1500 train_loss:4.2602 train_time:119077ms step_avg:426.80ms
step:290/1500 train_loss:4.1220 train_time:119500ms step_avg:426.79ms
step:291/1500 train_loss:4.1108 train_time:119922ms step_avg:426.77ms
step:292/1500 train_loss:4.1952 train_time:120346ms step_avg:426.76ms
step:293/1500 train_loss:4.1117 train_time:120769ms step_avg:426.75ms
step:294/1500 train_loss:4.1574 train_time:121201ms step_avg:426.76ms
step:295/1500 train_loss:4.1896 train_time:121622ms step_avg:426.74ms
step:296/1500 train_loss:4.0760 train_time:122045ms step_avg:426.73ms
step:297/1500 train_loss:4.0915 train_time:122468ms step_avg:426.72ms
step:298/1500 train_loss:4.0957 train_time:122893ms step_avg:426.71ms
step:299/1500 train_loss:4.2081 train_time:123314ms step_avg:426.69ms
step:300/1500 train_loss:4.0677 train_time:123737ms step_avg:426.68ms
step:301/1500 train_loss:4.2073 train_time:124159ms step_avg:426.66ms
step:302/1500 train_loss:4.2134 train_time:124581ms step_avg:426.65ms
step:303/1500 train_loss:4.1589 train_time:125003ms step_avg:426.63ms
step:304/1500 train_loss:4.2160 train_time:125426ms step_avg:426.62ms
step:305/1500 train_loss:4.1967 train_time:125849ms step_avg:426.61ms
step:306/1500 train_loss:4.6717 train_time:126270ms step_avg:426.59ms
step:307/1500 train_loss:4.1572 train_time:126697ms step_avg:426.59ms
step:308/1500 train_loss:4.0789 train_time:127121ms step_avg:426.58ms
step:309/1500 train_loss:4.2282 train_time:127542ms step_avg:426.56ms
step:310/1500 train_loss:4.0838 train_time:127964ms step_avg:426.55ms
step:311/1500 train_loss:4.3077 train_time:128386ms step_avg:426.53ms
step:312/1500 train_loss:4.1634 train_time:128808ms step_avg:426.52ms
step:313/1500 train_loss:4.0944 train_time:129229ms step_avg:426.50ms
step:314/1500 train_loss:4.1912 train_time:129651ms step_avg:426.48ms
step:315/1500 train_loss:4.3144 train_time:130074ms step_avg:426.47ms
step:316/1500 train_loss:4.1848 train_time:130499ms step_avg:426.47ms
step:317/1500 train_loss:4.0172 train_time:130922ms step_avg:426.45ms
step:318/1500 train_loss:4.0939 train_time:131344ms step_avg:426.44ms
step:319/1500 train_loss:4.1381 train_time:131766ms step_avg:426.43ms
step:320/1500 train_loss:4.1055 train_time:132187ms step_avg:426.41ms
step:321/1500 train_loss:4.2234 train_time:132611ms step_avg:426.40ms
step:322/1500 train_loss:4.1711 train_time:133033ms step_avg:426.39ms
step:323/1500 train_loss:4.1367 train_time:133454ms step_avg:426.37ms
step:324/1500 train_loss:4.2203 train_time:133876ms step_avg:426.36ms
step:325/1500 train_loss:4.1761 train_time:134298ms step_avg:426.34ms
step:326/1500 train_loss:4.2460 train_time:134720ms step_avg:426.33ms
step:327/1500 train_loss:4.1025 train_time:135141ms step_avg:426.31ms
step:328/1500 train_loss:4.5990 train_time:135562ms step_avg:426.30ms
step:329/1500 train_loss:4.2868 train_time:135985ms step_avg:426.28ms
step:330/1500 train_loss:4.0264 train_time:136406ms step_avg:426.27ms
step:331/1500 train_loss:3.9746 train_time:136828ms step_avg:426.26ms
step:332/1500 train_loss:4.1903 train_time:137251ms step_avg:426.24ms
step:333/1500 train_loss:4.1135 train_time:137673ms step_avg:426.23ms
step:334/1500 train_loss:4.0980 train_time:138098ms step_avg:426.23ms
step:335/1500 train_loss:4.0504 train_time:138521ms step_avg:426.22ms
step:336/1500 train_loss:4.2232 train_time:138944ms step_avg:426.21ms
step:337/1500 train_loss:4.1668 train_time:139366ms step_avg:426.20ms
step:338/1500 train_loss:4.6424 train_time:139789ms step_avg:426.19ms
step:339/1500 train_loss:4.1506 train_time:140211ms step_avg:426.17ms
step:340/1500 train_loss:4.0986 train_time:140632ms step_avg:426.16ms
step:341/1500 train_loss:4.1310 train_time:141054ms step_avg:426.14ms
step:342/1500 train_loss:4.0495 train_time:141476ms step_avg:426.13ms
step:343/1500 train_loss:4.0212 train_time:141898ms step_avg:426.12ms
step:344/1500 train_loss:4.0639 train_time:142321ms step_avg:426.11ms
step:345/1500 train_loss:4.1971 train_time:142742ms step_avg:426.10ms
step:346/1500 train_loss:4.0441 train_time:143165ms step_avg:426.09ms
step:347/1500 train_loss:3.9695 train_time:143589ms step_avg:426.08ms
step:348/1500 train_loss:4.0157 train_time:144010ms step_avg:426.07ms
step:349/1500 train_loss:4.0652 train_time:144431ms step_avg:426.05ms
step:350/1500 train_loss:4.0225 train_time:144853ms step_avg:426.04ms
step:351/1500 train_loss:3.7440 train_time:145274ms step_avg:426.02ms
step:352/1500 train_loss:4.0189 train_time:145698ms step_avg:426.02ms
step:353/1500 train_loss:4.3490 train_time:146121ms step_avg:426.01ms
step:354/1500 train_loss:3.8629 train_time:146542ms step_avg:425.99ms
step:355/1500 train_loss:4.1254 train_time:146966ms step_avg:425.99ms
step:356/1500 train_loss:3.9876 train_time:147388ms step_avg:425.98ms
step:357/1500 train_loss:4.0922 train_time:147808ms step_avg:425.96ms
step:358/1500 train_loss:4.0385 train_time:148229ms step_avg:425.95ms
step:359/1500 train_loss:4.0439 train_time:148651ms step_avg:425.94ms
step:360/1500 train_loss:4.0975 train_time:149074ms step_avg:425.93ms
step:361/1500 train_loss:3.6620 train_time:149497ms step_avg:425.92ms
step:362/1500 train_loss:4.2164 train_time:149919ms step_avg:425.91ms
step:363/1500 train_loss:4.1143 train_time:150340ms step_avg:425.89ms
step:364/1500 train_loss:4.0388 train_time:150762ms step_avg:425.88ms
step:365/1500 train_loss:3.9427 train_time:151185ms step_avg:425.87ms
step:366/1500 train_loss:4.1132 train_time:151606ms step_avg:425.86ms
step:367/1500 train_loss:4.0715 train_time:152030ms step_avg:425.86ms
step:368/1500 train_loss:4.0551 train_time:152453ms step_avg:425.85ms
step:369/1500 train_loss:4.0421 train_time:152874ms step_avg:425.83ms
step:370/1500 train_loss:3.9446 train_time:153298ms step_avg:425.83ms
step:371/1500 train_loss:4.0827 train_time:153731ms step_avg:425.85ms
step:372/1500 train_loss:3.9579 train_time:154153ms step_avg:425.84ms
step:373/1500 train_loss:3.8892 train_time:154575ms step_avg:425.83ms
step:374/1500 train_loss:4.1064 train_time:154998ms step_avg:425.82ms
step:375/1500 train_loss:4.0328 train_time:155420ms step_avg:425.81ms
step:375/1500 val_loss:4.0272 train_time:155424ms step_avg:425.82ms
step:376/1500 train_loss:4.0006 train_time:155845ms step_avg:425.81ms
step:377/1500 train_loss:4.0571 train_time:156266ms step_avg:425.79ms
step:378/1500 train_loss:3.9773 train_time:157260ms step_avg:427.34ms
step:379/1500 train_loss:4.0273 train_time:157680ms step_avg:427.32ms
step:380/1500 train_loss:4.0665 train_time:158268ms step_avg:427.75ms
step:381/1500 train_loss:4.1370 train_time:158690ms step_avg:427.73ms
step:382/1500 train_loss:4.0348 train_time:159110ms step_avg:427.72ms
step:383/1500 train_loss:4.0083 train_time:159531ms step_avg:427.70ms
step:384/1500 train_loss:3.9758 train_time:159959ms step_avg:427.70ms
step:385/1500 train_loss:4.0583 train_time:160381ms step_avg:427.68ms
step:386/1500 train_loss:3.9749 train_time:160804ms step_avg:427.67ms
step:387/1500 train_loss:4.0874 train_time:161226ms step_avg:427.65ms
step:388/1500 train_loss:4.2758 train_time:161649ms step_avg:427.64ms
step:389/1500 train_loss:3.9889 train_time:162071ms step_avg:427.63ms
step:390/1500 train_loss:3.9777 train_time:162494ms step_avg:427.62ms
step:391/1500 train_loss:4.0779 train_time:162916ms step_avg:427.60ms
step:392/1500 train_loss:4.0053 train_time:163339ms step_avg:427.59ms
step:393/1500 train_loss:4.1091 train_time:163762ms step_avg:427.58ms
step:394/1500 train_loss:3.9463 train_time:164184ms step_avg:427.56ms
step:395/1500 train_loss:4.0775 train_time:164606ms step_avg:427.55ms
step:396/1500 train_loss:3.8201 train_time:165029ms step_avg:427.54ms
step:397/1500 train_loss:4.0240 train_time:165450ms step_avg:427.52ms
step:398/1500 train_loss:4.0707 train_time:165873ms step_avg:427.51ms
step:399/1500 train_loss:4.0714 train_time:166297ms step_avg:427.50ms
step:400/1500 train_loss:3.9671 train_time:166719ms step_avg:427.48ms
step:401/1500 train_loss:4.0298 train_time:167140ms step_avg:427.47ms
step:402/1500 train_loss:4.0977 train_time:167563ms step_avg:427.46ms
step:403/1500 train_loss:4.0281 train_time:167985ms step_avg:427.44ms
step:404/1500 train_loss:4.1415 train_time:168408ms step_avg:427.43ms
step:405/1500 train_loss:3.8906 train_time:168830ms step_avg:427.42ms
step:406/1500 train_loss:3.9781 train_time:169255ms step_avg:427.41ms
step:407/1500 train_loss:4.2689 train_time:169675ms step_avg:427.39ms
step:408/1500 train_loss:3.9887 train_time:170098ms step_avg:427.38ms
step:409/1500 train_loss:3.9987 train_time:170521ms step_avg:427.37ms
step:410/1500 train_loss:4.0457 train_time:170946ms step_avg:427.36ms
step:411/1500 train_loss:3.9349 train_time:171367ms step_avg:427.35ms
step:412/1500 train_loss:3.9461 train_time:171788ms step_avg:427.33ms
step:413/1500 train_loss:4.3692 train_time:172211ms step_avg:427.32ms
step:414/1500 train_loss:3.8134 train_time:172632ms step_avg:427.31ms
step:415/1500 train_loss:4.2005 train_time:173059ms step_avg:427.31ms
step:416/1500 train_loss:3.9493 train_time:173480ms step_avg:427.29ms
step:417/1500 train_loss:3.9518 train_time:173905ms step_avg:427.28ms
step:418/1500 train_loss:4.1384 train_time:174325ms step_avg:427.27ms
step:419/1500 train_loss:3.8732 train_time:174747ms step_avg:427.25ms
step:420/1500 train_loss:3.9848 train_time:175170ms step_avg:427.24ms
step:421/1500 train_loss:3.9111 train_time:175592ms step_avg:427.23ms
step:422/1500 train_loss:3.8268 train_time:176014ms step_avg:427.22ms
step:423/1500 train_loss:3.9675 train_time:176437ms step_avg:427.21ms
step:424/1500 train_loss:4.0499 train_time:176859ms step_avg:427.20ms
step:425/1500 train_loss:3.8176 train_time:177279ms step_avg:427.18ms
step:426/1500 train_loss:3.9940 train_time:177702ms step_avg:427.17ms
step:427/1500 train_loss:3.8698 train_time:178123ms step_avg:427.15ms
step:428/1500 train_loss:4.0886 train_time:178544ms step_avg:427.14ms
step:429/1500 train_loss:4.0012 train_time:178968ms step_avg:427.13ms
step:430/1500 train_loss:3.9361 train_time:179389ms step_avg:427.12ms
step:431/1500 train_loss:3.9005 train_time:179812ms step_avg:427.11ms
step:432/1500 train_loss:3.8111 train_time:180233ms step_avg:427.09ms
step:433/1500 train_loss:3.9453 train_time:180657ms step_avg:427.09ms
step:434/1500 train_loss:4.0004 train_time:181079ms step_avg:427.07ms
step:435/1500 train_loss:3.9497 train_time:181501ms step_avg:427.06ms
step:436/1500 train_loss:4.0001 train_time:181925ms step_avg:427.05ms
step:437/1500 train_loss:4.0135 train_time:182345ms step_avg:427.04ms
step:438/1500 train_loss:3.8839 train_time:182769ms step_avg:427.03ms
step:439/1500 train_loss:3.9030 train_time:183192ms step_avg:427.02ms
step:440/1500 train_loss:3.8939 train_time:183615ms step_avg:427.01ms
step:441/1500 train_loss:4.0591 train_time:184036ms step_avg:427.00ms
step:442/1500 train_loss:3.9439 train_time:184459ms step_avg:426.99ms
step:443/1500 train_loss:3.9246 train_time:184880ms step_avg:426.98ms
step:444/1500 train_loss:3.8256 train_time:185301ms step_avg:426.96ms
step:445/1500 train_loss:4.0907 train_time:185724ms step_avg:426.95ms
step:446/1500 train_loss:4.0253 train_time:186148ms step_avg:426.94ms
step:447/1500 train_loss:4.0106 train_time:186572ms step_avg:426.94ms
step:448/1500 train_loss:3.9338 train_time:186994ms step_avg:426.93ms
step:449/1500 train_loss:4.0273 train_time:187417ms step_avg:426.92ms
step:450/1500 train_loss:3.8568 train_time:187840ms step_avg:426.91ms
step:451/1500 train_loss:3.8959 train_time:188260ms step_avg:426.89ms
step:452/1500 train_loss:3.7571 train_time:188682ms step_avg:426.88ms
step:453/1500 train_loss:3.8860 train_time:189106ms step_avg:426.88ms
step:454/1500 train_loss:3.8541 train_time:189526ms step_avg:426.86ms
step:455/1500 train_loss:3.8138 train_time:189947ms step_avg:426.85ms
step:456/1500 train_loss:4.0269 train_time:190370ms step_avg:426.84ms
step:457/1500 train_loss:3.9000 train_time:190792ms step_avg:426.83ms
step:458/1500 train_loss:3.9677 train_time:191212ms step_avg:426.81ms
step:459/1500 train_loss:4.0078 train_time:191634ms step_avg:426.80ms
step:460/1500 train_loss:3.8138 train_time:192058ms step_avg:426.80ms
step:461/1500 train_loss:3.9806 train_time:192481ms step_avg:426.79ms
step:462/1500 train_loss:3.8787 train_time:192905ms step_avg:426.78ms
step:463/1500 train_loss:3.8979 train_time:193326ms step_avg:426.77ms
step:464/1500 train_loss:3.9551 train_time:193746ms step_avg:426.75ms
step:465/1500 train_loss:3.8932 train_time:194167ms step_avg:426.74ms
step:466/1500 train_loss:3.8996 train_time:194589ms step_avg:426.73ms
step:467/1500 train_loss:3.9915 train_time:195011ms step_avg:426.72ms
step:468/1500 train_loss:4.0036 train_time:195433ms step_avg:426.71ms
step:469/1500 train_loss:3.9789 train_time:195858ms step_avg:426.71ms
step:470/1500 train_loss:3.8709 train_time:196279ms step_avg:426.69ms
step:471/1500 train_loss:3.9521 train_time:196702ms step_avg:426.68ms
step:472/1500 train_loss:4.0002 train_time:197124ms step_avg:426.67ms
step:473/1500 train_loss:3.9479 train_time:197546ms step_avg:426.67ms
step:474/1500 train_loss:3.9011 train_time:197970ms step_avg:426.66ms
step:475/1500 train_loss:3.7568 train_time:198392ms step_avg:426.65ms
step:476/1500 train_loss:4.2061 train_time:198815ms step_avg:426.64ms
step:477/1500 train_loss:3.9407 train_time:199237ms step_avg:426.63ms
step:478/1500 train_loss:3.7593 train_time:199659ms step_avg:426.62ms
step:479/1500 train_loss:3.9970 train_time:200080ms step_avg:426.61ms
step:480/1500 train_loss:3.9434 train_time:200503ms step_avg:426.60ms
step:481/1500 train_loss:4.0933 train_time:200924ms step_avg:426.59ms
step:482/1500 train_loss:3.8978 train_time:201346ms step_avg:426.58ms
step:483/1500 train_loss:3.7038 train_time:201769ms step_avg:426.57ms
step:484/1500 train_loss:3.9869 train_time:202190ms step_avg:426.56ms
step:485/1500 train_loss:3.8345 train_time:202611ms step_avg:426.55ms
step:486/1500 train_loss:3.8462 train_time:203034ms step_avg:426.54ms
step:487/1500 train_loss:3.7735 train_time:203459ms step_avg:426.54ms
step:488/1500 train_loss:3.8480 train_time:203882ms step_avg:426.53ms
step:489/1500 train_loss:4.0447 train_time:204303ms step_avg:426.52ms
step:490/1500 train_loss:3.8918 train_time:204724ms step_avg:426.51ms
step:491/1500 train_loss:3.7755 train_time:205145ms step_avg:426.50ms
step:492/1500 train_loss:3.7913 train_time:205567ms step_avg:426.49ms
step:493/1500 train_loss:3.9080 train_time:205990ms step_avg:426.48ms
step:494/1500 train_loss:3.7568 train_time:206411ms step_avg:426.47ms
step:495/1500 train_loss:3.8846 train_time:206834ms step_avg:426.46ms
step:496/1500 train_loss:3.8270 train_time:207258ms step_avg:426.46ms
step:497/1500 train_loss:3.7027 train_time:207679ms step_avg:426.45ms
step:498/1500 train_loss:3.9048 train_time:208102ms step_avg:426.44ms
step:499/1500 train_loss:3.9814 train_time:208525ms step_avg:426.43ms
step:500/1500 train_loss:4.0066 train_time:208946ms step_avg:426.42ms
step:500/1500 val_loss:3.8829 train_time:208950ms step_avg:426.43ms
step:501/1500 train_loss:3.9180 train_time:209371ms step_avg:426.42ms
step:502/1500 train_loss:3.9767 train_time:209793ms step_avg:426.41ms
step:503/1500 train_loss:3.9132 train_time:210214ms step_avg:426.40ms
step:504/1500 train_loss:3.9568 train_time:210637ms step_avg:426.39ms
step:505/1500 train_loss:3.9007 train_time:211059ms step_avg:426.38ms
step:506/1500 train_loss:3.9879 train_time:211481ms step_avg:426.37ms
step:507/1500 train_loss:3.8148 train_time:211903ms step_avg:426.36ms
step:508/1500 train_loss:3.9291 train_time:212325ms step_avg:426.35ms
step:509/1500 train_loss:4.0070 train_time:212744ms step_avg:426.34ms
step:510/1500 train_loss:3.9425 train_time:213167ms step_avg:426.33ms
step:511/1500 train_loss:3.7569 train_time:213589ms step_avg:426.33ms
step:512/1500 train_loss:3.9561 train_time:214016ms step_avg:426.33ms
step:513/1500 train_loss:3.8948 train_time:214437ms step_avg:426.32ms
step:514/1500 train_loss:3.8520 train_time:214860ms step_avg:426.31ms
step:515/1500 train_loss:3.9430 train_time:215280ms step_avg:426.30ms
step:516/1500 train_loss:3.9154 train_time:215701ms step_avg:426.29ms
step:517/1500 train_loss:4.2438 train_time:216122ms step_avg:426.28ms
step:518/1500 train_loss:3.8478 train_time:216544ms step_avg:426.27ms
step:519/1500 train_loss:3.9642 train_time:216965ms step_avg:426.26ms
step:520/1500 train_loss:3.8602 train_time:217391ms step_avg:426.26ms
step:521/1500 train_loss:3.8661 train_time:217815ms step_avg:426.25ms
step:522/1500 train_loss:3.8131 train_time:218236ms step_avg:426.24ms
step:523/1500 train_loss:3.8246 train_time:218657ms step_avg:426.23ms
step:524/1500 train_loss:4.4504 train_time:219080ms step_avg:426.23ms
step:525/1500 train_loss:3.9148 train_time:219503ms step_avg:426.22ms
step:526/1500 train_loss:3.8546 train_time:219925ms step_avg:426.21ms
step:527/1500 train_loss:3.8651 train_time:220346ms step_avg:426.20ms
step:528/1500 train_loss:3.8218 train_time:220768ms step_avg:426.19ms
step:529/1500 train_loss:3.7970 train_time:221189ms step_avg:426.18ms
step:530/1500 train_loss:4.0186 train_time:221614ms step_avg:426.18ms
step:531/1500 train_loss:3.8158 train_time:222036ms step_avg:426.17ms
step:532/1500 train_loss:4.0943 train_time:222457ms step_avg:426.16ms
step:533/1500 train_loss:3.9043 train_time:222878ms step_avg:426.15ms
step:534/1500 train_loss:3.8255 train_time:223300ms step_avg:426.14ms
step:535/1500 train_loss:3.8524 train_time:223722ms step_avg:426.14ms
step:536/1500 train_loss:3.7830 train_time:224143ms step_avg:426.13ms
step:537/1500 train_loss:3.9100 train_time:224564ms step_avg:426.12ms
step:538/1500 train_loss:3.8963 train_time:224986ms step_avg:426.11ms
step:539/1500 train_loss:3.8077 train_time:225410ms step_avg:426.11ms
step:540/1500 train_loss:4.2909 train_time:225832ms step_avg:426.10ms
step:541/1500 train_loss:3.8379 train_time:226255ms step_avg:426.09ms
step:542/1500 train_loss:3.9522 train_time:226677ms step_avg:426.08ms
step:543/1500 train_loss:3.7826 train_time:227097ms step_avg:426.07ms
step:544/1500 train_loss:3.7512 train_time:227519ms step_avg:426.06ms
step:545/1500 train_loss:3.8366 train_time:227939ms step_avg:426.05ms
step:546/1500 train_loss:3.7646 train_time:228360ms step_avg:426.04ms
step:547/1500 train_loss:3.8074 train_time:228780ms step_avg:426.03ms
step:548/1500 train_loss:3.8198 train_time:229201ms step_avg:426.02ms
step:549/1500 train_loss:3.7975 train_time:229625ms step_avg:426.02ms
step:550/1500 train_loss:3.8952 train_time:230049ms step_avg:426.02ms
step:551/1500 train_loss:3.7762 train_time:230469ms step_avg:426.01ms
step:552/1500 train_loss:3.7922 train_time:230891ms step_avg:426.00ms
step:553/1500 train_loss:4.1174 train_time:231314ms step_avg:425.99ms
step:554/1500 train_loss:3.9166 train_time:231735ms step_avg:425.98ms
step:555/1500 train_loss:3.8792 train_time:232157ms step_avg:425.98ms
step:556/1500 train_loss:3.8160 train_time:232579ms step_avg:425.97ms
step:557/1500 train_loss:3.8569 train_time:233001ms step_avg:425.96ms
step:558/1500 train_loss:3.5119 train_time:233423ms step_avg:425.95ms
step:559/1500 train_loss:3.7783 train_time:233844ms step_avg:425.95ms
step:560/1500 train_loss:3.8249 train_time:234265ms step_avg:425.94ms
step:561/1500 train_loss:3.8663 train_time:234686ms step_avg:425.93ms
step:562/1500 train_loss:3.7731 train_time:235114ms step_avg:425.93ms
step:563/1500 train_loss:3.7179 train_time:235536ms step_avg:425.92ms
step:564/1500 train_loss:3.9280 train_time:235957ms step_avg:425.92ms
step:565/1500 train_loss:3.7366 train_time:236381ms step_avg:425.91ms
step:566/1500 train_loss:3.8595 train_time:236805ms step_avg:425.91ms
step:567/1500 train_loss:3.8043 train_time:237865ms step_avg:427.05ms
step:568/1500 train_loss:3.7587 train_time:238286ms step_avg:427.04ms
step:569/1500 train_loss:3.8515 train_time:238712ms step_avg:427.03ms
step:570/1500 train_loss:3.8201 train_time:239300ms step_avg:427.32ms
step:571/1500 train_loss:3.8456 train_time:239722ms step_avg:427.31ms
step:572/1500 train_loss:3.9304 train_time:240143ms step_avg:427.30ms
step:573/1500 train_loss:3.8861 train_time:240563ms step_avg:427.29ms
step:574/1500 train_loss:3.8906 train_time:240984ms step_avg:427.28ms
step:575/1500 train_loss:3.9439 train_time:241405ms step_avg:427.27ms
step:576/1500 train_loss:3.8960 train_time:241826ms step_avg:427.25ms
step:577/1500 train_loss:3.9217 train_time:242250ms step_avg:427.25ms
step:578/1500 train_loss:3.8478 train_time:242672ms step_avg:427.24ms
step:579/1500 train_loss:3.8362 train_time:243093ms step_avg:427.23ms
step:580/1500 train_loss:3.8288 train_time:243515ms step_avg:427.22ms
step:581/1500 train_loss:3.7699 train_time:243937ms step_avg:427.21ms
step:582/1500 train_loss:3.7973 train_time:244360ms step_avg:427.20ms
step:583/1500 train_loss:4.0171 train_time:244781ms step_avg:427.19ms
step:584/1500 train_loss:3.7901 train_time:245202ms step_avg:427.18ms
step:585/1500 train_loss:3.7543 train_time:245623ms step_avg:427.17ms
step:586/1500 train_loss:3.9420 train_time:246044ms step_avg:427.16ms
step:587/1500 train_loss:3.6979 train_time:246465ms step_avg:427.15ms
step:588/1500 train_loss:3.8315 train_time:246887ms step_avg:427.14ms
step:589/1500 train_loss:3.8136 train_time:247313ms step_avg:427.14ms
step:590/1500 train_loss:4.1677 train_time:247734ms step_avg:427.13ms
step:591/1500 train_loss:3.9515 train_time:248155ms step_avg:427.12ms
step:592/1500 train_loss:3.6846 train_time:248577ms step_avg:427.11ms
step:593/1500 train_loss:3.7060 train_time:248998ms step_avg:427.10ms
step:594/1500 train_loss:3.6908 train_time:249419ms step_avg:427.09ms
step:595/1500 train_loss:3.7306 train_time:249840ms step_avg:427.08ms
step:596/1500 train_loss:4.1019 train_time:250263ms step_avg:427.07ms
step:597/1500 train_loss:3.8172 train_time:250683ms step_avg:427.06ms
step:598/1500 train_loss:3.7477 train_time:251105ms step_avg:427.05ms
step:599/1500 train_loss:3.8249 train_time:251526ms step_avg:427.04ms
step:600/1500 train_loss:3.6417 train_time:251951ms step_avg:427.04ms
step:601/1500 train_loss:3.7627 train_time:252373ms step_avg:427.03ms
step:602/1500 train_loss:3.8022 train_time:252794ms step_avg:427.02ms
step:603/1500 train_loss:3.8204 train_time:253217ms step_avg:427.01ms
step:604/1500 train_loss:3.9451 train_time:253639ms step_avg:427.00ms
step:605/1500 train_loss:3.8045 train_time:254062ms step_avg:426.99ms
step:606/1500 train_loss:3.7796 train_time:254483ms step_avg:426.98ms
step:607/1500 train_loss:3.7273 train_time:254904ms step_avg:426.98ms
step:608/1500 train_loss:3.9805 train_time:255325ms step_avg:426.96ms
step:609/1500 train_loss:3.8059 train_time:255746ms step_avg:426.96ms
step:610/1500 train_loss:3.7820 train_time:256168ms step_avg:426.95ms
step:611/1500 train_loss:3.8734 train_time:256589ms step_avg:426.94ms
step:612/1500 train_loss:3.7830 train_time:257014ms step_avg:426.93ms
step:613/1500 train_loss:3.7705 train_time:257437ms step_avg:426.93ms
step:614/1500 train_loss:3.9323 train_time:257858ms step_avg:426.92ms
step:615/1500 train_loss:3.8840 train_time:258280ms step_avg:426.91ms
step:616/1500 train_loss:3.8472 train_time:258702ms step_avg:426.90ms
step:617/1500 train_loss:3.7836 train_time:259123ms step_avg:426.89ms
step:618/1500 train_loss:3.7368 train_time:259545ms step_avg:426.88ms
step:619/1500 train_loss:3.8443 train_time:259966ms step_avg:426.87ms
step:620/1500 train_loss:3.7392 train_time:260387ms step_avg:426.86ms
step:621/1500 train_loss:3.7493 train_time:260814ms step_avg:426.86ms
step:622/1500 train_loss:4.0659 train_time:261237ms step_avg:426.86ms
step:623/1500 train_loss:3.7494 train_time:261659ms step_avg:426.85ms
step:624/1500 train_loss:3.7760 train_time:262081ms step_avg:426.84ms
step:625/1500 train_loss:3.8591 train_time:262502ms step_avg:426.83ms
step:625/1500 val_loss:3.7889 train_time:262506ms step_avg:426.84ms
step:626/1500 train_loss:3.8816 train_time:262927ms step_avg:426.83ms
step:627/1500 train_loss:3.9072 train_time:263348ms step_avg:426.82ms
step:628/1500 train_loss:3.8927 train_time:263774ms step_avg:426.82ms
step:629/1500 train_loss:3.9295 train_time:264195ms step_avg:426.81ms
step:630/1500 train_loss:3.7556 train_time:264617ms step_avg:426.80ms
step:631/1500 train_loss:3.8829 train_time:265039ms step_avg:426.79ms
step:632/1500 train_loss:3.9126 train_time:265461ms step_avg:426.79ms
step:633/1500 train_loss:3.8187 train_time:265882ms step_avg:426.78ms
step:634/1500 train_loss:3.7501 train_time:266306ms step_avg:426.77ms
step:635/1500 train_loss:3.8499 train_time:266727ms step_avg:426.76ms
step:636/1500 train_loss:4.1032 train_time:267148ms step_avg:426.75ms
step:637/1500 train_loss:3.6961 train_time:267576ms step_avg:426.76ms
step:638/1500 train_loss:3.5172 train_time:267998ms step_avg:426.75ms
step:639/1500 train_loss:3.7430 train_time:268420ms step_avg:426.74ms
step:640/1500 train_loss:3.7811 train_time:268841ms step_avg:426.73ms
step:641/1500 train_loss:3.7383 train_time:269264ms step_avg:426.73ms
step:642/1500 train_loss:3.7383 train_time:269686ms step_avg:426.72ms
step:643/1500 train_loss:3.7758 train_time:270107ms step_avg:426.71ms
step:644/1500 train_loss:3.7892 train_time:270535ms step_avg:426.71ms
step:645/1500 train_loss:3.7186 train_time:270958ms step_avg:426.71ms
step:646/1500 train_loss:3.9379 train_time:271378ms step_avg:426.70ms
step:647/1500 train_loss:3.8321 train_time:271799ms step_avg:426.69ms
step:648/1500 train_loss:3.8321 train_time:272223ms step_avg:426.68ms
step:649/1500 train_loss:3.8626 train_time:272645ms step_avg:426.67ms
step:650/1500 train_loss:3.9233 train_time:273067ms step_avg:426.67ms
step:651/1500 train_loss:3.7804 train_time:273488ms step_avg:426.66ms
step:652/1500 train_loss:3.9249 train_time:273911ms step_avg:426.65ms
step:653/1500 train_loss:3.7398 train_time:274335ms step_avg:426.65ms
step:654/1500 train_loss:3.8227 train_time:274756ms step_avg:426.64ms
step:655/1500 train_loss:3.5850 train_time:275179ms step_avg:426.63ms
step:656/1500 train_loss:3.7314 train_time:275601ms step_avg:426.63ms
step:657/1500 train_loss:3.7458 train_time:276022ms step_avg:426.62ms
step:658/1500 train_loss:3.6729 train_time:276443ms step_avg:426.61ms
step:659/1500 train_loss:3.8516 train_time:276868ms step_avg:426.61ms
step:660/1500 train_loss:3.7498 train_time:277289ms step_avg:426.60ms
step:661/1500 train_loss:3.8451 train_time:277709ms step_avg:426.59ms
step:662/1500 train_loss:3.9130 train_time:278131ms step_avg:426.58ms
step:663/1500 train_loss:3.8248 train_time:278552ms step_avg:426.57ms
step:664/1500 train_loss:3.7049 train_time:278976ms step_avg:426.57ms
step:665/1500 train_loss:3.7871 train_time:279398ms step_avg:426.56ms
step:666/1500 train_loss:3.6535 train_time:279819ms step_avg:426.55ms
step:667/1500 train_loss:3.9494 train_time:280241ms step_avg:426.55ms
step:668/1500 train_loss:3.7769 train_time:280663ms step_avg:426.54ms
step:669/1500 train_loss:3.7875 train_time:281085ms step_avg:426.53ms
step:670/1500 train_loss:3.6439 train_time:281506ms step_avg:426.52ms
step:671/1500 train_loss:3.7563 train_time:281927ms step_avg:426.52ms
step:672/1500 train_loss:3.7176 train_time:282351ms step_avg:426.51ms
step:673/1500 train_loss:3.7281 train_time:282774ms step_avg:426.51ms
step:674/1500 train_loss:4.0123 train_time:283197ms step_avg:426.50ms
step:675/1500 train_loss:3.8021 train_time:283619ms step_avg:426.49ms
step:676/1500 train_loss:3.8739 train_time:284039ms step_avg:426.48ms
step:677/1500 train_loss:3.6527 train_time:284460ms step_avg:426.48ms
step:678/1500 train_loss:3.7518 train_time:284881ms step_avg:426.47ms
step:679/1500 train_loss:3.6983 train_time:285302ms step_avg:426.46ms
step:680/1500 train_loss:3.8397 train_time:285724ms step_avg:426.45ms
step:681/1500 train_loss:3.7418 train_time:286145ms step_avg:426.45ms
step:682/1500 train_loss:3.7699 train_time:286566ms step_avg:426.44ms
step:683/1500 train_loss:3.8512 train_time:286987ms step_avg:426.43ms
step:684/1500 train_loss:3.8868 train_time:287409ms step_avg:426.42ms
step:685/1500 train_loss:3.7907 train_time:287830ms step_avg:426.42ms
step:686/1500 train_loss:3.8613 train_time:288252ms step_avg:426.41ms
step:687/1500 train_loss:3.7841 train_time:288676ms step_avg:426.40ms
step:688/1500 train_loss:3.8334 train_time:289098ms step_avg:426.40ms
step:689/1500 train_loss:3.4577 train_time:289519ms step_avg:426.39ms
step:690/1500 train_loss:3.5725 train_time:289941ms step_avg:426.38ms
step:691/1500 train_loss:3.7102 train_time:290363ms step_avg:426.38ms
step:692/1500 train_loss:3.5873 train_time:290785ms step_avg:426.37ms
step:693/1500 train_loss:3.7993 train_time:291207ms step_avg:426.36ms
step:694/1500 train_loss:3.8156 train_time:291629ms step_avg:426.36ms
step:695/1500 train_loss:3.7089 train_time:292052ms step_avg:426.35ms
step:696/1500 train_loss:3.6966 train_time:292475ms step_avg:426.35ms
step:697/1500 train_loss:4.0134 train_time:292897ms step_avg:426.34ms
step:698/1500 train_loss:3.7551 train_time:293320ms step_avg:426.34ms
step:699/1500 train_loss:3.7992 train_time:293742ms step_avg:426.33ms
step:700/1500 train_loss:3.9523 train_time:294163ms step_avg:426.32ms
step:701/1500 train_loss:3.7331 train_time:294587ms step_avg:426.32ms
step:702/1500 train_loss:3.6947 train_time:295009ms step_avg:426.31ms
step:703/1500 train_loss:3.6781 train_time:295432ms step_avg:426.31ms
step:704/1500 train_loss:3.6409 train_time:295854ms step_avg:426.30ms
step:705/1500 train_loss:3.7224 train_time:296277ms step_avg:426.30ms
step:706/1500 train_loss:3.7178 train_time:296698ms step_avg:426.29ms
step:707/1500 train_loss:3.7337 train_time:297120ms step_avg:426.28ms
step:708/1500 train_loss:3.8015 train_time:297543ms step_avg:426.28ms
step:709/1500 train_loss:3.7500 train_time:297964ms step_avg:426.27ms
step:710/1500 train_loss:3.7342 train_time:298387ms step_avg:426.27ms
step:711/1500 train_loss:3.6989 train_time:298809ms step_avg:426.26ms
step:712/1500 train_loss:3.7485 train_time:299231ms step_avg:426.26ms
step:713/1500 train_loss:3.8034 train_time:299654ms step_avg:426.25ms
step:714/1500 train_loss:3.8117 train_time:300076ms step_avg:426.24ms
step:715/1500 train_loss:3.7246 train_time:300497ms step_avg:426.24ms
step:716/1500 train_loss:3.7241 train_time:300918ms step_avg:426.23ms
step:717/1500 train_loss:3.7333 train_time:301340ms step_avg:426.22ms
step:718/1500 train_loss:3.8840 train_time:301762ms step_avg:426.22ms
step:719/1500 train_loss:3.7462 train_time:302185ms step_avg:426.21ms
step:720/1500 train_loss:3.8237 train_time:302606ms step_avg:426.21ms
step:721/1500 train_loss:4.0000 train_time:303028ms step_avg:426.20ms
step:722/1500 train_loss:3.6134 train_time:303450ms step_avg:426.19ms
step:723/1500 train_loss:3.8799 train_time:303876ms step_avg:426.19ms
step:724/1500 train_loss:3.9366 train_time:304298ms step_avg:426.19ms
step:725/1500 train_loss:3.7179 train_time:304720ms step_avg:426.18ms
step:726/1500 train_loss:3.7999 train_time:305140ms step_avg:426.17ms
step:727/1500 train_loss:3.6948 train_time:305561ms step_avg:426.17ms
step:728/1500 train_loss:3.7214 train_time:305983ms step_avg:426.16ms
step:729/1500 train_loss:3.8892 train_time:306408ms step_avg:426.16ms
step:730/1500 train_loss:3.8318 train_time:306831ms step_avg:426.15ms
step:731/1500 train_loss:3.8355 train_time:307252ms step_avg:426.15ms
step:732/1500 train_loss:3.7198 train_time:307676ms step_avg:426.14ms
step:733/1500 train_loss:3.7414 train_time:308098ms step_avg:426.14ms
step:734/1500 train_loss:3.9818 train_time:308518ms step_avg:426.13ms
step:735/1500 train_loss:3.7152 train_time:308938ms step_avg:426.12ms
step:736/1500 train_loss:3.7751 train_time:309361ms step_avg:426.12ms
step:737/1500 train_loss:3.8930 train_time:309783ms step_avg:426.11ms
step:738/1500 train_loss:3.8111 train_time:310206ms step_avg:426.11ms
step:739/1500 train_loss:3.7518 train_time:310627ms step_avg:426.10ms
step:740/1500 train_loss:3.6526 train_time:311049ms step_avg:426.09ms
step:741/1500 train_loss:4.2932 train_time:311477ms step_avg:426.10ms
step:742/1500 train_loss:3.6537 train_time:311897ms step_avg:426.09ms
step:743/1500 train_loss:3.7269 train_time:312319ms step_avg:426.08ms
step:744/1500 train_loss:3.7318 train_time:312741ms step_avg:426.08ms
step:745/1500 train_loss:3.7995 train_time:313161ms step_avg:426.07ms
step:746/1500 train_loss:3.7650 train_time:313582ms step_avg:426.06ms
step:747/1500 train_loss:3.7545 train_time:314004ms step_avg:426.06ms
step:748/1500 train_loss:3.7828 train_time:314427ms step_avg:426.05ms
step:749/1500 train_loss:3.7101 train_time:314850ms step_avg:426.05ms
step:750/1500 train_loss:3.7160 train_time:315276ms step_avg:426.05ms
step:750/1500 val_loss:3.7236 train_time:315279ms step_avg:426.05ms
step:751/1500 train_loss:3.7560 train_time:315699ms step_avg:426.05ms
step:752/1500 train_loss:3.7142 train_time:316121ms step_avg:426.04ms
step:753/1500 train_loss:3.7506 train_time:316544ms step_avg:426.03ms
step:754/1500 train_loss:3.7716 train_time:316965ms step_avg:426.03ms
step:755/1500 train_loss:3.7424 train_time:317388ms step_avg:426.02ms
step:756/1500 train_loss:3.8174 train_time:318351ms step_avg:426.74ms
step:757/1500 train_loss:3.6409 train_time:318771ms step_avg:426.73ms
step:758/1500 train_loss:3.8830 train_time:319193ms step_avg:426.73ms
step:759/1500 train_loss:3.8012 train_time:319612ms step_avg:426.72ms
step:760/1500 train_loss:3.7338 train_time:320204ms step_avg:426.94ms
step:761/1500 train_loss:3.8426 train_time:320629ms step_avg:426.94ms
step:762/1500 train_loss:3.5519 train_time:321053ms step_avg:426.93ms
step:763/1500 train_loss:3.7046 train_time:321475ms step_avg:426.93ms
step:764/1500 train_loss:3.8195 train_time:321897ms step_avg:426.92ms
step:765/1500 train_loss:3.4691 train_time:322319ms step_avg:426.91ms
step:766/1500 train_loss:3.8997 train_time:322739ms step_avg:426.90ms
step:767/1500 train_loss:3.7441 train_time:323161ms step_avg:426.90ms
step:768/1500 train_loss:3.7107 train_time:323583ms step_avg:426.89ms
step:769/1500 train_loss:3.7269 train_time:324005ms step_avg:426.88ms
step:770/1500 train_loss:3.7492 train_time:324433ms step_avg:426.89ms
step:771/1500 train_loss:3.8044 train_time:324855ms step_avg:426.88ms
step:772/1500 train_loss:4.0302 train_time:325276ms step_avg:426.87ms
step:773/1500 train_loss:3.6107 train_time:325698ms step_avg:426.87ms
step:774/1500 train_loss:3.7968 train_time:326121ms step_avg:426.86ms
step:775/1500 train_loss:3.7907 train_time:326542ms step_avg:426.85ms
step:776/1500 train_loss:3.7552 train_time:326964ms step_avg:426.85ms
step:777/1500 train_loss:3.5622 train_time:327385ms step_avg:426.84ms
step:778/1500 train_loss:3.5597 train_time:327807ms step_avg:426.83ms
step:779/1500 train_loss:3.6301 train_time:328233ms step_avg:426.83ms
step:780/1500 train_loss:3.7240 train_time:328654ms step_avg:426.82ms
step:781/1500 train_loss:3.7488 train_time:329075ms step_avg:426.82ms
step:782/1500 train_loss:3.8032 train_time:329497ms step_avg:426.81ms
step:783/1500 train_loss:3.7268 train_time:329918ms step_avg:426.80ms
step:784/1500 train_loss:3.7269 train_time:330340ms step_avg:426.80ms
step:785/1500 train_loss:3.7322 train_time:330764ms step_avg:426.79ms
step:786/1500 train_loss:3.7024 train_time:331188ms step_avg:426.79ms
step:787/1500 train_loss:3.6016 train_time:331609ms step_avg:426.78ms
step:788/1500 train_loss:3.8563 train_time:332035ms step_avg:426.78ms
step:789/1500 train_loss:3.6529 train_time:332457ms step_avg:426.77ms
step:790/1500 train_loss:3.7148 train_time:332878ms step_avg:426.77ms
step:791/1500 train_loss:3.7784 train_time:333298ms step_avg:426.76ms
step:792/1500 train_loss:3.9096 train_time:333719ms step_avg:426.75ms
step:793/1500 train_loss:3.9122 train_time:334142ms step_avg:426.75ms
step:794/1500 train_loss:3.6185 train_time:334563ms step_avg:426.74ms
step:795/1500 train_loss:3.7565 train_time:334986ms step_avg:426.73ms
step:796/1500 train_loss:3.8076 train_time:335407ms step_avg:426.73ms
step:797/1500 train_loss:3.9045 train_time:335833ms step_avg:426.73ms
step:798/1500 train_loss:3.6642 train_time:336255ms step_avg:426.72ms
step:799/1500 train_loss:3.8090 train_time:336677ms step_avg:426.71ms
step:800/1500 train_loss:3.7088 train_time:337100ms step_avg:426.71ms
step:801/1500 train_loss:3.6863 train_time:337520ms step_avg:426.70ms
step:802/1500 train_loss:3.7859 train_time:337940ms step_avg:426.69ms
step:803/1500 train_loss:3.6434 train_time:338364ms step_avg:426.69ms
step:804/1500 train_loss:3.6601 train_time:338786ms step_avg:426.68ms
step:805/1500 train_loss:3.7795 train_time:339208ms step_avg:426.68ms
step:806/1500 train_loss:3.6804 train_time:339635ms step_avg:426.68ms
step:807/1500 train_loss:3.6932 train_time:340056ms step_avg:426.67ms
step:808/1500 train_loss:3.7908 train_time:340477ms step_avg:426.66ms
step:809/1500 train_loss:3.7060 train_time:340897ms step_avg:426.65ms
step:810/1500 train_loss:3.6361 train_time:341320ms step_avg:426.65ms
step:811/1500 train_loss:3.7135 train_time:341742ms step_avg:426.64ms
step:812/1500 train_loss:3.7494 train_time:342164ms step_avg:426.64ms
step:813/1500 train_loss:3.7435 train_time:342585ms step_avg:426.63ms
step:814/1500 train_loss:3.7749 train_time:343005ms step_avg:426.62ms
step:815/1500 train_loss:3.7275 train_time:343431ms step_avg:426.62ms
step:816/1500 train_loss:3.7079 train_time:343854ms step_avg:426.62ms
step:817/1500 train_loss:3.8128 train_time:344277ms step_avg:426.61ms
step:818/1500 train_loss:3.9109 train_time:344697ms step_avg:426.61ms
step:819/1500 train_loss:3.6718 train_time:345120ms step_avg:426.60ms
step:820/1500 train_loss:3.8713 train_time:345541ms step_avg:426.59ms
step:821/1500 train_loss:3.6519 train_time:345962ms step_avg:426.59ms
step:822/1500 train_loss:3.6997 train_time:346387ms step_avg:426.59ms
step:823/1500 train_loss:3.8204 train_time:346807ms step_avg:426.58ms
step:824/1500 train_loss:3.7327 train_time:347232ms step_avg:426.58ms
step:825/1500 train_loss:3.6641 train_time:347657ms step_avg:426.57ms
step:826/1500 train_loss:3.7607 train_time:348076ms step_avg:426.56ms
step:827/1500 train_loss:3.6503 train_time:348498ms step_avg:426.56ms
step:828/1500 train_loss:3.8820 train_time:348920ms step_avg:426.55ms
step:829/1500 train_loss:3.7692 train_time:349340ms step_avg:426.54ms
step:830/1500 train_loss:3.8204 train_time:349763ms step_avg:426.54ms
step:831/1500 train_loss:3.6885 train_time:350184ms step_avg:426.53ms
step:832/1500 train_loss:3.7346 train_time:350604ms step_avg:426.53ms
step:833/1500 train_loss:3.6674 train_time:351029ms step_avg:426.52ms
step:834/1500 train_loss:3.7938 train_time:351450ms step_avg:426.52ms
step:835/1500 train_loss:3.6252 train_time:351872ms step_avg:426.51ms
step:836/1500 train_loss:3.6106 train_time:352295ms step_avg:426.51ms
step:837/1500 train_loss:3.8695 train_time:352716ms step_avg:426.50ms
step:838/1500 train_loss:3.5607 train_time:353138ms step_avg:426.50ms
step:839/1500 train_loss:3.7369 train_time:353560ms step_avg:426.49ms
step:840/1500 train_loss:3.5715 train_time:353980ms step_avg:426.48ms
step:841/1500 train_loss:3.6229 train_time:354406ms step_avg:426.48ms
step:842/1500 train_loss:3.7117 train_time:354834ms step_avg:426.48ms
step:843/1500 train_loss:3.7275 train_time:355256ms step_avg:426.48ms
step:844/1500 train_loss:3.7320 train_time:355679ms step_avg:426.47ms
step:845/1500 train_loss:3.5798 train_time:356101ms step_avg:426.47ms
step:846/1500 train_loss:3.8103 train_time:356524ms step_avg:426.46ms
step:847/1500 train_loss:3.6743 train_time:356945ms step_avg:426.46ms
step:848/1500 train_loss:3.6326 train_time:357369ms step_avg:426.45ms
step:849/1500 train_loss:3.7754 train_time:357790ms step_avg:426.45ms
step:850/1500 train_loss:3.6403 train_time:358213ms step_avg:426.44ms
step:851/1500 train_loss:3.5965 train_time:358635ms step_avg:426.44ms
step:852/1500 train_loss:3.8872 train_time:359057ms step_avg:426.43ms
step:853/1500 train_loss:3.5945 train_time:359480ms step_avg:426.43ms
step:854/1500 train_loss:3.7119 train_time:359902ms step_avg:426.42ms
step:855/1500 train_loss:3.7969 train_time:360325ms step_avg:426.42ms
step:856/1500 train_loss:3.6769 train_time:360746ms step_avg:426.41ms
step:857/1500 train_loss:3.6920 train_time:361168ms step_avg:426.41ms
step:858/1500 train_loss:3.7512 train_time:361590ms step_avg:426.40ms
step:859/1500 train_loss:3.6285 train_time:362012ms step_avg:426.40ms
step:860/1500 train_loss:3.7028 train_time:362434ms step_avg:426.39ms
step:861/1500 train_loss:3.7381 train_time:362855ms step_avg:426.39ms
step:862/1500 train_loss:3.7868 train_time:363278ms step_avg:426.38ms
step:863/1500 train_loss:3.7374 train_time:363700ms step_avg:426.38ms
step:864/1500 train_loss:3.7192 train_time:364122ms step_avg:426.37ms
step:865/1500 train_loss:3.5364 train_time:364544ms step_avg:426.37ms
step:866/1500 train_loss:3.7345 train_time:364967ms step_avg:426.36ms
step:867/1500 train_loss:4.0134 train_time:365389ms step_avg:426.36ms
step:868/1500 train_loss:3.5967 train_time:365810ms step_avg:426.35ms
step:869/1500 train_loss:3.7837 train_time:366234ms step_avg:426.35ms
step:870/1500 train_loss:3.7576 train_time:366655ms step_avg:426.34ms
step:871/1500 train_loss:3.6000 train_time:367077ms step_avg:426.34ms
step:872/1500 train_loss:3.5533 train_time:367499ms step_avg:426.33ms
step:873/1500 train_loss:3.8080 train_time:367921ms step_avg:426.33ms
step:874/1500 train_loss:3.5962 train_time:368343ms step_avg:426.32ms
step:875/1500 train_loss:3.3244 train_time:368765ms step_avg:426.32ms
step:875/1500 val_loss:3.6700 train_time:368768ms step_avg:426.32ms
step:876/1500 train_loss:3.7890 train_time:369186ms step_avg:426.31ms
step:877/1500 train_loss:3.5933 train_time:369609ms step_avg:426.31ms
step:878/1500 train_loss:3.7669 train_time:370031ms step_avg:426.30ms
step:879/1500 train_loss:3.6292 train_time:370451ms step_avg:426.30ms
step:880/1500 train_loss:3.8097 train_time:370873ms step_avg:426.29ms
step:881/1500 train_loss:3.4678 train_time:371295ms step_avg:426.29ms
step:882/1500 train_loss:3.6377 train_time:371717ms step_avg:426.28ms
step:883/1500 train_loss:3.8333 train_time:372139ms step_avg:426.28ms
step:884/1500 train_loss:3.9909 train_time:372562ms step_avg:426.27ms
step:885/1500 train_loss:3.7160 train_time:372986ms step_avg:426.27ms
step:886/1500 train_loss:3.6323 train_time:373406ms step_avg:426.26ms
step:887/1500 train_loss:3.7244 train_time:373827ms step_avg:426.26ms
step:888/1500 train_loss:4.2167 train_time:374250ms step_avg:426.25ms
step:889/1500 train_loss:3.9923 train_time:374670ms step_avg:426.25ms
step:890/1500 train_loss:3.6668 train_time:375092ms step_avg:426.24ms
step:891/1500 train_loss:3.6772 train_time:375513ms step_avg:426.24ms
step:892/1500 train_loss:3.4997 train_time:375935ms step_avg:426.23ms
step:893/1500 train_loss:3.8488 train_time:376355ms step_avg:426.22ms
step:894/1500 train_loss:3.5704 train_time:376777ms step_avg:426.22ms
step:895/1500 train_loss:3.8215 train_time:377199ms step_avg:426.21ms
step:896/1500 train_loss:3.8412 train_time:377620ms step_avg:426.21ms
step:897/1500 train_loss:3.6350 train_time:378042ms step_avg:426.20ms
step:898/1500 train_loss:3.6791 train_time:378464ms step_avg:426.20ms
step:899/1500 train_loss:3.7333 train_time:378885ms step_avg:426.19ms
step:900/1500 train_loss:3.6183 train_time:379306ms step_avg:426.19ms
step:901/1500 train_loss:3.5621 train_time:379728ms step_avg:426.18ms
step:902/1500 train_loss:3.7737 train_time:380151ms step_avg:426.18ms
step:903/1500 train_loss:3.7751 train_time:380572ms step_avg:426.17ms
step:904/1500 train_loss:3.6840 train_time:380993ms step_avg:426.17ms
step:905/1500 train_loss:3.6497 train_time:381415ms step_avg:426.16ms
step:906/1500 train_loss:3.6350 train_time:381836ms step_avg:426.16ms
step:907/1500 train_loss:3.8607 train_time:382258ms step_avg:426.15ms
step:908/1500 train_loss:3.6537 train_time:382686ms step_avg:426.15ms
step:909/1500 train_loss:3.6983 train_time:383109ms step_avg:426.15ms
step:910/1500 train_loss:3.6001 train_time:383532ms step_avg:426.15ms
step:911/1500 train_loss:3.6874 train_time:383954ms step_avg:426.14ms
step:912/1500 train_loss:3.7645 train_time:384376ms step_avg:426.14ms
step:913/1500 train_loss:3.7612 train_time:384798ms step_avg:426.13ms
step:914/1500 train_loss:3.6260 train_time:385220ms step_avg:426.13ms
step:915/1500 train_loss:3.8798 train_time:385642ms step_avg:426.12ms
step:916/1500 train_loss:3.6750 train_time:386063ms step_avg:426.12ms
step:917/1500 train_loss:3.7690 train_time:386486ms step_avg:426.11ms
step:918/1500 train_loss:3.7406 train_time:386908ms step_avg:426.11ms
step:919/1500 train_loss:4.9738 train_time:387330ms step_avg:426.11ms
step:920/1500 train_loss:3.6582 train_time:387752ms step_avg:426.10ms
step:921/1500 train_loss:3.7138 train_time:388173ms step_avg:426.10ms
step:922/1500 train_loss:3.6771 train_time:388595ms step_avg:426.09ms
step:923/1500 train_loss:3.7259 train_time:389015ms step_avg:426.08ms
step:924/1500 train_loss:3.7317 train_time:389437ms step_avg:426.08ms
step:925/1500 train_loss:3.8262 train_time:389859ms step_avg:426.08ms
step:926/1500 train_loss:3.8007 train_time:390285ms step_avg:426.08ms
step:927/1500 train_loss:3.6922 train_time:390708ms step_avg:426.07ms
step:928/1500 train_loss:3.6879 train_time:391129ms step_avg:426.07ms
step:929/1500 train_loss:3.9111 train_time:391551ms step_avg:426.06ms
step:930/1500 train_loss:3.7565 train_time:391974ms step_avg:426.06ms
step:931/1500 train_loss:3.5472 train_time:392395ms step_avg:426.05ms
step:932/1500 train_loss:3.6284 train_time:392817ms step_avg:426.05ms
step:933/1500 train_loss:3.8125 train_time:393239ms step_avg:426.04ms
step:934/1500 train_loss:3.5245 train_time:393661ms step_avg:426.04ms
step:935/1500 train_loss:3.7120 train_time:394087ms step_avg:426.04ms
step:936/1500 train_loss:3.5910 train_time:394510ms step_avg:426.04ms
step:937/1500 train_loss:3.6560 train_time:394933ms step_avg:426.03ms
step:938/1500 train_loss:3.7517 train_time:395354ms step_avg:426.03ms
step:939/1500 train_loss:3.6763 train_time:395777ms step_avg:426.02ms
step:940/1500 train_loss:3.8343 train_time:396199ms step_avg:426.02ms
step:941/1500 train_loss:3.6258 train_time:396620ms step_avg:426.02ms
step:942/1500 train_loss:3.6866 train_time:397041ms step_avg:426.01ms
step:943/1500 train_loss:3.4879 train_time:397462ms step_avg:426.00ms
step:944/1500 train_loss:3.8385 train_time:397887ms step_avg:426.00ms
step:945/1500 train_loss:3.5531 train_time:399197ms step_avg:426.95ms
step:946/1500 train_loss:3.5638 train_time:399618ms step_avg:426.94ms
step:947/1500 train_loss:5.1889 train_time:400039ms step_avg:426.94ms
step:948/1500 train_loss:3.7391 train_time:400463ms step_avg:426.93ms
step:949/1500 train_loss:3.6382 train_time:400887ms step_avg:426.93ms
step:950/1500 train_loss:3.5326 train_time:401478ms step_avg:427.10ms
step:951/1500 train_loss:3.5954 train_time:401899ms step_avg:427.10ms
step:952/1500 train_loss:3.5381 train_time:402321ms step_avg:427.09ms
step:953/1500 train_loss:3.6179 train_time:402743ms step_avg:427.09ms
step:954/1500 train_loss:3.6991 train_time:403163ms step_avg:427.08ms
step:955/1500 train_loss:3.5848 train_time:403586ms step_avg:427.07ms
step:956/1500 train_loss:3.6170 train_time:404009ms step_avg:427.07ms
step:957/1500 train_loss:3.5836 train_time:404432ms step_avg:427.07ms
step:958/1500 train_loss:3.6434 train_time:404854ms step_avg:427.06ms
step:959/1500 train_loss:3.6378 train_time:405275ms step_avg:427.06ms
step:960/1500 train_loss:3.6532 train_time:405697ms step_avg:427.05ms
step:961/1500 train_loss:3.5352 train_time:406118ms step_avg:427.04ms
step:962/1500 train_loss:3.7936 train_time:406540ms step_avg:427.04ms
step:963/1500 train_loss:3.7392 train_time:406963ms step_avg:427.03ms
step:964/1500 train_loss:3.5772 train_time:407385ms step_avg:427.03ms
step:965/1500 train_loss:3.5875 train_time:407807ms step_avg:427.02ms
step:966/1500 train_loss:3.6264 train_time:408227ms step_avg:427.02ms
step:967/1500 train_loss:3.8519 train_time:408649ms step_avg:427.01ms
step:968/1500 train_loss:3.6689 train_time:409070ms step_avg:427.00ms
step:969/1500 train_loss:3.6569 train_time:409492ms step_avg:427.00ms
step:970/1500 train_loss:3.7138 train_time:409913ms step_avg:426.99ms
step:971/1500 train_loss:3.5266 train_time:410334ms step_avg:426.99ms
step:972/1500 train_loss:3.6871 train_time:410756ms step_avg:426.98ms
step:973/1500 train_loss:3.6325 train_time:411182ms step_avg:426.98ms
step:974/1500 train_loss:3.6839 train_time:411604ms step_avg:426.98ms
step:975/1500 train_loss:3.7496 train_time:412024ms step_avg:426.97ms
step:976/1500 train_loss:3.6264 train_time:412446ms step_avg:426.96ms
step:977/1500 train_loss:3.8230 train_time:412869ms step_avg:426.96ms
step:978/1500 train_loss:3.7082 train_time:413292ms step_avg:426.95ms
step:979/1500 train_loss:3.5314 train_time:413714ms step_avg:426.95ms
step:980/1500 train_loss:3.8247 train_time:414137ms step_avg:426.95ms
step:981/1500 train_loss:3.5549 train_time:414560ms step_avg:426.94ms
step:982/1500 train_loss:3.7256 train_time:414986ms step_avg:426.94ms
step:983/1500 train_loss:3.6942 train_time:415409ms step_avg:426.94ms
step:984/1500 train_loss:3.6978 train_time:415832ms step_avg:426.93ms
step:985/1500 train_loss:3.6553 train_time:416253ms step_avg:426.93ms
step:986/1500 train_loss:3.7332 train_time:416677ms step_avg:426.92ms
step:987/1500 train_loss:3.5548 train_time:417098ms step_avg:426.92ms
step:988/1500 train_loss:3.6340 train_time:417519ms step_avg:426.91ms
step:989/1500 train_loss:3.6261 train_time:417942ms step_avg:426.91ms
step:990/1500 train_loss:3.5717 train_time:418366ms step_avg:426.90ms
step:991/1500 train_loss:3.7920 train_time:418787ms step_avg:426.90ms
step:992/1500 train_loss:3.6082 train_time:419210ms step_avg:426.89ms
step:993/1500 train_loss:3.5820 train_time:419634ms step_avg:426.89ms
step:994/1500 train_loss:3.6453 train_time:420055ms step_avg:426.89ms
step:995/1500 train_loss:3.7393 train_time:420476ms step_avg:426.88ms
step:996/1500 train_loss:3.6851 train_time:420898ms step_avg:426.87ms
step:997/1500 train_loss:3.5965 train_time:421320ms step_avg:426.87ms
step:998/1500 train_loss:3.9429 train_time:421740ms step_avg:426.86ms
step:999/1500 train_loss:3.6047 train_time:422163ms step_avg:426.86ms
step:1000/1500 train_loss:3.7301 train_time:422586ms step_avg:426.85ms
step:1000/1500 val_loss:3.6240 train_time:422589ms step_avg:426.86ms
step:1001/1500 train_loss:3.5987 train_time:423010ms step_avg:426.85ms
step:1002/1500 train_loss:3.6442 train_time:423433ms step_avg:426.85ms
step:1003/1500 train_loss:3.5324 train_time:423855ms step_avg:426.84ms
step:1004/1500 train_loss:3.7185 train_time:424276ms step_avg:426.84ms
step:1005/1500 train_loss:3.7664 train_time:424696ms step_avg:426.83ms
step:1006/1500 train_loss:3.5430 train_time:425118ms step_avg:426.83ms
step:1007/1500 train_loss:3.6230 train_time:425543ms step_avg:426.82ms
step:1008/1500 train_loss:3.5887 train_time:425965ms step_avg:426.82ms
step:1009/1500 train_loss:3.7113 train_time:426386ms step_avg:426.81ms
step:1010/1500 train_loss:3.8130 train_time:426807ms step_avg:426.81ms
step:1011/1500 train_loss:3.7085 train_time:427232ms step_avg:426.80ms
step:1012/1500 train_loss:3.6697 train_time:427652ms step_avg:426.80ms
step:1013/1500 train_loss:3.5311 train_time:428074ms step_avg:426.79ms
step:1014/1500 train_loss:3.6731 train_time:428495ms step_avg:426.79ms
step:1015/1500 train_loss:3.7814 train_time:428917ms step_avg:426.78ms
step:1016/1500 train_loss:3.4925 train_time:429342ms step_avg:426.78ms
step:1017/1500 train_loss:3.5874 train_time:429763ms step_avg:426.78ms
step:1018/1500 train_loss:3.5810 train_time:430185ms step_avg:426.77ms
step:1019/1500 train_loss:3.5275 train_time:430608ms step_avg:426.77ms
step:1020/1500 train_loss:3.6722 train_time:431028ms step_avg:426.76ms
step:1021/1500 train_loss:3.5821 train_time:431449ms step_avg:426.76ms
step:1022/1500 train_loss:3.5131 train_time:431872ms step_avg:426.75ms
step:1023/1500 train_loss:3.6266 train_time:432293ms step_avg:426.75ms
step:1024/1500 train_loss:3.6499 train_time:432718ms step_avg:426.74ms
step:1025/1500 train_loss:3.6295 train_time:433142ms step_avg:426.74ms
step:1026/1500 train_loss:3.6447 train_time:433563ms step_avg:426.73ms
step:1027/1500 train_loss:3.8038 train_time:433984ms step_avg:426.73ms
step:1028/1500 train_loss:3.4847 train_time:434405ms step_avg:426.72ms
step:1029/1500 train_loss:3.5481 train_time:434826ms step_avg:426.72ms
step:1030/1500 train_loss:3.4958 train_time:435247ms step_avg:426.71ms
step:1031/1500 train_loss:3.6693 train_time:435668ms step_avg:426.71ms
step:1032/1500 train_loss:3.6515 train_time:436090ms step_avg:426.70ms
step:1033/1500 train_loss:3.8313 train_time:436512ms step_avg:426.70ms
step:1034/1500 train_loss:3.6494 train_time:436937ms step_avg:426.70ms
step:1035/1500 train_loss:3.5641 train_time:437360ms step_avg:426.69ms
step:1036/1500 train_loss:3.5911 train_time:437781ms step_avg:426.69ms
step:1037/1500 train_loss:3.6483 train_time:438204ms step_avg:426.68ms
step:1038/1500 train_loss:3.9522 train_time:438626ms step_avg:426.68ms
step:1039/1500 train_loss:3.7736 train_time:439046ms step_avg:426.67ms
step:1040/1500 train_loss:3.6691 train_time:439470ms step_avg:426.67ms
step:1041/1500 train_loss:3.5621 train_time:439891ms step_avg:426.66ms
step:1042/1500 train_loss:3.6380 train_time:440313ms step_avg:426.66ms
step:1043/1500 train_loss:3.6740 train_time:440740ms step_avg:426.66ms
step:1044/1500 train_loss:3.6089 train_time:441162ms step_avg:426.66ms
step:1045/1500 train_loss:3.6128 train_time:441584ms step_avg:426.65ms
step:1046/1500 train_loss:3.6888 train_time:442006ms step_avg:426.65ms
step:1047/1500 train_loss:3.5940 train_time:442427ms step_avg:426.64ms
step:1048/1500 train_loss:3.8031 train_time:442848ms step_avg:426.64ms
step:1049/1500 train_loss:3.6537 train_time:443272ms step_avg:426.63ms
step:1050/1500 train_loss:3.5756 train_time:443693ms step_avg:426.63ms
step:1051/1500 train_loss:3.5474 train_time:444116ms step_avg:426.62ms
step:1052/1500 train_loss:3.6650 train_time:444542ms step_avg:426.62ms
step:1053/1500 train_loss:3.5378 train_time:444964ms step_avg:426.62ms
step:1054/1500 train_loss:3.8663 train_time:445385ms step_avg:426.61ms
step:1055/1500 train_loss:3.6957 train_time:445809ms step_avg:426.61ms
step:1056/1500 train_loss:3.5600 train_time:446230ms step_avg:426.61ms
step:1057/1500 train_loss:3.6558 train_time:446651ms step_avg:426.60ms
step:1058/1500 train_loss:3.7352 train_time:447071ms step_avg:426.59ms
step:1059/1500 train_loss:3.4556 train_time:447492ms step_avg:426.59ms
step:1060/1500 train_loss:3.5794 train_time:447923ms step_avg:426.59ms
step:1061/1500 train_loss:3.5964 train_time:448348ms step_avg:426.59ms
step:1062/1500 train_loss:3.5676 train_time:448772ms step_avg:426.59ms
step:1063/1500 train_loss:3.5456 train_time:449193ms step_avg:426.58ms
step:1064/1500 train_loss:3.6465 train_time:449617ms step_avg:426.58ms
step:1065/1500 train_loss:3.5470 train_time:450039ms step_avg:426.58ms
step:1066/1500 train_loss:3.5337 train_time:450460ms step_avg:426.57ms
step:1067/1500 train_loss:3.5619 train_time:450882ms step_avg:426.57ms
step:1068/1500 train_loss:3.4660 train_time:451304ms step_avg:426.56ms
step:1069/1500 train_loss:3.5831 train_time:451727ms step_avg:426.56ms
step:1070/1500 train_loss:3.4570 train_time:452152ms step_avg:426.56ms
step:1071/1500 train_loss:3.7124 train_time:452574ms step_avg:426.55ms
step:1072/1500 train_loss:3.6669 train_time:452996ms step_avg:426.55ms
step:1073/1500 train_loss:3.6117 train_time:453419ms step_avg:426.55ms
step:1074/1500 train_loss:3.6748 train_time:453842ms step_avg:426.54ms
step:1075/1500 train_loss:3.6207 train_time:454265ms step_avg:426.54ms
step:1076/1500 train_loss:3.5645 train_time:454687ms step_avg:426.54ms
step:1077/1500 train_loss:3.9571 train_time:455110ms step_avg:426.53ms
step:1078/1500 train_loss:3.6307 train_time:455533ms step_avg:426.53ms
step:1079/1500 train_loss:3.3483 train_time:455955ms step_avg:426.53ms
step:1080/1500 train_loss:3.6956 train_time:456378ms step_avg:426.52ms
step:1081/1500 train_loss:3.6073 train_time:456801ms step_avg:426.52ms
step:1082/1500 train_loss:3.6682 train_time:457223ms step_avg:426.51ms
step:1083/1500 train_loss:3.7728 train_time:457644ms step_avg:426.51ms
step:1084/1500 train_loss:3.6674 train_time:458067ms step_avg:426.51ms
step:1085/1500 train_loss:3.6421 train_time:458489ms step_avg:426.50ms
step:1086/1500 train_loss:3.6043 train_time:458911ms step_avg:426.50ms
step:1087/1500 train_loss:3.7990 train_time:459332ms step_avg:426.49ms
step:1088/1500 train_loss:3.6862 train_time:459753ms step_avg:426.49ms
step:1089/1500 train_loss:3.5207 train_time:460175ms step_avg:426.48ms
step:1090/1500 train_loss:3.5448 train_time:460597ms step_avg:426.48ms
step:1091/1500 train_loss:3.6625 train_time:461019ms step_avg:426.47ms
step:1092/1500 train_loss:3.4535 train_time:461441ms step_avg:426.47ms
step:1093/1500 train_loss:3.6517 train_time:461863ms step_avg:426.47ms
step:1094/1500 train_loss:3.7879 train_time:462286ms step_avg:426.46ms
step:1095/1500 train_loss:3.6291 train_time:462709ms step_avg:426.46ms
step:1096/1500 train_loss:3.5774 train_time:463131ms step_avg:426.46ms
step:1097/1500 train_loss:3.6076 train_time:463553ms step_avg:426.45ms
step:1098/1500 train_loss:3.6529 train_time:463974ms step_avg:426.45ms
step:1099/1500 train_loss:3.7236 train_time:464396ms step_avg:426.44ms
step:1100/1500 train_loss:3.6818 train_time:464820ms step_avg:426.44ms
step:1101/1500 train_loss:3.6118 train_time:465242ms step_avg:426.44ms
step:1102/1500 train_loss:3.4674 train_time:465664ms step_avg:426.43ms
step:1103/1500 train_loss:3.5447 train_time:466086ms step_avg:426.43ms
step:1104/1500 train_loss:3.6134 train_time:466508ms step_avg:426.42ms
step:1105/1500 train_loss:3.4936 train_time:466929ms step_avg:426.42ms
step:1106/1500 train_loss:4.2507 train_time:467351ms step_avg:426.41ms
step:1107/1500 train_loss:3.3953 train_time:467772ms step_avg:426.41ms
step:1108/1500 train_loss:3.7359 train_time:468194ms step_avg:426.41ms
step:1109/1500 train_loss:3.5267 train_time:468617ms step_avg:426.40ms
step:1110/1500 train_loss:3.6690 train_time:469042ms step_avg:426.40ms
step:1111/1500 train_loss:3.5938 train_time:469464ms step_avg:426.40ms
step:1112/1500 train_loss:3.6437 train_time:469886ms step_avg:426.39ms
step:1113/1500 train_loss:3.7362 train_time:470308ms step_avg:426.39ms
step:1114/1500 train_loss:3.5911 train_time:470729ms step_avg:426.39ms
step:1115/1500 train_loss:3.5467 train_time:471151ms step_avg:426.38ms
step:1116/1500 train_loss:3.4374 train_time:471573ms step_avg:426.38ms
step:1117/1500 train_loss:3.6057 train_time:471995ms step_avg:426.37ms
step:1118/1500 train_loss:3.7526 train_time:472418ms step_avg:426.37ms
step:1119/1500 train_loss:3.8003 train_time:472841ms step_avg:426.37ms
step:1120/1500 train_loss:3.6322 train_time:473263ms step_avg:426.36ms
step:1121/1500 train_loss:3.6628 train_time:473684ms step_avg:426.36ms
step:1122/1500 train_loss:3.5589 train_time:474108ms step_avg:426.36ms
step:1123/1500 train_loss:3.6229 train_time:474530ms step_avg:426.35ms
step:1124/1500 train_loss:3.7623 train_time:474952ms step_avg:426.35ms
step:1125/1500 train_loss:3.5236 train_time:475373ms step_avg:426.34ms
step:1125/1500 val_loss:3.5870 train_time:475377ms step_avg:426.35ms
step:1126/1500 train_loss:3.4172 train_time:475797ms step_avg:426.34ms
step:1127/1500 train_loss:3.6484 train_time:476218ms step_avg:426.34ms
step:1128/1500 train_loss:3.8658 train_time:476640ms step_avg:426.33ms
step:1129/1500 train_loss:3.4036 train_time:477063ms step_avg:426.33ms
step:1130/1500 train_loss:3.7233 train_time:477484ms step_avg:426.33ms
step:1131/1500 train_loss:3.5599 train_time:477907ms step_avg:426.32ms
step:1132/1500 train_loss:3.5861 train_time:478330ms step_avg:426.32ms
step:1133/1500 train_loss:3.5394 train_time:478751ms step_avg:426.31ms
step:1134/1500 train_loss:3.6980 train_time:479740ms step_avg:426.81ms
step:1135/1500 train_loss:3.6324 train_time:480161ms step_avg:426.81ms
step:1136/1500 train_loss:3.6868 train_time:480582ms step_avg:426.80ms
step:1137/1500 train_loss:3.7212 train_time:481004ms step_avg:426.80ms
step:1138/1500 train_loss:3.6349 train_time:481426ms step_avg:426.80ms
step:1139/1500 train_loss:3.5332 train_time:481850ms step_avg:426.79ms
step:1140/1500 train_loss:3.8352 train_time:482439ms step_avg:426.94ms
step:1141/1500 train_loss:3.6385 train_time:482862ms step_avg:426.93ms
step:1142/1500 train_loss:3.7335 train_time:483284ms step_avg:426.93ms
step:1143/1500 train_loss:3.6288 train_time:483705ms step_avg:426.92ms
step:1144/1500 train_loss:3.5378 train_time:484128ms step_avg:426.92ms
step:1145/1500 train_loss:3.6431 train_time:484552ms step_avg:426.92ms
step:1146/1500 train_loss:3.7617 train_time:484973ms step_avg:426.91ms
step:1147/1500 train_loss:3.7384 train_time:485394ms step_avg:426.91ms
step:1148/1500 train_loss:3.6475 train_time:485815ms step_avg:426.90ms
step:1149/1500 train_loss:3.6709 train_time:486236ms step_avg:426.90ms
step:1150/1500 train_loss:3.5177 train_time:486658ms step_avg:426.89ms
step:1151/1500 train_loss:3.5434 train_time:487080ms step_avg:426.89ms
step:1152/1500 train_loss:3.5081 train_time:487503ms step_avg:426.88ms
step:1153/1500 train_loss:3.6494 train_time:487925ms step_avg:426.88ms
step:1154/1500 train_loss:3.6265 train_time:488348ms step_avg:426.88ms
step:1155/1500 train_loss:3.6913 train_time:488768ms step_avg:426.87ms
step:1156/1500 train_loss:3.5340 train_time:489194ms step_avg:426.87ms
step:1157/1500 train_loss:3.7102 train_time:489615ms step_avg:426.87ms
step:1158/1500 train_loss:3.6660 train_time:490036ms step_avg:426.86ms
step:1159/1500 train_loss:3.4791 train_time:490457ms step_avg:426.86ms
step:1160/1500 train_loss:3.5139 train_time:490883ms step_avg:426.86ms
step:1161/1500 train_loss:3.5048 train_time:491306ms step_avg:426.85ms
step:1162/1500 train_loss:3.3085 train_time:491727ms step_avg:426.85ms
step:1163/1500 train_loss:3.6167 train_time:492151ms step_avg:426.84ms
step:1164/1500 train_loss:3.5890 train_time:492574ms step_avg:426.84ms
step:1165/1500 train_loss:3.4544 train_time:492995ms step_avg:426.84ms
step:1166/1500 train_loss:3.4418 train_time:493417ms step_avg:426.83ms
step:1167/1500 train_loss:3.5552 train_time:493838ms step_avg:426.83ms
step:1168/1500 train_loss:3.5666 train_time:494262ms step_avg:426.82ms
step:1169/1500 train_loss:3.8888 train_time:494682ms step_avg:426.82ms
step:1170/1500 train_loss:3.5622 train_time:495105ms step_avg:426.81ms
step:1171/1500 train_loss:3.5783 train_time:495528ms step_avg:426.81ms
step:1172/1500 train_loss:3.4800 train_time:495949ms step_avg:426.81ms
step:1173/1500 train_loss:3.5865 train_time:496371ms step_avg:426.80ms
step:1174/1500 train_loss:3.7182 train_time:496795ms step_avg:426.80ms
step:1175/1500 train_loss:3.5568 train_time:497216ms step_avg:426.80ms
step:1176/1500 train_loss:3.5754 train_time:497638ms step_avg:426.79ms
step:1177/1500 train_loss:3.6273 train_time:498060ms step_avg:426.79ms
step:1178/1500 train_loss:3.6153 train_time:498481ms step_avg:426.78ms
step:1179/1500 train_loss:3.6723 train_time:498902ms step_avg:426.78ms
step:1180/1500 train_loss:3.5720 train_time:499326ms step_avg:426.77ms
step:1181/1500 train_loss:3.5881 train_time:499748ms step_avg:426.77ms
step:1182/1500 train_loss:3.5270 train_time:500172ms step_avg:426.77ms
step:1183/1500 train_loss:3.5635 train_time:500594ms step_avg:426.76ms
step:1184/1500 train_loss:3.5129 train_time:501015ms step_avg:426.76ms
step:1185/1500 train_loss:3.6796 train_time:501436ms step_avg:426.75ms
step:1186/1500 train_loss:3.7369 train_time:501858ms step_avg:426.75ms
step:1187/1500 train_loss:3.5353 train_time:502279ms step_avg:426.75ms
step:1188/1500 train_loss:3.5936 train_time:502700ms step_avg:426.74ms
step:1189/1500 train_loss:3.6090 train_time:503121ms step_avg:426.74ms
step:1190/1500 train_loss:3.4573 train_time:503544ms step_avg:426.73ms
step:1191/1500 train_loss:3.6314 train_time:503967ms step_avg:426.73ms
step:1192/1500 train_loss:3.7688 train_time:504394ms step_avg:426.73ms
step:1193/1500 train_loss:3.5791 train_time:504813ms step_avg:426.72ms
step:1194/1500 train_loss:3.4595 train_time:505236ms step_avg:426.72ms
step:1195/1500 train_loss:3.7563 train_time:505659ms step_avg:426.72ms
step:1196/1500 train_loss:3.5536 train_time:506119ms step_avg:426.74ms
step:1197/1500 train_loss:3.5653 train_time:506540ms step_avg:426.74ms
step:1198/1500 train_loss:3.4633 train_time:506963ms step_avg:426.74ms
step:1199/1500 train_loss:3.4799 train_time:507385ms step_avg:426.73ms
step:1200/1500 train_loss:3.5278 train_time:507807ms step_avg:426.73ms
step:1201/1500 train_loss:3.6141 train_time:508232ms step_avg:426.73ms
step:1202/1500 train_loss:3.6847 train_time:508653ms step_avg:426.72ms
step:1203/1500 train_loss:3.7229 train_time:509074ms step_avg:426.72ms
step:1204/1500 train_loss:3.6015 train_time:509496ms step_avg:426.71ms
step:1205/1500 train_loss:3.5159 train_time:509918ms step_avg:426.71ms
step:1206/1500 train_loss:3.6098 train_time:510339ms step_avg:426.70ms
step:1207/1500 train_loss:3.6536 train_time:510760ms step_avg:426.70ms
step:1208/1500 train_loss:3.6994 train_time:511181ms step_avg:426.70ms
step:1209/1500 train_loss:3.5826 train_time:511603ms step_avg:426.69ms
step:1210/1500 train_loss:3.4401 train_time:512026ms step_avg:426.69ms
step:1211/1500 train_loss:3.4916 train_time:512447ms step_avg:426.68ms
step:1212/1500 train_loss:3.5832 train_time:512872ms step_avg:426.68ms
step:1213/1500 train_loss:3.6020 train_time:513296ms step_avg:426.68ms
step:1214/1500 train_loss:3.6259 train_time:513721ms step_avg:426.68ms
step:1215/1500 train_loss:3.5040 train_time:514142ms step_avg:426.67ms
step:1216/1500 train_loss:3.5786 train_time:514563ms step_avg:426.67ms
step:1217/1500 train_loss:3.5283 train_time:514985ms step_avg:426.67ms
step:1218/1500 train_loss:3.5144 train_time:515406ms step_avg:426.66ms
step:1219/1500 train_loss:3.6104 train_time:515828ms step_avg:426.66ms
step:1220/1500 train_loss:3.4441 train_time:516251ms step_avg:426.65ms
step:1221/1500 train_loss:3.6776 train_time:516673ms step_avg:426.65ms
step:1222/1500 train_loss:3.7052 train_time:517096ms step_avg:426.65ms
step:1223/1500 train_loss:3.6189 train_time:517517ms step_avg:426.64ms
step:1224/1500 train_loss:3.4838 train_time:517940ms step_avg:426.64ms
step:1225/1500 train_loss:3.4786 train_time:518362ms step_avg:426.64ms
step:1226/1500 train_loss:3.5529 train_time:518785ms step_avg:426.63ms
step:1227/1500 train_loss:3.5384 train_time:519207ms step_avg:426.63ms
step:1228/1500 train_loss:3.4771 train_time:519631ms step_avg:426.63ms
step:1229/1500 train_loss:3.6453 train_time:520053ms step_avg:426.62ms
step:1230/1500 train_loss:3.5644 train_time:520475ms step_avg:426.62ms
step:1231/1500 train_loss:3.6153 train_time:520897ms step_avg:426.61ms
step:1232/1500 train_loss:3.7801 train_time:521319ms step_avg:426.61ms
step:1233/1500 train_loss:3.6800 train_time:521740ms step_avg:426.61ms
step:1234/1500 train_loss:3.6164 train_time:522160ms step_avg:426.60ms
step:1235/1500 train_loss:3.7610 train_time:522582ms step_avg:426.60ms
step:1236/1500 train_loss:3.5268 train_time:523005ms step_avg:426.59ms
step:1237/1500 train_loss:3.4930 train_time:523427ms step_avg:426.59ms
step:1238/1500 train_loss:3.4456 train_time:523848ms step_avg:426.59ms
step:1239/1500 train_loss:3.5152 train_time:524268ms step_avg:426.58ms
step:1240/1500 train_loss:3.5285 train_time:524693ms step_avg:426.58ms
step:1241/1500 train_loss:3.5689 train_time:525115ms step_avg:426.58ms
step:1242/1500 train_loss:3.6184 train_time:525537ms step_avg:426.57ms
step:1243/1500 train_loss:3.4933 train_time:525960ms step_avg:426.57ms
step:1244/1500 train_loss:3.5887 train_time:526383ms step_avg:426.57ms
step:1245/1500 train_loss:3.6023 train_time:526806ms step_avg:426.56ms
step:1246/1500 train_loss:3.6085 train_time:527228ms step_avg:426.56ms
step:1247/1500 train_loss:3.4364 train_time:527649ms step_avg:426.56ms
step:1248/1500 train_loss:3.5764 train_time:528071ms step_avg:426.55ms
step:1249/1500 train_loss:3.6285 train_time:528493ms step_avg:426.55ms
step:1250/1500 train_loss:3.6056 train_time:528916ms step_avg:426.54ms
step:1250/1500 val_loss:3.5548 train_time:528919ms step_avg:426.55ms
step:1251/1500 train_loss:3.5123 train_time:529341ms step_avg:426.54ms
step:1252/1500 train_loss:3.7104 train_time:529763ms step_avg:426.54ms
step:1253/1500 train_loss:3.5693 train_time:530185ms step_avg:426.54ms
step:1254/1500 train_loss:3.4995 train_time:530606ms step_avg:426.53ms
step:1255/1500 train_loss:3.6411 train_time:531028ms step_avg:426.53ms
step:1256/1500 train_loss:3.6997 train_time:531451ms step_avg:426.53ms
step:1257/1500 train_loss:3.5101 train_time:531874ms step_avg:426.52ms
step:1258/1500 train_loss:3.5477 train_time:532297ms step_avg:426.52ms
step:1259/1500 train_loss:3.5955 train_time:532721ms step_avg:426.52ms
step:1260/1500 train_loss:3.5294 train_time:533148ms step_avg:426.52ms
step:1261/1500 train_loss:3.4012 train_time:533570ms step_avg:426.52ms
step:1262/1500 train_loss:3.5039 train_time:533995ms step_avg:426.51ms
step:1263/1500 train_loss:3.5784 train_time:534417ms step_avg:426.51ms
step:1264/1500 train_loss:3.4151 train_time:534838ms step_avg:426.51ms
step:1265/1500 train_loss:3.6351 train_time:535258ms step_avg:426.50ms
step:1266/1500 train_loss:3.6154 train_time:535680ms step_avg:426.50ms
step:1267/1500 train_loss:3.6206 train_time:536102ms step_avg:426.49ms
step:1268/1500 train_loss:3.5688 train_time:536524ms step_avg:426.49ms
step:1269/1500 train_loss:3.6045 train_time:536952ms step_avg:426.49ms
step:1270/1500 train_loss:3.4591 train_time:537374ms step_avg:426.49ms
step:1271/1500 train_loss:3.3100 train_time:537795ms step_avg:426.48ms
step:1272/1500 train_loss:3.5840 train_time:538217ms step_avg:426.48ms
step:1273/1500 train_loss:3.5464 train_time:538639ms step_avg:426.48ms
step:1274/1500 train_loss:3.6008 train_time:539062ms step_avg:426.47ms
step:1275/1500 train_loss:3.5510 train_time:539485ms step_avg:426.47ms
step:1276/1500 train_loss:3.6454 train_time:539906ms step_avg:426.47ms
step:1277/1500 train_loss:3.6682 train_time:540330ms step_avg:426.46ms
step:1278/1500 train_loss:3.6228 train_time:540753ms step_avg:426.46ms
step:1279/1500 train_loss:3.6183 train_time:541176ms step_avg:426.46ms
step:1280/1500 train_loss:3.4515 train_time:541598ms step_avg:426.46ms
step:1281/1500 train_loss:3.5569 train_time:542022ms step_avg:426.45ms
step:1282/1500 train_loss:3.6296 train_time:542447ms step_avg:426.45ms
step:1283/1500 train_loss:3.6621 train_time:542873ms step_avg:426.45ms
step:1284/1500 train_loss:3.5546 train_time:543295ms step_avg:426.45ms
step:1285/1500 train_loss:3.5738 train_time:543716ms step_avg:426.44ms
step:1286/1500 train_loss:3.5627 train_time:544138ms step_avg:426.44ms
step:1287/1500 train_loss:3.5371 train_time:544562ms step_avg:426.44ms
step:1288/1500 train_loss:3.6701 train_time:544983ms step_avg:426.43ms
step:1289/1500 train_loss:3.5031 train_time:545405ms step_avg:426.43ms
step:1290/1500 train_loss:3.5926 train_time:545827ms step_avg:426.43ms
step:1291/1500 train_loss:3.6574 train_time:546252ms step_avg:426.43ms
step:1292/1500 train_loss:3.5864 train_time:546674ms step_avg:426.42ms
step:1293/1500 train_loss:3.6876 train_time:547095ms step_avg:426.42ms
step:1294/1500 train_loss:3.7058 train_time:547517ms step_avg:426.42ms
step:1295/1500 train_loss:3.6644 train_time:547939ms step_avg:426.41ms
step:1296/1500 train_loss:3.4762 train_time:548360ms step_avg:426.41ms
step:1297/1500 train_loss:3.5639 train_time:548783ms step_avg:426.40ms
step:1298/1500 train_loss:3.4606 train_time:549203ms step_avg:426.40ms
step:1299/1500 train_loss:3.5258 train_time:549626ms step_avg:426.40ms
step:1300/1500 train_loss:3.6058 train_time:550050ms step_avg:426.40ms
step:1301/1500 train_loss:3.6086 train_time:550472ms step_avg:426.39ms
step:1302/1500 train_loss:3.6102 train_time:550901ms step_avg:426.39ms
step:1303/1500 train_loss:3.7679 train_time:551323ms step_avg:426.39ms
step:1304/1500 train_loss:3.5392 train_time:551750ms step_avg:426.39ms
step:1305/1500 train_loss:3.7331 train_time:552174ms step_avg:426.39ms
step:1306/1500 train_loss:3.4694 train_time:552596ms step_avg:426.39ms
step:1307/1500 train_loss:3.6648 train_time:553018ms step_avg:426.38ms
step:1308/1500 train_loss:3.6626 train_time:553442ms step_avg:426.38ms
step:1309/1500 train_loss:3.5161 train_time:553864ms step_avg:426.38ms
step:1310/1500 train_loss:3.4942 train_time:554284ms step_avg:426.37ms
step:1311/1500 train_loss:3.4921 train_time:554705ms step_avg:426.37ms
step:1312/1500 train_loss:3.4921 train_time:555127ms step_avg:426.36ms
step:1313/1500 train_loss:3.5990 train_time:555551ms step_avg:426.36ms
step:1314/1500 train_loss:3.5545 train_time:555973ms step_avg:426.36ms
step:1315/1500 train_loss:3.2702 train_time:556395ms step_avg:426.36ms
step:1316/1500 train_loss:3.5033 train_time:556818ms step_avg:426.35ms
step:1317/1500 train_loss:3.5847 train_time:557241ms step_avg:426.35ms
step:1318/1500 train_loss:3.6126 train_time:557662ms step_avg:426.35ms
step:1319/1500 train_loss:3.4968 train_time:558085ms step_avg:426.34ms
step:1320/1500 train_loss:3.6228 train_time:558508ms step_avg:426.34ms
step:1321/1500 train_loss:3.6818 train_time:558929ms step_avg:426.34ms
step:1322/1500 train_loss:3.5676 train_time:559353ms step_avg:426.34ms
step:1323/1500 train_loss:3.5180 train_time:560400ms step_avg:426.81ms
step:1324/1500 train_loss:3.5388 train_time:560822ms step_avg:426.80ms
step:1325/1500 train_loss:3.6305 train_time:561247ms step_avg:426.80ms
step:1326/1500 train_loss:3.6976 train_time:561669ms step_avg:426.80ms
step:1327/1500 train_loss:3.4394 train_time:562091ms step_avg:426.80ms
step:1328/1500 train_loss:3.3673 train_time:562514ms step_avg:426.79ms
step:1329/1500 train_loss:3.6833 train_time:562934ms step_avg:426.79ms
step:1330/1500 train_loss:3.5359 train_time:563526ms step_avg:426.91ms
step:1331/1500 train_loss:3.6493 train_time:563951ms step_avg:426.91ms
step:1332/1500 train_loss:3.5524 train_time:564375ms step_avg:426.91ms
step:1333/1500 train_loss:3.9519 train_time:564801ms step_avg:426.91ms
step:1334/1500 train_loss:3.6571 train_time:565222ms step_avg:426.90ms
step:1335/1500 train_loss:3.5662 train_time:565646ms step_avg:426.90ms
step:1336/1500 train_loss:3.5095 train_time:566069ms step_avg:426.90ms
step:1337/1500 train_loss:3.5056 train_time:566489ms step_avg:426.89ms
step:1338/1500 train_loss:3.7611 train_time:566913ms step_avg:426.89ms
step:1339/1500 train_loss:3.6989 train_time:567333ms step_avg:426.89ms
step:1340/1500 train_loss:3.5465 train_time:567757ms step_avg:426.88ms
step:1341/1500 train_loss:3.4990 train_time:568178ms step_avg:426.88ms
step:1342/1500 train_loss:3.8047 train_time:568600ms step_avg:426.88ms
step:1343/1500 train_loss:3.5793 train_time:569023ms step_avg:426.87ms
step:1344/1500 train_loss:3.5703 train_time:569450ms step_avg:426.87ms
step:1345/1500 train_loss:3.6274 train_time:569871ms step_avg:426.87ms
step:1346/1500 train_loss:3.5895 train_time:570292ms step_avg:426.87ms
step:1347/1500 train_loss:3.5002 train_time:570713ms step_avg:426.86ms
step:1348/1500 train_loss:3.4558 train_time:571135ms step_avg:426.86ms
step:1349/1500 train_loss:3.5487 train_time:571556ms step_avg:426.85ms
step:1350/1500 train_loss:3.4730 train_time:571977ms step_avg:426.85ms
step:1351/1500 train_loss:3.6051 train_time:572400ms step_avg:426.85ms
step:1352/1500 train_loss:3.4604 train_time:572823ms step_avg:426.84ms
step:1353/1500 train_loss:3.5215 train_time:573248ms step_avg:426.84ms
step:1354/1500 train_loss:3.6198 train_time:573670ms step_avg:426.84ms
step:1355/1500 train_loss:3.4662 train_time:574092ms step_avg:426.83ms
step:1356/1500 train_loss:3.3882 train_time:574513ms step_avg:426.83ms
step:1357/1500 train_loss:3.7329 train_time:574933ms step_avg:426.83ms
step:1358/1500 train_loss:3.6719 train_time:575353ms step_avg:426.82ms
step:1359/1500 train_loss:3.3859 train_time:575776ms step_avg:426.82ms
step:1360/1500 train_loss:3.6642 train_time:576200ms step_avg:426.81ms
step:1361/1500 train_loss:3.5480 train_time:576621ms step_avg:426.81ms
step:1362/1500 train_loss:3.3984 train_time:577042ms step_avg:426.81ms
step:1363/1500 train_loss:3.5923 train_time:577464ms step_avg:426.80ms
step:1364/1500 train_loss:3.4885 train_time:577885ms step_avg:426.80ms
step:1365/1500 train_loss:3.5014 train_time:578307ms step_avg:426.79ms
step:1366/1500 train_loss:3.5234 train_time:578728ms step_avg:426.79ms
step:1367/1500 train_loss:3.6235 train_time:579152ms step_avg:426.79ms
step:1368/1500 train_loss:3.6153 train_time:579574ms step_avg:426.78ms
step:1369/1500 train_loss:3.5593 train_time:579996ms step_avg:426.78ms
step:1370/1500 train_loss:3.4797 train_time:580417ms step_avg:426.78ms
step:1371/1500 train_loss:3.8037 train_time:580841ms step_avg:426.78ms
step:1372/1500 train_loss:3.5405 train_time:581263ms step_avg:426.77ms
step:1373/1500 train_loss:3.5765 train_time:581684ms step_avg:426.77ms
step:1374/1500 train_loss:3.5717 train_time:582105ms step_avg:426.76ms
step:1375/1500 train_loss:3.3720 train_time:582525ms step_avg:426.76ms
step:1375/1500 val_loss:3.5304 train_time:582534ms step_avg:426.76ms
step:1376/1500 train_loss:3.7626 train_time:582954ms step_avg:426.76ms
step:1377/1500 train_loss:3.5549 train_time:583376ms step_avg:426.76ms
step:1378/1500 train_loss:3.6952 train_time:583799ms step_avg:426.75ms
step:1379/1500 train_loss:3.7209 train_time:584222ms step_avg:426.75ms
step:1380/1500 train_loss:3.3537 train_time:584643ms step_avg:426.75ms
step:1381/1500 train_loss:3.5318 train_time:585065ms step_avg:426.74ms
step:1382/1500 train_loss:3.9550 train_time:585486ms step_avg:426.74ms
step:1383/1500 train_loss:3.4413 train_time:585909ms step_avg:426.74ms
step:1384/1500 train_loss:3.6090 train_time:586331ms step_avg:426.73ms
step:1385/1500 train_loss:3.6795 train_time:586752ms step_avg:426.73ms
step:1386/1500 train_loss:3.5900 train_time:587175ms step_avg:426.73ms
step:1387/1500 train_loss:3.5721 train_time:587597ms step_avg:426.72ms
step:1388/1500 train_loss:3.4177 train_time:588019ms step_avg:426.72ms
step:1389/1500 train_loss:3.5602 train_time:588440ms step_avg:426.71ms
step:1390/1500 train_loss:3.5282 train_time:588862ms step_avg:426.71ms
step:1391/1500 train_loss:3.7863 train_time:589282ms step_avg:426.71ms
step:1392/1500 train_loss:3.5066 train_time:589709ms step_avg:426.71ms
step:1393/1500 train_loss:3.5004 train_time:590131ms step_avg:426.70ms
step:1394/1500 train_loss:3.4654 train_time:590554ms step_avg:426.70ms
step:1395/1500 train_loss:3.7401 train_time:590976ms step_avg:426.70ms
step:1396/1500 train_loss:3.6349 train_time:591398ms step_avg:426.69ms
step:1397/1500 train_loss:3.6471 train_time:591821ms step_avg:426.69ms
step:1398/1500 train_loss:3.5130 train_time:592242ms step_avg:426.69ms
step:1399/1500 train_loss:3.4870 train_time:592663ms step_avg:426.68ms
step:1400/1500 train_loss:3.5444 train_time:593086ms step_avg:426.68ms
step:1401/1500 train_loss:3.5244 train_time:593510ms step_avg:426.68ms
step:1402/1500 train_loss:3.5497 train_time:593932ms step_avg:426.68ms
step:1403/1500 train_loss:3.5157 train_time:594355ms step_avg:426.67ms
step:1404/1500 train_loss:3.7389 train_time:594777ms step_avg:426.67ms
step:1405/1500 train_loss:3.4871 train_time:595199ms step_avg:426.67ms
step:1406/1500 train_loss:3.5334 train_time:595621ms step_avg:426.66ms
step:1407/1500 train_loss:3.5356 train_time:596042ms step_avg:426.66ms
step:1408/1500 train_loss:3.3947 train_time:596465ms step_avg:426.66ms
step:1409/1500 train_loss:3.5220 train_time:596890ms step_avg:426.65ms
step:1410/1500 train_loss:3.5029 train_time:597312ms step_avg:426.65ms
step:1411/1500 train_loss:3.4995 train_time:597734ms step_avg:426.65ms
step:1412/1500 train_loss:3.5876 train_time:598157ms step_avg:426.65ms
step:1413/1500 train_loss:3.5244 train_time:598578ms step_avg:426.64ms
step:1414/1500 train_loss:3.5711 train_time:598999ms step_avg:426.64ms
step:1415/1500 train_loss:3.5603 train_time:599420ms step_avg:426.63ms
step:1416/1500 train_loss:3.6379 train_time:599841ms step_avg:426.63ms
step:1417/1500 train_loss:3.4439 train_time:600265ms step_avg:426.63ms
step:1418/1500 train_loss:3.5071 train_time:600687ms step_avg:426.62ms
step:1419/1500 train_loss:3.5997 train_time:601110ms step_avg:426.62ms
step:1420/1500 train_loss:3.6204 train_time:601533ms step_avg:426.62ms
step:1421/1500 train_loss:3.6114 train_time:601956ms step_avg:426.62ms
step:1422/1500 train_loss:3.5879 train_time:602377ms step_avg:426.61ms
step:1423/1500 train_loss:3.5580 train_time:602798ms step_avg:426.61ms
step:1424/1500 train_loss:3.5572 train_time:603220ms step_avg:426.61ms
step:1425/1500 train_loss:3.5599 train_time:603641ms step_avg:426.60ms
step:1426/1500 train_loss:3.4254 train_time:604065ms step_avg:426.60ms
step:1427/1500 train_loss:3.5396 train_time:604487ms step_avg:426.60ms
step:1428/1500 train_loss:3.4905 train_time:604909ms step_avg:426.59ms
step:1429/1500 train_loss:3.5982 train_time:605331ms step_avg:426.59ms
step:1430/1500 train_loss:3.5611 train_time:605753ms step_avg:426.59ms
step:1431/1500 train_loss:3.4912 train_time:606174ms step_avg:426.58ms
step:1432/1500 train_loss:3.5391 train_time:606598ms step_avg:426.58ms
step:1433/1500 train_loss:3.5722 train_time:607019ms step_avg:426.58ms
step:1434/1500 train_loss:3.3889 train_time:607441ms step_avg:426.57ms
step:1435/1500 train_loss:3.5437 train_time:607863ms step_avg:426.57ms
step:1436/1500 train_loss:3.3617 train_time:608283ms step_avg:426.57ms
step:1437/1500 train_loss:3.4389 train_time:608709ms step_avg:426.57ms
step:1438/1500 train_loss:3.6281 train_time:609131ms step_avg:426.56ms
step:1439/1500 train_loss:3.5863 train_time:609553ms step_avg:426.56ms
step:1440/1500 train_loss:3.5349 train_time:609974ms step_avg:426.56ms
step:1441/1500 train_loss:3.3972 train_time:610396ms step_avg:426.55ms
step:1442/1500 train_loss:3.5702 train_time:610819ms step_avg:426.55ms
step:1443/1500 train_loss:3.6284 train_time:611241ms step_avg:426.55ms
step:1444/1500 train_loss:3.7045 train_time:611663ms step_avg:426.54ms
step:1445/1500 train_loss:3.6733 train_time:612086ms step_avg:426.54ms
step:1446/1500 train_loss:3.5540 train_time:612508ms step_avg:426.54ms
step:1447/1500 train_loss:3.4270 train_time:612929ms step_avg:426.53ms
step:1448/1500 train_loss:3.5011 train_time:613353ms step_avg:426.53ms
step:1449/1500 train_loss:3.5185 train_time:613774ms step_avg:426.53ms
step:1450/1500 train_loss:3.6350 train_time:614196ms step_avg:426.52ms
step:1451/1500 train_loss:3.6323 train_time:614619ms step_avg:426.52ms
step:1452/1500 train_loss:3.4408 train_time:615039ms step_avg:426.52ms
step:1453/1500 train_loss:3.5590 train_time:615460ms step_avg:426.51ms
step:1454/1500 train_loss:3.4763 train_time:615882ms step_avg:426.51ms
step:1455/1500 train_loss:3.5059 train_time:616309ms step_avg:426.51ms
step:1456/1500 train_loss:3.5521 train_time:616740ms step_avg:426.51ms
step:1457/1500 train_loss:3.4875 train_time:617161ms step_avg:426.51ms
step:1458/1500 train_loss:3.3833 train_time:617583ms step_avg:426.51ms
step:1459/1500 train_loss:3.6245 train_time:618010ms step_avg:426.51ms
step:1460/1500 train_loss:3.4915 train_time:618433ms step_avg:426.51ms
step:1461/1500 train_loss:3.5455 train_time:618854ms step_avg:426.50ms
step:1462/1500 train_loss:3.6741 train_time:619275ms step_avg:426.50ms
step:1463/1500 train_loss:3.4889 train_time:619698ms step_avg:426.50ms
step:1464/1500 train_loss:3.6813 train_time:620121ms step_avg:426.49ms
step:1465/1500 train_loss:3.5739 train_time:620543ms step_avg:426.49ms
step:1466/1500 train_loss:3.5735 train_time:620966ms step_avg:426.49ms
step:1467/1500 train_loss:3.4994 train_time:621387ms step_avg:426.48ms
step:1468/1500 train_loss:3.6547 train_time:621810ms step_avg:426.48ms
step:1469/1500 train_loss:3.5253 train_time:622233ms step_avg:426.48ms
step:1470/1500 train_loss:3.4957 train_time:622656ms step_avg:426.48ms
step:1471/1500 train_loss:3.5453 train_time:623079ms step_avg:426.47ms
step:1472/1500 train_loss:3.4740 train_time:623506ms step_avg:426.47ms
step:1473/1500 train_loss:3.5741 train_time:623930ms step_avg:426.47ms
step:1474/1500 train_loss:3.6561 train_time:624352ms step_avg:426.47ms
step:1475/1500 train_loss:3.5360 train_time:624776ms step_avg:426.47ms
step:1476/1500 train_loss:3.3639 train_time:625198ms step_avg:426.47ms
step:1477/1500 train_loss:3.4803 train_time:625620ms step_avg:426.46ms
step:1478/1500 train_loss:3.4555 train_time:626043ms step_avg:426.46ms
step:1479/1500 train_loss:3.5460 train_time:626465ms step_avg:426.46ms
step:1480/1500 train_loss:3.6258 train_time:626885ms step_avg:426.45ms
step:1481/1500 train_loss:3.4911 train_time:627311ms step_avg:426.45ms
step:1482/1500 train_loss:3.6688 train_time:627730ms step_avg:426.45ms
step:1483/1500 train_loss:3.6021 train_time:628153ms step_avg:426.44ms
step:1484/1500 train_loss:3.5025 train_time:628575ms step_avg:426.44ms
step:1485/1500 train_loss:3.4805 train_time:628997ms step_avg:426.44ms
step:1486/1500 train_loss:3.4912 train_time:629420ms step_avg:426.44ms
step:1487/1500 train_loss:3.4632 train_time:629841ms step_avg:426.43ms
step:1488/1500 train_loss:3.5499 train_time:630264ms step_avg:426.43ms
step:1489/1500 train_loss:3.4676 train_time:630687ms step_avg:426.43ms
step:1490/1500 train_loss:3.5483 train_time:631109ms step_avg:426.43ms
step:1491/1500 train_loss:3.4843 train_time:631533ms step_avg:426.42ms
step:1492/1500 train_loss:3.4111 train_time:631954ms step_avg:426.42ms
step:1493/1500 train_loss:3.4825 train_time:632377ms step_avg:426.42ms
step:1494/1500 train_loss:3.6625 train_time:632800ms step_avg:426.42ms
step:1495/1500 train_loss:3.5141 train_time:633222ms step_avg:426.41ms
step:1496/1500 train_loss:3.2732 train_time:633643ms step_avg:426.41ms
step:1497/1500 train_loss:3.5806 train_time:634066ms step_avg:426.41ms
step:1498/1500 train_loss:3.5375 train_time:634488ms step_avg:426.40ms
step:1499/1500 train_loss:3.5876 train_time:634909ms step_avg:426.40ms
step:1500/1500 train_loss:3.5409 train_time:635330ms step_avg:426.40ms
step:1500/1500 val_loss:3.5153 train_time:635334ms step_avg:426.40ms
