====================================================================================================
# NOTE: record from https://github.com/KellerJordan/modded-nanogpt/blob/master/records/track_1_short/2024-10-14_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt
# ====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
import json
import dataclasses
import subprocess
import csv
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \\sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=3e-4, momentum=0.95, nesterov=True, backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]
            for p in group['params']:
                g = p.grad
                if g is None:
                    continue
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.mul_(momentum).add_(g)
                if group['nesterov']:
                    g = g.add(buf, alpha=momentum)
                if g.size(0) == 3 * g.size(1): # split grouped QKV parameters
                    g = torch.cat([zeropower_backend(g1, steps=group['backend_steps']) for g1 in g.split(g.size(1))])
                    scale = g.size(1)**0.5
                else:
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    scale = max(g.size(0), g.size(1))**0.5 # scale to have update.square().mean() == 1
                p.data.add_(g, alpha=-lr * scale)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

def _apply_gate_act(logits: torch.Tensor, kind: str) -> torch.Tensor:
    if kind == "sigmoid":
        return torch.sigmoid(logits)
    if kind == "ns_sigmoid":
        return 0.5 + 0.5 * torch.sigmoid(logits)
    raise ValueError(f"unknown gate_act={kind}")

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.attn_gate = getattr(config, "attn_gate", "none")
        self.gate_pos = getattr(config, "gate_pos", "sdpa")
        self.gate_act = getattr(config, "gate_act", "sigmoid")
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)
        if self.attn_gate == "headwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_head, bias=False)
            self.gate_param = None
        elif self.attn_gate == "elementwise":
            self.c_gate = nn.Linear(self.n_embd, self.n_embd, bias=False)
            self.gate_param = None
        elif self.attn_gate == "const":
            self.c_gate = None
            self.gate_param = nn.Parameter(torch.zeros(self.n_head, self.head_dim))
        else:
            self.c_gate = None
            self.gate_param = None

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        if self.attn_gate != "none" and self.gate_pos == "value":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            v = v * gate
        cos, sin = self.rotary(q)
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2) # (B, T, n_head, head_dim)
        if self.attn_gate != "none" and self.gate_pos == "sdpa":
            if self.attn_gate == "const":
                gate = _apply_gate_act(self.gate_param, self.gate_act)[None, None, :, :]
            else:
                gate_logits = self.c_gate(x)
                gate = _apply_gate_act(gate_logits, self.gate_act)
                if self.attn_gate == "headwise":
                    gate = gate.view(B, T, self.n_head, 1)
                else:
                    gate = gate.view(B, T, self.n_head, self.head_dim)
            y = y * gate
        y = y.contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768
    attn_gate : str = "none"
    gate_pos : str = "sdpa"
    gate_act : str = "sigmoid"

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying

    def forward(self, idx, targets=None, return_logits=True):

        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8*64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 5100 # number of iterations to run
    learning_rate : float = 0.0036
    warmup_iters : int = 0
    warmdown_iters : int = 1450 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    seed : int = 1337
    attn_gate : str = "none" # none|headwise|elementwise|const
    gate_pos : str = "sdpa" # sdpa|value
    gate_act : str = "sigmoid" # sigmoid|ns_sigmoid
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

def apply_env_overrides():
    # environment-variable overrides allow quick sweeps without editing code
    args.learning_rate = float(os.environ.get("LR", args.learning_rate))
    args.seed = int(os.environ.get("SEED", args.seed))
    args.attn_gate = os.environ.get("ATTNGATE", args.attn_gate)
    args.gate_pos = os.environ.get("GATEPOS", args.gate_pos)
    args.gate_act = os.environ.get("GATEACT", args.gate_act)
    args.num_iterations = int(os.environ.get("NUM_ITER", args.num_iterations))
    args.val_loss_every = int(os.environ.get("VAL_EVERY", args.val_loss_every))

def get_git_commit():
    try:
        return subprocess.check_output(["git", "rev-parse", "HEAD"], text=True).strip()
    except Exception:
        return "unknown"

apply_env_overrides()
torch.manual_seed(args.seed)
torch.cuda.manual_seed_all(args.seed)
np.random.seed(args.seed)

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.
git_commit = get_git_commit() if master_process else "unknown"

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(
    vocab_size=num_vocab,
    n_layer=12,
    n_head=6,
    n_embd=768,
    attn_gate=args.attn_gate,
    gate_pos=args.gate_pos,
    gate_act=args.gate_act,
))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
optimizer1 = torch.optim.AdamW(raw_model.lm_head.parameters(), lr=args.learning_rate, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer2 = Muon(raw_model.transformer.h.parameters(), lr=0.1*args.learning_rate, momentum=0.95)
optimizers = [optimizer1, optimizer2]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        f.write(f"git_commit: {git_commit}\n")
        f.write(f"seed: {args.seed}\n")
        f.write("hyperparameters:\n")
        f.write(json.dumps(dataclasses.asdict(args), indent=2))
        f.write("\n")
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')

training_time_ms = 0
best_val_loss = float("inf")
final_val_loss = None
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        val_loss_item = val_loss.item()
        final_val_loss = val_loss_item
        best_val_loss = min(best_val_loss, val_loss_item)
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss_item:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms\n')
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            _, loss = model(x, y, return_logits=False)
            train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process:
        approx_time = training_time_ms + 1000 * (time.time() - t0)
        print(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")
        with open(logfile, "a") as f:
            f.write(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms\n")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")
    timed_steps_final = max(args.num_iterations - 9, 1)
    ms_per_step = training_time_ms / timed_steps_final
    os.makedirs("experiments", exist_ok=True)
    results_path = os.path.join("experiments", "results.csv")
    fieldnames = [
        "run_id",
        "date",
        "git_commit",
        "seed",
        "attn_gate",
        "gate_pos",
        "gate_act",
        "learning_rate",
        "batch_size",
        "device_batch_size",
        "sequence_length",
        "num_iterations",
        "warmdown_iters",
        "final_val_loss",
        "best_val_loss",
        "train_time_ms",
        "ms_per_step",
        "gpu_name",
        "n_gpus",
        "runpod_instance",
        "notes",
    ]
    final_loss_value = final_val_loss if final_val_loss is not None else float("nan")
    best_loss_value = best_val_loss if best_val_loss < float("inf") else float("nan")
    row = {
        "run_id": run_id,
        "date": time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime()),
        "git_commit": git_commit,
        "seed": args.seed,
        "attn_gate": args.attn_gate,
        "gate_pos": args.gate_pos,
        "gate_act": args.gate_act,
        "learning_rate": args.learning_rate,
        "batch_size": args.batch_size,
        "device_batch_size": args.device_batch_size,
        "sequence_length": args.sequence_length,
        "num_iterations": args.num_iterations,
        "warmdown_iters": args.warmdown_iters,
        "final_val_loss": final_loss_value,
        "best_val_loss": best_loss_value,
        "train_time_ms": training_time_ms,
        "ms_per_step": ms_per_step,
        "gpu_name": torch.cuda.get_device_name(ddp_local_rank),
        "n_gpus": ddp_world_size,
        "runpod_instance": os.environ.get("RUNPOD_INSTANCE_TYPE", "unknown"),
        "notes": "",
    }
    write_header = not os.path.exists(results_path)
    with open(results_path, "a", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if write_header:
            writer.writeheader()
        writer.writerow(row)
====================================================================================================
git_commit: 21aae13b20675947154a15b640706eb3a47e5fcd
seed: 1337
hyperparameters:
{
  "input_bin": "data/fineweb10B/fineweb_train_*.bin",
  "input_val_bin": "data/fineweb10B/fineweb_val_*.bin",
  "batch_size": 512,
  "device_batch_size": 64,
  "sequence_length": 1024,
  "num_iterations": 1500,
  "learning_rate": 0.0036,
  "warmup_iters": 0,
  "warmdown_iters": 1450,
  "weight_decay": 0,
  "seed": 1337,
  "attn_gate": "headwise",
  "gate_pos": "sdpa",
  "gate_act": "sigmoid",
  "val_loss_every": 125,
  "val_tokens": 10485760,
  "save_every": 0
}
Running pytorch 2.8.0+cu128 compiled for CUDA 12.8
nvidia-smi:
Sun Dec  7 09:55:35 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:00:07.0 Off |                    0 |
| N/A   46C    P0            117W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          On  |   00000000:00:08.0 Off |                    0 |
| N/A   48C    P0            118W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100 80GB PCIe          On  |   00000000:00:09.0 Off |                    0 |
| N/A   43C    P0            108W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100 80GB PCIe          On  |   00000000:00:0A.0 Off |                    0 |
| N/A   45C    P0            110W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100 80GB PCIe          On  |   00000000:00:0B.0 Off |                    0 |
| N/A   48C    P0            115W /  300W |    2182MiB /  81920MiB |     18%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100 80GB PCIe          On  |   00000000:00:0C.0 Off |                    0 |
| N/A   45C    P0            142W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100 80GB PCIe          On  |   00000000:00:0D.0 Off |                    0 |
| N/A   47C    P0            120W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100 80GB PCIe          On  |   00000000:00:0E.0 Off |                    0 |
| N/A   46C    P0            112W /  300W |    2182MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1500 val_loss:15.9616 train_time:329ms step_avg:nanms
step:1/1500 train_loss:15.9512 train_time:69120ms step_avg:nanms
step:2/1500 train_loss:9.5078 train_time:69517ms step_avg:nanms
step:3/1500 train_loss:8.6369 train_time:69919ms step_avg:nanms
step:4/1500 train_loss:7.9071 train_time:70318ms step_avg:nanms
step:5/1500 train_loss:7.5316 train_time:70718ms step_avg:nanms
step:6/1500 train_loss:7.4460 train_time:71120ms step_avg:nanms
step:7/1500 train_loss:7.0815 train_time:71521ms step_avg:nanms
step:8/1500 train_loss:7.3246 train_time:71923ms step_avg:nanms
step:9/1500 train_loss:7.0533 train_time:72323ms step_avg:nanms
step:10/1500 train_loss:6.9158 train_time:72725ms step_avg:nanms
step:11/1500 train_loss:6.7821 train_time:390ms step_avg:nanms
step:12/1500 train_loss:6.7320 train_time:792ms step_avg:nanms
step:13/1500 train_loss:6.5369 train_time:1194ms step_avg:398.03ms
step:14/1500 train_loss:6.5285 train_time:1596ms step_avg:399.02ms
step:15/1500 train_loss:6.4964 train_time:1998ms step_avg:399.52ms
step:16/1500 train_loss:6.4437 train_time:2399ms step_avg:399.81ms
step:17/1500 train_loss:6.4570 train_time:2802ms step_avg:400.27ms
step:18/1500 train_loss:6.4915 train_time:3203ms step_avg:400.41ms
step:19/1500 train_loss:6.3092 train_time:3604ms step_avg:400.48ms
step:20/1500 train_loss:6.3365 train_time:4009ms step_avg:400.89ms
step:21/1500 train_loss:6.0154 train_time:4411ms step_avg:401.00ms
step:22/1500 train_loss:6.3653 train_time:4814ms step_avg:401.15ms
step:23/1500 train_loss:6.5852 train_time:5217ms step_avg:401.28ms
step:24/1500 train_loss:6.2723 train_time:5620ms step_avg:401.42ms
step:25/1500 train_loss:6.4064 train_time:6023ms step_avg:401.53ms
step:26/1500 train_loss:6.1176 train_time:6426ms step_avg:401.63ms
step:27/1500 train_loss:6.0357 train_time:6828ms step_avg:401.65ms
step:28/1500 train_loss:6.1744 train_time:7231ms step_avg:401.74ms
step:29/1500 train_loss:5.8597 train_time:7635ms step_avg:401.86ms
step:30/1500 train_loss:6.1423 train_time:8039ms step_avg:401.93ms
step:31/1500 train_loss:5.9702 train_time:8443ms step_avg:402.03ms
step:32/1500 train_loss:5.9487 train_time:8846ms step_avg:402.09ms
step:33/1500 train_loss:5.7755 train_time:9248ms step_avg:402.08ms
step:34/1500 train_loss:6.0533 train_time:9649ms step_avg:402.04ms
step:35/1500 train_loss:5.9903 train_time:10052ms step_avg:402.07ms
step:36/1500 train_loss:6.1348 train_time:10454ms step_avg:402.08ms
step:37/1500 train_loss:6.0693 train_time:10857ms step_avg:402.10ms
step:38/1500 train_loss:5.9727 train_time:11260ms step_avg:402.14ms
step:39/1500 train_loss:5.8477 train_time:11662ms step_avg:402.13ms
step:40/1500 train_loss:5.8699 train_time:12065ms step_avg:402.17ms
step:41/1500 train_loss:5.7900 train_time:12468ms step_avg:402.19ms
step:42/1500 train_loss:5.8082 train_time:12872ms step_avg:402.25ms
step:43/1500 train_loss:5.7012 train_time:13276ms step_avg:402.31ms
step:44/1500 train_loss:5.7947 train_time:13680ms step_avg:402.34ms
step:45/1500 train_loss:5.7651 train_time:14084ms step_avg:402.40ms
step:46/1500 train_loss:5.9147 train_time:14489ms step_avg:402.46ms
step:47/1500 train_loss:5.7107 train_time:14892ms step_avg:402.49ms
step:48/1500 train_loss:5.5841 train_time:15296ms step_avg:402.52ms
step:49/1500 train_loss:5.7857 train_time:15700ms step_avg:402.55ms
step:50/1500 train_loss:5.6844 train_time:16104ms step_avg:402.61ms
step:51/1500 train_loss:5.8180 train_time:16507ms step_avg:402.61ms
step:52/1500 train_loss:5.6819 train_time:16910ms step_avg:402.62ms
step:53/1500 train_loss:5.5526 train_time:17312ms step_avg:402.61ms
step:54/1500 train_loss:5.6821 train_time:17715ms step_avg:402.61ms
step:55/1500 train_loss:5.5535 train_time:18121ms step_avg:402.68ms
step:56/1500 train_loss:5.8942 train_time:18523ms step_avg:402.66ms
step:57/1500 train_loss:5.5562 train_time:18924ms step_avg:402.64ms
step:58/1500 train_loss:5.4289 train_time:19327ms step_avg:402.65ms
step:59/1500 train_loss:5.5645 train_time:19730ms step_avg:402.65ms
step:60/1500 train_loss:5.5435 train_time:20133ms step_avg:402.67ms
step:61/1500 train_loss:5.6426 train_time:20536ms step_avg:402.67ms
step:62/1500 train_loss:5.4140 train_time:20940ms step_avg:402.69ms
step:63/1500 train_loss:5.5172 train_time:21343ms step_avg:402.70ms
step:64/1500 train_loss:5.4948 train_time:21746ms step_avg:402.71ms
step:65/1500 train_loss:5.1555 train_time:22152ms step_avg:402.76ms
step:66/1500 train_loss:5.2982 train_time:22555ms step_avg:402.77ms
step:67/1500 train_loss:5.4670 train_time:22961ms step_avg:402.83ms
step:68/1500 train_loss:5.3408 train_time:23364ms step_avg:402.83ms
step:69/1500 train_loss:5.6026 train_time:23767ms step_avg:402.83ms
step:70/1500 train_loss:5.2399 train_time:24173ms step_avg:402.88ms
step:71/1500 train_loss:5.2684 train_time:24576ms step_avg:402.88ms
step:72/1500 train_loss:5.4594 train_time:24978ms step_avg:402.87ms
step:73/1500 train_loss:5.4015 train_time:25383ms step_avg:402.91ms
step:74/1500 train_loss:5.2729 train_time:25790ms step_avg:402.96ms
step:75/1500 train_loss:5.4015 train_time:26192ms step_avg:402.96ms
step:76/1500 train_loss:5.3810 train_time:26598ms step_avg:402.99ms
step:77/1500 train_loss:5.3340 train_time:27001ms step_avg:403.00ms
step:78/1500 train_loss:5.4179 train_time:27403ms step_avg:402.99ms
step:79/1500 train_loss:5.5060 train_time:27809ms step_avg:403.03ms
step:80/1500 train_loss:5.2684 train_time:28215ms step_avg:403.07ms
step:81/1500 train_loss:5.3779 train_time:28618ms step_avg:403.07ms
step:82/1500 train_loss:5.1481 train_time:29023ms step_avg:403.10ms
step:83/1500 train_loss:5.3283 train_time:29427ms step_avg:403.10ms
step:84/1500 train_loss:5.2687 train_time:29831ms step_avg:403.12ms
step:85/1500 train_loss:5.2635 train_time:30234ms step_avg:403.12ms
step:86/1500 train_loss:5.1132 train_time:30639ms step_avg:403.15ms
step:87/1500 train_loss:5.3342 train_time:31043ms step_avg:403.15ms
step:88/1500 train_loss:5.2372 train_time:31448ms step_avg:403.17ms
step:89/1500 train_loss:5.2926 train_time:31851ms step_avg:403.18ms
step:90/1500 train_loss:5.2506 train_time:32256ms step_avg:403.20ms
step:91/1500 train_loss:5.1840 train_time:32661ms step_avg:403.22ms
step:92/1500 train_loss:5.1553 train_time:33072ms step_avg:403.31ms
step:93/1500 train_loss:5.2964 train_time:33477ms step_avg:403.34ms
step:94/1500 train_loss:5.1091 train_time:33878ms step_avg:403.31ms
step:95/1500 train_loss:5.1282 train_time:34281ms step_avg:403.31ms
step:96/1500 train_loss:5.1600 train_time:34685ms step_avg:403.31ms
step:97/1500 train_loss:5.0757 train_time:35087ms step_avg:403.30ms
step:98/1500 train_loss:5.1521 train_time:35490ms step_avg:403.29ms
step:99/1500 train_loss:5.0807 train_time:35893ms step_avg:403.29ms
step:100/1500 train_loss:5.1917 train_time:36297ms step_avg:403.30ms
step:101/1500 train_loss:5.1649 train_time:36701ms step_avg:403.31ms
step:102/1500 train_loss:5.0672 train_time:37106ms step_avg:403.32ms
step:103/1500 train_loss:5.1668 train_time:37511ms step_avg:403.34ms
step:104/1500 train_loss:5.1247 train_time:37915ms step_avg:403.35ms
step:105/1500 train_loss:4.9870 train_time:38320ms step_avg:403.37ms
step:106/1500 train_loss:5.0722 train_time:38724ms step_avg:403.37ms
step:107/1500 train_loss:5.2718 train_time:39128ms step_avg:403.38ms
step:108/1500 train_loss:5.0505 train_time:39532ms step_avg:403.38ms
step:109/1500 train_loss:4.8434 train_time:39936ms step_avg:403.39ms
step:110/1500 train_loss:5.0206 train_time:40339ms step_avg:403.39ms
step:111/1500 train_loss:5.0174 train_time:40742ms step_avg:403.38ms
step:112/1500 train_loss:4.9687 train_time:41146ms step_avg:403.39ms
step:113/1500 train_loss:5.0851 train_time:41551ms step_avg:403.41ms
step:114/1500 train_loss:5.0047 train_time:41955ms step_avg:403.41ms
step:115/1500 train_loss:4.8620 train_time:42359ms step_avg:403.42ms
step:116/1500 train_loss:5.0150 train_time:42761ms step_avg:403.41ms
step:117/1500 train_loss:4.9242 train_time:43166ms step_avg:403.42ms
step:118/1500 train_loss:4.8755 train_time:43571ms step_avg:403.43ms
step:119/1500 train_loss:5.0345 train_time:43976ms step_avg:403.45ms
step:120/1500 train_loss:4.9874 train_time:44379ms step_avg:403.44ms
step:121/1500 train_loss:4.9110 train_time:44784ms step_avg:403.46ms
step:122/1500 train_loss:4.8131 train_time:45187ms step_avg:403.46ms
step:123/1500 train_loss:4.9342 train_time:45592ms step_avg:403.47ms
step:124/1500 train_loss:4.7875 train_time:45995ms step_avg:403.46ms
step:125/1500 train_loss:5.0930 train_time:46400ms step_avg:403.48ms
step:125/1500 val_loss:4.9272 train_time:46413ms step_avg:403.59ms
step:126/1500 train_loss:4.9759 train_time:46806ms step_avg:403.50ms
step:127/1500 train_loss:4.9174 train_time:47210ms step_avg:403.51ms
step:128/1500 train_loss:4.9708 train_time:47615ms step_avg:403.52ms
step:129/1500 train_loss:4.8477 train_time:48019ms step_avg:403.52ms
step:130/1500 train_loss:5.1628 train_time:48423ms step_avg:403.53ms
step:131/1500 train_loss:4.9102 train_time:48827ms step_avg:403.53ms
step:132/1500 train_loss:4.9184 train_time:49234ms step_avg:403.55ms
step:133/1500 train_loss:4.8724 train_time:49638ms step_avg:403.56ms
step:134/1500 train_loss:4.9053 train_time:50043ms step_avg:403.57ms
step:135/1500 train_loss:4.8036 train_time:50447ms step_avg:403.57ms
step:136/1500 train_loss:4.9274 train_time:50849ms step_avg:403.56ms
step:137/1500 train_loss:4.7015 train_time:51254ms step_avg:403.57ms
step:138/1500 train_loss:4.8615 train_time:51658ms step_avg:403.58ms
step:139/1500 train_loss:4.8136 train_time:52060ms step_avg:403.57ms
step:140/1500 train_loss:4.8400 train_time:52466ms step_avg:403.58ms
step:141/1500 train_loss:4.9177 train_time:52870ms step_avg:403.59ms
step:142/1500 train_loss:4.7881 train_time:53276ms step_avg:403.60ms
step:143/1500 train_loss:4.8371 train_time:53679ms step_avg:403.60ms
step:144/1500 train_loss:4.7082 train_time:54082ms step_avg:403.60ms
step:145/1500 train_loss:4.8390 train_time:54487ms step_avg:403.61ms
step:146/1500 train_loss:4.7836 train_time:54891ms step_avg:403.61ms
step:147/1500 train_loss:4.6556 train_time:55294ms step_avg:403.61ms
step:148/1500 train_loss:4.8090 train_time:55699ms step_avg:403.62ms
step:149/1500 train_loss:4.8130 train_time:56103ms step_avg:403.62ms
step:150/1500 train_loss:4.8399 train_time:56509ms step_avg:403.63ms
step:151/1500 train_loss:4.8753 train_time:56913ms step_avg:403.64ms
step:152/1500 train_loss:4.7620 train_time:57317ms step_avg:403.64ms
step:153/1500 train_loss:4.7537 train_time:57722ms step_avg:403.65ms
step:154/1500 train_loss:4.8487 train_time:58125ms step_avg:403.65ms
step:155/1500 train_loss:4.8045 train_time:58529ms step_avg:403.65ms
step:156/1500 train_loss:4.7541 train_time:58937ms step_avg:403.68ms
step:157/1500 train_loss:4.7870 train_time:59341ms step_avg:403.68ms
step:158/1500 train_loss:4.8925 train_time:59745ms step_avg:403.68ms
step:159/1500 train_loss:4.6889 train_time:60150ms step_avg:403.69ms
step:160/1500 train_loss:4.7567 train_time:60555ms step_avg:403.70ms
step:161/1500 train_loss:4.5835 train_time:60961ms step_avg:403.71ms
step:162/1500 train_loss:4.7747 train_time:61364ms step_avg:403.71ms
step:163/1500 train_loss:4.8044 train_time:61772ms step_avg:403.74ms
step:164/1500 train_loss:4.7975 train_time:62176ms step_avg:403.74ms
step:165/1500 train_loss:4.6038 train_time:62579ms step_avg:403.74ms
step:166/1500 train_loss:4.7305 train_time:62984ms step_avg:403.74ms
step:167/1500 train_loss:4.8550 train_time:63386ms step_avg:403.73ms
step:168/1500 train_loss:4.6461 train_time:63791ms step_avg:403.74ms
step:169/1500 train_loss:4.7374 train_time:64195ms step_avg:403.74ms
step:170/1500 train_loss:4.5966 train_time:64598ms step_avg:403.74ms
step:171/1500 train_loss:4.4954 train_time:65001ms step_avg:403.73ms
step:172/1500 train_loss:4.6441 train_time:65404ms step_avg:403.73ms
step:173/1500 train_loss:4.6377 train_time:65807ms step_avg:403.72ms
step:174/1500 train_loss:4.6841 train_time:66211ms step_avg:403.72ms
step:175/1500 train_loss:4.8433 train_time:66613ms step_avg:403.72ms
step:176/1500 train_loss:4.6941 train_time:67016ms step_avg:403.71ms
step:177/1500 train_loss:4.5418 train_time:67421ms step_avg:403.72ms
step:178/1500 train_loss:4.5110 train_time:67824ms step_avg:403.72ms
step:179/1500 train_loss:4.5937 train_time:68229ms step_avg:403.72ms
step:180/1500 train_loss:4.5966 train_time:68634ms step_avg:403.73ms
step:181/1500 train_loss:4.5924 train_time:69039ms step_avg:403.74ms
step:182/1500 train_loss:4.7229 train_time:69444ms step_avg:403.74ms
step:183/1500 train_loss:4.5903 train_time:69847ms step_avg:403.74ms
step:184/1500 train_loss:4.5423 train_time:70251ms step_avg:403.74ms
step:185/1500 train_loss:4.5495 train_time:70655ms step_avg:403.74ms
step:186/1500 train_loss:4.6727 train_time:71058ms step_avg:403.74ms
step:187/1500 train_loss:4.5842 train_time:71461ms step_avg:403.73ms
step:188/1500 train_loss:4.7658 train_time:71866ms step_avg:403.74ms
step:189/1500 train_loss:4.5940 train_time:73012ms step_avg:407.89ms
step:190/1500 train_loss:4.5195 train_time:73561ms step_avg:408.67ms
step:191/1500 train_loss:4.6552 train_time:73971ms step_avg:408.68ms
step:192/1500 train_loss:4.5020 train_time:74381ms step_avg:408.69ms
step:193/1500 train_loss:4.4305 train_time:74792ms step_avg:408.70ms
step:194/1500 train_loss:4.6608 train_time:75203ms step_avg:408.71ms
step:195/1500 train_loss:4.5793 train_time:75613ms step_avg:408.72ms
step:196/1500 train_loss:4.7666 train_time:76022ms step_avg:408.72ms
step:197/1500 train_loss:4.6305 train_time:76434ms step_avg:408.74ms
step:198/1500 train_loss:4.4746 train_time:76845ms step_avg:408.75ms
step:199/1500 train_loss:4.5486 train_time:77255ms step_avg:408.76ms
step:200/1500 train_loss:4.4176 train_time:77666ms step_avg:408.77ms
step:201/1500 train_loss:4.5109 train_time:78077ms step_avg:408.78ms
step:202/1500 train_loss:4.4140 train_time:78489ms step_avg:408.80ms
step:203/1500 train_loss:4.6562 train_time:78898ms step_avg:408.80ms
step:204/1500 train_loss:4.5001 train_time:79310ms step_avg:408.82ms
step:205/1500 train_loss:4.5552 train_time:79720ms step_avg:408.82ms
step:206/1500 train_loss:4.6555 train_time:80131ms step_avg:408.83ms
step:207/1500 train_loss:4.3200 train_time:80542ms step_avg:408.84ms
step:208/1500 train_loss:4.4752 train_time:80954ms step_avg:408.86ms
step:209/1500 train_loss:4.4611 train_time:81365ms step_avg:408.87ms
step:210/1500 train_loss:4.6180 train_time:81777ms step_avg:408.89ms
step:211/1500 train_loss:4.5519 train_time:82188ms step_avg:408.90ms
step:212/1500 train_loss:4.4211 train_time:82599ms step_avg:408.90ms
step:213/1500 train_loss:4.5099 train_time:83009ms step_avg:408.91ms
step:214/1500 train_loss:4.3928 train_time:83420ms step_avg:408.92ms
step:215/1500 train_loss:4.4593 train_time:83830ms step_avg:408.93ms
step:216/1500 train_loss:4.3142 train_time:84242ms step_avg:408.94ms
step:217/1500 train_loss:4.4113 train_time:84653ms step_avg:408.95ms
step:218/1500 train_loss:4.3751 train_time:85062ms step_avg:408.95ms
step:219/1500 train_loss:4.4181 train_time:85473ms step_avg:408.96ms
step:220/1500 train_loss:4.4068 train_time:85885ms step_avg:408.98ms
step:221/1500 train_loss:4.4328 train_time:86295ms step_avg:408.98ms
step:222/1500 train_loss:4.4482 train_time:86706ms step_avg:408.99ms
step:223/1500 train_loss:4.3722 train_time:87117ms step_avg:409.00ms
step:224/1500 train_loss:4.3583 train_time:87529ms step_avg:409.01ms
step:225/1500 train_loss:4.5923 train_time:87941ms step_avg:409.03ms
step:226/1500 train_loss:4.2140 train_time:88350ms step_avg:409.03ms
step:227/1500 train_loss:4.3033 train_time:88762ms step_avg:409.04ms
step:228/1500 train_loss:4.3093 train_time:89174ms step_avg:409.06ms
step:229/1500 train_loss:4.4592 train_time:89585ms step_avg:409.06ms
step:230/1500 train_loss:4.2507 train_time:89995ms step_avg:409.07ms
step:231/1500 train_loss:4.3851 train_time:90407ms step_avg:409.08ms
step:232/1500 train_loss:4.2422 train_time:90817ms step_avg:409.08ms
step:233/1500 train_loss:4.2772 train_time:91227ms step_avg:409.09ms
step:234/1500 train_loss:4.4327 train_time:91639ms step_avg:409.10ms
step:235/1500 train_loss:4.3214 train_time:92049ms step_avg:409.11ms
step:236/1500 train_loss:4.2158 train_time:92461ms step_avg:409.12ms
step:237/1500 train_loss:4.4031 train_time:92873ms step_avg:409.13ms
step:238/1500 train_loss:4.3869 train_time:93286ms step_avg:409.15ms
step:239/1500 train_loss:4.2464 train_time:93695ms step_avg:409.15ms
step:240/1500 train_loss:4.4019 train_time:94106ms step_avg:409.16ms
step:241/1500 train_loss:4.4031 train_time:94517ms step_avg:409.17ms
step:242/1500 train_loss:4.2715 train_time:94928ms step_avg:409.17ms
step:243/1500 train_loss:4.4654 train_time:95339ms step_avg:409.18ms
step:244/1500 train_loss:4.3036 train_time:95751ms step_avg:409.19ms
step:245/1500 train_loss:4.3465 train_time:96160ms step_avg:409.19ms
step:246/1500 train_loss:4.4197 train_time:96570ms step_avg:409.20ms
step:247/1500 train_loss:4.3555 train_time:96982ms step_avg:409.21ms
step:248/1500 train_loss:4.2921 train_time:97392ms step_avg:409.21ms
step:249/1500 train_loss:4.4108 train_time:97802ms step_avg:409.21ms
step:250/1500 train_loss:4.1932 train_time:98214ms step_avg:409.23ms
step:250/1500 val_loss:4.2890 train_time:98228ms step_avg:409.28ms
step:251/1500 train_loss:4.2511 train_time:98620ms step_avg:409.21ms
step:252/1500 train_loss:4.3601 train_time:99032ms step_avg:409.22ms
step:253/1500 train_loss:4.4052 train_time:99442ms step_avg:409.23ms
step:254/1500 train_loss:4.2158 train_time:99853ms step_avg:409.23ms
step:255/1500 train_loss:4.1704 train_time:100264ms step_avg:409.24ms
step:256/1500 train_loss:4.3425 train_time:100674ms step_avg:409.24ms
step:257/1500 train_loss:4.2489 train_time:101084ms step_avg:409.25ms
step:258/1500 train_loss:4.2594 train_time:101497ms step_avg:409.26ms
step:259/1500 train_loss:4.2340 train_time:101907ms step_avg:409.27ms
step:260/1500 train_loss:4.2801 train_time:102320ms step_avg:409.28ms
step:261/1500 train_loss:4.3218 train_time:102731ms step_avg:409.29ms
step:262/1500 train_loss:4.2789 train_time:103142ms step_avg:409.29ms
step:263/1500 train_loss:4.2549 train_time:103552ms step_avg:409.30ms
step:264/1500 train_loss:4.1656 train_time:103962ms step_avg:409.30ms
step:265/1500 train_loss:4.2491 train_time:104372ms step_avg:409.30ms
step:266/1500 train_loss:4.1154 train_time:104782ms step_avg:409.30ms
step:267/1500 train_loss:4.1748 train_time:105193ms step_avg:409.31ms
step:268/1500 train_loss:4.1869 train_time:105604ms step_avg:409.32ms
step:269/1500 train_loss:4.2014 train_time:106015ms step_avg:409.33ms
step:270/1500 train_loss:4.1114 train_time:106426ms step_avg:409.33ms
step:271/1500 train_loss:4.3456 train_time:106838ms step_avg:409.34ms
step:272/1500 train_loss:4.2460 train_time:107248ms step_avg:409.35ms
step:273/1500 train_loss:4.1603 train_time:107660ms step_avg:409.35ms
step:274/1500 train_loss:4.2033 train_time:108070ms step_avg:409.36ms
step:275/1500 train_loss:4.2787 train_time:108481ms step_avg:409.36ms
step:276/1500 train_loss:4.2962 train_time:108893ms step_avg:409.37ms
step:277/1500 train_loss:4.4786 train_time:109304ms step_avg:409.38ms
step:278/1500 train_loss:4.2678 train_time:109715ms step_avg:409.38ms
step:279/1500 train_loss:4.3397 train_time:110127ms step_avg:409.39ms
step:280/1500 train_loss:4.2408 train_time:110537ms step_avg:409.40ms
step:281/1500 train_loss:4.3607 train_time:110947ms step_avg:409.40ms
step:282/1500 train_loss:4.1936 train_time:111358ms step_avg:409.41ms
step:283/1500 train_loss:4.2135 train_time:111769ms step_avg:409.41ms
step:284/1500 train_loss:4.1434 train_time:112180ms step_avg:409.42ms
step:285/1500 train_loss:4.2880 train_time:112591ms step_avg:409.42ms
step:286/1500 train_loss:4.2995 train_time:113001ms step_avg:409.42ms
step:287/1500 train_loss:4.3231 train_time:113413ms step_avg:409.43ms
step:288/1500 train_loss:4.1620 train_time:113824ms step_avg:409.44ms
step:289/1500 train_loss:4.2502 train_time:114234ms step_avg:409.44ms
step:290/1500 train_loss:4.1056 train_time:114645ms step_avg:409.45ms
step:291/1500 train_loss:4.0986 train_time:115056ms step_avg:409.45ms
step:292/1500 train_loss:4.1844 train_time:115466ms step_avg:409.46ms
step:293/1500 train_loss:4.1001 train_time:115877ms step_avg:409.46ms
step:294/1500 train_loss:4.1420 train_time:116289ms step_avg:409.47ms
step:295/1500 train_loss:4.1832 train_time:116698ms step_avg:409.47ms
step:296/1500 train_loss:4.0643 train_time:117108ms step_avg:409.47ms
step:297/1500 train_loss:4.0816 train_time:117520ms step_avg:409.48ms
step:298/1500 train_loss:4.0901 train_time:117930ms step_avg:409.48ms
step:299/1500 train_loss:4.1926 train_time:118339ms step_avg:409.48ms
step:300/1500 train_loss:4.0606 train_time:118750ms step_avg:409.48ms
step:301/1500 train_loss:4.1989 train_time:119161ms step_avg:409.49ms
step:302/1500 train_loss:4.2042 train_time:119571ms step_avg:409.49ms
step:303/1500 train_loss:4.1482 train_time:119980ms step_avg:409.49ms
step:304/1500 train_loss:4.2053 train_time:120391ms step_avg:409.49ms
step:305/1500 train_loss:4.1855 train_time:120800ms step_avg:409.49ms
step:306/1500 train_loss:4.6583 train_time:121210ms step_avg:409.49ms
step:307/1500 train_loss:4.1531 train_time:121621ms step_avg:409.50ms
step:308/1500 train_loss:4.0591 train_time:122031ms step_avg:409.50ms
step:309/1500 train_loss:4.2181 train_time:122442ms step_avg:409.51ms
step:310/1500 train_loss:4.0796 train_time:122853ms step_avg:409.51ms
step:311/1500 train_loss:4.3032 train_time:123264ms step_avg:409.51ms
step:312/1500 train_loss:4.1509 train_time:123673ms step_avg:409.51ms
step:313/1500 train_loss:4.0851 train_time:124084ms step_avg:409.52ms
step:314/1500 train_loss:4.1799 train_time:124495ms step_avg:409.52ms
step:315/1500 train_loss:4.2994 train_time:124905ms step_avg:409.53ms
step:316/1500 train_loss:4.1791 train_time:125316ms step_avg:409.53ms
step:317/1500 train_loss:4.0165 train_time:125729ms step_avg:409.54ms
step:318/1500 train_loss:4.0866 train_time:126138ms step_avg:409.54ms
step:319/1500 train_loss:4.1253 train_time:126548ms step_avg:409.54ms
step:320/1500 train_loss:4.1008 train_time:126962ms step_avg:409.56ms
step:321/1500 train_loss:4.2040 train_time:127375ms step_avg:409.57ms
step:322/1500 train_loss:4.1566 train_time:127786ms step_avg:409.57ms
step:323/1500 train_loss:4.1303 train_time:128197ms step_avg:409.57ms
step:324/1500 train_loss:4.2179 train_time:128609ms step_avg:409.58ms
step:325/1500 train_loss:4.1713 train_time:129019ms step_avg:409.59ms
step:326/1500 train_loss:4.2388 train_time:129429ms step_avg:409.58ms
step:327/1500 train_loss:4.0951 train_time:129839ms step_avg:409.59ms
step:328/1500 train_loss:4.5841 train_time:130250ms step_avg:409.59ms
step:329/1500 train_loss:4.2814 train_time:130661ms step_avg:409.60ms
step:330/1500 train_loss:4.0268 train_time:131071ms step_avg:409.60ms
step:331/1500 train_loss:3.9666 train_time:131483ms step_avg:409.60ms
step:332/1500 train_loss:4.1779 train_time:131959ms step_avg:409.81ms
step:333/1500 train_loss:4.1052 train_time:132369ms step_avg:409.81ms
step:334/1500 train_loss:4.0827 train_time:132780ms step_avg:409.81ms
step:335/1500 train_loss:4.0448 train_time:133194ms step_avg:409.83ms
step:336/1500 train_loss:4.2221 train_time:133604ms step_avg:409.83ms
step:337/1500 train_loss:4.1601 train_time:134016ms step_avg:409.83ms
step:338/1500 train_loss:4.6258 train_time:134425ms step_avg:409.83ms
step:339/1500 train_loss:4.1424 train_time:134836ms step_avg:409.84ms
step:340/1500 train_loss:4.0918 train_time:135248ms step_avg:409.84ms
step:341/1500 train_loss:4.1261 train_time:135658ms step_avg:409.84ms
step:342/1500 train_loss:4.0467 train_time:136068ms step_avg:409.84ms
step:343/1500 train_loss:4.0166 train_time:136479ms step_avg:409.85ms
step:344/1500 train_loss:4.0627 train_time:136890ms step_avg:409.85ms
step:345/1500 train_loss:4.1935 train_time:137300ms step_avg:409.85ms
step:346/1500 train_loss:4.0391 train_time:137711ms step_avg:409.85ms
step:347/1500 train_loss:3.9687 train_time:138121ms step_avg:409.86ms
step:348/1500 train_loss:4.0162 train_time:138531ms step_avg:409.86ms
step:349/1500 train_loss:4.0575 train_time:138942ms step_avg:409.86ms
step:350/1500 train_loss:4.0216 train_time:139353ms step_avg:409.86ms
step:351/1500 train_loss:3.7477 train_time:139764ms step_avg:409.86ms
step:352/1500 train_loss:4.0102 train_time:140173ms step_avg:409.86ms
step:353/1500 train_loss:4.3337 train_time:140583ms step_avg:409.86ms
step:354/1500 train_loss:3.8544 train_time:140994ms step_avg:409.87ms
step:355/1500 train_loss:4.1229 train_time:141405ms step_avg:409.87ms
step:356/1500 train_loss:3.9872 train_time:141815ms step_avg:409.87ms
step:357/1500 train_loss:4.0900 train_time:142226ms step_avg:409.87ms
step:358/1500 train_loss:4.0359 train_time:142637ms step_avg:409.88ms
step:359/1500 train_loss:4.0396 train_time:143049ms step_avg:409.88ms
step:360/1500 train_loss:4.0885 train_time:143459ms step_avg:409.88ms
step:361/1500 train_loss:3.6563 train_time:143868ms step_avg:409.88ms
step:362/1500 train_loss:4.2215 train_time:144279ms step_avg:409.88ms
step:363/1500 train_loss:4.1126 train_time:144689ms step_avg:409.88ms
step:364/1500 train_loss:4.0349 train_time:145099ms step_avg:409.88ms
step:365/1500 train_loss:3.9337 train_time:145509ms step_avg:409.88ms
step:366/1500 train_loss:4.1113 train_time:145920ms step_avg:409.89ms
step:367/1500 train_loss:4.0648 train_time:146329ms step_avg:409.89ms
step:368/1500 train_loss:4.0468 train_time:146742ms step_avg:409.89ms
step:369/1500 train_loss:4.0352 train_time:147153ms step_avg:409.90ms
step:370/1500 train_loss:3.9308 train_time:147563ms step_avg:409.90ms
step:371/1500 train_loss:4.0800 train_time:147973ms step_avg:409.90ms
step:372/1500 train_loss:3.9533 train_time:148384ms step_avg:409.90ms
step:373/1500 train_loss:3.8875 train_time:148795ms step_avg:409.90ms
step:374/1500 train_loss:4.1071 train_time:149205ms step_avg:409.90ms
step:375/1500 train_loss:4.0297 train_time:149615ms step_avg:409.90ms
step:375/1500 val_loss:4.0243 train_time:149628ms step_avg:409.94ms
step:376/1500 train_loss:3.9967 train_time:150022ms step_avg:409.89ms
step:377/1500 train_loss:4.0630 train_time:150432ms step_avg:409.90ms
step:378/1500 train_loss:3.9779 train_time:151812ms step_avg:412.53ms
step:379/1500 train_loss:4.0324 train_time:152223ms step_avg:412.53ms
step:380/1500 train_loss:4.0699 train_time:152806ms step_avg:412.99ms
step:381/1500 train_loss:4.1365 train_time:153218ms step_avg:412.99ms
step:382/1500 train_loss:4.0411 train_time:153628ms step_avg:412.98ms
step:383/1500 train_loss:4.0103 train_time:154038ms step_avg:412.97ms
step:384/1500 train_loss:3.9818 train_time:154449ms step_avg:412.97ms
step:385/1500 train_loss:4.0609 train_time:154859ms step_avg:412.96ms
step:386/1500 train_loss:3.9730 train_time:155270ms step_avg:412.95ms
step:387/1500 train_loss:4.0863 train_time:155681ms step_avg:412.95ms
step:388/1500 train_loss:4.2720 train_time:156091ms step_avg:412.94ms
step:389/1500 train_loss:3.9910 train_time:156503ms step_avg:412.94ms
step:390/1500 train_loss:3.9831 train_time:156914ms step_avg:412.93ms
step:391/1500 train_loss:4.0873 train_time:157324ms step_avg:412.92ms
step:392/1500 train_loss:4.0061 train_time:157736ms step_avg:412.92ms
step:393/1500 train_loss:4.1099 train_time:158146ms step_avg:412.91ms
step:394/1500 train_loss:3.9491 train_time:158557ms step_avg:412.91ms
step:395/1500 train_loss:4.0789 train_time:158966ms step_avg:412.90ms
step:396/1500 train_loss:3.8250 train_time:159378ms step_avg:412.90ms
step:397/1500 train_loss:4.0205 train_time:159787ms step_avg:412.89ms
step:398/1500 train_loss:4.0701 train_time:160198ms step_avg:412.88ms
step:399/1500 train_loss:4.0800 train_time:160608ms step_avg:412.87ms
step:400/1500 train_loss:3.9684 train_time:161019ms step_avg:412.87ms
step:401/1500 train_loss:4.0190 train_time:161430ms step_avg:412.86ms
step:402/1500 train_loss:4.0990 train_time:161840ms step_avg:412.86ms
step:403/1500 train_loss:4.0328 train_time:162251ms step_avg:412.85ms
step:404/1500 train_loss:4.1339 train_time:162660ms step_avg:412.84ms
step:405/1500 train_loss:3.8814 train_time:163070ms step_avg:412.84ms
step:406/1500 train_loss:3.9763 train_time:163480ms step_avg:412.83ms
step:407/1500 train_loss:4.2686 train_time:163892ms step_avg:412.83ms
step:408/1500 train_loss:3.9900 train_time:164302ms step_avg:412.82ms
step:409/1500 train_loss:4.0047 train_time:164712ms step_avg:412.81ms
step:410/1500 train_loss:4.0521 train_time:165122ms step_avg:412.81ms
step:411/1500 train_loss:3.9379 train_time:165534ms step_avg:412.80ms
step:412/1500 train_loss:3.9544 train_time:165944ms step_avg:412.80ms
step:413/1500 train_loss:4.3717 train_time:166355ms step_avg:412.79ms
step:414/1500 train_loss:3.8380 train_time:166765ms step_avg:412.79ms
step:415/1500 train_loss:4.1927 train_time:167176ms step_avg:412.78ms
step:416/1500 train_loss:3.9462 train_time:167587ms step_avg:412.78ms
step:417/1500 train_loss:3.9515 train_time:167998ms step_avg:412.77ms
step:418/1500 train_loss:4.1445 train_time:168408ms step_avg:412.76ms
step:419/1500 train_loss:3.8752 train_time:168817ms step_avg:412.76ms
step:420/1500 train_loss:3.9909 train_time:169227ms step_avg:412.75ms
step:421/1500 train_loss:3.9102 train_time:169639ms step_avg:412.75ms
step:422/1500 train_loss:3.8281 train_time:170049ms step_avg:412.74ms
step:423/1500 train_loss:3.9638 train_time:170459ms step_avg:412.73ms
step:424/1500 train_loss:4.0538 train_time:170870ms step_avg:412.73ms
step:425/1500 train_loss:3.8133 train_time:171280ms step_avg:412.72ms
step:426/1500 train_loss:3.9932 train_time:171691ms step_avg:412.72ms
step:427/1500 train_loss:3.8725 train_time:172103ms step_avg:412.72ms
step:428/1500 train_loss:4.0859 train_time:172513ms step_avg:412.71ms
step:429/1500 train_loss:4.0032 train_time:172928ms step_avg:412.72ms
step:430/1500 train_loss:3.9416 train_time:173338ms step_avg:412.71ms
step:431/1500 train_loss:3.9028 train_time:173748ms step_avg:412.70ms
step:432/1500 train_loss:3.8124 train_time:174159ms step_avg:412.70ms
step:433/1500 train_loss:3.9484 train_time:174571ms step_avg:412.70ms
step:434/1500 train_loss:4.0061 train_time:174982ms step_avg:412.69ms
step:435/1500 train_loss:3.9542 train_time:175394ms step_avg:412.69ms
step:436/1500 train_loss:4.0028 train_time:175805ms step_avg:412.69ms
step:437/1500 train_loss:4.0129 train_time:176213ms step_avg:412.68ms
step:438/1500 train_loss:3.8933 train_time:176625ms step_avg:412.68ms
step:439/1500 train_loss:3.9083 train_time:177035ms step_avg:412.67ms
step:440/1500 train_loss:3.8832 train_time:177445ms step_avg:412.66ms
step:441/1500 train_loss:4.0657 train_time:177856ms step_avg:412.66ms
step:442/1500 train_loss:3.9492 train_time:178268ms step_avg:412.66ms
step:443/1500 train_loss:3.9332 train_time:178677ms step_avg:412.65ms
step:444/1500 train_loss:3.8290 train_time:179089ms step_avg:412.65ms
step:445/1500 train_loss:4.0952 train_time:179499ms step_avg:412.64ms
step:446/1500 train_loss:4.0273 train_time:179909ms step_avg:412.64ms
step:447/1500 train_loss:4.0176 train_time:180319ms step_avg:412.63ms
step:448/1500 train_loss:3.9402 train_time:180730ms step_avg:412.62ms
step:449/1500 train_loss:4.0326 train_time:181139ms step_avg:412.62ms
step:450/1500 train_loss:3.8663 train_time:181551ms step_avg:412.62ms
step:451/1500 train_loss:3.9044 train_time:181962ms step_avg:412.61ms
step:452/1500 train_loss:3.7676 train_time:182371ms step_avg:412.60ms
step:453/1500 train_loss:3.8894 train_time:182780ms step_avg:412.60ms
step:454/1500 train_loss:3.8594 train_time:183191ms step_avg:412.59ms
step:455/1500 train_loss:3.8141 train_time:183601ms step_avg:412.59ms
step:456/1500 train_loss:4.0354 train_time:184010ms step_avg:412.58ms
step:457/1500 train_loss:3.9020 train_time:184421ms step_avg:412.58ms
step:458/1500 train_loss:3.9734 train_time:184832ms step_avg:412.57ms
step:459/1500 train_loss:4.0134 train_time:185242ms step_avg:412.57ms
step:460/1500 train_loss:3.8167 train_time:185652ms step_avg:412.56ms
step:461/1500 train_loss:3.9848 train_time:186070ms step_avg:412.57ms
step:462/1500 train_loss:3.8749 train_time:186480ms step_avg:412.57ms
step:463/1500 train_loss:3.9069 train_time:186891ms step_avg:412.56ms
step:464/1500 train_loss:3.9562 train_time:187303ms step_avg:412.56ms
step:465/1500 train_loss:3.8999 train_time:187713ms step_avg:412.56ms
step:466/1500 train_loss:3.9074 train_time:188123ms step_avg:412.55ms
step:467/1500 train_loss:3.9933 train_time:188533ms step_avg:412.55ms
step:468/1500 train_loss:4.0069 train_time:188946ms step_avg:412.55ms
step:469/1500 train_loss:3.9872 train_time:189356ms step_avg:412.54ms
step:470/1500 train_loss:3.8732 train_time:189767ms step_avg:412.54ms
step:471/1500 train_loss:3.9525 train_time:190177ms step_avg:412.53ms
step:472/1500 train_loss:4.0161 train_time:190587ms step_avg:412.53ms
step:473/1500 train_loss:3.9534 train_time:190999ms step_avg:412.52ms
step:474/1500 train_loss:3.9047 train_time:191409ms step_avg:412.52ms
step:475/1500 train_loss:3.7636 train_time:191820ms step_avg:412.52ms
step:476/1500 train_loss:4.1936 train_time:192230ms step_avg:412.51ms
step:477/1500 train_loss:3.9508 train_time:192640ms step_avg:412.51ms
step:478/1500 train_loss:3.7703 train_time:193051ms step_avg:412.50ms
step:479/1500 train_loss:4.0043 train_time:193461ms step_avg:412.50ms
step:480/1500 train_loss:3.9531 train_time:193873ms step_avg:412.49ms
step:481/1500 train_loss:4.0902 train_time:194283ms step_avg:412.49ms
step:482/1500 train_loss:3.9078 train_time:194694ms step_avg:412.49ms
step:483/1500 train_loss:3.7101 train_time:195106ms step_avg:412.49ms
step:484/1500 train_loss:3.9953 train_time:195515ms step_avg:412.48ms
step:485/1500 train_loss:3.8438 train_time:195925ms step_avg:412.47ms
step:486/1500 train_loss:3.8558 train_time:196338ms step_avg:412.47ms
step:487/1500 train_loss:3.7787 train_time:196748ms step_avg:412.47ms
step:488/1500 train_loss:3.8538 train_time:197159ms step_avg:412.47ms
step:489/1500 train_loss:4.0492 train_time:197570ms step_avg:412.46ms
step:490/1500 train_loss:3.8949 train_time:197980ms step_avg:412.46ms
step:491/1500 train_loss:3.7811 train_time:198390ms step_avg:412.45ms
step:492/1500 train_loss:3.7952 train_time:198801ms step_avg:412.45ms
step:493/1500 train_loss:3.9130 train_time:199212ms step_avg:412.45ms
step:494/1500 train_loss:3.7619 train_time:199622ms step_avg:412.44ms
step:495/1500 train_loss:3.8923 train_time:200033ms step_avg:412.44ms
step:496/1500 train_loss:3.8298 train_time:200443ms step_avg:412.44ms
step:497/1500 train_loss:3.7105 train_time:200854ms step_avg:412.43ms
step:498/1500 train_loss:3.9104 train_time:201264ms step_avg:412.43ms
step:499/1500 train_loss:3.9854 train_time:201676ms step_avg:412.42ms
step:500/1500 train_loss:4.0165 train_time:202087ms step_avg:412.42ms
step:500/1500 val_loss:3.8890 train_time:202100ms step_avg:412.45ms
step:501/1500 train_loss:3.9216 train_time:202493ms step_avg:412.41ms
step:502/1500 train_loss:3.9826 train_time:202904ms step_avg:412.41ms
step:503/1500 train_loss:3.9247 train_time:203314ms step_avg:412.40ms
step:504/1500 train_loss:3.9633 train_time:203724ms step_avg:412.40ms
step:505/1500 train_loss:3.9113 train_time:204135ms step_avg:412.39ms
step:506/1500 train_loss:3.9984 train_time:204545ms step_avg:412.39ms
step:507/1500 train_loss:3.8156 train_time:204956ms step_avg:412.39ms
step:508/1500 train_loss:3.9369 train_time:205367ms step_avg:412.38ms
step:509/1500 train_loss:4.0180 train_time:205779ms step_avg:412.38ms
step:510/1500 train_loss:3.9547 train_time:206190ms step_avg:412.38ms
step:511/1500 train_loss:3.7634 train_time:206600ms step_avg:412.38ms
step:512/1500 train_loss:3.9596 train_time:207011ms step_avg:412.37ms
step:513/1500 train_loss:3.9040 train_time:207423ms step_avg:412.37ms
step:514/1500 train_loss:3.8600 train_time:207833ms step_avg:412.37ms
step:515/1500 train_loss:3.9372 train_time:208244ms step_avg:412.36ms
step:516/1500 train_loss:3.9211 train_time:208654ms step_avg:412.36ms
step:517/1500 train_loss:4.2541 train_time:209065ms step_avg:412.36ms
step:518/1500 train_loss:3.8600 train_time:209475ms step_avg:412.35ms
step:519/1500 train_loss:3.9644 train_time:209887ms step_avg:412.35ms
step:520/1500 train_loss:3.8623 train_time:210297ms step_avg:412.35ms
step:521/1500 train_loss:3.8669 train_time:210707ms step_avg:412.34ms
step:522/1500 train_loss:3.8253 train_time:211120ms step_avg:412.34ms
step:523/1500 train_loss:3.8373 train_time:211530ms step_avg:412.34ms
step:524/1500 train_loss:4.4606 train_time:211940ms step_avg:412.33ms
step:525/1500 train_loss:3.9230 train_time:212351ms step_avg:412.33ms
step:526/1500 train_loss:3.8649 train_time:212762ms step_avg:412.33ms
step:527/1500 train_loss:3.8726 train_time:213171ms step_avg:412.32ms
step:528/1500 train_loss:3.8274 train_time:213583ms step_avg:412.32ms
step:529/1500 train_loss:3.8022 train_time:213994ms step_avg:412.32ms
step:530/1500 train_loss:4.0231 train_time:214403ms step_avg:412.31ms
step:531/1500 train_loss:3.8248 train_time:214816ms step_avg:412.31ms
step:532/1500 train_loss:4.0968 train_time:215226ms step_avg:412.31ms
step:533/1500 train_loss:3.9138 train_time:215637ms step_avg:412.31ms
step:534/1500 train_loss:3.8370 train_time:216047ms step_avg:412.30ms
step:535/1500 train_loss:3.8620 train_time:216459ms step_avg:412.30ms
step:536/1500 train_loss:3.7963 train_time:216868ms step_avg:412.30ms
step:537/1500 train_loss:3.9209 train_time:217278ms step_avg:412.29ms
step:538/1500 train_loss:3.9111 train_time:217688ms step_avg:412.29ms
step:539/1500 train_loss:3.8145 train_time:218100ms step_avg:412.29ms
step:540/1500 train_loss:4.2988 train_time:218510ms step_avg:412.28ms
step:541/1500 train_loss:3.8473 train_time:218920ms step_avg:412.28ms
step:542/1500 train_loss:3.9635 train_time:219333ms step_avg:412.28ms
step:543/1500 train_loss:3.7861 train_time:219743ms step_avg:412.28ms
step:544/1500 train_loss:3.7571 train_time:220153ms step_avg:412.27ms
step:545/1500 train_loss:3.8400 train_time:220564ms step_avg:412.27ms
step:546/1500 train_loss:3.7677 train_time:220974ms step_avg:412.27ms
step:547/1500 train_loss:3.8115 train_time:221383ms step_avg:412.26ms
step:548/1500 train_loss:3.8279 train_time:221793ms step_avg:412.25ms
step:549/1500 train_loss:3.8048 train_time:222203ms step_avg:412.25ms
step:550/1500 train_loss:3.9014 train_time:222615ms step_avg:412.25ms
step:551/1500 train_loss:3.7875 train_time:223025ms step_avg:412.25ms
step:552/1500 train_loss:3.8013 train_time:223437ms step_avg:412.24ms
step:553/1500 train_loss:4.1306 train_time:223847ms step_avg:412.24ms
step:554/1500 train_loss:3.9279 train_time:224256ms step_avg:412.24ms
step:555/1500 train_loss:3.8901 train_time:224665ms step_avg:412.23ms
step:556/1500 train_loss:3.8254 train_time:225076ms step_avg:412.23ms
step:557/1500 train_loss:3.8713 train_time:225486ms step_avg:412.22ms
step:558/1500 train_loss:3.5178 train_time:225897ms step_avg:412.22ms
step:559/1500 train_loss:3.7860 train_time:226307ms step_avg:412.22ms
step:560/1500 train_loss:3.8267 train_time:226719ms step_avg:412.22ms
step:561/1500 train_loss:3.8766 train_time:227128ms step_avg:412.21ms
step:562/1500 train_loss:3.7817 train_time:227538ms step_avg:412.21ms
step:563/1500 train_loss:3.7268 train_time:227949ms step_avg:412.20ms
step:564/1500 train_loss:3.9359 train_time:228360ms step_avg:412.20ms
step:565/1500 train_loss:3.7508 train_time:228770ms step_avg:412.20ms
step:566/1500 train_loss:3.8649 train_time:229182ms step_avg:412.20ms
step:567/1500 train_loss:3.8138 train_time:230447ms step_avg:413.73ms
step:568/1500 train_loss:3.7613 train_time:230859ms step_avg:413.73ms
step:569/1500 train_loss:3.8602 train_time:231269ms step_avg:413.72ms
step:570/1500 train_loss:3.8296 train_time:231849ms step_avg:414.02ms
step:571/1500 train_loss:3.8551 train_time:232262ms step_avg:414.01ms
step:572/1500 train_loss:3.9430 train_time:232674ms step_avg:414.01ms
step:573/1500 train_loss:3.8957 train_time:233084ms step_avg:414.00ms
step:574/1500 train_loss:3.9089 train_time:233494ms step_avg:414.00ms
step:575/1500 train_loss:3.9465 train_time:233904ms step_avg:413.99ms
step:576/1500 train_loss:3.9068 train_time:234314ms step_avg:413.98ms
step:577/1500 train_loss:3.9263 train_time:234724ms step_avg:413.98ms
step:578/1500 train_loss:3.8542 train_time:235134ms step_avg:413.97ms
step:579/1500 train_loss:3.8450 train_time:235544ms step_avg:413.96ms
step:580/1500 train_loss:3.8314 train_time:235955ms step_avg:413.96ms
step:581/1500 train_loss:3.7761 train_time:236364ms step_avg:413.95ms
step:582/1500 train_loss:3.8067 train_time:236774ms step_avg:413.94ms
step:583/1500 train_loss:4.0294 train_time:237185ms step_avg:413.94ms
step:584/1500 train_loss:3.7998 train_time:237596ms step_avg:413.93ms
step:585/1500 train_loss:3.7663 train_time:238007ms step_avg:413.93ms
step:586/1500 train_loss:3.9536 train_time:238417ms step_avg:413.92ms
step:587/1500 train_loss:3.7054 train_time:238828ms step_avg:413.91ms
step:588/1500 train_loss:3.8421 train_time:239240ms step_avg:413.91ms
step:589/1500 train_loss:3.8261 train_time:239650ms step_avg:413.90ms
step:590/1500 train_loss:4.1773 train_time:240061ms step_avg:413.90ms
step:591/1500 train_loss:3.9552 train_time:240474ms step_avg:413.90ms
step:592/1500 train_loss:3.6935 train_time:240883ms step_avg:413.89ms
step:593/1500 train_loss:3.7067 train_time:241293ms step_avg:413.88ms
step:594/1500 train_loss:3.6971 train_time:241702ms step_avg:413.87ms
step:595/1500 train_loss:3.7373 train_time:242115ms step_avg:413.87ms
step:596/1500 train_loss:4.1082 train_time:242526ms step_avg:413.87ms
step:597/1500 train_loss:3.8284 train_time:242935ms step_avg:413.86ms
step:598/1500 train_loss:3.7602 train_time:243347ms step_avg:413.86ms
step:599/1500 train_loss:3.8351 train_time:243758ms step_avg:413.85ms
step:600/1500 train_loss:3.6539 train_time:244167ms step_avg:413.84ms
step:601/1500 train_loss:3.7713 train_time:244579ms step_avg:413.84ms
step:602/1500 train_loss:3.8084 train_time:244991ms step_avg:413.84ms
step:603/1500 train_loss:3.8282 train_time:245402ms step_avg:413.83ms
step:604/1500 train_loss:3.9580 train_time:245812ms step_avg:413.82ms
step:605/1500 train_loss:3.8067 train_time:246223ms step_avg:413.82ms
step:606/1500 train_loss:3.7999 train_time:246634ms step_avg:413.82ms
step:607/1500 train_loss:3.7350 train_time:247046ms step_avg:413.81ms
step:608/1500 train_loss:3.9898 train_time:247455ms step_avg:413.80ms
step:609/1500 train_loss:3.8195 train_time:247864ms step_avg:413.80ms
step:610/1500 train_loss:3.7913 train_time:248275ms step_avg:413.79ms
step:611/1500 train_loss:3.8910 train_time:248686ms step_avg:413.79ms
step:612/1500 train_loss:3.7854 train_time:249096ms step_avg:413.78ms
step:613/1500 train_loss:3.7757 train_time:249507ms step_avg:413.78ms
step:614/1500 train_loss:3.9389 train_time:249921ms step_avg:413.78ms
step:615/1500 train_loss:3.8939 train_time:250328ms step_avg:413.77ms
step:616/1500 train_loss:3.8599 train_time:250738ms step_avg:413.76ms
step:617/1500 train_loss:3.7932 train_time:251148ms step_avg:413.75ms
step:618/1500 train_loss:3.7463 train_time:251560ms step_avg:413.75ms
step:619/1500 train_loss:3.8505 train_time:251969ms step_avg:413.74ms
step:620/1500 train_loss:3.7455 train_time:252380ms step_avg:413.74ms
step:621/1500 train_loss:3.7576 train_time:252791ms step_avg:413.73ms
step:622/1500 train_loss:4.0773 train_time:253199ms step_avg:413.72ms
step:623/1500 train_loss:3.7643 train_time:253609ms step_avg:413.72ms
step:624/1500 train_loss:3.7858 train_time:254021ms step_avg:413.71ms
step:625/1500 train_loss:3.8784 train_time:254430ms step_avg:413.71ms
step:625/1500 val_loss:3.7999 train_time:254443ms step_avg:413.73ms
step:626/1500 train_loss:3.8926 train_time:254834ms step_avg:413.69ms
step:627/1500 train_loss:3.9215 train_time:255245ms step_avg:413.69ms
step:628/1500 train_loss:3.9033 train_time:255655ms step_avg:413.68ms
step:629/1500 train_loss:3.9432 train_time:256066ms step_avg:413.68ms
step:630/1500 train_loss:3.7661 train_time:256477ms step_avg:413.67ms
step:631/1500 train_loss:3.8931 train_time:256886ms step_avg:413.67ms
step:632/1500 train_loss:3.9275 train_time:257295ms step_avg:413.66ms
step:633/1500 train_loss:3.8261 train_time:257705ms step_avg:413.65ms
step:634/1500 train_loss:3.7629 train_time:258118ms step_avg:413.65ms
step:635/1500 train_loss:3.8614 train_time:258527ms step_avg:413.64ms
step:636/1500 train_loss:4.1120 train_time:258937ms step_avg:413.64ms
step:637/1500 train_loss:3.7073 train_time:259348ms step_avg:413.63ms
step:638/1500 train_loss:3.5198 train_time:259759ms step_avg:413.63ms
step:639/1500 train_loss:3.7528 train_time:260168ms step_avg:413.62ms
step:640/1500 train_loss:3.7984 train_time:260578ms step_avg:413.62ms
step:641/1500 train_loss:3.7438 train_time:260989ms step_avg:413.61ms
step:642/1500 train_loss:3.7504 train_time:261399ms step_avg:413.61ms
step:643/1500 train_loss:3.7918 train_time:261809ms step_avg:413.60ms
step:644/1500 train_loss:3.7998 train_time:262220ms step_avg:413.60ms
step:645/1500 train_loss:3.7296 train_time:262631ms step_avg:413.59ms
step:646/1500 train_loss:3.9493 train_time:263041ms step_avg:413.59ms
step:647/1500 train_loss:3.8471 train_time:263451ms step_avg:413.58ms
step:648/1500 train_loss:3.8460 train_time:263862ms step_avg:413.58ms
step:649/1500 train_loss:3.8714 train_time:264271ms step_avg:413.57ms
step:650/1500 train_loss:3.9330 train_time:264681ms step_avg:413.56ms
step:651/1500 train_loss:3.7873 train_time:265091ms step_avg:413.56ms
step:652/1500 train_loss:3.9327 train_time:265501ms step_avg:413.55ms
step:653/1500 train_loss:3.7571 train_time:265913ms step_avg:413.55ms
step:654/1500 train_loss:3.8372 train_time:266323ms step_avg:413.55ms
step:655/1500 train_loss:3.6016 train_time:266733ms step_avg:413.54ms
step:656/1500 train_loss:3.7483 train_time:267144ms step_avg:413.54ms
step:657/1500 train_loss:3.7506 train_time:267554ms step_avg:413.53ms
step:658/1500 train_loss:3.6836 train_time:267964ms step_avg:413.52ms
step:659/1500 train_loss:3.8599 train_time:268372ms step_avg:413.52ms
step:660/1500 train_loss:3.7629 train_time:268784ms step_avg:413.51ms
step:661/1500 train_loss:3.8533 train_time:269195ms step_avg:413.51ms
step:662/1500 train_loss:3.9245 train_time:269606ms step_avg:413.51ms
step:663/1500 train_loss:3.8388 train_time:270015ms step_avg:413.50ms
step:664/1500 train_loss:3.7176 train_time:270425ms step_avg:413.49ms
step:665/1500 train_loss:3.7995 train_time:270835ms step_avg:413.49ms
step:666/1500 train_loss:3.6708 train_time:271246ms step_avg:413.48ms
step:667/1500 train_loss:3.9531 train_time:271657ms step_avg:413.48ms
step:668/1500 train_loss:3.7920 train_time:272067ms step_avg:413.48ms
step:669/1500 train_loss:3.8018 train_time:272477ms step_avg:413.47ms
step:670/1500 train_loss:3.6507 train_time:272887ms step_avg:413.47ms
step:671/1500 train_loss:3.7658 train_time:273298ms step_avg:413.46ms
step:672/1500 train_loss:3.7262 train_time:273709ms step_avg:413.46ms
step:673/1500 train_loss:3.7452 train_time:274118ms step_avg:413.45ms
step:674/1500 train_loss:4.0275 train_time:274529ms step_avg:413.45ms
step:675/1500 train_loss:3.8168 train_time:274939ms step_avg:413.44ms
step:676/1500 train_loss:3.8923 train_time:275350ms step_avg:413.44ms
step:677/1500 train_loss:3.6650 train_time:275761ms step_avg:413.43ms
step:678/1500 train_loss:3.7655 train_time:276171ms step_avg:413.43ms
step:679/1500 train_loss:3.7154 train_time:276582ms step_avg:413.43ms
step:680/1500 train_loss:3.8523 train_time:276992ms step_avg:413.42ms
step:681/1500 train_loss:3.7525 train_time:277404ms step_avg:413.42ms
step:682/1500 train_loss:3.7819 train_time:277815ms step_avg:413.42ms
step:683/1500 train_loss:3.8546 train_time:278224ms step_avg:413.41ms
step:684/1500 train_loss:3.9025 train_time:278635ms step_avg:413.40ms
step:685/1500 train_loss:3.8021 train_time:279046ms step_avg:413.40ms
step:686/1500 train_loss:3.8767 train_time:279457ms step_avg:413.40ms
step:687/1500 train_loss:3.8052 train_time:279867ms step_avg:413.39ms
step:688/1500 train_loss:3.8462 train_time:280277ms step_avg:413.39ms
step:689/1500 train_loss:3.4629 train_time:280686ms step_avg:413.38ms
step:690/1500 train_loss:3.5834 train_time:281098ms step_avg:413.38ms
step:691/1500 train_loss:3.7256 train_time:281508ms step_avg:413.37ms
step:692/1500 train_loss:3.6039 train_time:281921ms step_avg:413.37ms
step:693/1500 train_loss:3.8101 train_time:282332ms step_avg:413.37ms
step:694/1500 train_loss:3.8319 train_time:282743ms step_avg:413.37ms
step:695/1500 train_loss:3.7217 train_time:283152ms step_avg:413.36ms
step:696/1500 train_loss:3.7072 train_time:283562ms step_avg:413.36ms
step:697/1500 train_loss:4.0201 train_time:283974ms step_avg:413.35ms
step:698/1500 train_loss:3.7720 train_time:284384ms step_avg:413.35ms
step:699/1500 train_loss:3.8130 train_time:284794ms step_avg:413.34ms
step:700/1500 train_loss:3.9732 train_time:285206ms step_avg:413.34ms
step:701/1500 train_loss:3.7480 train_time:285616ms step_avg:413.34ms
step:702/1500 train_loss:3.7073 train_time:286027ms step_avg:413.33ms
step:703/1500 train_loss:3.6886 train_time:286437ms step_avg:413.33ms
step:704/1500 train_loss:3.6488 train_time:286848ms step_avg:413.33ms
step:705/1500 train_loss:3.7358 train_time:287258ms step_avg:413.32ms
step:706/1500 train_loss:3.7334 train_time:287669ms step_avg:413.32ms
step:707/1500 train_loss:3.7466 train_time:288080ms step_avg:413.31ms
step:708/1500 train_loss:3.8158 train_time:288491ms step_avg:413.31ms
step:709/1500 train_loss:3.7599 train_time:288900ms step_avg:413.30ms
step:710/1500 train_loss:3.7416 train_time:289310ms step_avg:413.30ms
step:711/1500 train_loss:3.7075 train_time:289720ms step_avg:413.30ms
step:712/1500 train_loss:3.7542 train_time:290131ms step_avg:413.29ms
step:713/1500 train_loss:3.8162 train_time:290540ms step_avg:413.29ms
step:714/1500 train_loss:3.8262 train_time:290952ms step_avg:413.28ms
step:715/1500 train_loss:3.7396 train_time:291363ms step_avg:413.28ms
step:716/1500 train_loss:3.7373 train_time:291773ms step_avg:413.28ms
step:717/1500 train_loss:3.7547 train_time:292182ms step_avg:413.27ms
step:718/1500 train_loss:3.8967 train_time:292592ms step_avg:413.27ms
step:719/1500 train_loss:3.7575 train_time:293003ms step_avg:413.26ms
step:720/1500 train_loss:3.8353 train_time:293413ms step_avg:413.26ms
step:721/1500 train_loss:4.0068 train_time:293823ms step_avg:413.25ms
step:722/1500 train_loss:3.6322 train_time:294234ms step_avg:413.25ms
step:723/1500 train_loss:3.8896 train_time:294645ms step_avg:413.25ms
step:724/1500 train_loss:3.9520 train_time:295054ms step_avg:413.24ms
step:725/1500 train_loss:3.7301 train_time:295466ms step_avg:413.24ms
step:726/1500 train_loss:3.8100 train_time:295877ms step_avg:413.24ms
step:727/1500 train_loss:3.7046 train_time:296287ms step_avg:413.23ms
step:728/1500 train_loss:3.7288 train_time:296699ms step_avg:413.23ms
step:729/1500 train_loss:3.9012 train_time:297109ms step_avg:413.23ms
step:730/1500 train_loss:3.8401 train_time:297519ms step_avg:413.22ms
step:731/1500 train_loss:3.8503 train_time:297930ms step_avg:413.22ms
step:732/1500 train_loss:3.7338 train_time:298341ms step_avg:413.22ms
step:733/1500 train_loss:3.7540 train_time:298750ms step_avg:413.21ms
step:734/1500 train_loss:3.9942 train_time:299159ms step_avg:413.20ms
step:735/1500 train_loss:3.7285 train_time:299570ms step_avg:413.20ms
step:736/1500 train_loss:3.7843 train_time:299981ms step_avg:413.20ms
step:737/1500 train_loss:3.9088 train_time:300391ms step_avg:413.19ms
step:738/1500 train_loss:3.8263 train_time:300801ms step_avg:413.19ms
step:739/1500 train_loss:3.7652 train_time:301212ms step_avg:413.18ms
step:740/1500 train_loss:3.6657 train_time:301622ms step_avg:413.18ms
step:741/1500 train_loss:4.3038 train_time:302033ms step_avg:413.18ms
step:742/1500 train_loss:3.6636 train_time:302444ms step_avg:413.17ms
step:743/1500 train_loss:3.7374 train_time:302855ms step_avg:413.17ms
step:744/1500 train_loss:3.7534 train_time:303266ms step_avg:413.17ms
step:745/1500 train_loss:3.8059 train_time:303677ms step_avg:413.17ms
step:746/1500 train_loss:3.7817 train_time:304087ms step_avg:413.16ms
step:747/1500 train_loss:3.7612 train_time:304497ms step_avg:413.16ms
step:748/1500 train_loss:3.7987 train_time:304909ms step_avg:413.16ms
step:749/1500 train_loss:3.7237 train_time:305319ms step_avg:413.15ms
step:750/1500 train_loss:3.7316 train_time:305728ms step_avg:413.15ms
step:750/1500 val_loss:3.7364 train_time:305741ms step_avg:413.16ms
step:751/1500 train_loss:3.7640 train_time:306134ms step_avg:413.14ms
step:752/1500 train_loss:3.7285 train_time:306544ms step_avg:413.13ms
step:753/1500 train_loss:3.7651 train_time:306954ms step_avg:413.13ms
step:754/1500 train_loss:3.7864 train_time:307365ms step_avg:413.12ms
step:755/1500 train_loss:3.7543 train_time:307776ms step_avg:413.12ms
step:756/1500 train_loss:3.8285 train_time:308880ms step_avg:414.05ms
step:757/1500 train_loss:3.6530 train_time:309294ms step_avg:414.05ms
step:758/1500 train_loss:3.8950 train_time:309705ms step_avg:414.04ms
step:759/1500 train_loss:3.8131 train_time:310115ms step_avg:414.04ms
step:760/1500 train_loss:3.7487 train_time:310701ms step_avg:414.27ms
step:761/1500 train_loss:3.8554 train_time:311113ms step_avg:414.27ms
step:762/1500 train_loss:3.5652 train_time:311523ms step_avg:414.26ms
step:763/1500 train_loss:3.7184 train_time:311934ms step_avg:414.26ms
step:764/1500 train_loss:3.8264 train_time:312344ms step_avg:414.25ms
step:765/1500 train_loss:3.4818 train_time:312754ms step_avg:414.24ms
step:766/1500 train_loss:3.9034 train_time:313165ms step_avg:414.24ms
step:767/1500 train_loss:3.7546 train_time:313576ms step_avg:414.23ms
step:768/1500 train_loss:3.7196 train_time:313986ms step_avg:414.23ms
step:769/1500 train_loss:3.7397 train_time:314395ms step_avg:414.22ms
step:770/1500 train_loss:3.7600 train_time:314805ms step_avg:414.22ms
step:771/1500 train_loss:3.8187 train_time:315215ms step_avg:414.21ms
step:772/1500 train_loss:4.0463 train_time:315624ms step_avg:414.20ms
step:773/1500 train_loss:3.6248 train_time:316034ms step_avg:414.20ms
step:774/1500 train_loss:3.8143 train_time:316445ms step_avg:414.19ms
step:775/1500 train_loss:3.7969 train_time:316855ms step_avg:414.19ms
step:776/1500 train_loss:3.7704 train_time:317265ms step_avg:414.18ms
step:777/1500 train_loss:3.5707 train_time:317675ms step_avg:414.18ms
step:778/1500 train_loss:3.5751 train_time:318088ms step_avg:414.18ms
step:779/1500 train_loss:3.6414 train_time:318498ms step_avg:414.17ms
step:780/1500 train_loss:3.7365 train_time:318907ms step_avg:414.17ms
step:781/1500 train_loss:3.7565 train_time:319317ms step_avg:414.16ms
step:782/1500 train_loss:3.8205 train_time:319726ms step_avg:414.15ms
step:783/1500 train_loss:3.7346 train_time:320136ms step_avg:414.15ms
step:784/1500 train_loss:3.7318 train_time:320545ms step_avg:414.14ms
step:785/1500 train_loss:3.7412 train_time:320959ms step_avg:414.14ms
step:786/1500 train_loss:3.7147 train_time:321366ms step_avg:414.13ms
step:787/1500 train_loss:3.6186 train_time:321776ms step_avg:414.13ms
step:788/1500 train_loss:3.8981 train_time:322186ms step_avg:414.12ms
step:789/1500 train_loss:3.6690 train_time:322596ms step_avg:414.12ms
step:790/1500 train_loss:3.7301 train_time:323006ms step_avg:414.11ms
step:791/1500 train_loss:3.7897 train_time:323418ms step_avg:414.11ms
step:792/1500 train_loss:3.9253 train_time:323828ms step_avg:414.10ms
step:793/1500 train_loss:3.9296 train_time:324241ms step_avg:414.10ms
step:794/1500 train_loss:3.6335 train_time:324651ms step_avg:414.10ms
step:795/1500 train_loss:3.7699 train_time:325062ms step_avg:414.09ms
step:796/1500 train_loss:3.8237 train_time:325472ms step_avg:414.09ms
step:797/1500 train_loss:3.9159 train_time:325887ms step_avg:414.09ms
step:798/1500 train_loss:3.6817 train_time:326297ms step_avg:414.08ms
step:799/1500 train_loss:3.8241 train_time:326706ms step_avg:414.08ms
step:800/1500 train_loss:3.7191 train_time:327116ms step_avg:414.07ms
step:801/1500 train_loss:3.7023 train_time:327527ms step_avg:414.07ms
step:802/1500 train_loss:3.8006 train_time:327937ms step_avg:414.06ms
step:803/1500 train_loss:3.6566 train_time:328346ms step_avg:414.06ms
step:804/1500 train_loss:3.6747 train_time:328756ms step_avg:414.05ms
step:805/1500 train_loss:3.7962 train_time:329168ms step_avg:414.05ms
step:806/1500 train_loss:3.6925 train_time:329579ms step_avg:414.04ms
step:807/1500 train_loss:3.7055 train_time:329989ms step_avg:414.04ms
step:808/1500 train_loss:3.8023 train_time:330401ms step_avg:414.04ms
step:809/1500 train_loss:3.7217 train_time:330812ms step_avg:414.03ms
step:810/1500 train_loss:3.6448 train_time:331222ms step_avg:414.03ms
step:811/1500 train_loss:3.7240 train_time:331634ms step_avg:414.02ms
step:812/1500 train_loss:3.7634 train_time:332046ms step_avg:414.02ms
step:813/1500 train_loss:3.7563 train_time:332457ms step_avg:414.02ms
step:814/1500 train_loss:3.7874 train_time:332867ms step_avg:414.01ms
step:815/1500 train_loss:3.7367 train_time:333276ms step_avg:414.01ms
step:816/1500 train_loss:3.7220 train_time:333688ms step_avg:414.00ms
step:817/1500 train_loss:3.8296 train_time:334097ms step_avg:414.00ms
step:818/1500 train_loss:3.9146 train_time:334507ms step_avg:413.99ms
step:819/1500 train_loss:3.6831 train_time:334920ms step_avg:413.99ms
step:820/1500 train_loss:3.8820 train_time:335331ms step_avg:413.99ms
step:821/1500 train_loss:3.6637 train_time:335740ms step_avg:413.98ms
step:822/1500 train_loss:3.7102 train_time:336151ms step_avg:413.98ms
step:823/1500 train_loss:3.8286 train_time:336563ms step_avg:413.98ms
step:824/1500 train_loss:3.7463 train_time:336973ms step_avg:413.97ms
step:825/1500 train_loss:3.6763 train_time:337384ms step_avg:413.97ms
step:826/1500 train_loss:3.7730 train_time:337795ms step_avg:413.96ms
step:827/1500 train_loss:3.6691 train_time:338204ms step_avg:413.96ms
step:828/1500 train_loss:3.8943 train_time:338613ms step_avg:413.95ms
step:829/1500 train_loss:3.7794 train_time:339024ms step_avg:413.95ms
step:830/1500 train_loss:3.8344 train_time:339435ms step_avg:413.95ms
step:831/1500 train_loss:3.6947 train_time:339845ms step_avg:413.94ms
step:832/1500 train_loss:3.7456 train_time:340256ms step_avg:413.94ms
step:833/1500 train_loss:3.6746 train_time:340666ms step_avg:413.93ms
step:834/1500 train_loss:3.8073 train_time:341078ms step_avg:413.93ms
step:835/1500 train_loss:3.6400 train_time:341489ms step_avg:413.93ms
step:836/1500 train_loss:3.6192 train_time:341899ms step_avg:413.92ms
step:837/1500 train_loss:3.8797 train_time:342310ms step_avg:413.92ms
step:838/1500 train_loss:3.5820 train_time:342721ms step_avg:413.91ms
step:839/1500 train_loss:3.7538 train_time:343132ms step_avg:413.91ms
step:840/1500 train_loss:3.5911 train_time:343541ms step_avg:413.91ms
step:841/1500 train_loss:3.6373 train_time:343952ms step_avg:413.90ms
step:842/1500 train_loss:3.7182 train_time:344364ms step_avg:413.90ms
step:843/1500 train_loss:3.7388 train_time:344774ms step_avg:413.89ms
step:844/1500 train_loss:3.7395 train_time:345185ms step_avg:413.89ms
step:845/1500 train_loss:3.5898 train_time:345597ms step_avg:413.89ms
step:846/1500 train_loss:3.8269 train_time:346007ms step_avg:413.88ms
step:847/1500 train_loss:3.6937 train_time:346418ms step_avg:413.88ms
step:848/1500 train_loss:3.6504 train_time:346829ms step_avg:413.88ms
step:849/1500 train_loss:3.7873 train_time:347240ms step_avg:413.87ms
step:850/1500 train_loss:3.6523 train_time:347651ms step_avg:413.87ms
step:851/1500 train_loss:3.6105 train_time:348061ms step_avg:413.87ms
step:852/1500 train_loss:3.8970 train_time:348471ms step_avg:413.86ms
step:853/1500 train_loss:3.6119 train_time:348881ms step_avg:413.86ms
step:854/1500 train_loss:3.7276 train_time:349292ms step_avg:413.85ms
step:855/1500 train_loss:3.8084 train_time:349703ms step_avg:413.85ms
step:856/1500 train_loss:3.6824 train_time:350114ms step_avg:413.85ms
step:857/1500 train_loss:3.7096 train_time:350523ms step_avg:413.84ms
step:858/1500 train_loss:3.7620 train_time:350933ms step_avg:413.84ms
step:859/1500 train_loss:3.6430 train_time:351344ms step_avg:413.83ms
step:860/1500 train_loss:3.7226 train_time:351754ms step_avg:413.83ms
step:861/1500 train_loss:3.7512 train_time:352163ms step_avg:413.82ms
step:862/1500 train_loss:3.8008 train_time:352574ms step_avg:413.82ms
step:863/1500 train_loss:3.7534 train_time:352985ms step_avg:413.82ms
step:864/1500 train_loss:3.7347 train_time:353395ms step_avg:413.81ms
step:865/1500 train_loss:3.5598 train_time:353803ms step_avg:413.80ms
step:866/1500 train_loss:3.7470 train_time:354214ms step_avg:413.80ms
step:867/1500 train_loss:4.0221 train_time:354626ms step_avg:413.80ms
step:868/1500 train_loss:3.6068 train_time:355036ms step_avg:413.80ms
step:869/1500 train_loss:3.7918 train_time:355448ms step_avg:413.79ms
step:870/1500 train_loss:3.7728 train_time:355858ms step_avg:413.79ms
step:871/1500 train_loss:3.6111 train_time:356269ms step_avg:413.79ms
step:872/1500 train_loss:3.5689 train_time:356678ms step_avg:413.78ms
step:873/1500 train_loss:3.8246 train_time:357088ms step_avg:413.77ms
step:874/1500 train_loss:3.6059 train_time:357499ms step_avg:413.77ms
step:875/1500 train_loss:3.3339 train_time:357909ms step_avg:413.77ms
step:875/1500 val_loss:3.6834 train_time:357922ms step_avg:413.78ms
step:876/1500 train_loss:3.8017 train_time:358316ms step_avg:413.76ms
step:877/1500 train_loss:3.6101 train_time:358726ms step_avg:413.76ms
step:878/1500 train_loss:3.7823 train_time:359137ms step_avg:413.75ms
step:879/1500 train_loss:3.6397 train_time:359547ms step_avg:413.75ms
step:880/1500 train_loss:3.8217 train_time:359956ms step_avg:413.74ms
step:881/1500 train_loss:3.4842 train_time:360367ms step_avg:413.74ms
step:882/1500 train_loss:3.6555 train_time:360778ms step_avg:413.74ms
step:883/1500 train_loss:3.8525 train_time:361188ms step_avg:413.73ms
step:884/1500 train_loss:4.0060 train_time:361598ms step_avg:413.73ms
step:885/1500 train_loss:3.7292 train_time:362009ms step_avg:413.72ms
step:886/1500 train_loss:3.6450 train_time:362420ms step_avg:413.72ms
step:887/1500 train_loss:3.7412 train_time:362830ms step_avg:413.72ms
step:888/1500 train_loss:4.2259 train_time:363241ms step_avg:413.71ms
step:889/1500 train_loss:4.0007 train_time:363651ms step_avg:413.71ms
step:890/1500 train_loss:3.6808 train_time:364063ms step_avg:413.71ms
step:891/1500 train_loss:3.6920 train_time:364473ms step_avg:413.70ms
step:892/1500 train_loss:3.5179 train_time:364882ms step_avg:413.70ms
step:893/1500 train_loss:3.8642 train_time:365292ms step_avg:413.69ms
step:894/1500 train_loss:3.5864 train_time:365704ms step_avg:413.69ms
step:895/1500 train_loss:3.8307 train_time:366114ms step_avg:413.69ms
step:896/1500 train_loss:3.8524 train_time:366524ms step_avg:413.68ms
step:897/1500 train_loss:3.6522 train_time:366935ms step_avg:413.68ms
step:898/1500 train_loss:3.6955 train_time:367345ms step_avg:413.68ms
step:899/1500 train_loss:3.7449 train_time:367755ms step_avg:413.67ms
step:900/1500 train_loss:3.6335 train_time:368165ms step_avg:413.67ms
step:901/1500 train_loss:3.5759 train_time:368577ms step_avg:413.67ms
step:902/1500 train_loss:3.7838 train_time:368987ms step_avg:413.66ms
step:903/1500 train_loss:3.7932 train_time:369396ms step_avg:413.66ms
step:904/1500 train_loss:3.6941 train_time:369806ms step_avg:413.65ms
step:905/1500 train_loss:3.6560 train_time:370216ms step_avg:413.65ms
step:906/1500 train_loss:3.6491 train_time:370625ms step_avg:413.64ms
step:907/1500 train_loss:3.8745 train_time:371035ms step_avg:413.64ms
step:908/1500 train_loss:3.6655 train_time:371447ms step_avg:413.64ms
step:909/1500 train_loss:3.7105 train_time:371857ms step_avg:413.63ms
step:910/1500 train_loss:3.6163 train_time:372267ms step_avg:413.63ms
step:911/1500 train_loss:3.7065 train_time:372678ms step_avg:413.63ms
step:912/1500 train_loss:3.7803 train_time:373088ms step_avg:413.62ms
step:913/1500 train_loss:3.7675 train_time:373498ms step_avg:413.62ms
step:914/1500 train_loss:3.6431 train_time:373908ms step_avg:413.62ms
step:915/1500 train_loss:3.8931 train_time:374318ms step_avg:413.61ms
step:916/1500 train_loss:3.6858 train_time:374727ms step_avg:413.61ms
step:917/1500 train_loss:3.7836 train_time:375138ms step_avg:413.60ms
step:918/1500 train_loss:3.7536 train_time:375549ms step_avg:413.60ms
step:919/1500 train_loss:4.9866 train_time:375959ms step_avg:413.60ms
step:920/1500 train_loss:3.6707 train_time:376371ms step_avg:413.59ms
step:921/1500 train_loss:3.7245 train_time:376781ms step_avg:413.59ms
step:922/1500 train_loss:3.6914 train_time:377190ms step_avg:413.59ms
step:923/1500 train_loss:3.7422 train_time:377601ms step_avg:413.58ms
step:924/1500 train_loss:3.7535 train_time:378012ms step_avg:413.58ms
step:925/1500 train_loss:3.8433 train_time:378422ms step_avg:413.58ms
step:926/1500 train_loss:3.8159 train_time:378833ms step_avg:413.57ms
step:927/1500 train_loss:3.7105 train_time:379243ms step_avg:413.57ms
step:928/1500 train_loss:3.7041 train_time:379653ms step_avg:413.57ms
step:929/1500 train_loss:3.9298 train_time:380063ms step_avg:413.56ms
step:930/1500 train_loss:3.7726 train_time:380474ms step_avg:413.56ms
step:931/1500 train_loss:3.5578 train_time:380885ms step_avg:413.56ms
step:932/1500 train_loss:3.6447 train_time:381296ms step_avg:413.55ms
step:933/1500 train_loss:3.8273 train_time:381708ms step_avg:413.55ms
step:934/1500 train_loss:3.5434 train_time:382118ms step_avg:413.55ms
step:935/1500 train_loss:3.7276 train_time:382528ms step_avg:413.54ms
step:936/1500 train_loss:3.6013 train_time:382939ms step_avg:413.54ms
step:937/1500 train_loss:3.6713 train_time:383349ms step_avg:413.54ms
step:938/1500 train_loss:3.7626 train_time:383763ms step_avg:413.54ms
step:939/1500 train_loss:3.6908 train_time:384171ms step_avg:413.53ms
step:940/1500 train_loss:3.8483 train_time:384582ms step_avg:413.53ms
step:941/1500 train_loss:3.6413 train_time:384992ms step_avg:413.52ms
step:942/1500 train_loss:3.7012 train_time:385402ms step_avg:413.52ms
step:943/1500 train_loss:3.5023 train_time:385814ms step_avg:413.52ms
step:944/1500 train_loss:3.8575 train_time:386224ms step_avg:413.52ms
step:945/1500 train_loss:3.5642 train_time:387129ms step_avg:414.04ms
step:946/1500 train_loss:3.5790 train_time:387540ms step_avg:414.04ms
step:947/1500 train_loss:5.2049 train_time:387950ms step_avg:414.03ms
step:948/1500 train_loss:3.7531 train_time:388359ms step_avg:414.03ms
step:949/1500 train_loss:3.6513 train_time:388769ms step_avg:414.02ms
step:950/1500 train_loss:3.5496 train_time:389348ms step_avg:414.20ms
step:951/1500 train_loss:3.6075 train_time:389760ms step_avg:414.20ms
step:952/1500 train_loss:3.5584 train_time:390171ms step_avg:414.19ms
step:953/1500 train_loss:3.6357 train_time:390582ms step_avg:414.19ms
step:954/1500 train_loss:3.7105 train_time:390992ms step_avg:414.19ms
step:955/1500 train_loss:3.5999 train_time:391402ms step_avg:414.18ms
step:956/1500 train_loss:3.6312 train_time:391813ms step_avg:414.18ms
step:957/1500 train_loss:3.5919 train_time:392223ms step_avg:414.17ms
step:958/1500 train_loss:3.6536 train_time:392632ms step_avg:414.17ms
step:959/1500 train_loss:3.6468 train_time:393043ms step_avg:414.17ms
step:960/1500 train_loss:3.6645 train_time:393452ms step_avg:414.16ms
step:961/1500 train_loss:3.5469 train_time:393864ms step_avg:414.16ms
step:962/1500 train_loss:3.8056 train_time:394275ms step_avg:414.15ms
step:963/1500 train_loss:3.7524 train_time:394685ms step_avg:414.15ms
step:964/1500 train_loss:3.5587 train_time:395095ms step_avg:414.15ms
step:965/1500 train_loss:3.6034 train_time:395507ms step_avg:414.14ms
step:966/1500 train_loss:3.6424 train_time:395917ms step_avg:414.14ms
step:967/1500 train_loss:3.8594 train_time:396326ms step_avg:414.13ms
step:968/1500 train_loss:3.6842 train_time:396737ms step_avg:414.13ms
step:969/1500 train_loss:3.6744 train_time:397153ms step_avg:414.13ms
step:970/1500 train_loss:3.7300 train_time:397563ms step_avg:414.13ms
step:971/1500 train_loss:3.5372 train_time:397974ms step_avg:414.13ms
step:972/1500 train_loss:3.7018 train_time:398385ms step_avg:414.12ms
step:973/1500 train_loss:3.6380 train_time:398798ms step_avg:414.12ms
step:974/1500 train_loss:3.6970 train_time:399208ms step_avg:414.12ms
step:975/1500 train_loss:3.7652 train_time:399618ms step_avg:414.11ms
step:976/1500 train_loss:3.6357 train_time:400028ms step_avg:414.11ms
step:977/1500 train_loss:3.8317 train_time:400438ms step_avg:414.10ms
step:978/1500 train_loss:3.7213 train_time:400849ms step_avg:414.10ms
step:979/1500 train_loss:3.5428 train_time:401259ms step_avg:414.10ms
step:980/1500 train_loss:3.8380 train_time:401669ms step_avg:414.09ms
step:981/1500 train_loss:3.5739 train_time:402080ms step_avg:414.09ms
step:982/1500 train_loss:3.7348 train_time:402491ms step_avg:414.09ms
step:983/1500 train_loss:3.7144 train_time:402902ms step_avg:414.08ms
step:984/1500 train_loss:3.7162 train_time:403312ms step_avg:414.08ms
step:985/1500 train_loss:3.6697 train_time:403723ms step_avg:414.08ms
step:986/1500 train_loss:3.7443 train_time:404133ms step_avg:414.07ms
step:987/1500 train_loss:3.5678 train_time:404544ms step_avg:414.07ms
step:988/1500 train_loss:3.6427 train_time:404955ms step_avg:414.06ms
step:989/1500 train_loss:3.6444 train_time:405365ms step_avg:414.06ms
step:990/1500 train_loss:3.5865 train_time:405774ms step_avg:414.06ms
step:991/1500 train_loss:3.8037 train_time:406184ms step_avg:414.05ms
step:992/1500 train_loss:3.6265 train_time:406597ms step_avg:414.05ms
step:993/1500 train_loss:3.5997 train_time:407007ms step_avg:414.05ms
step:994/1500 train_loss:3.6646 train_time:407417ms step_avg:414.04ms
step:995/1500 train_loss:3.7526 train_time:407828ms step_avg:414.04ms
step:996/1500 train_loss:3.6995 train_time:408238ms step_avg:414.03ms
step:997/1500 train_loss:3.6109 train_time:408647ms step_avg:414.03ms
step:998/1500 train_loss:3.9598 train_time:409058ms step_avg:414.03ms
step:999/1500 train_loss:3.6159 train_time:409468ms step_avg:414.02ms
step:1000/1500 train_loss:3.7400 train_time:409878ms step_avg:414.02ms
step:1000/1500 val_loss:3.6386 train_time:409891ms step_avg:414.03ms
step:1001/1500 train_loss:3.6089 train_time:410283ms step_avg:414.01ms
step:1002/1500 train_loss:3.6626 train_time:410694ms step_avg:414.01ms
step:1003/1500 train_loss:3.5490 train_time:411105ms step_avg:414.00ms
step:1004/1500 train_loss:3.7317 train_time:411517ms step_avg:414.00ms
step:1005/1500 train_loss:3.7812 train_time:411927ms step_avg:414.00ms
step:1006/1500 train_loss:3.5541 train_time:412338ms step_avg:413.99ms
step:1007/1500 train_loss:3.6383 train_time:412748ms step_avg:413.99ms
step:1008/1500 train_loss:3.6022 train_time:413158ms step_avg:413.99ms
step:1009/1500 train_loss:3.7264 train_time:413570ms step_avg:413.98ms
step:1010/1500 train_loss:3.8233 train_time:413979ms step_avg:413.98ms
step:1011/1500 train_loss:3.7153 train_time:414389ms step_avg:413.98ms
step:1012/1500 train_loss:3.6862 train_time:414800ms step_avg:413.97ms
step:1013/1500 train_loss:3.5488 train_time:415211ms step_avg:413.97ms
step:1014/1500 train_loss:3.6848 train_time:415621ms step_avg:413.97ms
step:1015/1500 train_loss:3.8000 train_time:416031ms step_avg:413.96ms
step:1016/1500 train_loss:3.5072 train_time:416444ms step_avg:413.96ms
step:1017/1500 train_loss:3.6017 train_time:416854ms step_avg:413.96ms
step:1018/1500 train_loss:3.5991 train_time:417264ms step_avg:413.95ms
step:1019/1500 train_loss:3.5481 train_time:417676ms step_avg:413.95ms
step:1020/1500 train_loss:3.6864 train_time:418087ms step_avg:413.95ms
step:1021/1500 train_loss:3.5975 train_time:418496ms step_avg:413.94ms
step:1022/1500 train_loss:3.5317 train_time:418907ms step_avg:413.94ms
step:1023/1500 train_loss:3.6371 train_time:419317ms step_avg:413.94ms
step:1024/1500 train_loss:3.6650 train_time:419727ms step_avg:413.93ms
step:1025/1500 train_loss:3.6475 train_time:420136ms step_avg:413.93ms
step:1026/1500 train_loss:3.6589 train_time:420548ms step_avg:413.92ms
step:1027/1500 train_loss:3.8161 train_time:420958ms step_avg:413.92ms
step:1028/1500 train_loss:3.4980 train_time:421369ms step_avg:413.92ms
step:1029/1500 train_loss:3.5593 train_time:421781ms step_avg:413.92ms
step:1030/1500 train_loss:3.5090 train_time:422192ms step_avg:413.91ms
step:1031/1500 train_loss:3.6822 train_time:422603ms step_avg:413.91ms
step:1032/1500 train_loss:3.6655 train_time:423013ms step_avg:413.91ms
step:1033/1500 train_loss:3.8451 train_time:423424ms step_avg:413.90ms
step:1034/1500 train_loss:3.6599 train_time:423834ms step_avg:413.90ms
step:1035/1500 train_loss:3.5797 train_time:424245ms step_avg:413.90ms
step:1036/1500 train_loss:3.6037 train_time:424656ms step_avg:413.89ms
step:1037/1500 train_loss:3.6598 train_time:425067ms step_avg:413.89ms
step:1038/1500 train_loss:3.9681 train_time:425476ms step_avg:413.89ms
step:1039/1500 train_loss:3.7897 train_time:425887ms step_avg:413.88ms
step:1040/1500 train_loss:3.6856 train_time:426300ms step_avg:413.88ms
step:1041/1500 train_loss:3.5785 train_time:426710ms step_avg:413.88ms
step:1042/1500 train_loss:3.6486 train_time:427121ms step_avg:413.88ms
step:1043/1500 train_loss:3.6887 train_time:427531ms step_avg:413.87ms
step:1044/1500 train_loss:3.6181 train_time:427942ms step_avg:413.87ms
step:1045/1500 train_loss:3.6302 train_time:428354ms step_avg:413.87ms
step:1046/1500 train_loss:3.7014 train_time:428764ms step_avg:413.86ms
step:1047/1500 train_loss:3.6060 train_time:429174ms step_avg:413.86ms
step:1048/1500 train_loss:3.8154 train_time:429584ms step_avg:413.86ms
step:1049/1500 train_loss:3.6670 train_time:429995ms step_avg:413.85ms
step:1050/1500 train_loss:3.5902 train_time:430405ms step_avg:413.85ms
step:1051/1500 train_loss:3.5608 train_time:430817ms step_avg:413.85ms
step:1052/1500 train_loss:3.6825 train_time:431228ms step_avg:413.85ms
step:1053/1500 train_loss:3.5567 train_time:431637ms step_avg:413.84ms
step:1054/1500 train_loss:3.8812 train_time:432048ms step_avg:413.84ms
step:1055/1500 train_loss:3.7073 train_time:432458ms step_avg:413.84ms
step:1056/1500 train_loss:3.5746 train_time:432868ms step_avg:413.83ms
step:1057/1500 train_loss:3.6724 train_time:433279ms step_avg:413.83ms
step:1058/1500 train_loss:3.7513 train_time:433688ms step_avg:413.82ms
step:1059/1500 train_loss:3.4725 train_time:434099ms step_avg:413.82ms
step:1060/1500 train_loss:3.5893 train_time:434509ms step_avg:413.82ms
step:1061/1500 train_loss:3.6123 train_time:434921ms step_avg:413.82ms
step:1062/1500 train_loss:3.5877 train_time:435332ms step_avg:413.81ms
step:1063/1500 train_loss:3.5618 train_time:435742ms step_avg:413.81ms
step:1064/1500 train_loss:3.6584 train_time:436152ms step_avg:413.81ms
step:1065/1500 train_loss:3.5599 train_time:436563ms step_avg:413.80ms
step:1066/1500 train_loss:3.5493 train_time:436973ms step_avg:413.80ms
step:1067/1500 train_loss:3.5769 train_time:437382ms step_avg:413.80ms
step:1068/1500 train_loss:3.4810 train_time:437792ms step_avg:413.79ms
step:1069/1500 train_loss:3.6023 train_time:438203ms step_avg:413.79ms
step:1070/1500 train_loss:3.4735 train_time:438613ms step_avg:413.79ms
step:1071/1500 train_loss:3.7275 train_time:439025ms step_avg:413.78ms
step:1072/1500 train_loss:3.6840 train_time:439436ms step_avg:413.78ms
step:1073/1500 train_loss:3.6257 train_time:439846ms step_avg:413.78ms
step:1074/1500 train_loss:3.6879 train_time:440258ms step_avg:413.78ms
step:1075/1500 train_loss:3.6368 train_time:440669ms step_avg:413.77ms
step:1076/1500 train_loss:3.5779 train_time:441079ms step_avg:413.77ms
step:1077/1500 train_loss:3.9681 train_time:441491ms step_avg:413.77ms
step:1078/1500 train_loss:3.6401 train_time:441901ms step_avg:413.77ms
step:1079/1500 train_loss:3.3641 train_time:442312ms step_avg:413.76ms
step:1080/1500 train_loss:3.7112 train_time:442723ms step_avg:413.76ms
step:1081/1500 train_loss:3.6263 train_time:443134ms step_avg:413.76ms
step:1082/1500 train_loss:3.6825 train_time:443544ms step_avg:413.75ms
step:1083/1500 train_loss:3.7849 train_time:443956ms step_avg:413.75ms
step:1084/1500 train_loss:3.6807 train_time:444389ms step_avg:413.77ms
step:1085/1500 train_loss:3.6492 train_time:444798ms step_avg:413.77ms
step:1086/1500 train_loss:3.6207 train_time:445209ms step_avg:413.76ms
step:1087/1500 train_loss:3.8139 train_time:445620ms step_avg:413.76ms
step:1088/1500 train_loss:3.7013 train_time:446030ms step_avg:413.76ms
step:1089/1500 train_loss:3.5337 train_time:446439ms step_avg:413.75ms
step:1090/1500 train_loss:3.5640 train_time:446850ms step_avg:413.75ms
step:1091/1500 train_loss:3.6790 train_time:447259ms step_avg:413.75ms
step:1092/1500 train_loss:3.4701 train_time:447669ms step_avg:413.74ms
step:1093/1500 train_loss:3.6695 train_time:448080ms step_avg:413.74ms
step:1094/1500 train_loss:3.8006 train_time:448491ms step_avg:413.74ms
step:1095/1500 train_loss:3.6397 train_time:448900ms step_avg:413.73ms
step:1096/1500 train_loss:3.5919 train_time:449311ms step_avg:413.73ms
step:1097/1500 train_loss:3.6158 train_time:449722ms step_avg:413.73ms
step:1098/1500 train_loss:3.6634 train_time:450132ms step_avg:413.72ms
step:1099/1500 train_loss:3.7379 train_time:450542ms step_avg:413.72ms
step:1100/1500 train_loss:3.6962 train_time:450953ms step_avg:413.72ms
step:1101/1500 train_loss:3.6222 train_time:451363ms step_avg:413.71ms
step:1102/1500 train_loss:3.4829 train_time:451773ms step_avg:413.71ms
step:1103/1500 train_loss:3.5616 train_time:452183ms step_avg:413.71ms
step:1104/1500 train_loss:3.6303 train_time:452595ms step_avg:413.71ms
step:1105/1500 train_loss:3.5107 train_time:453004ms step_avg:413.70ms
step:1106/1500 train_loss:4.2609 train_time:453415ms step_avg:413.70ms
step:1107/1500 train_loss:3.4143 train_time:453825ms step_avg:413.70ms
step:1108/1500 train_loss:3.7542 train_time:454234ms step_avg:413.69ms
step:1109/1500 train_loss:3.5348 train_time:454644ms step_avg:413.69ms
step:1110/1500 train_loss:3.6803 train_time:455055ms step_avg:413.69ms
step:1111/1500 train_loss:3.6123 train_time:455467ms step_avg:413.68ms
step:1112/1500 train_loss:3.6547 train_time:455877ms step_avg:413.68ms
step:1113/1500 train_loss:3.7556 train_time:456288ms step_avg:413.68ms
step:1114/1500 train_loss:3.6058 train_time:456700ms step_avg:413.68ms
step:1115/1500 train_loss:3.5540 train_time:457110ms step_avg:413.67ms
step:1116/1500 train_loss:3.4497 train_time:457521ms step_avg:413.67ms
step:1117/1500 train_loss:3.6207 train_time:457933ms step_avg:413.67ms
step:1118/1500 train_loss:3.7700 train_time:458344ms step_avg:413.67ms
step:1119/1500 train_loss:3.8155 train_time:458754ms step_avg:413.66ms
step:1120/1500 train_loss:3.6487 train_time:459165ms step_avg:413.66ms
step:1121/1500 train_loss:3.6740 train_time:459576ms step_avg:413.66ms
step:1122/1500 train_loss:3.5758 train_time:459987ms step_avg:413.66ms
step:1123/1500 train_loss:3.6366 train_time:460398ms step_avg:413.65ms
step:1124/1500 train_loss:3.7709 train_time:460808ms step_avg:413.65ms
step:1125/1500 train_loss:3.5424 train_time:461219ms step_avg:413.65ms
step:1125/1500 val_loss:3.6022 train_time:461232ms step_avg:413.66ms
step:1126/1500 train_loss:3.4256 train_time:461625ms step_avg:413.64ms
step:1127/1500 train_loss:3.6610 train_time:462036ms step_avg:413.64ms
step:1128/1500 train_loss:3.8790 train_time:462446ms step_avg:413.64ms
step:1129/1500 train_loss:3.4216 train_time:462859ms step_avg:413.64ms
step:1130/1500 train_loss:3.7373 train_time:463268ms step_avg:413.63ms
step:1131/1500 train_loss:3.5752 train_time:463678ms step_avg:413.63ms
step:1132/1500 train_loss:3.6012 train_time:464090ms step_avg:413.63ms
step:1133/1500 train_loss:3.5517 train_time:464502ms step_avg:413.63ms
step:1134/1500 train_loss:3.7121 train_time:465460ms step_avg:414.11ms
step:1135/1500 train_loss:3.6499 train_time:465872ms step_avg:414.11ms
step:1136/1500 train_loss:3.6983 train_time:466281ms step_avg:414.10ms
step:1137/1500 train_loss:3.7344 train_time:466690ms step_avg:414.10ms
step:1138/1500 train_loss:3.6467 train_time:467102ms step_avg:414.10ms
step:1139/1500 train_loss:3.5502 train_time:467512ms step_avg:414.09ms
step:1140/1500 train_loss:3.8579 train_time:468099ms step_avg:414.25ms
step:1141/1500 train_loss:3.6523 train_time:468513ms step_avg:414.25ms
step:1142/1500 train_loss:3.7481 train_time:468923ms step_avg:414.24ms
step:1143/1500 train_loss:3.6420 train_time:469333ms step_avg:414.24ms
step:1144/1500 train_loss:3.5570 train_time:469744ms step_avg:414.24ms
step:1145/1500 train_loss:3.6544 train_time:470155ms step_avg:414.23ms
step:1146/1500 train_loss:3.7748 train_time:470564ms step_avg:414.23ms
step:1147/1500 train_loss:3.7513 train_time:470975ms step_avg:414.23ms
step:1148/1500 train_loss:3.6643 train_time:471385ms step_avg:414.22ms
step:1149/1500 train_loss:3.6896 train_time:471796ms step_avg:414.22ms
step:1150/1500 train_loss:3.5338 train_time:472206ms step_avg:414.22ms
step:1151/1500 train_loss:3.5640 train_time:472618ms step_avg:414.21ms
step:1152/1500 train_loss:3.5261 train_time:473028ms step_avg:414.21ms
step:1153/1500 train_loss:3.6642 train_time:473437ms step_avg:414.21ms
step:1154/1500 train_loss:3.6416 train_time:473845ms step_avg:414.20ms
step:1155/1500 train_loss:3.7073 train_time:474257ms step_avg:414.20ms
step:1156/1500 train_loss:3.5582 train_time:474667ms step_avg:414.19ms
step:1157/1500 train_loss:3.7252 train_time:475076ms step_avg:414.19ms
step:1158/1500 train_loss:3.6827 train_time:475487ms step_avg:414.19ms
step:1159/1500 train_loss:3.4908 train_time:475898ms step_avg:414.18ms
step:1160/1500 train_loss:3.5290 train_time:476308ms step_avg:414.18ms
step:1161/1500 train_loss:3.5212 train_time:476717ms step_avg:414.18ms
step:1162/1500 train_loss:3.3096 train_time:477128ms step_avg:414.17ms
step:1163/1500 train_loss:3.6239 train_time:477538ms step_avg:414.17ms
step:1164/1500 train_loss:3.6027 train_time:477949ms step_avg:414.17ms
step:1165/1500 train_loss:3.4684 train_time:478359ms step_avg:414.16ms
step:1166/1500 train_loss:3.4620 train_time:478770ms step_avg:414.16ms
step:1167/1500 train_loss:3.5718 train_time:479181ms step_avg:414.16ms
step:1168/1500 train_loss:3.5836 train_time:479591ms step_avg:414.15ms
step:1169/1500 train_loss:3.9000 train_time:480002ms step_avg:414.15ms
step:1170/1500 train_loss:3.5783 train_time:480413ms step_avg:414.15ms
step:1171/1500 train_loss:3.5907 train_time:480825ms step_avg:414.15ms
step:1172/1500 train_loss:3.4903 train_time:481235ms step_avg:414.14ms
step:1173/1500 train_loss:3.6035 train_time:481646ms step_avg:414.14ms
step:1174/1500 train_loss:3.7353 train_time:482058ms step_avg:414.14ms
step:1175/1500 train_loss:3.5756 train_time:482467ms step_avg:414.13ms
step:1176/1500 train_loss:3.5907 train_time:482879ms step_avg:414.13ms
step:1177/1500 train_loss:3.6415 train_time:483290ms step_avg:414.13ms
step:1178/1500 train_loss:3.6275 train_time:483700ms step_avg:414.13ms
step:1179/1500 train_loss:3.6812 train_time:484122ms step_avg:414.13ms
step:1180/1500 train_loss:3.5886 train_time:484533ms step_avg:414.13ms
step:1181/1500 train_loss:3.6036 train_time:484943ms step_avg:414.13ms
step:1182/1500 train_loss:3.5412 train_time:485354ms step_avg:414.12ms
step:1183/1500 train_loss:3.5756 train_time:485764ms step_avg:414.12ms
step:1184/1500 train_loss:3.5308 train_time:486174ms step_avg:414.12ms
step:1185/1500 train_loss:3.6945 train_time:486584ms step_avg:414.11ms
step:1186/1500 train_loss:3.7520 train_time:486996ms step_avg:414.11ms
step:1187/1500 train_loss:3.5512 train_time:487406ms step_avg:414.11ms
step:1188/1500 train_loss:3.6097 train_time:487817ms step_avg:414.11ms
step:1189/1500 train_loss:3.6285 train_time:488228ms step_avg:414.10ms
step:1190/1500 train_loss:3.4715 train_time:488638ms step_avg:414.10ms
step:1191/1500 train_loss:3.6440 train_time:489047ms step_avg:414.10ms
step:1192/1500 train_loss:3.7879 train_time:489459ms step_avg:414.09ms
step:1193/1500 train_loss:3.5869 train_time:489869ms step_avg:414.09ms
step:1194/1500 train_loss:3.4725 train_time:490281ms step_avg:414.09ms
step:1195/1500 train_loss:3.7739 train_time:490692ms step_avg:414.09ms
step:1196/1500 train_loss:3.5725 train_time:491102ms step_avg:414.08ms
step:1197/1500 train_loss:3.5771 train_time:491513ms step_avg:414.08ms
step:1198/1500 train_loss:3.4828 train_time:491924ms step_avg:414.08ms
step:1199/1500 train_loss:3.4897 train_time:492334ms step_avg:414.07ms
step:1200/1500 train_loss:3.5411 train_time:492745ms step_avg:414.07ms
step:1201/1500 train_loss:3.6264 train_time:493156ms step_avg:414.07ms
step:1202/1500 train_loss:3.6992 train_time:493566ms step_avg:414.07ms
step:1203/1500 train_loss:3.7356 train_time:493977ms step_avg:414.06ms
step:1204/1500 train_loss:3.6138 train_time:494387ms step_avg:414.06ms
step:1205/1500 train_loss:3.5273 train_time:494798ms step_avg:414.06ms
step:1206/1500 train_loss:3.6214 train_time:495207ms step_avg:414.05ms
step:1207/1500 train_loss:3.6674 train_time:495616ms step_avg:414.05ms
step:1208/1500 train_loss:3.7161 train_time:496027ms step_avg:414.05ms
step:1209/1500 train_loss:3.5950 train_time:496437ms step_avg:414.04ms
step:1210/1500 train_loss:3.4562 train_time:496848ms step_avg:414.04ms
step:1211/1500 train_loss:3.5052 train_time:497258ms step_avg:414.04ms
step:1212/1500 train_loss:3.6032 train_time:497668ms step_avg:414.03ms
step:1213/1500 train_loss:3.6142 train_time:498078ms step_avg:414.03ms
step:1214/1500 train_loss:3.6359 train_time:498489ms step_avg:414.03ms
step:1215/1500 train_loss:3.5138 train_time:498928ms step_avg:414.05ms
step:1216/1500 train_loss:3.5912 train_time:499338ms step_avg:414.04ms
step:1217/1500 train_loss:3.5364 train_time:499749ms step_avg:414.04ms
step:1218/1500 train_loss:3.5335 train_time:500158ms step_avg:414.04ms
step:1219/1500 train_loss:3.6239 train_time:500569ms step_avg:414.04ms
step:1220/1500 train_loss:3.4504 train_time:500979ms step_avg:414.03ms
step:1221/1500 train_loss:3.6938 train_time:501390ms step_avg:414.03ms
step:1222/1500 train_loss:3.7218 train_time:501801ms step_avg:414.03ms
step:1223/1500 train_loss:3.6333 train_time:502211ms step_avg:414.02ms
step:1224/1500 train_loss:3.4944 train_time:502622ms step_avg:414.02ms
step:1225/1500 train_loss:3.4924 train_time:503033ms step_avg:414.02ms
step:1226/1500 train_loss:3.5692 train_time:503444ms step_avg:414.02ms
step:1227/1500 train_loss:3.5510 train_time:503853ms step_avg:414.01ms
step:1228/1500 train_loss:3.4892 train_time:504263ms step_avg:414.01ms
step:1229/1500 train_loss:3.6631 train_time:504674ms step_avg:414.01ms
step:1230/1500 train_loss:3.5784 train_time:505084ms step_avg:414.00ms
step:1231/1500 train_loss:3.6358 train_time:505495ms step_avg:414.00ms
step:1232/1500 train_loss:3.7963 train_time:505907ms step_avg:414.00ms
step:1233/1500 train_loss:3.6932 train_time:506316ms step_avg:414.00ms
step:1234/1500 train_loss:3.6268 train_time:506727ms step_avg:413.99ms
step:1235/1500 train_loss:3.7829 train_time:507138ms step_avg:413.99ms
step:1236/1500 train_loss:3.5442 train_time:507548ms step_avg:413.99ms
step:1237/1500 train_loss:3.5035 train_time:507959ms step_avg:413.98ms
step:1238/1500 train_loss:3.4650 train_time:508369ms step_avg:413.98ms
step:1239/1500 train_loss:3.5354 train_time:508779ms step_avg:413.98ms
step:1240/1500 train_loss:3.5468 train_time:509189ms step_avg:413.97ms
step:1241/1500 train_loss:3.5862 train_time:509600ms step_avg:413.97ms
step:1242/1500 train_loss:3.6327 train_time:510011ms step_avg:413.97ms
step:1243/1500 train_loss:3.5074 train_time:510421ms step_avg:413.97ms
step:1244/1500 train_loss:3.6000 train_time:510832ms step_avg:413.96ms
step:1245/1500 train_loss:3.6149 train_time:511243ms step_avg:413.96ms
step:1246/1500 train_loss:3.6193 train_time:511653ms step_avg:413.96ms
step:1247/1500 train_loss:3.4499 train_time:512063ms step_avg:413.96ms
step:1248/1500 train_loss:3.5980 train_time:512474ms step_avg:413.95ms
step:1249/1500 train_loss:3.6458 train_time:512885ms step_avg:413.95ms
step:1250/1500 train_loss:3.6299 train_time:513295ms step_avg:413.95ms
step:1250/1500 val_loss:3.5704 train_time:513308ms step_avg:413.96ms
step:1251/1500 train_loss:3.5225 train_time:513701ms step_avg:413.94ms
step:1252/1500 train_loss:3.7221 train_time:514111ms step_avg:413.94ms
step:1253/1500 train_loss:3.5893 train_time:514524ms step_avg:413.94ms
step:1254/1500 train_loss:3.5163 train_time:514934ms step_avg:413.93ms
step:1255/1500 train_loss:3.6554 train_time:515343ms step_avg:413.93ms
step:1256/1500 train_loss:3.7158 train_time:515754ms step_avg:413.93ms
step:1257/1500 train_loss:3.5303 train_time:516165ms step_avg:413.93ms
step:1258/1500 train_loss:3.5570 train_time:516575ms step_avg:413.92ms
step:1259/1500 train_loss:3.6073 train_time:516987ms step_avg:413.92ms
step:1260/1500 train_loss:3.5466 train_time:517397ms step_avg:413.92ms
step:1261/1500 train_loss:3.4152 train_time:517807ms step_avg:413.91ms
step:1262/1500 train_loss:3.5131 train_time:518217ms step_avg:413.91ms
step:1263/1500 train_loss:3.5987 train_time:518628ms step_avg:413.91ms
step:1264/1500 train_loss:3.4331 train_time:519038ms step_avg:413.91ms
step:1265/1500 train_loss:3.6502 train_time:519449ms step_avg:413.90ms
step:1266/1500 train_loss:3.6316 train_time:519860ms step_avg:413.90ms
step:1267/1500 train_loss:3.6386 train_time:520272ms step_avg:413.90ms
step:1268/1500 train_loss:3.5834 train_time:520682ms step_avg:413.90ms
step:1269/1500 train_loss:3.6194 train_time:521093ms step_avg:413.89ms
step:1270/1500 train_loss:3.4681 train_time:521504ms step_avg:413.89ms
step:1271/1500 train_loss:3.3265 train_time:521915ms step_avg:413.89ms
step:1272/1500 train_loss:3.5985 train_time:522327ms step_avg:413.89ms
step:1273/1500 train_loss:3.5618 train_time:522739ms step_avg:413.89ms
step:1274/1500 train_loss:3.6082 train_time:523149ms step_avg:413.88ms
step:1275/1500 train_loss:3.5681 train_time:523560ms step_avg:413.88ms
step:1276/1500 train_loss:3.6599 train_time:523969ms step_avg:413.88ms
step:1277/1500 train_loss:3.6806 train_time:524380ms step_avg:413.88ms
step:1278/1500 train_loss:3.6437 train_time:524791ms step_avg:413.87ms
step:1279/1500 train_loss:3.6345 train_time:525201ms step_avg:413.87ms
step:1280/1500 train_loss:3.4664 train_time:525612ms step_avg:413.87ms
step:1281/1500 train_loss:3.5759 train_time:526023ms step_avg:413.87ms
step:1282/1500 train_loss:3.6429 train_time:526433ms step_avg:413.86ms
step:1283/1500 train_loss:3.6751 train_time:526842ms step_avg:413.86ms
step:1284/1500 train_loss:3.5716 train_time:527255ms step_avg:413.86ms
step:1285/1500 train_loss:3.5918 train_time:527666ms step_avg:413.86ms
step:1286/1500 train_loss:3.5761 train_time:528074ms step_avg:413.85ms
step:1287/1500 train_loss:3.5492 train_time:528485ms step_avg:413.85ms
step:1288/1500 train_loss:3.6824 train_time:528896ms step_avg:413.85ms
step:1289/1500 train_loss:3.5217 train_time:529307ms step_avg:413.84ms
step:1290/1500 train_loss:3.6039 train_time:529717ms step_avg:413.84ms
step:1291/1500 train_loss:3.6744 train_time:530129ms step_avg:413.84ms
step:1292/1500 train_loss:3.5991 train_time:530539ms step_avg:413.84ms
step:1293/1500 train_loss:3.7050 train_time:530949ms step_avg:413.83ms
step:1294/1500 train_loss:3.7178 train_time:531361ms step_avg:413.83ms
step:1295/1500 train_loss:3.6819 train_time:531771ms step_avg:413.83ms
step:1296/1500 train_loss:3.4902 train_time:532181ms step_avg:413.83ms
step:1297/1500 train_loss:3.5813 train_time:532592ms step_avg:413.82ms
step:1298/1500 train_loss:3.4729 train_time:533003ms step_avg:413.82ms
step:1299/1500 train_loss:3.5417 train_time:533414ms step_avg:413.82ms
step:1300/1500 train_loss:3.6150 train_time:533825ms step_avg:413.82ms
step:1301/1500 train_loss:3.6281 train_time:534236ms step_avg:413.82ms
step:1302/1500 train_loss:3.6286 train_time:534647ms step_avg:413.81ms
step:1303/1500 train_loss:3.7785 train_time:535058ms step_avg:413.81ms
step:1304/1500 train_loss:3.5572 train_time:535468ms step_avg:413.81ms
step:1305/1500 train_loss:3.7598 train_time:535878ms step_avg:413.81ms
step:1306/1500 train_loss:3.4839 train_time:536287ms step_avg:413.80ms
step:1307/1500 train_loss:3.6775 train_time:536697ms step_avg:413.80ms
step:1308/1500 train_loss:3.6776 train_time:537108ms step_avg:413.80ms
step:1309/1500 train_loss:3.5358 train_time:537517ms step_avg:413.79ms
step:1310/1500 train_loss:3.5078 train_time:537928ms step_avg:413.79ms
step:1311/1500 train_loss:3.5082 train_time:538338ms step_avg:413.79ms
step:1312/1500 train_loss:3.5044 train_time:538749ms step_avg:413.79ms
step:1313/1500 train_loss:3.6154 train_time:539159ms step_avg:413.78ms
step:1314/1500 train_loss:3.5662 train_time:539570ms step_avg:413.78ms
step:1315/1500 train_loss:3.2884 train_time:539980ms step_avg:413.78ms
step:1316/1500 train_loss:3.5183 train_time:540392ms step_avg:413.78ms
step:1317/1500 train_loss:3.6026 train_time:540803ms step_avg:413.77ms
step:1318/1500 train_loss:3.6292 train_time:541213ms step_avg:413.77ms
step:1319/1500 train_loss:3.5081 train_time:541624ms step_avg:413.77ms
step:1320/1500 train_loss:3.6351 train_time:542036ms step_avg:413.77ms
step:1321/1500 train_loss:3.6926 train_time:542447ms step_avg:413.77ms
step:1322/1500 train_loss:3.5809 train_time:542858ms step_avg:413.76ms
step:1323/1500 train_loss:3.5276 train_time:544046ms step_avg:414.35ms
step:1324/1500 train_loss:3.5552 train_time:544458ms step_avg:414.35ms
step:1325/1500 train_loss:3.6512 train_time:544869ms step_avg:414.35ms
step:1326/1500 train_loss:3.7105 train_time:545280ms step_avg:414.35ms
step:1327/1500 train_loss:3.4524 train_time:545690ms step_avg:414.34ms
step:1328/1500 train_loss:3.3876 train_time:546099ms step_avg:414.34ms
step:1329/1500 train_loss:3.6973 train_time:546509ms step_avg:414.34ms
step:1330/1500 train_loss:3.5449 train_time:547099ms step_avg:414.47ms
step:1331/1500 train_loss:3.6649 train_time:547512ms step_avg:414.47ms
step:1332/1500 train_loss:3.5646 train_time:547923ms step_avg:414.47ms
step:1333/1500 train_loss:3.9654 train_time:548335ms step_avg:414.46ms
step:1334/1500 train_loss:3.6723 train_time:548745ms step_avg:414.46ms
step:1335/1500 train_loss:3.5817 train_time:549154ms step_avg:414.46ms
step:1336/1500 train_loss:3.5265 train_time:549566ms step_avg:414.45ms
step:1337/1500 train_loss:3.5215 train_time:549976ms step_avg:414.45ms
step:1338/1500 train_loss:3.7760 train_time:550386ms step_avg:414.45ms
step:1339/1500 train_loss:3.7163 train_time:550797ms step_avg:414.45ms
step:1340/1500 train_loss:3.5607 train_time:551208ms step_avg:414.44ms
step:1341/1500 train_loss:3.5164 train_time:551618ms step_avg:414.44ms
step:1342/1500 train_loss:3.8215 train_time:552027ms step_avg:414.43ms
step:1343/1500 train_loss:3.5962 train_time:552438ms step_avg:414.43ms
step:1344/1500 train_loss:3.5927 train_time:552848ms step_avg:414.43ms
step:1345/1500 train_loss:3.6416 train_time:553258ms step_avg:414.43ms
step:1346/1500 train_loss:3.6110 train_time:553667ms step_avg:414.42ms
step:1347/1500 train_loss:3.5168 train_time:554078ms step_avg:414.42ms
step:1348/1500 train_loss:3.4731 train_time:554488ms step_avg:414.42ms
step:1349/1500 train_loss:3.5645 train_time:554897ms step_avg:414.41ms
step:1350/1500 train_loss:3.4877 train_time:555308ms step_avg:414.41ms
step:1351/1500 train_loss:3.6183 train_time:555719ms step_avg:414.41ms
step:1352/1500 train_loss:3.4716 train_time:556129ms step_avg:414.40ms
step:1353/1500 train_loss:3.5363 train_time:556540ms step_avg:414.40ms
step:1354/1500 train_loss:3.6348 train_time:556951ms step_avg:414.40ms
step:1355/1500 train_loss:3.4849 train_time:557362ms step_avg:414.40ms
step:1356/1500 train_loss:3.4024 train_time:557775ms step_avg:414.39ms
step:1357/1500 train_loss:3.7469 train_time:558185ms step_avg:414.39ms
step:1358/1500 train_loss:3.6834 train_time:558595ms step_avg:414.39ms
step:1359/1500 train_loss:3.4043 train_time:559005ms step_avg:414.38ms
step:1360/1500 train_loss:3.6836 train_time:559416ms step_avg:414.38ms
step:1361/1500 train_loss:3.5631 train_time:559826ms step_avg:414.38ms
step:1362/1500 train_loss:3.4128 train_time:560235ms step_avg:414.37ms
step:1363/1500 train_loss:3.6037 train_time:560645ms step_avg:414.37ms
step:1364/1500 train_loss:3.5023 train_time:561056ms step_avg:414.37ms
step:1365/1500 train_loss:3.5207 train_time:561465ms step_avg:414.37ms
step:1366/1500 train_loss:3.5436 train_time:561876ms step_avg:414.36ms
step:1367/1500 train_loss:3.6421 train_time:562287ms step_avg:414.36ms
step:1368/1500 train_loss:3.6307 train_time:562698ms step_avg:414.36ms
step:1369/1500 train_loss:3.5756 train_time:563107ms step_avg:414.35ms
step:1370/1500 train_loss:3.4944 train_time:563520ms step_avg:414.35ms
step:1371/1500 train_loss:3.8193 train_time:563931ms step_avg:414.35ms
step:1372/1500 train_loss:3.5580 train_time:564341ms step_avg:414.35ms
step:1373/1500 train_loss:3.5943 train_time:564752ms step_avg:414.34ms
step:1374/1500 train_loss:3.5908 train_time:565162ms step_avg:414.34ms
step:1375/1500 train_loss:3.3876 train_time:565572ms step_avg:414.34ms
step:1375/1500 val_loss:3.5458 train_time:565585ms step_avg:414.35ms
step:1376/1500 train_loss:3.7774 train_time:565979ms step_avg:414.33ms
step:1377/1500 train_loss:3.5698 train_time:566390ms step_avg:414.33ms
step:1378/1500 train_loss:3.7088 train_time:566800ms step_avg:414.33ms
step:1379/1500 train_loss:3.7407 train_time:567211ms step_avg:414.33ms
step:1380/1500 train_loss:3.3720 train_time:567622ms step_avg:414.32ms
step:1381/1500 train_loss:3.5511 train_time:568032ms step_avg:414.32ms
step:1382/1500 train_loss:3.9675 train_time:568443ms step_avg:414.32ms
step:1383/1500 train_loss:3.4595 train_time:568855ms step_avg:414.32ms
step:1384/1500 train_loss:3.6259 train_time:569265ms step_avg:414.31ms
step:1385/1500 train_loss:3.6953 train_time:569677ms step_avg:414.31ms
step:1386/1500 train_loss:3.6130 train_time:570088ms step_avg:414.31ms
step:1387/1500 train_loss:3.5916 train_time:570498ms step_avg:414.30ms
step:1388/1500 train_loss:3.4316 train_time:570910ms step_avg:414.30ms
step:1389/1500 train_loss:3.5789 train_time:571320ms step_avg:414.30ms
step:1390/1500 train_loss:3.5480 train_time:571729ms step_avg:414.30ms
step:1391/1500 train_loss:3.8031 train_time:572138ms step_avg:414.29ms
step:1392/1500 train_loss:3.5216 train_time:572550ms step_avg:414.29ms
step:1393/1500 train_loss:3.5168 train_time:572962ms step_avg:414.29ms
step:1394/1500 train_loss:3.4800 train_time:573372ms step_avg:414.29ms
step:1395/1500 train_loss:3.7620 train_time:573784ms step_avg:414.28ms
step:1396/1500 train_loss:3.6552 train_time:574195ms step_avg:414.28ms
step:1397/1500 train_loss:3.6586 train_time:574605ms step_avg:414.28ms
step:1398/1500 train_loss:3.5281 train_time:575016ms step_avg:414.28ms
step:1399/1500 train_loss:3.5017 train_time:575428ms step_avg:414.28ms
step:1400/1500 train_loss:3.5628 train_time:575838ms step_avg:414.27ms
step:1401/1500 train_loss:3.5436 train_time:576249ms step_avg:414.27ms
step:1402/1500 train_loss:3.5686 train_time:576660ms step_avg:414.27ms
step:1403/1500 train_loss:3.5282 train_time:577071ms step_avg:414.26ms
step:1404/1500 train_loss:3.7576 train_time:577482ms step_avg:414.26ms
step:1405/1500 train_loss:3.5014 train_time:577892ms step_avg:414.26ms
step:1406/1500 train_loss:3.5482 train_time:578301ms step_avg:414.26ms
step:1407/1500 train_loss:3.5532 train_time:578712ms step_avg:414.25ms
step:1408/1500 train_loss:3.4107 train_time:579127ms step_avg:414.25ms
step:1409/1500 train_loss:3.5348 train_time:579538ms step_avg:414.25ms
step:1410/1500 train_loss:3.5163 train_time:579948ms step_avg:414.25ms
step:1411/1500 train_loss:3.5096 train_time:580359ms step_avg:414.25ms
step:1412/1500 train_loss:3.6034 train_time:580769ms step_avg:414.24ms
step:1413/1500 train_loss:3.5407 train_time:581179ms step_avg:414.24ms
step:1414/1500 train_loss:3.5876 train_time:581590ms step_avg:414.24ms
step:1415/1500 train_loss:3.5722 train_time:582002ms step_avg:414.24ms
step:1416/1500 train_loss:3.6520 train_time:582411ms step_avg:414.23ms
step:1417/1500 train_loss:3.4558 train_time:582823ms step_avg:414.23ms
step:1418/1500 train_loss:3.5250 train_time:583234ms step_avg:414.23ms
step:1419/1500 train_loss:3.6185 train_time:583643ms step_avg:414.23ms
step:1420/1500 train_loss:3.6450 train_time:584052ms step_avg:414.22ms
step:1421/1500 train_loss:3.6284 train_time:584463ms step_avg:414.22ms
step:1422/1500 train_loss:3.6031 train_time:584874ms step_avg:414.22ms
step:1423/1500 train_loss:3.5764 train_time:585284ms step_avg:414.21ms
step:1424/1500 train_loss:3.5690 train_time:585695ms step_avg:414.21ms
step:1425/1500 train_loss:3.5753 train_time:586106ms step_avg:414.21ms
step:1426/1500 train_loss:3.4453 train_time:586516ms step_avg:414.21ms
step:1427/1500 train_loss:3.5539 train_time:586927ms step_avg:414.20ms
step:1428/1500 train_loss:3.5042 train_time:587338ms step_avg:414.20ms
step:1429/1500 train_loss:3.6134 train_time:587747ms step_avg:414.20ms
step:1430/1500 train_loss:3.5797 train_time:588156ms step_avg:414.19ms
step:1431/1500 train_loss:3.5059 train_time:588567ms step_avg:414.19ms
step:1432/1500 train_loss:3.5487 train_time:588977ms step_avg:414.19ms
step:1433/1500 train_loss:3.5889 train_time:589390ms step_avg:414.19ms
step:1434/1500 train_loss:3.4078 train_time:589800ms step_avg:414.19ms
step:1435/1500 train_loss:3.5611 train_time:590211ms step_avg:414.18ms
step:1436/1500 train_loss:3.3795 train_time:590623ms step_avg:414.18ms
step:1437/1500 train_loss:3.4571 train_time:591034ms step_avg:414.18ms
step:1438/1500 train_loss:3.6467 train_time:591444ms step_avg:414.18ms
step:1439/1500 train_loss:3.6022 train_time:591855ms step_avg:414.17ms
step:1440/1500 train_loss:3.5541 train_time:592266ms step_avg:414.17ms
step:1441/1500 train_loss:3.4123 train_time:592675ms step_avg:414.17ms
step:1442/1500 train_loss:3.5922 train_time:593087ms step_avg:414.17ms
step:1443/1500 train_loss:3.6476 train_time:593497ms step_avg:414.16ms
step:1444/1500 train_loss:3.7202 train_time:593906ms step_avg:414.16ms
step:1445/1500 train_loss:3.6840 train_time:594316ms step_avg:414.16ms
step:1446/1500 train_loss:3.5698 train_time:594728ms step_avg:414.16ms
step:1447/1500 train_loss:3.4368 train_time:595137ms step_avg:414.15ms
step:1448/1500 train_loss:3.5163 train_time:595549ms step_avg:414.15ms
step:1449/1500 train_loss:3.5355 train_time:595960ms step_avg:414.15ms
step:1450/1500 train_loss:3.6519 train_time:596370ms step_avg:414.15ms
step:1451/1500 train_loss:3.6446 train_time:596779ms step_avg:414.14ms
step:1452/1500 train_loss:3.4606 train_time:597190ms step_avg:414.14ms
step:1453/1500 train_loss:3.5744 train_time:597601ms step_avg:414.14ms
step:1454/1500 train_loss:3.4879 train_time:598010ms step_avg:414.13ms
step:1455/1500 train_loss:3.5154 train_time:598421ms step_avg:414.13ms
step:1456/1500 train_loss:3.5696 train_time:598833ms step_avg:414.13ms
step:1457/1500 train_loss:3.5004 train_time:599242ms step_avg:414.13ms
step:1458/1500 train_loss:3.3960 train_time:599652ms step_avg:414.12ms
step:1459/1500 train_loss:3.6425 train_time:600064ms step_avg:414.12ms
step:1460/1500 train_loss:3.5090 train_time:600474ms step_avg:414.12ms
step:1461/1500 train_loss:3.5608 train_time:600885ms step_avg:414.12ms
step:1462/1500 train_loss:3.6888 train_time:601296ms step_avg:414.12ms
step:1463/1500 train_loss:3.5062 train_time:601705ms step_avg:414.11ms
step:1464/1500 train_loss:3.6957 train_time:602115ms step_avg:414.11ms
step:1465/1500 train_loss:3.5916 train_time:602526ms step_avg:414.11ms
step:1466/1500 train_loss:3.5903 train_time:602940ms step_avg:414.11ms
step:1467/1500 train_loss:3.5189 train_time:603350ms step_avg:414.10ms
step:1468/1500 train_loss:3.6677 train_time:603761ms step_avg:414.10ms
step:1469/1500 train_loss:3.5397 train_time:604172ms step_avg:414.10ms
step:1470/1500 train_loss:3.5141 train_time:604582ms step_avg:414.10ms
step:1471/1500 train_loss:3.5611 train_time:604991ms step_avg:414.09ms
step:1472/1500 train_loss:3.4899 train_time:605402ms step_avg:414.09ms
step:1473/1500 train_loss:3.5927 train_time:605813ms step_avg:414.09ms
step:1474/1500 train_loss:3.6678 train_time:606223ms step_avg:414.09ms
step:1475/1500 train_loss:3.5520 train_time:606633ms step_avg:414.08ms
step:1476/1500 train_loss:3.3775 train_time:607045ms step_avg:414.08ms
step:1477/1500 train_loss:3.4997 train_time:607456ms step_avg:414.08ms
step:1478/1500 train_loss:3.4700 train_time:607867ms step_avg:414.08ms
step:1479/1500 train_loss:3.5644 train_time:608277ms step_avg:414.08ms
step:1480/1500 train_loss:3.6410 train_time:608688ms step_avg:414.07ms
step:1481/1500 train_loss:3.5063 train_time:609099ms step_avg:414.07ms
step:1482/1500 train_loss:3.6845 train_time:609510ms step_avg:414.07ms
step:1483/1500 train_loss:3.6134 train_time:609920ms step_avg:414.07ms
step:1484/1500 train_loss:3.5171 train_time:610332ms step_avg:414.07ms
step:1485/1500 train_loss:3.5030 train_time:610742ms step_avg:414.06ms
step:1486/1500 train_loss:3.5048 train_time:611153ms step_avg:414.06ms
step:1487/1500 train_loss:3.4772 train_time:611563ms step_avg:414.06ms
step:1488/1500 train_loss:3.5681 train_time:611973ms step_avg:414.05ms
step:1489/1500 train_loss:3.4795 train_time:612384ms step_avg:414.05ms
step:1490/1500 train_loss:3.5677 train_time:612796ms step_avg:414.05ms
step:1491/1500 train_loss:3.4980 train_time:613207ms step_avg:414.05ms
step:1492/1500 train_loss:3.4238 train_time:613617ms step_avg:414.05ms
step:1493/1500 train_loss:3.4980 train_time:614027ms step_avg:414.04ms
step:1494/1500 train_loss:3.6802 train_time:614438ms step_avg:414.04ms
step:1495/1500 train_loss:3.5246 train_time:614848ms step_avg:414.04ms
step:1496/1500 train_loss:3.2875 train_time:615261ms step_avg:414.04ms
step:1497/1500 train_loss:3.5953 train_time:615673ms step_avg:414.04ms
step:1498/1500 train_loss:3.5568 train_time:616084ms step_avg:414.03ms
step:1499/1500 train_loss:3.5985 train_time:616494ms step_avg:414.03ms
step:1500/1500 train_loss:3.5564 train_time:616905ms step_avg:414.03ms
step:1500/1500 val_loss:3.5311 train_time:616917ms step_avg:414.04ms
